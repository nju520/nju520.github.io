<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    
    <title>hwbnju.com</title>
    
    <link>http://hwbnju.com</link>
    <description>nju520's Blog</description>
    <language>en-uk</language>
    <managingEditor> nju520</managingEditor>
    <atom:link href="rss" rel="self" type="application/rss+xml" />
    
<item>
  <title>Sidekiq 异步任务调度与执行</title>
  <link>//sidekiq</link>
  <author>nju520</author>
  <pubDate>2018-03-18T00:00:00+08:00</pubDate>
  <guid>//sidekiq</guid>
  <description><![CDATA[
  <p>sidekiq 是 Ruby 中一款非常优秀的后台任务处理软件, 其本身提供的API十分简洁, 源代码也易于阅读, 没有太多花哨的代码. Sidekiq 将 Redis 的各种数据结构用得都起到好处, 我们可以通过 Sidekiq 加深对 Redis 的印象以及学习如何恰当高效地结合 Redis 实现业务逻辑.本篇文章从 Sidekiq 的启动开始,详细解读 Sidekiq 的异步任务调度和执行.  除此之外, 我还会介绍中间件机制以及在此基础上实现的任务重试机制.</p>

<blockquote>
  <p>本篇文章涉及的 Sidekiq 版本是 5.0.5</p>
</blockquote>

<h2 id="初识-sidekiq">初识 Sidekiq</h2>

<p>在我们具体解读<code>Sidekiq</code>的源码之前, 我们先来熟悉一下<code>Sidekiq</code>异步任务的创建和执行, 保证我们对其结构有一个总体的认识.</p>

<p><code>Sidekiq</code>的使用非常简洁, 我们只需要在<code>app/workers</code>文件夹中添加一个<code>worker</code>,来处理异步请求:</p>

<pre><code class="language-ruby">class HardWorker
  include Sidekiq::Worker
    
  def perform(name, count)
  # do something you want
  end
end
</code></pre>

<p>我们可以在需要执行操作的地方提交异步任务了:</p>

<pre><code class="language-ruby">#. 常规提交
HardWorker.perform_async('hehe', 10)

# 延迟提交 10分钟
HardWorker.perform_in(10.minutes, 'sleep', 10)

# 指定将来的某个时刻提交
# 我们指定此任务明天的这个此刻执行
HardWorker.perform_at(Time.now + 1.day, 'run', 200)
</code></pre>

<p>当我们执行上述三个提交方法时, <code>Sidekiq Worker</code>会将一个异步任务以<code>JSON</code>的形式将相关的参数信息加入到 <code>Redis</code>中并等待消费者对任务的拉取和处理.</p>

<p><code>Sidekiq</code>的消费者由三个部分:</p>

<ul>
  <li>Sidekiq::Scheduled::Poller: 定时任务拉取器.
    <ul>
      <li>负责在一定时间范围内不定时检查定时任务(scheduled)以及重试任务(retry), 将计划时间已经超过当前时间的任务追加到各自对应的任务队列中</li>
      <li>Sidekiq::Manager: worker 管理器. 负责按照配置的<code>concurrency</code>参数创建匹配数量的<code>worker</code>, 同时负责<code>worker</code>的管理. 这里的<code>worker</code>实际上就是一个<code>Processor</code>的实例</li>
    </ul>
  </li>
  <li>Sidekiq::Processor:  负责执行指定的任务</li>
</ul>

<p>它们三者会相互协作共同完成对<code>Redis</code>中任务消费的全过程.</p>

<p><img src="" alt="Sidekiq Module" /></p>

<h2 id="异步任务入队">异步任务入队</h2>

<p>当我们对需要异步执行的任务执行<code>Worker.perform_async</code>的方法时, <code>Sidekiq</code>其实并不会真正取创建一个<code>HardWroker</code>等具体<code>Worker</code>对象, 它实际上会调用<code>Worker.client_push</code>方法将当前的<code>class</code>和<code>args</code>参数传进去, 也就是我们需要异步执行的类和<code>perform</code>方法所需要的参数, 以及<code>Sidekiq</code>添加的额外参数:</p>

<pre><code class="language-json">{
  class: "Platform::ActiveUserWorker", 
  args: ["2018-03-09"], 
  retry: true, 
  queue: "default", 
  jid: "f2c20ffd382925563ffbc6b0", 
  created_at: 1520524801.3932867, 
  enqueued_at: 1520524801.3934016
}
</code></pre>

<p>使用<code>pry</code>工具来查看一下源码:</p>

<pre><code class="language-ruby">[4] pry(main)&gt; $ Sidekiq::Worker::ClassMethods#perform_async

From: /sidekiq-5.0.5/lib/sidekiq/worker.rb @ line 86:
Owner: Sidekiq::Worker::ClassMethods
Visibility: public
Number of lines: 3

def perform_async(*args)
  client_push('class'.freeze =&gt; self, 'args'.freeze =&gt; args)
end

</code></pre>

<p>除了<code>perform_async</code>之外, `	Worker<code>还提供了两种用于在一段时间之后或者未来的某个时刻执行相应任务的方法 </code>Worker.perform_at<code>和</code>Worker.perform_in`:</p>

<pre><code class="language-ruby">From: /sidekiq-5.0.5/lib/sidekiq/worker.rb @ line 92:
Owner: Sidekiq::Worker::ClassMethods
Visibility: public
Number of lines: 12

def perform_in(interval, *args)
  int = interval.to_f
  now = Time.now.to_f
  ts = (int &lt; 1_000_000_000 ? now + int : int)
  # 比普通的 perform_async 多了一个 at 参数
  item = { 'class'.freeze =&gt; self, 'args'.freeze =&gt; args, 'at'.freeze =&gt; ts }
  item.delete('at'.freeze) if ts &lt;= now

  client_push(item)
end

#. 在底层实现中, perform_at 与 perform_in 是同一个方法的两种形式的调用
alias_method :perform_at, :perform_in
</code></pre>

<p>为了使用同一个接口支持两种不同的安排方式(时间点和多久之后), 方法内部对传入的<code>internal</code>进行了判定:</p>

<ul>
  <li><code>interval.to_f &lt; 1_000_000_000</code>: 此时方法就认为传入的参数是一段时间.
    <ul>
      <li><code>Time.at 1_000_000_000</code> == 2001-09-09 09:46:40 +0800</li>
    </ul>
  </li>
  <li>interval.to_f &gt;= 1_000_000_000: 此时方法断定传入的参数是未来的某个时间点, eg:  <code>Time.now + 1.day</code>
    <ul>
      <li>如果传入的时间点是过去的时间点, 那么才 <code>item</code>中会删除<code>at</code></li>
    </ul>
  </li>
</ul>

<p>虽然<code>Worker.perform_at</code>和<code>Worker.perform_in</code>是完全相同的方法, 但是我们在使用时还是尽量遵循方法的语义选择两者中更符合使用逻辑的方法.</p>

<p>以上三种创建异步任务的方式, 最终都执行了<code>Worker.client_push</code>方法. 该方法接受一个哈希参数, 参数大致形式如下:</p>

<pre><code class="language-ruby">{
  class: "Platform::ActiveUserWorker", 
  args: ["2018-03-09"], 
  at: '60.0'
 }
</code></pre>

<p>在方法的实现中, 首先获取上下文中的<code>Redis</code>线程池, 并将传入的<code>item</code>对象压入Redis`队列中</p>

<pre><code class="language-ruby">[3] pry(main)&gt; $ Sidekiq::Worker::ClassMethods#client_push

From: /sidekiq-5.0.5/lib/sidekiq/worker.rb @ line 136:
Owner: Sidekiq::Worker::ClassMethods
Visibility: public
Number of lines: 9

def client_push(item) # :nodoc:
  # Redis 连接池
  pool = Thread.current[:sidekiq_via_pool] || get_sidekiq_options['pool'.freeze] || Sidekiq.redis_pool
  # stringify
  item.keys.each do |key|
    item[key.to_s] = item.delete(key)
  end

  Sidekiq::Client.new(pool).push(item)
end
</code></pre>

<p><code>client_push</code>方法最后调用了<code>Sidekiq::Client.new</code> 实例化一个<code>Sidekiq::Client</code>, 并将<code>item</code>  压入到<code>Redis</code>队列.</p>

<pre><code class="language-ruby">[4] pry(main)&gt; $ Sidekiq::Client#push

From: /sidekiq-5.0.5/lib/sidekiq/client.rb @ line 69:
Owner: Sidekiq::Client
Visibility: public
Number of lines: 9

def push(item)
  normed = normalize_item(item)
  payload = process_single(item['class'.freeze], normed)

  if payload
    # 此时传入的 payload 只有一个
    raw_push([payload])
    payload['jid'.freeze]
  end
end

def normalize_item(item)
  # 省略错误处理
  # 如果传入的 item 没有携带某些参数时, 就采用系统默认的参数
  normalized_hash(item['class'])
    .each{ |key, value| item[key] = value if item[key].nil? }

  item['class'] = item['class'].to_s
  item['queue'] = item['queue'].to_s
  item['jid'] ||= SecureRandom.hex(12)
  item['created_at'] ||= Time.now.to_f
  item
end

# 获取默认参数
def normalized_hash(item_class)
  if item_class.is_a?(Class)
    # 省略错误处理(需要普通的 SomeWorker include Sidekiq::Worker)
    item_class.get_sidekiq_options
  else
    Sidekiq.default_worker_options
  end
end

# Sidekiq 提供了两个默认参数
DEFAULT_WORKER_OPTIONS = {
  'retry' =&gt; true,
  'queue' =&gt; 'default'
}


# 每个中间件对传入的哈希进行处理之后,返回 item
# 具体实现请见 ·又见中间件·
def process_single(worker_class, item)
  queue = item['queue']

  middleware.invoke(worker_class, item, queue, @redis_pool) do
    item
  end
end
</code></pre>

<p>从代码的注释我们可以知道,  <code>Sidekiq::Client#push</code>方法接受的哈希参数包括以下内容:</p>

<ul>
  <li>queue: 具名队列, 默认为 <code>default</code></li>
  <li>class: 被调用的<code>worker</code></li>
  <li>args: 传给<code>Worker.perform</code>的参数, 必须是 <code>JSON-serializable</code>, 而且必须是一个数组</li>
  <li>at: 计划执行的时间点, 必须是 <code>Numeric</code></li>
  <li>retry: 如果任务失败是否重试标志, 默认为 <code>true</code></li>
</ul>

<p>从<code>Worker.perform_async</code>到<code>Client#push</code>方法, 都对即将加入到<code>Redis</code>队列的哈希进行处理, 从添加<code>at</code>字段到字符串化、再到<code>Client#normalize_item</code>方法中添加默认参数<code>retry</code>、<code>queue</code>, <code>jid</code>、<code>created_at</code>. 经过 <code>process_single</code>的处理, 传入 <code>raw_push</code>的哈希值大致如下:</p>

<pre><code class="language-json">{
 jobstr: 
     {
      class: "Platform::ActiveUserWorker", 
      args: ["2018-03-09"], 
      retry: true, 
      queue: "default", 
      jid: "f2c20ffd382925563ffbc6b0", 
      created_at: 1520524801.3932867, 
      enqueued_at: 1520524801.3934016
     }
}
</code></pre>

<p>所有添加异步任务的方法最终都调用了私有方法<code>Client#raw_push</code> , 此方法继续调用<code>atomc_push</code>向<code>Redis</code>添加数据.</p>

<pre><code class="language-ruby">def raw_push(payloads)
  # # 
  @redis_pool.with do |conn|
    conn.multi do
      atomic_push(conn, payloads)
    end
  end
  true
end
</code></pre>

<p>添加数据时会分两种情况:</p>

<ul>
  <li>当异步任务再未来的某一个时间点进行安排时, 此任务就会加入到一个有序集合 <code>schedule</code>
    <ul>
      <li>有序集合的 <code>score</code>自然是异步任务执行的时刻
​</li>
    </ul>
  </li>
  <li>当任务为立即执行任务时:
    <ul>
      <li>设置当前异步任务入队的时间<code>enqueued_at</code></li>
      <li>Sidekiq将<code>payload</code>所属的<strong>队列</strong>加入到一个大队列 <code>queues</code>的集合中</li>
      <li>将负载 <code>payload</code>直接压入 <code>"#queue:#{q}"</code>队列中等待消费者的拉取.</li>
    </ul>
  </li>
</ul>

<pre><code class="language-ruby">From: sidekiq-5.0.5/lib/sidekiq/client.rb @ line 191:
Owner: Sidekiq::Client
Visibility: private
Number of lines: 17

def atomic_push(conn, payloads)
  # 根据传入的负载是否有 at key
  if payloads.first['at'.freeze]
    conn.zadd('schedule'.freeze, payloads.map do |hash|
      at = hash.delete('at'.freeze).to_s
      # 传入的 payload 需要转成 JSON 格式
      # [score, payload]
      [at, Sidekiq.dump_json(hash)]
    end)
  else
    q = payloads.first['queue'.freeze]
    now = Time.now.to_f
    to_push = payloads.map do |entry|
      entry['enqueued_at'.freeze] = now
      Sidekiq.dump_json(entry)
    end
    conn.sadd('queues'.freeze, q)
    conn.lpush("queue:#{q}", to_push)
  end
end
</code></pre>

<h3 id="redis的存储">Redis的存储</h3>

<p>无论是立即执行还是未来计划的异步任务都会进入<code>Redis</code>的队列中, 但是它们之间的存储还是有所区别.</p>

<ul>
  <li><code>Worker.perform_at/in</code>会将任务以<code>[at, payload]</code>的形式加入到<code>schedules</code>有序集合中</li>
  <li><code>Worker.perform_async</code>将负载直接加入到指定的队列 <code>"queue:#{q}"中, 并向整个</code>Sidekiq<code>的队伍集合</code>queues`中添加该队列</li>
</ul>

<p>所有的<code>payload</code>都包含一个异步任务需要执行的全部信息:</p>

<ul>
  <li>
    <p>执行的队列: queue</p>
  </li>
  <li>
    <p>异步队列的类 <code>class</code></p>
  </li>
  <li>参数 <code>args</code>: 将传入 <code>Worker.perform</code>方法
    <ul>
      <li><code>sidekiq_options</code>中的默认参数: <code>retry</code> 、 <code>queue</code></li>
    </ul>
  </li>
  <li>
    <p><code>jid</code>: 任务唯一标识符, 通过<code>SecureRandom.hex(12)</code>生成</p>
  </li>
  <li>
    <p>enqueued_at: 入队时间</p>
  </li>
  <li>
    <p><code>created_at</code>: 创建时间</p>

    <p>​</p>

    <p><img src="" alt="payload" /></p>

    <p>​</p>
  </li>
</ul>

<p>接下来我们就从<code>Sidekiq</code>启动画面着手, 还是我们的<code>Sidekiq</code>源码解读之旅吧!</p>

<h2 id="启动">启动</h2>

<p>每当我们启动一个<code>Sidekiq</code>服务时, 令人印象深刻地就是在命令行中出现了一个功夫少年:</p>

<pre><code>
         m,
         `$b
    .ss,  $$:         .,d$
    `$$P,d$P'    .,md$P"'
     ,$$$$$bmmd$$$P^'
   .d$$$$$$$$$$P'
   $$^' `"^$$$'       ____  _     _      _    _
   $:     ,$$:       / ___|(_) __| | ___| | _(_) __ _
   `b     :$$        \___ \| |/ _` |/ _ \ |/ / |/ _` |
          $$:         ___) | | (_| |  __/   &lt;| | (_| |
          $$         |____/|_|\__,_|\___|_|\_\_|\__, |
        .d$$                                       |_|


</code></pre>

<p>我们可以通过如下指令找到运行<code>sidekiq</code>的bin文件:</p>

<pre><code class="language-ruby">$ where sidekiq
/Users/bobo/.rvm/gems/ruby-2.4.2/bin/sidekiq
/usr/local/bin/sidekiq
</code></pre>

<p>我们就从 <code>bin/sidekiq.rb</code> 文件开始我们的源码之旅:</p>

<pre><code class="language-ruby">require_relative '../lib/sidekiq/cli'

begin
  cli = Sidekiq::CLI.instance # &lt;==== just skip
  cli.parse
  cli.run # &lt;======== here we go
rescue =&gt; e
  raise e if $DEBUG
  STDERR.puts e.message
  STDERR.puts e.backtrace.join("\n")
  exit 1
end
</code></pre>

<p>启动文件首先是创建一个<code>CLI</code>对象, 执行<code>CLI#parse</code>方法对参数进行解析, 其中包括队列的配置, worker数量的配置, 在此不展开. 紧接着调用<code>CLI#run</code>方法. 让我们继续往下分析, 打开一个<code>CLI#run</code>方法:</p>

<pre><code class="language-ruby">def run
  # 打印控制台 banner 信息, 打印日志及运行环境
  # 信号处理
    
  self_read, self_write = IO.pipe
  require 'sidekiq/launcher'
  @launcher = Sidekiq::Launcher.new(options)
  begin
    launcher.run # &lt;======= here we go
    while readable_io = IO.select([self_read])
      signal = readable_io.first[0].gets.strip
      handle_single(signal)
    end
  rescue Interrupt
    # 进程接收到的信号处理以及退出逻辑
    launcher.stop
  	exit(0)
  end
end
</code></pre>

<h3 id="从-launcher-到-manager">从 Launcher 到 Manager</h3>

<p><code>CLI#run</code>方法首先是实例化一个<code>Sidekiq::Launcher</code>对象, 紧随其后调用了<code>Launcher#run</code>方法, <code>Launcher#run</code>方法又做了哪些事情呢?</p>

<pre><code class="language-ruby"># lib/launcher.rb
def run
  @thread = safe_thread("heartbeat", &amp;method(:start_heartbeat))
  @poller.start
  @manager.start
end
</code></pre>

<p><code>Launcher#run</code>方法首先通过<code>safe_thread</code>创建了一个新线程, 线程主要负责执行<code>start_heartbeat</code>方法, 其实就是心跳代码, 负责定时检查<code>sidekiq</code>的健康状态, 暂且不表.</p>

<pre><code class="language-ruby"># lib/launcher.rb
def safe_thread(name, &amp;block)
  Thread.new do
    Thread.current['sidekiq_label'] = name
    watchdog(name, &amp;block)
  end
end

def watchdog(last_words)
  yield
rescue Exception =&gt; ex
  handle_exception(ex, { context: last_words })
  raise ex
end
</code></pre>

<p><code>Launcher#run</code>第二行和第三行代码分别启动了<code>@poller</code>以及<code>@manager</code>. 这两个实例是从创建的?</p>

<p>让我们回顾一下前面的<code>lib/cli.rb</code>中的<code>CLI#run</code>方法, 它会负责创建<code>Sidekiq::Launcher</code>的实例, 让我们来看一下<code>Sidekiq::Launcher#initialize</code>定义:</p>

<pre><code class="language-ruby"># lib/launcher.rb 
def initialize(options)
  @manager = Sidekiq::Manager.new(options)
  @poller = Sidekiq::Scheduled::Poller.new
  @done = false
  @options = options
end
</code></pre>

<p>我们可以看到, <code>@manager</code>是在创建<code>Sidekiq::Launcher</code>实例的过程中同步创建的<code>Sidekiq::Manager</code>实例.</p>

<p>同理, <code>@poller</code>是同步创建的<code>Sidekiq::Scheduled::Poller</code>实例.</p>

<p>我们首先来看一下<code>@poller.start</code>的逻辑:</p>

<pre><code class="language-ruby"># lib/scheduled.rb
def start
  @thread ||= safe_thread("scheduler") do
    initial_wait

    while !@done
      enqueue
      wait
    end
    Sidekiq.logger.info("Scheduler exiting...")
  end
end
</code></pre>

<p>我们可以看到 <code>Sidekiq::Scheduled::Poller#start</code>方法创建了一个新线程, 在线程中执行了两部分代码:</p>

<ul>
  <li>初始化等待值</li>
  <li>在一个循环中不断的<code>enqueue</code>以及<code>wait</code></li>
</ul>

<p>PS: <code>Sidekiq::Scheduled::Poller#start</code>方法在线程创建完毕之后就会立刻返回, 至于新启动的新线程中的逻辑, 请前往下面的章节<code>Sidekiq::Scheduled::Poller</code>作更深一步分析.</p>

<p>我们继续查看一下<code>@manager</code>的启动到底做了什么:</p>

<pre><code class="language-ruby"># lib/manager.rb
def start
  @workers.each do |x|
    x.start
  end
end
</code></pre>

<p>这里的 <code>@workers</code>是什么? 我们来看一下<code>Sidekiq::Manager#initialize</code>方法:</p>

<pre><code class="language-ruby"># lib/manager.rb
def initialize(options={})
   @options = options
   @count = options[:concurrency] || 25
   
   @done = false
   @workers = Set.new
   @count.times do
     # 创建 Processor 实例时传入的参数就是 Manager 实例
     @workers &lt;&lt; Processor.new(self)
   end
   # Mutex
   @plock = Mutex.new
 end
</code></pre>

<p>原来如此, 在创建了<code>Sidekiq::Manager</code>实例之后, 又同步创建了多个<code>Sidekiq::Processor</code>的实例, 实例的个数取决于<code>options[:concurrency] || 25</code>, 也就是配置的<code>concurrency</code>的值, 缺省值为<code>25</code>. 至此, 我们知晓 sidekiq中的<code>worker</code>数量就在此设置, <code>Sidekiq::Manager</code>按照配置的数量创建指定数量的 <code>worker</code>.</p>

<p>继续来看我们的<code>Sidekiq::Manager#start</code>方法. 简而言之, <code>Sidekiq::Manager</code>在 <code>start</code>的时候就只做了一件事: 调用其管理的所有的<code>worker</code>的<code>start</code>方法, 就是<code>Sidekiq::Processor#start</code>.</p>

<pre><code class="language-ruby"># lib/processor.rb
def start
  @thread ||= safe_thread("processor", &amp;method(:run))
end
</code></pre>

<p>又是熟悉的味道, 在这里又调用了<code>safe_thread</code>来创建一个新线程, 这就意味着每个<code>worker</code>都是基于自己的一个新线程的, 在这个新线程中执行的是私有方法 <code>Sidekiq::Processor#run</code>:</p>

<pre><code class="language-ruby"># lib/processor.rb
def run
  begin
    while !@done
      process_one
    end
    @mgr.processor_stopped(self)
  rescue Sidekiq::Shutdown
    @mgr.processor_stopped(self)
  rescue Exception =&gt; ex
    @mgr.processor_died(self, ex)
  end
end
</code></pre>

<p>在一个<code>while</code>循环中, 只调用了一个<code>Sidekiq::Processor#process_one</code>实例方法. 顾名思义, 这里是说每个<code>worker</code>(Processor 实例)在没被结束之前, 都重复处理一个新的任务.</p>

<p><code>Sidekiq::Processor#process_one</code>又做了什么工作? 怎么决定应该先处理那个任务? 这就会在后面章节<code>Sidekiq::Processor才是做工的!</code>深入挖掘.</p>

<h3 id="流程时序">流程时序</h3>

<p>我们来总结一下<code>Sidekiq</code>启动之后的处理流程</p>

<p><img src="" alt="Sidekiq start" /></p>

<ol>
  <li>首先创建<code>Sidekiq::CLI</code>实例, 并执行其<code>run</code>方法</li>
  <li><code>Sidekiq::CLI</code>的实例在执行<code>#run</code>过程中, 创建了<code>Sidekiq::Launcher</code>实例, 并调用其<code>#run</code>方法</li>
  <li><code>Sidekiq::Launcher</code>的实例在创建后, 同步创建了<code>Sidekiq::Scheduled::Poller</code>的实例以及<code>Sidekiq::Manager</code>的实例. 在其执行<code>Sidekiq::Launcher::start</code>过程中, 分别调用了这两个实例的<code>start</code>方法</li>
  <li><code>Sidekiq::Scheduled::Poller</code>的实例在执行<code>start</code>过程中, 创建了一个内部循环执行的线程, 不断执行<code>enqueue</code> -&gt; <code>wait</code></li>
  <li><code>Sidekiq::Manager</code>的实例在创建后, 同步创建若干个指定的<code>worker</code>, 也就是<code>Sidekiq::Processor</code>的实例, 并在执行<code>start</code>方法的过程中对每个<code>worker</code>执行<code>start</code></li>
  <li><code>Sidekiq::Processor</code>实例<code>worker</code>在执行<code>start</code>方法的过程中创建了一个新的线程, 在其中循环执行<code>process_one</code></li>
</ol>

<p>以上就是<code>Sidekiq</code>的主要启动过程, 后续分别针对:</p>

<ul>
  <li>Sidekiq::Scheduled::Poller</li>
  <li>Sidekiq::Manager</li>
</ul>

<p>深入研究.</p>

<h2 id="定时任务拉取器">定时任务拉取器</h2>

<p>我们从<code>Sidekiq::Scheduled::Poller#start</code>方法继续我们的源码之旅:</p>

<pre><code class="language-ruby"># lib/scheduled.rb
def start
  @thread ||= safe_thread("scheduler") do
    initial_wait

    while !@done
      enqueue
      wait
    end
    Sidekiq.logger.info("Scheduler exiting...")
  end
end
</code></pre>

<p>我们可以看到, <code>start</code>方法的核心就在<code>while</code>循环中, 在循环之前调用了<code>initial_wait</code>方法:</p>

<pre><code class="language-ruby">INITIAL_WAIT = 10

def initial_wait
  # Have all processes sleep between 5-15 seconds.  
  # 10 seconds to give time for the heartbeat to register 
  # (if the poll interval is going to be calculated by the number of workers)
  # 5 random seconds to ensure they don't all hit Redis at the same time.
  total = 0
  total += INITIAL_WAIT unless Sidekiq.options[:poll_interval_average]
  total += (5 * rand)

  @sleeper.pop(total)
  rescue Timeout::Error
end
</code></pre>

<p>结合注释我们可以看出, <code>initial_wait</code>为了避免所有进程在后续逻辑中同时触发<code>Redis IO</code>而做的设计.</p>

<p>这里是为了防止类似雪崩之类的系统故障出现. 让当前进程随机等待一定范围的时间, 从而就可以跟其他进程错开了.</p>

<p>即随其后, 我们来研究一下<code>while</code>循环体中的方法:</p>

<pre><code class="language-ruby">while !@done
  enqueue
  wait
end
</code></pre>

<p>继续查看<code>enqueue</code>的实现:</p>

<pre><code class="language-ruby">def enqueue
  begin
    @enq.enqueue_jobs
  rescue =&gt; ex
    # Most likely a problem with redis networking.
    # Punt and try again at the next interval
    logger.error ex.message
    handle_exception(ex)
  end
end

</code></pre>

<p><code>enqueue</code>只是调用了实例变量<code>@enq</code>的<code>enqueue_jobs</code>方法而已. <code>@enq</code>是在初始化<code>Sidekiq::Scheduled::Poller</code>实例对象中创建的:</p>

<pre><code class="language-ruby">def initialize
  @enq = (Sidekiq.options[:scheduled_enq] || Sidekiq::Scheduled::Enq).new
  @sleeper = ConnectionPool::TimedStack.new
  @done = false
  @thread = nil
end
</code></pre>

<p>缺省的情况下, <code>@enq</code>就是<code>Sidekiq::Scheduled::Enq</code>的实例, 让我们来看一下<code>@enq</code>的实例方法<code>enqueue_jobs</code>:</p>

<pre><code class="language-ruby"># lib/scheduled.rb
SETS = %w(retry schedule)

def enqueue_jobs(now=Time.now.to_f.to_s, sorted_sets=SETS)
  Sidekiq.redis do |conn|
    sorted_sets.each do |sorted_set|
      while job = conn.zrangebyscore(sorted_set, '-inf', now, :limit =&gt; [0, 1]).first do
        if conn.zrem(sorted_set, job)
          Sidekiq::Client.push(Sidekiq.load_json(job))
          Sidekiq::Logging.logger.debug { "enqueued #{sorted_set}: #{job}" }
        end
      end
    end
  end
end
</code></pre>

<p>我把原代码中的注释移除, 让我们来一步步研究<code>enqueue_jobs</code>是如何将定时任务和重试任务推入指定的队列中去的.</p>

<p>首先传入<code>enqueue_jobs</code>的<code>now</code>默认为当前时间,<code>sorted_sets</code>默认为<code>["retry", "schedule"]</code>.</p>

<ul>
  <li>
    <p>retry: 重试任务队列</p>
  </li>
  <li>
    <p>schedule: 定时任务队列</p>

    <p>在<code>Sidekiq</code>中, 重试任务和定时任务实质上都是<code>scheduled jobs</code>. 这两个队列使用了<code>Redis</code>中有序集合类型, 进入队列的任务以其执行时间作为数据的<code>score</code>, 写入<code>Redis</code>之后按照其<code>score</code>排序, 也就是按照任务的计划执行时间排序.</p>
  </li>
</ul>

<p><code>Sidekiq</code>分别针对<code>retry</code>队列和<code>	schedule</code>队列做了一个循环, 循环体内每次通过<code>Redis</code>的<code>ZRANGEBYSCORE</code>命令取出一个计划时间小于等于当前时间的任务:</p>
<pre><code class="language-ruby">job = conn.zrangebyscore(sorted_set, '-inf'.freeze, now, :limit =&gt; [0, 1]).first
</code></pre>

<p>拿到一个<code>job</code>之后, 将其从原队列中移除, 并调用<code>Sidekiq::Client.push</code>  方法将此任务加到指定队列中.</p>

<p>此时<code>job</code>可以看作是马上执行的任务, 可以直接被推入指定的队列</p>

<p><code>job</code>中的内容就是我们之前分析过的哈希 <code>payload</code>:</p>

<pre><code class="language-json">{
  class: "Platform::ActiveUserWorker", 
  args: ["2018-03-09"], 
  retry: true, 
  queue: "default", 
  jid: "f2c20ffd382925563ffbc6b0", 
  created_at: 1520524801.3932867, 
  enqueued_at: 1520524801.3934016
}
</code></pre>

<p>至此, 我们就知晓了<code>enqueue_jobs</code>就是分别从<code>retry有序集合和</code>schedule`有序集合中取出已经到达计划时间的任务, 并将其一一加入到原来的队列.</p>

<p>PS: <strong>定时任务以及重试任务的计划时间只是计划加进执行中队列的时间, 并非执行时间, 执行的时间取决于队列的长度以及队列的执行速度了</strong>.</p>

<p>接着我们的<code>enqueue_jobs</code>, 后面调用<code>wait</code>方法:</p>

<pre><code class="language-ruby"># lib/scheduled.rb
def wait
  @sleeper.pop(random_poll_interval)
rescue Timeout::Error
  # expected
rescue =&gt; ex
  # if poll_interval_average hasn't been calculated yet, we can
  # raise an error trying to reach Redis.
  logger.error ex.message
  handle_exception(ex)
  sleep 5
end
</code></pre>

<p><code>wait</code>方法只是做了一个休眠, 休眠的实现依赖<code>@sleeper</code>的<code>pop</code>方法的实现.</p>

<p><code>@sleeper</code>是在<code>Sidekiq::Scheduled::Poller#initialize</code>的实现的, 它是<code>ConnectionPool::TimeStack</code>的实例, 其<code>pop</code>方法会阻塞当前代码的执行, 直到有值返回或者到达指定的超时时间, 这里<code>Sidekiq</code>就利用了其阻塞的特性, 作为<code>wait</code>方法休眠器的实现.</p>

<p>休眠时间<code>random_poll_interval</code>不固定. 一般来说, 如果没有自行配置, 每次拉取的时间间隔大约在7.5秒–22.5秒</p>

<h3 id="小结">小结</h3>

<p>从本小节的源码分析来看, 我们可以知晓<code>Sidekiq</code>对定时任务和重试任务都一视同仁,处理流程如下:</p>

<ol>
  <li>所有定时任务(包括重试任务)以其计划时间为<code>score</code>,加入到<code>retry</code>和<code>schedule</code>有序集合中</li>
  <li>sidekiq的定时任务拉取器从<code>retry</code>以及<code>schedule</code>有序集合中取出已到达计划时间的任务, 并将其加入该任务计划的队列中, 后续的执行则和普通队列中的任务一致.</li>
  <li>拉取器会每隔随机事件进行休眠, 然后继续从步骤2开始, 周而复始</li>
</ol>

<p>=&gt; 定时任务<code>perform_in</code>以及<code>perform_at</code>计划时间都不是确切的时间!只是允许计划任务加入到普通队列的时间, 具体执行时间还得由队列的长度以及队列的处理速度决定.</p>

<h2 id="sidekiqprocessor-才是做工的">Sidekiq::Processor 才是做工的!</h2>

<p>本小节我们来深入研究一下<code>Sidekiq</code>中做苦力的那个<code>worker</code>.</p>

<p><code>worker</code>核心实现在于<code>process_one</code></p>

<pre><code class="language-ruby"># lib/processor.rb
def process_one
  @job = fetch  #&lt;===== here we go
  process(@job) if @job # &lt;=== next step
  @job = nil
end
</code></pre>

<p>通过调用<code>fetch</code>方法抓取一个任务, 当任务成功获取后, 就将其最为参数传入<code>process</code>方法中去, 由<code>process</code>实际执行任务; 如果没有获取到任务, 则直接重新尝试获取新的任务</p>

<pre><code># lib/processor.rb
def fetch
  j = get_one
  if j &amp;&amp; @done
    j.requeue
    nil
  else
    j
  end
end
</code></pre>

<p><code>fetch</code>方法中的<code>j</code>仿佛又回到了大学期间写<code>C</code>语言的那段时光.</p>

<p><code>fetch</code>方法通过<code>get_one</code>方法从队列中获取任务.</p>

<p>当获取任务之后, 判断当前<code>worker</code>是否已经停止(@done == true), 如果是就将任务重新压入队列中;否则就返回抓取到的一个任务.</p>

<pre><code class="language-ruby"># lib/processor.rb
def get_one
  begin
    work = @strategy.retrieve_work
    # 省略 logger
    work
  rescue Sidekiq::Shutdown
  rescue =&gt; ex
    handle_fetch_exception(ex)
  end
end
</code></pre>

<p>核心代码就是<code>work = @strategy.retrive_work</code>.</p>

<p><code>@strategy</code>必然来自<code>Sidekiq::Processor#initialize</code> 方法:</p>

<pre><code class="language-ruby"># lib/processor.rb
def initialize(mgr)
  # ...
  @strategy = (mgr.options[:fetch] || Sidekiq::BasicFetch).new(mgr.options)
end
</code></pre>

<p>默认情况下使用<code>Sidekiq::BasicFetch</code>类生成一个<code>@strategy</code>实例.</p>

<p>让我们查看一下这个策略类的<code>retrive_work</code>方法:</p>

<pre><code class="language-ruby"># lib/fetch.rb
def retrieve_work
  # 返回值有两个(key, value) queue_name, job =&gt; work
  work = Sidekiq.redis { |conn| conn.brpop(*queues_cmd) } # &lt;===== here we go
  UnitOfWork.new(*work) if work
end
</code></pre>

<p><code>Sidekiq::BasicFetch</code>抓取任务的逻辑是直接通过 <code>Redis BRPOP</code> 命令从所有队列中阻塞地取出第一个任务:</p>

<blockquote>
  <p>BRPOP is a blocking list pop primitive. It is the blocking version of RPOP because it blocks the connection when there are no elements to pop from any of the given lists. An element is popped from the tail of the first list that is non-empty, with the given keys being checked in the order that they are given.</p>

  <p><code>BRPOP key1 [key2 key3 ....] timeout</code></p>
</blockquote>

<p>我们来查看一下<code>queues_cmd</code>此方法究竟做了什么?</p>

<pre><code class="language-ruby"># Creating the Redis#brpop command takes into account any
# configured queue weights. By default Redis#brpop returns
# data from the first queue that has pending elements. We
# recreate the queue command each time we invoke Redis#brpop
# to honor weights and avoid queue starvation.
def queues_cmd
  if @strictly_ordered_queues
    @queues
  else
    queues = @queues.shuffle.uniq # here we go
    queues &lt;&lt; TIMEOUT
    queues
  end
end
</code></pre>

<p>上述代码中的两个实例变量设置于<code>Sidekiq::BasicFetch#initialize</code>:</p>

<pre><code class="language-ruby">def initialize(options)
  @strictly_ordered_queues = !!options[:strict]
  # 读取 `sidekiq` 配置文件中的 `:queues`选项
  @queues = options[:queues].map { |q| "queue:#{q}" }
  if @strictly_ordered_queues
    @queues = @queues.uniq
    @queues &lt;&lt; TIMEOUT
  end
end
</code></pre>

<p>默认情况下我们没有设置<code>options[:strict]</code>, 因此 <code>queue_cmd</code>进入<code>else</code>分支.</p>

<pre><code class="language-ruby">queues = @queues.shuffle.uniq
</code></pre>

<p>这里的<code>@queues</code>来自于<code>options[:queues]</code>中的配置.</p>

<p>让我们来分析一下这个配置到底来自哪里:</p>

<p><img src="" alt="options" /></p>

<p>最终我们在<code>Sidekiq::CLI</code>中调用<code>parse</code>设置<code>options</code>参数的.</p>

<pre><code class="language-ruby">def parse_queue(opts, q, weight=nil)
  [weight.to_i, 1].max.times do
   (opts[:queues] ||= []) &lt;&lt; q
  end
  opts[:strict] = false if weight.to_i &gt; 0
end
</code></pre>

<p><code>Sidekiq</code>在解析<code>:queues</code>的相关配置时, 会按照每个队列及其权重, 生成了一个重复次数等于队列权重的队列的新数组. 看一下我们项目的配置文件<code>sidekiq.yml</code>:</p>

<pre><code class="language-yaml">:queues:
  - [default, 2]
  - [review, 5]
  - [finance, 3]

</code></pre>

<p>根据队列的权重, 生成的数组中就会有同等数量的队列:</p>

<pre><code class="language-ruby">%w(default default review review review review review finance finance finance)
</code></pre>

<p>这里的权重主要用于后面确定每个不同队列被处理到的优先权的比重.</p>

<p>让我们继续讨论:</p>

<pre><code class="language-ruby">queues = @queues.shuffle.uniq
queues &lt;&lt; TIMEOUT
</code></pre>

<p>每次<code>worker</code>在请求信的任务时, <code>Sidekiq</code>都会按照原来的<code>@queues</code>执行<code>shuffle</code>方法. <code>shuffle</code>方法将数组元素随机排序, 亦即“洗牌”. 结合前面的权重, 每个队列洗牌后排在第一位的概率与其权重挂钩.</p>

<p>最后的<code>uniq</code>方法确保队列名称没有重复,避免<code>Redis</code>在执行<code>BRPOP</code>命令时重复检查同一队列.</p>

<p>这里使用<code>BRPOP</code>命令还有一个好处,就是当前面优先级的队列里面没有任务时, 可以依次将机会给后面的队列.</p>

<p>第二行<code>queues &lt;&lt; TIMEOUT</code>则是在<code>BRPOP</code>命令末尾追加超时设置, 也就是<code>Redis</code>命令最多阻塞2秒, 超时则直接放弃.</p>

<p>了解了如何获取任务之后, 任务通过<code>Sidekiq::BasicFetch::UnitOfwork</code>结构化实例后返回给调用方:</p>

<pre><code class="language-ruby">UnitOfWork = Struct.new(:queue, :job) do
  def acknowledge
    # nothing to do
  end

  def queue_name
    queue.sub(/.*queue:/, '')
  end

  def requeue
    Sidekiq.redis do |conn|
      conn.rpush("queue:#{queue_name}", job)
    end
  end
end
</code></pre>

<p>让我们重新回到<code>Sidekiq::Processor#process_one</code></p>

<pre><code class="language-ruby"># lib/processor.rb
def process_one
  @job = fetch
  process(@job) if @job  # here we go
  @job = nil
end
</code></pre>

<p><code>fetch</code>方法返回一个结构体化的实例对象, 然后交给<code>process</code>全权处理:</p>

<pre><code class="language-ruby"># lib/processor.rb
# 移除了一些异常处理代码
def process(work)
  jobstr = work.job
  queue = work.queue_name

  ack = false
  begin
    job_hash = Sidekiq.load_json(jobstr)
    ack = true
    # dispatch 返回经过中间件处理过的一个 SomeWorker实例
    dispatch(job_hash, queue) do |worker|
      # 此处的解释见 `又见中间件`
      Sidekiq.server_middleware.invoke(worker, job_hash, queue) do
        execute_job(worker, cloned(job_hash['args']))
      end
    end
  ensure
    work.acknowledge if ack
  end
end


</code></pre>

<p>我们传入的参数<code>work</code>中就包含之前被压入队列的任务信息,包括队列名称, 任务对应的类, 任务调用所需要的参数,等等.</p>

<pre><code class="language-json">{
  class: "Platform::ActiveUserWorker", 
  args: ["2018-03-09"], 
  retry: true, 
  queue: "default", 
  jid: "f2c20ffd382925563ffbc6b0", 
  created_at: 1520524801.3932867, 
  enqueued_at: 1520524801.3934016
}
</code></pre>
<p>根据这些信息我们重新实例化任务对象, 并且将实例化的任务对象<code>worker</code>以及任务参数都传递给<code>execute_job</code>调用.</p>

<p>让我们一睹<code>execute_job</code>的实现:</p>

<pre><code class="language-ruby">def execute_job(worker, cloned_args)
  worker.perform(*cloned_args)
end
</code></pre>

<p>原来如此嘛, 我们使用<code>	Sidekiq</code>创建的某个<code>Worker</code>, 最终在此处调用.</p>

<p>至此, 任务的调度过程就到此为止, 剩下的就是周而复始的重复了.</p>

<h3 id="小结-1">小结</h3>

<p>经过上面的分析, 我们可以明白<code>Sidekiq</code>中<code>worker</code>的工作原理:</p>

<ol>
  <li>按照配置文件中设置的队列名称及其权重, 每次重新排列等待处理队列顺序, 高权重的队列有更高的优先级</li>
  <li>将重新排列的队列按顺序传递给<code>Redis BRPOP</code>命令, 同时设置2秒超时</li>
  <li><code>Sidekiq</code>将从队列中获取到实例化的任务, 并且根据携带的参数调用了具体任务的<code>perform</code>方法</li>
</ol>

<h2 id="又遇中间件">又遇中间件</h2>

<p>我们前面在探究<code>Sidekiq::Processor#process</code>方法时有个关键的<code>中间件</code>代码片段:</p>

<pre><code class="language-ruby">Sidekiq.server_middleware.invoke(worker, job_hash, queue) do
  execute_job(worker, cloned(job_hash['args']))
end
</code></pre>

<p>让我们来看一下<code>server_middleware</code>方法:</p>

<pre><code class="language-ruby">def self.server_middleware
  @server_chain ||= default_server_middleware
  yield @server_chain if block_given?
  @server_chain
end
</code></pre>

<p>默认情况下 <code>@server_chain</code>为<code>default_server_middleware</code>:</p>

<pre><code class="language-ruby">def self.default_server_middleware
  Middleware::Chain.new
end
</code></pre>

<p>这里并没有发现内置的中间件, 这是因为<code>sidekiq 5.0.0</code>版本以上的移除了原来存在的<code>RetryJobs</code>以及<code>Logging</code>:</p>

<blockquote>
  <ul>
    <li><strong>BREAKING CHANGE</strong> Job dispatch was refactored for safer integration with
Rails 5.  The <strong>Logging</strong> and <strong>RetryJobs</strong> server middleware were removed and
functionality integrated directly into Sidekiq::Processor.  These aren’t
commonly used public APIs so this shouldn’t impact most users.
      <pre><code>Sidekiq::Middleware::Server::RetryJobs -&gt; Sidekiq::JobRetry
Sidekiq::Middleware::Server::Logging -&gt; Sidekiq::JobLogger
</code></pre>
    </li>
  </ul>
</blockquote>

<p>从<code>Sidekiq</code>更新日志可以看出, 原来的两个内置中间件现在已经直接移到了`Sidekiq::Processor类中.</p>

<p>让我们来看一下<code>Sidekiq::Processor#dispatch</code>方法的实现:</p>

<pre><code class="language-ruby">def dispatch(job_hash, queue)
  # since middleware can mutate the job hash
  # we clone here so we report the original
  # job structure to the Web UI
  pristine = cloned(job_hash)

  Sidekiq::Logging.with_job_hash_context(job_hash) do
    @retrier.global(pristine, queue) do
      @logging.call(job_hash, queue) do
        stats(pristine, queue) do
          # Rails 5 requires a Reloader to wrap code execution.  In order to
          # constantize the worker and instantiate an instance, we have to call
          # the Reloader.  It handles code loading, db connection management, etc.
          # Effectively this block denotes a "unit of work" to Rails.
          @reloader.call do
            klass  = constantize(job_hash['class'])
            worker = klass.new
            worker.jid = job_hash['jid']
            @retrier.local(worker, pristine, queue) do
              yield worker
            end
          end
        end
      end
    end
  end
end
</code></pre>

<p>原来的Sidekiq::Processor::<code>Logger</code>中间件以及<code>Sidekiq::Processor::Retry</code>放在了这里处理, 我们直接看一下<code>local</code>方法:</p>

<pre><code class="language-ruby">def local(worker, msg, queue)
  yield
rescue Skip =&gt; ex
  raise ex
rescue Sidekiq::Shutdown =&gt; ey
  # ignore, will be pushed back onto queue during hard_shutdown
  raise ey
rescue Exception =&gt; e
  # ignore, will be pushed back onto queue during hard_shutdown
  raise Sidekiq::Shutdown if exception_caused_by_shutdown?(e)

  if msg['retry'] == nil
    msg['retry'] = worker.class.get_sidekiq_options['retry']
  end

  raise e unless msg['retry']
  attempt_retry(worker, msg, queue, e)
  # We've handled this error associated with this job, don't
  # need to handle it at the global level
  raise Skip
end
</code></pre>

<p>关注点还是在代码的最后<code>attempt_retry</code>. 此处表示当执行中的任务出现异常时, 除去停机的因素以及禁用了重试机制后, 尝试进行下次重试运行.</p>

<pre><code class="language-ruby"># lib/processor.rb
# 移除一些无关紧要的配置
def attempt_retry(worker, msg, queue, exception)
  max_retry_attempts = retry_attempts_from(msg['retry'], @max_retries)

  count = if msg['retry_count']
    msg['retried_at'] = Time.now.to_f
    msg['retry_count'] += 1
  else
    msg['failed_at'] = Time.now.to_f
    msg['retry_count'] = 0
  end

  if count &lt; max_retry_attempts
    delay = delay_for(worker, count, exception)
    logger.debug { "Failure! Retry #{count} in #{delay} seconds" }
    retry_at = Time.now.to_f + delay
    payload = Sidekiq.dump_json(msg)
    Sidekiq.redis do |conn|
      conn.zadd('retry', retry_at.to_s, payload)
    end
  else
    # Goodbye dear message, you (re)tried your best I'm sure.
    retries_exhausted(worker, msg, exception)
  end
end
</code></pre>

<p><code>Sidekiq</code>在捕获异常之后, 首先检查此任务是否已经重试过. 如果之前已经重试, 就在原来计数的基础上<code>+1</code>, 同时更新重试时间; 如果之前没有重试过, 就初始化重试次数为0, 设定初次失败的时间.</p>

<p>随后<code>Sidekiq</code>检查重试的累积次数是否已经超过了最大限制次数, 如果已经超过, 则放弃重试, 毕竟努力了这么多次还失败, 还是<code>go to dead</code>吧; 如果没有超过最大限制次数, 说明还有机会成功, 此任务就会被压入<code>retry</code>队列中.</p>

<p>关于下次重试的时间<code>delay_for</code>本篇文章就不再涉及, 有兴趣的同学可以深入研究一下.</p>

<h3 id="小结-2">小结</h3>

<ul>
  <li><code>Sidekiq</code>在执行任务时, 通过与<code>Rack</code>类似的中间件机制即使捕获失败的任务, 针对允许再次重试的任务, 按照一定的策略计算重试时间</li>
</ul>

<h2 id="总结">总结</h2>

<p>关于<code>Sidekiq</code>源码的解读暂时告一段落. 整个源码很少有弄不懂的地方, 代码的风格也很<code>Ruby</code>, 没有过多的奇异技巧.</p>

<p><code>Sidekiq</code>与<code>Redis</code>的队列和有序集合等数据结构的结合恰到好处, 我们可以通过<code>Sidekiq</code>来加深对<code>Redis</code>的认识, 还可以从中学习如何高效地结合<code>Redis</code>实现业务逻辑.</p>

<p>解读的过程中有一些和我们架构不甚相关的逻辑处理和异常处理都被忽略, 这也是阅读一份源码需要注意的地方,.我们要从大局出发, 将整个框架的组织结构和大的模块理清楚, 然后针对关键的方法深入挖掘.</p>

<h2 id="再会">再会</h2>

<p>本篇文章主要从<code>架构</code>入手, 着重分析了<code>Sidekiq</code>异步任务的调度和实现, 关于多线程以及<code>Unix</code>信号等相关的知识我打算再下一篇文章中详细解读, 敬请期待~</p>


  ]]></description>
</item>

<item>
  <title>TCP Socket 编程 -- 网络架构模式</title>
  <link>//tcp-scokets-arch</link>
  <author>nju520</author>
  <pubDate>2018-03-15T00:00:00+08:00</pubDate>
  <guid>//tcp-scokets-arch</guid>
  <description><![CDATA[
  <p>前面的两篇<code>TCP Socket</code>系列文章涵盖了<code>TCP Socket</code>的基础知识和必备技能, 接下来的部分我们将转向最佳实践和真实案例.</p>

<p>如果你的任务就用<code>Ruby</code>写一个简单的<code>FTP</code> 服务器, 那么仅了解前两篇文章是有所帮助的, 但是这些知识无法让你创造出伟大的软件.</p>

<p>尽管你了解建造模块, 但是你还不知道架构网络应用程序的常见方式, 如何处理并发? 如何处理错误? 处理缓慢的客户端的最好方式是什么? 如何最有效地利用资源?</p>

<p>这类问题正是本篇文章所阐述的. 接下来我们要学习六中网络架构模式, 然后把它们应用到一个案例项目中.</p>

<h2 id="ftp-服务器">FTP 服务器</h2>

<p>与其用一堆图标和抽象的描述, 我更喜欢的说明问题的方式就是采用一个能够实现的案例项目并采用不同的架构重复实现它. 这样才能深刻理解不同架构之间的差异.</p>

<p>出于这个原因, 我要编写一个包含了部分<code>FTP</code>功能的服务器.</p>

<ul>
  <li>
    <p>为什么只包含部分功能呢? 因为我希望将注意力放在<strong>架构模式</strong>,而非协议实现上.</p>
  </li>
  <li>
    <p>为什么选择<code>FTP</code>呢? 因为这样就不用再编写单独的客户端程序就可以测试了. 现成的<code>FTP</code>足够我们测试了.</p>
  </li>
</ul>

<blockquote>
  <p><code>FTP</code>协议就代表文件传输协议(File Transfer Protocol) , 通过运行在<code>TCP</code>之上, 用于两台计算机之间传送文件.</p>
</blockquote>

<p><code>FTP</code>有点像是在浏览文件系统. <code>FTP</code>同时使用两个<code>TCP</code>套接字.</p>

<ul>
  <li>控制套接字(control_socket): 用于在服务器和客户端之间发送<code>FTP</code>命令和参数</li>
  <li>读写数据套接字(connection socket): 每当要传送文件数据时, 就会使用一个新的套接字.</li>
</ul>

<p>分为两个套接字的好处, 使得在传送文件的同时仍然可以在<code>控制套接字</code>上继续处理命令.</p>

<p>我们先来实现这个<code>FTP</code>服务器. 它定义了一些常用的方法, 用于写入格式化的<code>FTP</code>响应以及建立控制套接字. 它还提供了一个<code>CommandHandler</code>类, 封装了基于每个连接的单独命令的处理. 这一点很重要, 同一个服务器上的每个连接可能有不同的工作目录, <code>CommandHandler</code>类也考虑到了这一点.</p>

<pre><code class="language-ruby">module FTP
  class CommandHandler
    # 必须是双引号的 \r\n
    CRLF = "\r\n"

    attr_reader :connection

    def initialize(connection)
      @connection = connection
    end

    def pwd
      @pwd || Dir.pwd
    end

    # 处理具体指令, 根据指令返回对应的数据结果

    def handle(data)
      command = data[0..3].strip.upcase
      options = data[4..-1].strip

      puts "#{show_time} command: #{command}  options: #{options}"

      case command
      when 'USER'
        # 可以接收匿名的用户
        "#{show_time} 230 Logged in anonymously"

      when 'SYST'
        # 用户名?
        "#{show_time} 215 UNIX Working With FTP"

      when 'CWD'
        if File.directory?(options)
          @pwd = options
          "#{show_time} 250 directory change to #{pwd}"
        else
          "#{show_time} 550 directory not found"
        end

      when 'PWD'
        "#{show_time} 257 \"#{pwd}\" is the current directory"

      when 'PORT'
        parts = options.split(',')
        ip_address = parts[0..3].join('.')
        port = Integer(parts[4]) * 256 + Integer(parts[5])

        # 启动一个新的 `socket`, 作为 client 来响应 `FTP`客户端的请求
        @data_socket = TCPSocket.new(ip_address, port)
        "#{show_time} 200 Active connection established (#{port})"

      when 'HeHe'
        parts = options.split(',')
        address_family = parts[0]
        ip_address = parts[2..5].join('.')
        port = Integer(parts[7]) * 256 + Integer(parts[8])

        # 启动一个新的 `socket`, 作为 client 来响应 `FTP`客户端的请求
        @data_socket = TCPSocket.new(ip_address, port)
        "#{show_time} 200 Long Port Active connection established (#{port})"

      when 'RETR'
        file = File.open(File.join(pwd, options), 'r')
        connection.respond "125 Data transfer starting #{file.size} bytes"

        bytes = IO.copy_stream(file, @data_socket)
        @data_socket.close

        "#{show_time} 226 Closing data connection, sent #{bytes} bytes"

      when 'LIST'
        connection.respond '125 Opening data connection for file list'

        result = Dir.entries(pwd).join(CRLF)
        @data_socket.write(result)
        @data_socket.close

        "#{show_time} 226 Closing data connection, sent #{result.size} bytes"

      when 'QUIT'
        "#{show_time} 221 Ciao"
      else
        "#{show_time} 502 Don't know how to respond to #{command}"
      end

    end

    private
    def show_time
      "[#{Time.now.strftime("%Y-%m-%d %H:%M")}]"
    end
  end
end

</code></pre>

<p>再接下来的几个小节我们分别实现不同架构的服务器.</p>

<h2 id="串行化">串行化</h2>

<p>我们要学习的第一个网络架构模式就是处理请求的<code>串行化模型</code>.</p>

<h3 id="流程">流程</h3>

<p>在串行化架构中, 所有的客户端连接都是依次进行处理的. 因为不涉及并发, 多个客户端不会同时接受服务.</p>

<p>串行化架构的处理流程很直观:</p>

<ol>
  <li>客户端连接</li>
  <li>客户端/服务器交换请求及响应</li>
  <li>客户端断开连接</li>
  <li>返回步骤1</li>
</ol>

<h3 id="实现">实现</h3>

<pre><code class="language-ruby"># serial.rb
#  串行化架构处理流程
# 1. 客户端连接
# 2. 客户端/服务器 交换请求并响应
# 3. 客户端断开连接
# 4. 返回步骤一重复下一此连接

require 'socket'
require_relative 'command_handler'

module FTP
  CRLF = '\r\n'

  class Serial

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def gets
      @client.gets(CRLF)
    end

    def respond(message)
      @client.write(message)
      @client.write(CRLF)
    end

    def run
      loop do
        @client = @control_socket.accept
        respond '220 OHAI'

        # 创建一个新的 `socket` 连接来单独处理请求
        handler = CommandHandler.new(self)

        loop do
          # 接收来自客户端的请求
          request = gets
          if request
            respond handler.handle(request)
          else
            @client.close
            break
          end
        end
      end
    end

  end
end

# 初始化我们的一个服务器实例
server = FTP::Serial.new(4481)

# 启动服务器
server.run

</code></pre>

<p><code>FTP::Serial</code>类只负责联网和并发操作, 协议处理部分交给<code>FTP::CommandHandler</code>类的方法来处理. 接下来你会经常看到这种模式.</p>

<p>让我们从头开始分析串行化架构模式.</p>

<pre><code class="language-ruby">class Serial

  def initialize(port = 21)
    @control_socket = TCPServer.new(port)
    trap(:INT) {exit}
  end

  def gets
    @client.gets(CRLF)
  end

  def respond(message)
    @client.write(message)
    @client.write(CRLF)
  end
end
</code></pre>

<p>这三个方法属于这类特定实现的样板代码<code>boilerplate</code>.</p>

<ul>
  <li>
    <p>initialize: 打开一个套接字, 由该套接字接受客户端连接</p>
  </li>
  <li>
    <p>gets: 将<code>gets</code>委托给当前客户端连接. 它传递了一个明确的分隔符, 用以保证在具有不同默认分隔符的平台之间的可移植性.</p>
  </li>
  <li>
    <p>respond: 用来写入格式化过的<code>FTP</code>响应. <code>message</code>中包含了整数类型的响应代码以及对应的字符串详细. 当<code>FTP客户端</code>收到<code>\r\n</code>组合时, 它就知道已经获得了完整的响应信息.</p>

    <p>​</p>
  </li>
</ul>

<pre><code class="language-ruby">def run
  loop do
    @client = @control_socket.accept
    respond '220 OHAI'

    handler = CommandHandler.new(self)
  end
end
</code></pre>

<p>这是服务器的主循环, 所有的处理逻辑都发生在外部主循环之内.</p>

<p>循环中唯一调用<code>accept</code>就在此. 它接受一个来自<code>@control_socket</code>的连接, 后者在<code>initialize</code>中进行初始化. 代码响应<code>220</code>是属于<code>FTP</code>规定的, 表示<code>Service ready for new user</code>, <code>FTP</code>服务要求服务器在接受一个新的客户端连接之后要打声招呼.</p>

<p>最后一处为该连接进行<code>CommandHandler</code>的初始化. 该类封装了服务器上的每个连接的当前状态( 当前工作目录). 我们可以将接入的请求交给<code>handler</code>对象, 然后获得对应的响应.</p>

<p>这部分代码是串行化代码只进行并发的绊脚石. 进行处理时, 服务器没发继续接受新的连接, 更谈不上实现并发了. 当我们学到其他模式如何应对这种情况时, 就会明显看出它们之间的差异了.</p>

<pre><code class="language-ruby">loop do
  request = gets

  if request
    respond handler.handle(request)
  else
    @client.close
    break
  end
end
</code></pre>

<p>这部分完成了我们的<code>FTP服务器</code>的串行化实现.</p>

<p>在内部循环中, 使用<code>gets</code>从客户端套接字中获取带有显式分隔符的请求, 然后将请求交给<code>handler</code>来处理,由它为客户端构造对应的响应信息.</p>

<h3 id="运行">运行</h3>

<p>鉴于这是一个功能完善的<code>FTP服务器</code>, 我们实际上可以运行该服务器, 使用标准的<code>FTP客户端</code>进行连接, 来看一下它的表现:</p>

<pre><code class="language-shell"># 开启 `FTP服务器`
$ ruby serial.rb


# 开启 标准的`FTP客户端`
$ ftp -a -v localhost 4481

# 输入指令
$ pwd 

$ cd /var/log


</code></pre>

<p>我们可以通过查看系统进程信息来看一下<code>串行化架构</code>的进程模式:</p>

<pre><code class="language-shell">λ lsof -i:4481
COMMAND   PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME
ruby    73426 bobo    9u  IPv6 0x60dd91188c3b4949      0t0  TCP *:4481 (LISTEN)
ruby    73426 bobo   10u  IPv6 0x60dd91188c3b6049      0t0  TCP localhost:4481-&gt;localhost:62166 (ESTABLISHED)
gftp    73435 bobo    3u  IPv4 0x60dd9118a7de4731      0t0  TCP localhost:62166-&gt;localhost:4481 (ESTABLISHED)
gftp    73435 bobo    4u  IPv4 0x60dd9118a7de4731      0t0  TCP localhost:62166-&gt;localhost:4481 (ESTABLISHED)
gftp    73491 bobo    3u  IPv4 0x60dd9118a7dee091      0t0  TCP localhost:62168-&gt;localhost:4481 (ESTABLISHED)
gftp    73491 bobo    4u  IPv4 0x60dd9118a7dee091      0t0  TCP localhost:62168-&gt;localhost:4481 (ESTABLISHED)

</code></pre>

<p>我们通过指令<code>lsof -i:4481</code>查看端口 <code>4481</code>上的进程:</p>

<ul>
  <li><code>73426</code>: 此进程为控制套接字进行, 负责接受客户端的请求并且返回指令和参数
    <ul>
      <li>第二行的<code>PID</code>	仍然是<code>73426</code>, 这说明串行架构并没有开辟新的进程来处理请求, 而是在同一个进程下.</li>
    </ul>
  </li>
  <li>73435: 我们运行的第一个<code>FTP客户端</code>, 负责向<code>FTP服务器</code>发送请求</li>
  <li>73491: 我们运行的第二个<code>FTP客户端</code>. 我还注意到只有第一个客户端退出时, 服务器才会响应第二个客户端的请求.</li>
</ul>

<blockquote>
  <p>Mac OS High Sierra 已经把<code>FTP</code> 命令行工具移除, 只能使用<code>sftp</code>访问, 我们可以使用如下方式安装:</p>

  <pre><code class="language-shell">$ brew install inetutils

$ brew link --overwrite inetutils

# 安装成功后将下面路径加入到 ~/.zshrc
export PATH="/usr/local/opt/inetutils/libexec/gnubin:$PATH"

MANPATH="/usr/local/opt/inetutils/libexec/gnuman:$MANPATH"

就可以直接使用 `ftp`命令并可以通过 `man`来查看帮助
</code></pre>
</blockquote>

<h3 id="思考">思考</h3>

<p>很难明确地归纳每种模式的优劣, 因为这完全取决于我们的需求. 我会尽力解释每种模式最适用的场景及其所做出的一些权衡.</p>

<p><strong>串行化架构</strong>最大的优势在于它的简单性. 没有锁, 没有共享状态, 处理完一个连接之后才能处理另外一个. 在资源使用方面亦是如此: 一个实例处理一个连接, 一个萝卜一个坑, 绝不多消耗资源.</p>

<p><strong>串行化架构</strong>最大的劣势就是不能并发操作. 及时时当前连接处于空闲, 也不能处理等待的连接. 同样, 如果某个连接使用的链路速度不佳, 或者在发送请求之间暂停, 那么服务器就只能保持阻塞, 直到连接关闭.</p>

<p>对接下来更有意思的模式而言,  <strong>串行化模式</strong>仅仅只是一个起点而已.</p>

<h2 id="单连接进程">单连接进程</h2>

<blockquote>
  <p>这是首个可以对请求进行并行处理的网络架构</p>
</blockquote>

<h3 id="流程-1">流程</h3>

<p>要支持并发处理, 只需要将串行化架构略加修改即可. 接受连接的代码不需要改动, 处理来自套接字数据的逻辑<code>CommandHandler</code>也保持不变.</p>

<p>相关改动出现在<strong>接受连接</strong>之后, 服务器会<code>fork</code>出一个子进程, 这个子进程的唯一目的就是在处理新连接. 连接处理完毕之后就退出.</p>

<blockquote>
  <p>进程衍生:</p>

  <p>只要我们使用命令 <code>ruby myapp.rb</code>启动程序, 就会生成一个新的<code>Ruby</code>进程来载入并执行代码.</p>

  <p>如果在程序中使用<code>fork</code>, 那实际上就是在运行期间创建了一个新进程. <code>fork</code>可以使我们获得两个一模一样的进程. 新创建的进程被视为“孩子”; 原先的进程被视为“双亲”. 一旦<code>fork</code>完成, 就拥有了两个进程,它们可以各行其道.</p>

  <p>这一点及其重要, 它意味着我们可以 <code>accept</code>一个连接, <code>fork</code>一个子进程, 这个子进程就会自动获得一份客户端连接的副本. 无需其他设置、数据共享或者锁, 直接就可以开始并行处理了.</p>
</blockquote>

<p>让我们来理清事件流程:</p>

<ol>
  <li>一个连接抵达服务器</li>
  <li>主服务器进程接受该连接</li>
  <li>主进程衍生出一个和服务器主进程一模一样的新子进程</li>
  <li>服务器主进程返回步骤1, 由子进程并行处理连接</li>
</ol>

<p>得益于内核语义, 这些进程是并行执行的. 子进程处理连接时, 原先的父进程可以继续接受新连接, 衍生出新的子进程对新连接进行处理.</p>

<p>不管何时, 总是有一个父进程等着接受连接, 但是会有多个子进程分别处理单个连接.</p>

<h3 id="实现-1">实现</h3>

<pre><code class="language-ruby">#  串行化架构处理流程
# 1. 一个连接抵达芙蕖
# 2. 主服务器进程接受该连接
# 3. 主进程衍生出和服务器一模一样的子进程
# 4. 服务器主进程返回步骤 1, 由子进程并行处理连接


require 'socket'
require_relative 'command_handler'

module FTP
  CRLF = '\r\n'

  class ProcessPerConnection

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def gets
      @client.gets(CRLF)
    end

    def respond(message)
      @client.write(message)
      @client.write(CRLF)
    end

    def run
      loop do
        @client = @control_socket.accept

        pid = fork do
          respond '220 OHAI'

          handler = CommandHandler.new(self)
          loop do
            request = gets

            if request
              respond handler.handle(request)
            else
              @client.close
              break
            end
          end
        end

        Process.detach(pid)

      end
    end

  end
end

# 初始化我们的一个服务器实例
server = FTP::ProcessPerConnection.new(4481)

# 启动服务器
server.run

</code></pre>

<p>如你所见, 大部分代码都没有变动. 最大的不同在于内循环被放在了一个<code>fork</code>调用中</p>

<pre><code class="language-ruby">@client = @control_socket.accept

pid = fork do
  respond '220 OHAI'

  handler = CommandHandler.new(self)
  #...
end
</code></pre>

<p>使用<code>accept</code>接受连接之后, 服务器进程立刻使用代码块来调用<code>fork</code>. 新的子进程会对该代码块进行求值, 然后退出.</p>

<p>这意味着每一个接入的连接都由一个独立的进程处理. 父进程不会对代码块求值, 它只会沿着自己的执行路径进行.</p>

<pre><code class="language-ruby">Process.detach(pid)
</code></pre>

<p>我们在最后调用了<code>Process.detach</code>. 在一个进程退出之后, 它并不会被完全清除, 直到其父进程查询该进程的退出状态. 在这里我们并不关心子进程的退出状态是什么, 所有提前把它与父进程分离. 确保子进程退出后, 所占用的资源能够完全清除.</p>

<p>让我运行 <code>lsof -wni tcp:4481</code>查看一下端口<code>4481</code>的情况吧:</p>

<pre><code class="language-shell">λ lsof -wni tcp:4481
COMMAND   PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME
ruby    84347 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84347 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
ruby    84347 bobo   11u  IPv6 0x60dd91188c3b6049      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63002 (ESTABLISHED)
ruby    84347 bobo   12u  IPv6 0x60dd91188c3b6609      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63017 (ESTABLISHED)
gftp    84355 bobo    3u  IPv4 0x60dd9118a6cb3351      0t0  TCP 127.0.0.1:62997-&gt;127.0.0.1:4481 (ESTABLISHED)
gftp    84355 bobo    4u  IPv4 0x60dd9118a6cb3351      0t0  TCP 127.0.0.1:62997-&gt;127.0.0.1:4481 (ESTABLISHED)
ruby    84356 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84356 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
gftp    84373 bobo    3u  IPv4 0x60dd91188bda2731      0t0  TCP 127.0.0.1:63002-&gt;127.0.0.1:4481 (ESTABLISHED)
gftp    84373 bobo    4u  IPv4 0x60dd91188bda2731      0t0  TCP 127.0.0.1:63002-&gt;127.0.0.1:4481 (ESTABLISHED)
ruby    84374 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84374 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
ruby    84374 bobo   11u  IPv6 0x60dd91188c3b6049      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63002 (ESTABLISHED)
gftp    84859 bobo    3u  IPv4 0x60dd91188fc9bcb1      0t0  TCP 127.0.0.1:63017-&gt;127.0.0.1:4481 (ESTABLISHED)
gftp    84859 bobo    4u  IPv4 0x60dd91188fc9bcb1      0t0  TCP 127.0.0.1:63017-&gt;127.0.0.1:4481 (ESTABLISHED)
ruby    84860 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84860 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
ruby    84860 bobo   11u  IPv6 0x60dd91188c3b6049      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63002 (ESTABLISHED)
ruby    84860 bobo   12u  IPv6 0x60dd91188c3b6609      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63017 (ESTABLISHED)

</code></pre>

<p>从端口情况可以看出, 我打开了三个客户端,   每打开一个客户端, 我们的<code>FTP服务器</code>就会开辟一个新的进程来处理客户端请求, 主进程继续循环接受客户端连接.</p>

<h3 id="思考-1">思考</h3>

<p><strong>单连接进程</strong>有很多优势.</p>

<ul>
  <li>
    <p>简单. 为了能够<strong>并行处理</strong>多个客户端, 只需要在串行化实现的基础上增加及少量的代码即可</p>
  </li>
  <li>
    <p>这种并行操作不难理解. <code>fork</code>实际上提供了一个子进程所需要的所有东西的副本. 我们不需要留心边界情况, 没有锁和竞争条件, 只是简单的分离而已.</p>

    <p>一个明显的劣势就是, 对于<code>fork</code>出的子进程的数量没有施加限制. 如果客户端的数量不大, 这倒没什么大问题, 但是如果生成了上百个进程, 那么我们的系统可能会崩溃了. 这方面可以使用我们接下来要实现的<code>preforking</code>模式来解决.</p>

    <p>还有一点, 对于不同的操作环境, 使用<code>fork</code>可能会出现问题. 只有<code>Unix</code>系统才支持<code>fork</code>, 这意味着<code>Windows</code>或者<code>JRuby</code>就没发使用<code>fork</code>了.</p>

    <p>我们究竟该使用<code>进程</code>还是<code>线程</code>, 这个问题留到下一小节来讨论, 届时我们会接触到线程.</p>
  </li>
</ul>

<h2 id="单连接线程">单连接线程</h2>

<h3 id="讲解">讲解</h3>

<p><strong>单连接线程模式</strong>和上一节的<strong>单连接进程模式</strong>非常相似. 不同之处就在于, 它是生成新线程, 而非新进程</p>

<blockquote>
  <p>线程与进程</p>

  <p>线程和进程都可以用于并行操作, 但是方式大不相同, 究竟使用哪个取决于实际情况.</p>

  <p><strong>生成(spawn)</strong>: 就生成而言, 线程的生成成本要低得多. 生成一个进程需要创建原始进程所拥有的一切资源的副本. 线程以进程为单位, 多个线程都存在于同一个进程中. 由于多个线程共享存在, 无需创建副本, 因而线程的生成速度要快得多.</p>

  <p><strong>同步(sync)</strong>: 因为线程共享内存, 当使用会被多个线程访问的数据结构时, 一定要多加小心. 这通常意味着要在线程之间使用互斥量(mutex)、枷锁以及同步访问. 进程就无需如此了, 因为每个进程都有自己的一份资源副本.</p>

  <p><strong>并行(p)</strong>: 两者都提供了由内核实现的并行计算能力. 关于<code>MRI</code>中的线程并行需要注意的一件重要的事情: 解释器对当前执行环境使用了一个<strong>全局锁</strong>. 因为线程以进程为单位, 这意味着它们都运行在一个解释器中. 即使使用了多线程, <code>MRI</code>也使得它们无法实现真正的并行. 在另外一些<code>Ruby</code>实现中, 如<code>JRuby</code>或者<code>Rubinius2.0</code>, 就不存在这样的问题.</p>

  <p>进程没有这方面的麻烦, 因为每次都是生成新的进程, 它都会获得自己的一份<code>Ruby解释器</code>的副本, 所以也就无需全局锁. 在<code>MRI</code> zhong , <strong>只有进程才能实现真正的并发</strong></p>

  <p>关于并行和线程还要说明一点. 即使是<code>MRI</code>使用了全局解释器🔒, 它对线程的处理也非常巧妙. 如果某个线程阻塞在<code>IO</code>上, <code>Ruby</code>能够让其他的线程继续执行.</p>

  <p>总而言之, 线程是轻量级的, 进程是重量级的. 两者都用于并行操作, 两者都有各自适用的环境.</p>
</blockquote>

<h3 id="实现-2">实现</h3>

<pre><code class="language-ruby">#  单连接线程架构处理流程
# 1. 启动一个线程池, 初始化一个 `control_socket`
# 2. 每接受一个新的连接请求时, 创建一个新线程来处理
# 3. `control_socket` 继续返回 2 等待接受新的连接

require 'socket'
require_relative 'command_handler'

module FTP

  Connection = Struct.new(:client) do
    CRLF = "\r\n"

    def gets
      client.gets(CRLF)
    end

    def respond(message)
      client.write(message)
      client.write(CRLF)
    end

    def close
      client.close
    end
  end

  class ThreadPerConnection

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) { exit }
    end

    def run
      Thread.abort_on_exception = true

      loop do
        # 接受客户端请求
        conn = Connection.new(@control_socket.accept)

        Thread.new do
          conn.respond '220 OHAI'

          handler = FTP::CommandHandler.new(conn)
          loop do
            request = conn.gets

            if request
              conn.respond handler.handle(request)
            else
              conn.close
              break
            end
          end
        end
      end
    end # end of run

  end
end

# 初始化我们的一个服务器实例
server = FTP::ThreadPerConnection.new(4481)

# 启动服务器
server.run

</code></pre>

<p>之前的样板代码被我放到了<code>Connection</code>类中, 而不是直接定义在服务器类中:</p>

<pre><code class="language-ruby">connection = Struct.new(:client) do
  def gets
  # ..
  end

  def respond(message)
  # ..
  end

  def close
  # ..
  end
end
</code></pre>

<p><code>run</code>方法我们也采用创建线程的模式:</p>

<pre><code class="language-ruby">def run
  Thread.abort_on_exception = true

  loop do
    # 接受客户端请求
    conn = Connection.new(@control_socket.accept)

    Thread.new do
      conn.respond '220 OHAI'

      handler = FTP::CommandHandler.new(conn)
      loop do
        request = conn.gets

        if request
          conn.respond handler.handle(request)
        else
          conn.close
          break
        end
      end
    end
  end
end # end of run
</code></pre>

<p>这其中有两处关键的不同.</p>

<ul>
  <li>采用 <code>Thread.new</code>生成了一个线程</li>
  <li>从<code>accept</code>返回的客户端套接字被传给<code>Connection.new</code>; 每个线程均获得自己的<code>Connection</code> 实例</li>
</ul>

<p>使用线程时, 每个线程使用一个全新的<code>Connection</code>实例非常重要. 如果我们像以前那样, 简单地将客户端套接字分配给一个实例变量, 那么它会在所有的活动现场之间共享. 因为这些线程是从一个共享的<code>FTP服务器</code>  实例中生成的, 所有它们会共享该实例的内部状态.</p>

<p>这与同进程打交道有着显著差别, 在后者中每个进程都会获得内存中所有资源的副本.</p>

<blockquote>
  <p>之所以很多开发者声称线程编程不容易, 其中一个原因便是状态共享. 如果你使用线程进行套接字编程, 有一条简单的经验: 让每个线程获得它自己的连接对象.</p>
</blockquote>

<h3 id="思考-2">思考</h3>

<p><strong>单连接线程模式</strong>与<strong>单连接进程模式</strong>有很多共同的优势: 代码修改量少, 很容易理解.</p>

<p>尽管使用线程会引入锁以及同步问题, 但是这里我们并不用担心这个问题, 因为每个连接都是由单个独立线程来处理的.</p>

<p>该模式较<strong>单连接进程</strong>的一个优势就是线程占用资源少, 因而获得数量上的增加. 比起进程, 它能够为客户端服务提供更好的并发性.</p>

<p>不过先等等, 别忘了<code>MRI GIL</code>使得这一优势无法变成现实. 归根结底, 没有哪个模式能够所向披靡, 每一种模式都应该思考、尝试、检验.</p>

<p><strong>单连接线程模式</strong>与<strong>单连接进程模式</strong>都有一个共同的劣势: 线程数会不断增加, 直到系统不堪重负.</p>

<p>如果你的服务器要处理持续增加的连接, 系统可能难以在所有的活动线程上进行维护和切换.</p>

<p>这可以通过限制活动线程数解决.</p>

<h2 id="preforking">Preforking</h2>

<h3 id="讲解-1">讲解</h3>

<p><code>Preforking</code>模式是建立在<strong>单连接进程模式</strong>的基础上.</p>

<p>它依赖进程作为并行操作的手段, 但并不为每个接入的连接衍生出对应的子进程, 而是在服务器启动后, 连接到达之前就预先衍生出一批进程.</p>

<h4 id="处理流程">处理流程</h4>

<ol>
  <li>主服务器进程创建一个侦听套接字</li>
  <li>主服务器进程衍生出一大批子进程</li>
  <li>每个子进程在共享套接字上接受连接, 然后独立进行处理</li>
  <li>主服务器进行密切关注子进程</li>
</ol>

<p>这个流程的重点在于, 主服务器进程打开侦听套接字, 却并不接受该套接字之上的连接. 它随后衍生出预定义数量的一批子进程, 每个子进程都有一份侦听套接字的副本. 子进程在各自的侦听套接字上调用<code>accept</code>, 不再考虑父进程.</p>

<p>这个模式的精妙之处在于, 无需担心负载均衡或者子进程连接的同步, 因为内核已经替我们完成这个工作了.</p>

<p>对于多个进程试图在同一个套接字的不同副本上接受(accept)连接的问题, 内核会均衡负载并确保只有一个套接字副本可以接受某个特定的连接</p>

<h3 id="实现-3">实现</h3>

<pre><code class="language-ruby"># Preforking

require 'socket'
require_relative 'command_handler'

module FTP
  CRLF = "\r\n"
  CONCURRENCY = 4

  class Preforking

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def gets
      @client.gets(CRLF)
    end

    def respond(message)
      @client.write(message)
      @client.write(CRLF)
    end

    def run
      child_pids = []

      CONCURRENCY.times do
        child_pids &lt;&lt; span_child
      end

      trap(:INT) {
        child_pids.each do |child_pid|
          begin
            Process.kill(:INT, child_pid)
          rescue Errno::ESRCH
          end
        end

        exit
      }

      loop do
        pid = Process.wait
        $stderr.puts "[#{Time.now.stftime("%Y-%m-%d %H:%M")}] Process #{pid} quit unexpectedly"

        child_pids.delete(pid)
        child_pids &lt;&lt; span_child
      end

    end # end of run

    def span_child
      fork do
        loop do
          @client = @control_socket.accept
          respond '220 OHAI'

          handler = CommandHandler.new(self)
          loop do
            request = gets

            if request
              respond handler.handle(request)
            else
              @client.close
              break
            end
          end
        end
      end
    end # end of span_child

  end
end

# 初始化我们的一个服务器实例
server = FTP::Preforking.new(4481)

# 启动服务器
server.run

</code></pre>

<p>我们先来看一下 <code>run</code>方法:</p>

<p>我们会在<code>run</code> 方法中多次调用了<code>spawn_child</code>方法, 具体次数基于我们自定义的<code>CONCURRENCY</code>中的值而定. <code>spawn_child</code>会<code>fork</code>一个新进程然后返回其进程<code>id</code>, 该值是唯一的.</p>

<p>生成子进程后, 父进程为<code>INT</code>信息定义了一个信号处理器. 当你键入<code>Ctrl+C</code>时, 进程就会收到该信号. 这个信号处理器仅用于将父进程接收到的<code>INT</code>信号转发给它的子进程.</p>

<p>因为子进程独立于父进程存在, 即使是父进程结束了, 子进程也不会收到影响. 所以对于父进程而言, 在退出之前清理自己的子进程就很有必要.</p>

<p>信号处理完之后, 父进程就进入了<code>Process.wait</code>循环. 该方法会一直阻塞到有子进程退出为止.</p>

<p><code>Process.wait</code>返回退出子进程的<code>pid</code>.因为子进程并不应该退出, 所有我们将<code>子进程异常退出</code>视为一场情况.</p>

<p>随后在<code>STDERR</code>上打印一条信息并生成一个新的子进程代替.</p>

<p>在一些<code>Preforking</code>服务器中, 尤其是<code>Unicorn</code>, 父进程承担了更为活跃的角色, 它还负责监视自己的子进程. 例如父进程可能会查看是否有哪个子进程耗费了太多的时间处理请求. 如果是, 父进程会终止该进进程并生成新的子进程取代它.</p>

<p>我们再来看一下<code>spawn_child</code>方法:</p>

<p>这种方法的核心部分应该很熟悉了. 这次它被放入了<code>fork</code>和<code>loop</code>外. 因此新进程在调用<code>accept</code>之前就已经衍生出来了. 最外层的循环确保每个连接处理并关闭后, 继续处理新的连接. 通过这种方法, 每个子进程都处于它们各自的<code>接受连接</code>循环中.</p>

<h3 id="思考-3">思考</h3>

<p><code>Preforking</code>不用在每个连接期间进行<code>fork</code>. 进程衍生的成本可不少.在单连接进程架构中, 每个连接都要承担由此带来的开销.</p>

<p>由于<code>Preforking</code>在<code>accept</code>连接之前就生成了所有连接, 因而避免了进程过量的情况.</p>

<p>比起与<code>Preforking</code>类似的线程模式, 这个模式的一个优势就是完全隔离.</p>

<p>因为每个进程都拥有包括<code>Ruby</code>解释器在哪的所有资源的副本, 单个进程中的故障不会影响其他进程.</p>

<p>因为线程共享资源以及内存空间, 单线程故障可能会无法预测地影响到其他线程.</p>

<p><code>Preforking</code>的一个劣势就是: 衍生的进程越多, 消耗的内存也越多.</p>

<p>进程可不是免费的午餐. 考虑到每个衍生的进程都会获得所有资源的一份副本, 我们可以预料到每一次进程衍生, 内存占用率就要增加100%(以父进程为基准).</p>

<p>按照这种衍生方式, 占用<code>100MB</code>内存的进程在衍生出4个子进程之后将占用<code>500MB</code>内存.</p>

<p>即使这样, 也才4个并发连接.</p>

<h2 id="线程池">线程池</h2>

<p>线程池模式之于 <code>Preforking</code>, 一如单连接线程与单连接进程之间的关系. 同<code>Preforking</code>类似, 线程池在服务器启动后会生成一批线程, 将处理连接的任务交给独立的线程来完成.</p>

<p><strong>线程池模式</strong>处理流程和<code>Preforking</code>一样, 只需要把“进程”修改为“线程”就行了.</p>

<pre><code class="language-ruby"># ThreadPool

require 'socket'
require 'thread'
require_relative 'command_handler'

module FTP
  Connection = Struct.new(:client) do
    CRLF = "\r\n"

    def gets
      client.gets(CRLF)
    end

    def respond(message)
      client.write(message)
      client.write(CRLF)
    end

    def close
      client.close
    end
  end

  class ThreadPool
    CONCURRENCY = 25

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def run
      Thread.abort_on_exception = true
      threads = ThreadGroup.new


      CONCURRENCY.times do
        threads.add spawn_thread
      end

      sleep
    end

    def spawn_thread
      Thread.new do
        loop do
          conn = Connection.new(@control_socket.accept)
          conn.respond '220 OHAI'

          handler = CommandHandler.new(self)

          loop do
            request = conn.gets

            if request
              conn.respond handler.handle(request)
            else
              conn.close
              break
            end
          end
        end
      end
    end # end of spawn_thread

  end
end

# 初始化我们的一个服务器实例
server = FTP::ThreadPool.new(4481)

# 启动服务器
server.run

</code></pre>

<p>这里在此出现了两个方法: 一个用来生成线程, 一个用来封装线程生成以及线程从未.</p>

<p>因为我们使用的是线程,因此还需要使用<code>Connnection</code>类.</p>

<pre><code class="language-ruby">def run
  Thread.abort_on_exception = true
  threads = ThreadGroup.new


  CONCURRENCY.times do
    threads.add spawn_thread
  end

  sleep
end
</code></pre>

<p><code>run</code> 方法创建了一个<code>ThreadGroup</code>实例跟踪所有的线程. <code>ThreadGroup</code>有点像一个可对线程进行操作的数组. 我们可以 向<code>ThreadGroup</code>中加入线程, 当某个线程成员执行结束之后, 它就会从这个线程组中丢弃.</p>

<p>我可以使用<code>ThreadGroup#list</code>获得组中当前所有活动现场列表.在这个实现中, 我们其实并没有用到这个技巧.</p>

<p>同上一节的<strong>Preforking</strong>类似, 我们依据<code>CONCURRENCY</code>的值多次调用<code>spawn_thread</code>. 注意这里的<code>CONCURRENCY</code>的值要比<code>Preforking</code>中的高. 这还是因为线程的开销更小一些, 所有我们可以使用更多的线程. 要记住的是<code>MRI GIL</code>减少了一部分由此带来的收益.</p>

<p>方法的最后我们调用了<code>sleep</code>来避免方法退出. 当线程池中的线程有工作任务时, 主线程保持空闲. 理论上它可以监视线程池, 不过这里我们只是使用了<code>sleep</code>不让其退出.</p>

<p><code>spawn_thread</code>方法平淡无奇, 没什么出彩之处, 它和 <code>Preforking</code>中<code>spawn_child</code>一样. 生成一个线程, 重复执行连接处理代码.内核会确保一个连接只能由单个线程接受.</p>

<h3 id="思考-4">思考</h3>

<p>有关线程池模式大部分的思路内容和<code>Preforking</code>一样.</p>

<p>除了那些线程和进程之间显而易见的权衡之外, 线程池模式不需要每次处理连接时都生成线程, 也没有什么令人抓狂的锁或者竞争条件, 但却仍提供了并行处理能力.</p>

<h2 id="事件驱动">事件驱动</h2>

<p>迄今为止我没看到的这些模式其实都是串行化模式的变体而已. 其他的几种模式实际上使用的结构和串行化相同, 只不过包装了线程或者进程.</p>

<p><strong>事件驱动</strong>模式采用的是一种和之前完全不同的方法.</p>

<h3 id="讲解-2">讲解</h3>

<p><strong>事件驱动模式</strong>(基于Reactor模式)如今可谓风头正劲. 它也是EventMachine、Twisted、Node.js以及Nginx等库的核心所在.</p>

<p>该模式结合了单线程和单进程, 它至少可以达到之前模式所提供的并行操作级别.</p>

<p>它以一个中央连接复用器(被称为<code>Reactor</code>核心)为核心. 连接生命周期中的每个阶段都被分解成单个的事件, 这些事件之间可以按照任意的次序交错并处理. 连接的不同阶段只是一些IO操作而已:</p>

<p><code>accept</code> 、<code>read </code>、<code>write</code> 、<code>close</code>.</p>

<p>中央复用器监视所有活动连接的事件, 在触发事件时分派相关的代码.</p>

<p>下面是事件驱动模式的工作流程:</p>

<ol>
  <li>服务器监视侦听套接字, 等待接入的连接</li>
  <li>将接入的新连接加入到<strong>套接字列表</strong>中进行监视</li>
  <li>服务器现在要监视活动连接以及侦听套接字</li>
  <li>当某个活动连接可读时, 服务器从该连接读取一块数据并分派相关的回调函数</li>
  <li>当某个活动连接仍然可读时, 服务器读取另一块数据并再次分派给相关的回调函数.</li>
  <li>服务器收到另外一个新连接, 将其加入套接字列表进行监视.</li>
  <li>服务器注意到第一个连接已经可以写入, 因而将响应信息写入该连接.</li>
</ol>

<p>记住: <strong>所有的一切都发生在单个线程中</strong>. 第一个连接仍在读/写过程中, 服务器就可以<code>accept</code>新连接了.</p>

<p>服务器将每次操作分隔成小块, 这样属于多连接的不同事件就可以彼此交错了</p>

<h3 id="实现-4">实现</h3>

<pre><code class="language-ruby">require 'socket'
require_relative 'command_handler'

module FTP
  class Evented
    CHUNK_SIZE = 1024 * 16

    class Connection
      CRLF = "\r\n"
      attr_reader :client

      def initialize(io)
        @client = io
        @request, @response = "", ""
        @handler = CommandHandler.new(self)

        respond "220 OHAI"
        # 写数据
        on_writable
      end

      # 处理数据并发送响应
      def on_data(data)
        @request &lt;&lt; data

        if @request.end_with?(CRLF)
          # 调用 `handle` 来处理此次请求并将返回的数据写入到 `response`
          respond @handler.handle(@request)
          @request = ""
        end
      end

      def respond(message)
        @response &lt;&lt; message + CRLF
        # 立即加载可以写入的任何内容
        # 其余部分将在下次套接字可写入时充实
        on_writable
      end

      def on_writable
        bytes = client.write_nonblock(@response)
        @response.slice!(0, bytes)
      end

      def monitor_for_reading?
        true
      end

      def monitor_for_writing?
        !(@response.empty?)
      end
    end # end of Connection

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) { exit }
    end

    def run
      @handles = {}

      loop do
        to_read  = @handles.values.select(&amp;:monitor_for_reading?).map(&amp;:client)
        to_write = @handles.values.select(&amp;:monitor_for_writing?).map(&amp;:client)
        readables, writables = IO.select(to_read + [@control_socket], to_write)

        readables.each do |socket|
          # 侦听套接字负责侦听
          if socket == @control_socket
            io = @control_socket.accept
            connection = Connection.new(io)
            @handles[io.fileno] = connection
          # 其余读套接字负责读取数据
          else
            connection = @handles[socket.fileno]

            begin
              data = socket.read_nonblock(CHUNK_SIZE)
              connection.on_data(data)
            # 没有数据可读时就重试, 实际上啥也没做, `each` 循环继续到下一个 `socket`
            rescue Errno::EAGAIN
            rescue EOFError
              # 当读取到 `EOF` 时就删除此 socket
              @handles.delete(socket.fileno)
            end
          end
        end # end of readables

        writables.each do |socket|
          connection = @handles[socket.fileno]
          # 往 socket 写入数据
          connection.on_writable
        end
      end # end of loop
    end # end of run
  end # end of Evented
end

server = FTP::Evented.new(4481)

server.run

</code></pre>

<p>这个实采用了一种同之前那些实现不同的手法. 我们把代码分解成几个部分研究.</p>

<pre><code class="language-ruby">class Connection
# ..
end
</code></pre>

<p>我们定义了一个<code>Connection</code>类作为事件驱动服务器.</p>

<p>在前面几个线程模式的示例中, 我们用<code>Connection</code>类保持进程间的状态隔离. 这个示例并没有使用线程, 为什么需要<code>Connection</code>类呢?</p>

<p>所有基于进程的模式都使用进程隔离连接. 不管利用即成的方法如何, 它们总是确保无论何时都由单个独立的进程处理单个连接, 所有每个连接基本上是由一个进程描述.</p>

<p><strong>事件驱动模式</strong>用的是单线程, 但是可以同时处理多个用户连接, 所有它需要使用一个对象来描述每个独立的连接, 这样就不会破坏连接各自的状态.</p>

<pre><code class="language-ruby">class Connection
  CRLF = "\r\n"
  attr_reader :client

  def initialize
    @client = io
      @request, @response = "", ""
      @handler = CommandHandler.new(self)

      respond "220 OHAI"
      on_writable
  end
end
</code></pre>

<p><code>Connection</code>类的开始部分看起来有些眼熟.</p>

<p><code>Connection</code>类将底层的<code>IO</code>对象存储在它的<code>@client</code>实例变量中. 外界可以通过<code>attr_reader</code>对其进行访问.</p>

<p>当连接初始化完毕后, 它会像从前一样获得自己的<code>CommandHandler</code>实例. 随后它写入<code>FTP</code>所要求的定制的<code>hello</code>响应. 不过并非直接写入客户端连接, 而是将响应的主体信息写入<code>@response</code>变量.</p>

<p>下面我们将会看到这将引发<code>Reactor</code>接管操作并将数据发送到客户端.</p>

<pre><code class="language-ruby"># 处理数据并发送响应
def on_data(data)
  @request &lt;&lt; data

  if @request.end_with?(CRLF)
    # 完成此次请求
    respond @handler.handle(@request)
    @request = ""
  end
end

def respond(message)
  @response &lt;&lt; message + CRLF
  # 立即加载可以写入的任何内容
  # 其余部分将在下次套接字可写入时充实
  on_writable
end

def on_writable
  bytes = client.write_nonblock(@response)
  @response.slice!(0, bytes)
end
</code></pre>

<p><code>Connection</code>类定义了若干与<code>Reactor</code>核心进行交换的生命周期方法.</p>

<p>例如, 当<code>Reactor</code>从客户端连接读取数据时, 它触发<code>on_data</code>处理数据.在<code>on_data</code>内部, 检查接受到的是否是一个完整的请求, 如果是会请求<code>@handler</code>建立对应的响应并将其赋给<code>@response</code>.</p>

<p>当客户端连接可以进行写入时就调用<code>on_writable</code>方法. 这就要和<code>@response</code> 变量打交道了. 它将<code>@response</code>中的内容写入客户端连接. 根据能够写入的字节数, 将成功写入的数据从<code>@response</code>中移除.</p>

<p>这样,随后的写操作就只会写入<code>@response</code>中本次没能写入的部分内容. 如果能够写入全部内容, 那么<code>@response</code>就变成了一个空字符串, 就无法再进行写操作了.</p>

<pre><code class="language-ruby">def monitor_for_reading?
  true
end

def monitor_for_writing?
  !(@response.empty?)
end
</code></pre>

<p><code>monitor_for_reading</code>以及<code>monitor_for_writing</code>这两个方法被<code>Reactor</code>用来查询是否应该监视特定连接的读写状态. 在本例中, 只要有新的数据, 我们都希望进行读取. 如果<code>@response</code>有内容可写, 我们希望获知可以进行写入的时机. 如果<code>@response</code>中没有内容, 即使是客户端连接可以写入, <code>Reactor</code>也不会发出通知.</p>

<p><strong>这就是	<code>Reactor</code>核心的工作内容</strong>.</p>

<p><code>@handler</code>看起来像是这样:</p>

<pre><code class="language-ruby">{12 =&gt; #&lt;FTP::Evented::Connection::hehe&gt;}
</code></pre>

<p>其中键对应的是文件描述符编号, 值对应的是<code>Connection</code>对象.</p>

<pre><code class="language-ruby">to_read  = @handles.values.select(&amp;:monitor_for_reading?).map(&amp;:client)
to_write = @handles.values.select(&amp;:monitor_for_writing?).map(&amp;:client)
readables, writables = IO.select(to_read + [@control_socket], to_write)
</code></pre>

<p>主循环<code>run</code>中我们首先查询每个活动连接, 看是否需要使用之前介绍的生命周期方法对其进行读/写监视.</p>

<p>对于有需要的连接, 它获取其底层<code>IO</code>对象的引用.</p>

<p><code>Reactor</code>随后将这些<code>IO</code>实例传给不带超时参数的<code>IO.select</code>.</p>

<p><code>IO.select</code>会一直阻塞到某个受监控的套接字出现值得关注的事件为止.</p>

<p>⚠️: <code>Reactor</code>还会监视<code>@control_socket</code>是否可读, 以便检测到新接入的客户端连接.</p>

<p><code>  Reactor</code>根据它从<code>IO.select</code>  中接收到的事件触发对应的方法.</p>

<pre><code class="language-ruby">readables.each do |socket|
  # 侦听套接字负责侦听
  if socket == @control_socket
    io = @control_socket.accept
    connection = Connection.new(io)
    @handles[io.fileno] = connection
  # 其余读套接字负责读取数据
  else
    connection = @handles[socket.fileno]

    begin
      data = socket.read_nonblock(CHUNK_SIZE)
      connection.on_data(data)
    rescue Errno::EAGAIN # 没有数据可读时就重试, 实际上啥也没做, `each` 循环继续到下一个 `socket`
    rescue EOFError
      # 当读取到 `EOF` 时就删除此 socket
      @handles.delete(socket.fileno)
    end
  end
end # end of readables
</code></pre>

<p>首先处理可读的套接字. 如果<code>@control_socket</code>可读,就意味着出现了一个新的客户端连接. <code>Reactor</code>调用<code>accept</code>接受连接, 建立一个新的<code>Connection</code>并将其放入<code>@handles</code>散列中, 这样就可以在下一次的<code>each</code>循环中进行监视了.</p>

<p>接下来要处理可读的套接字是普通的客户端连接的情况.</p>

<p>在这种情况下, 代码会尝试读取数据, 触发对应的<code>Connection</code>的<code>on_data</code>方法. 如果读取出现阻塞(Errno::EAGAIN), 不做任何处理, 让事件落空为止.如果客户端断开连接(EOFError), 那么要确保从<code>@handles</code>散列中删除相应的条目, 使得对应的对象可以被回收并不再受到监视.</p>

<pre><code class="language-ruby">writables.each do |socket|
  connection = @handles[socket.fileno]
  # 往 socket 写入数据
  connection.on_writable
end
</code></pre>

<p>最后通过触发<code>Connection#on_writable</code>方法处理可写的套接字.</p>

<h3 id="思考-5">思考</h3>

<p><strong>事件驱动模式</strong>同其他模式有着显著的不同, 因而也就产生了尤为不同的优势和劣势.</p>

<p>首先, 该模式以极高的并发处理能力而闻名, 能够处理成千上万的并发连接. 光这一点就让其他模式无法望其项背, 因为他们都受到进程/线程数量的限制.</p>

<p>如果服务器需要生成5000个线程来处理5000个连接, 服务器估计不堪重负. 就处理并发连接而言, 事件驱动模式可谓一枝独秀并广为流传.</p>

<p>它主要的劣势是所施加的变成模型. 一方面这个模型更简单, 因为无需处理众多线程和进程. 这意味着就不存在共享内存、同步、越界进程等等.</p>

<p>但是考虑到所有的并发都发生在单个线程内部, 有一条非常重要的规则必须遵循: <strong>绝对不能阻塞<code>Reactor</code></strong>.</p>

<p>要诠释着一点,让我们来仔细查看一下实现代码. 在<code>CommandHandler</code>类中, 当处理<code>FTP</code>文件传输命令(RETR)时,它实际上打开了一个套接字, 以流的方式发送数据, 然后关闭套接字. 重要的是这个套接字是在<code>Reactor</code>主循环之外使用的, <code>Reactor</code>对其一无所知.</p>

<p>假设客户端在一条速度缓慢的连接上请求文件传输, 这会对<code>Reactor</code>造成什么影响呢?</p>

<p>考虑到一切都运行在同一个线程之内, 单个迟缓的客户端连接会阻塞住整个<code>Reactor</code>.当<code>Reactor</code>在<code>Connection</code>上触发某个方法时, <code>Reactor</code>会一直阻塞到该方法返回为止.</p>

<p>由于<code>on_data</code>方法委托给了<code>CommandHandler</code>, 当它以数据流的方式向客户端进行文件传输时, <code>Reactor</code>一直处于阻塞. 在这期间, 无法读取其他数据, 也就无法接受新的连接.</p>

<p>应用程序需要达成的任何事情都应该快速完成, 这一点非常重要. 我们如何使用<code>Reactor</code>处理缓慢的连接呢?</p>

<p><strong>利用<code>Reactor</code>自身</strong></p>

<p>如果你采用该模式, 那就需要确保所有阻塞式<code>IO</code>都由<code>Reactor</code>自己来处理. 在这个例子中就意味着由 <code>CommandHandler</code>所使用的套接字需要被封装到<code>Connection</code>的子类中, 它定义了自己的一套<code>on_data</code>和<code>on_writable</code>方法.</p>

<p>当<code>Reactor</code>可以向缓慢的连接中写入数据时, 它就会触发响应的<code>on_writable</code>方法, 该方法能够在没有阻塞的情况下尽可能多的向客户端写入数据. 这样<code>Reactor</code>就可以在等待这个缓慢的远程连接的同时继续处理其他连接, 一旦那条远程连接再次可用, 仍可对其进行处理.</p>

<p>简而言之, 事件驱动模式提供了一些显而易见的优势, 真正简化了套接字编程的某些方面. 另一方面, 它需要你重新考虑自己的应用程序设计的全部<code>IO</code>操作. 该模式所带来的益处很容易被一些迟钝的代码或者含有阻塞式<code>IO</code>的第三方代码块搞得烟消云散.</p>

<h2 id="混合模式">混合模式</h2>

<h2 id="再会">再会</h2>

  ]]></description>
</item>


  </channel>
</rss>
