<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    
    <title>hwbnju.com</title>
    
    <link>http://hwbnju.com</link>
    <description>nju520's Blog</description>
    <language>en-uk</language>
    <managingEditor> nju520</managingEditor>
    <atom:link href="rss" rel="self" type="application/rss+xml" />
    
<item>
  <title>Sidekiq 异步任务调度与执行</title>
  <link>//sidekiq</link>
  <author>nju520</author>
  <pubDate>2018-03-18T00:00:00+08:00</pubDate>
  <guid>//sidekiq</guid>
  <description><![CDATA[
  <p>sidekiq 是 Ruby 中一款非常优秀的后台任务处理软件, 其本身提供的API十分简洁, 源代码也易于阅读, 没有太多花哨的代码. Sidekiq 将 Redis 的各种数据结构用得都起到好处, 我们可以通过 Sidekiq 加深对 Redis 的印象以及学习如何恰当高效地结合 Redis 实现业务逻辑.本篇文章从 Sidekiq 的启动开始,详细解读 Sidekiq 的异步任务调度和执行.  除此之外, 我还会介绍中间件机制以及在此基础上实现的任务重试机制.</p>

<blockquote>
  <p>本篇文章涉及的 Sidekiq 版本是 5.0.5</p>
</blockquote>

<h2 id="初识-sidekiq">初识 Sidekiq</h2>

<p>在我们具体解读<code>Sidekiq</code>的源码之前, 我们先来熟悉一下<code>Sidekiq</code>异步任务的创建和执行, 保证我们对其结构有一个总体的认识.</p>

<p><code>Sidekiq</code>的使用非常简洁, 我们只需要在<code>app/workers</code>文件夹中添加一个<code>worker</code>,来处理异步请求:</p>

<pre><code class="language-ruby">class HardWorker
  include Sidekiq::Worker

  def perform(name, count)
  # do something you want
  end
end
</code></pre>

<p>我们可以在需要执行操作的地方提交异步任务了:</p>

<pre><code class="language-ruby">#. 常规提交
HardWorker.perform_async('hehe', 10)

# 延迟提交 10分钟
HardWorker.perform_in(10.minutes, 'sleep', 10)

# 指定将来的某个时刻提交
# 我们指定此任务明天的这个此刻执行
HardWorker.perform_at(Time.now + 1.day, 'run', 200)
</code></pre>

<p>当我们执行上述三个提交方法时, <code>Sidekiq Worker</code>会将一个异步任务以<code>JSON</code>的形式将相关的参数信息加入到 <code>Redis</code>中并等待消费者对任务的拉取和处理.</p>

<p><code>Sidekiq</code>的消费者由三个部分:</p>

<ul>
  <li>Sidekiq::Scheduled::Poller: 定时任务拉取器.
    <ul>
      <li>负责在一定时间范围内不定时检查定时任务(scheduled)以及重试任务(retry), 将计划时间已经超过当前时间的任务追加到各自对应的任务队列中</li>
      <li>Sidekiq::Manager: worker 管理器. 负责按照配置的<code>concurrency</code>参数创建匹配数量的<code>worker</code>, 同时负责<code>worker</code>的管理. 这里的<code>worker</code>实际上就是一个<code>Processor</code>的实例</li>
    </ul>
  </li>
  <li>Sidekiq::Processor:  负责执行指定的任务</li>
</ul>

<p>它们三者会相互协作共同完成对<code>Redis</code>中任务消费的全过程.</p>

<p><img src="" alt="Sidekiq Module" /></p>

<h2 id="异步任务入队">异步任务入队</h2>

<p>当我们对需要异步执行的任务执行<code>Worker.perform_async</code>的方法时, <code>Sidekiq</code>其实并不会真正取创建一个<code>HardWroker</code>等具体<code>Worker</code>对象, 它实际上会调用<code>Worker.client_push</code>方法将当前的<code>class</code>和<code>args</code>参数传进去, 也就是我们需要异步执行的类和<code>perform</code>方法所需要的参数, 以及<code>Sidekiq</code>添加的额外参数:</p>

<pre><code class="language-json">{
  "class": "Platform::ActiveUserWorker",
  "args": ["2018-03-09"],
  "retry": true,
  "queue": "default",
  "jid": "f2c20ffd382925563ffbc6b0",
  "created_at": 1520524801.3932867,
  "enqueued_at": 1520524801.3934016
}
</code></pre>

<p>使用<code>pry</code>工具来查看一下源码:</p>

<pre><code class="language-ruby">[4] pry(main)&gt; $ Sidekiq::Worker::ClassMethods#perform_async

From: /sidekiq-5.0.5/lib/sidekiq/worker.rb @ line 86:
Owner: Sidekiq::Worker::ClassMethods
Visibility: public
Number of lines: 3

def perform_async(*args)
  client_push('class'.freeze =&gt; self, 'args'.freeze =&gt; args)
end

</code></pre>

<p>除了<code>perform_async</code>之外, `	Worker<code>还提供了两种用于在一段时间之后或者未来的某个时刻执行相应任务的方法 </code>Worker.perform_at<code>和</code>Worker.perform_in`:</p>

<pre><code class="language-ruby">From: /sidekiq-5.0.5/lib/sidekiq/worker.rb @ line 92:
Owner: Sidekiq::Worker::ClassMethods
Visibility: public
Number of lines: 12

def perform_in(interval, *args)
  int = interval.to_f
  now = Time.now.to_f
  ts = (int &lt; 1_000_000_000 ? now + int : int)
  # 比普通的 perform_async 多了一个 at 参数
  item = { 'class'.freeze =&gt; self, 'args'.freeze =&gt; args, 'at'.freeze =&gt; ts }
  item.delete('at'.freeze) if ts &lt;= now

  client_push(item)
end

#. 在底层实现中, perform_at 与 perform_in 是同一个方法的两种形式的调用
alias_method :perform_at, :perform_in
</code></pre>

<p>为了使用同一个接口支持两种不同的安排方式(时间点和多久之后), 方法内部对传入的<code>internal</code>进行了判定:</p>

<ul>
  <li><code>interval.to_f &lt; 1_000_000_000</code>: 此时方法就认为传入的参数是一段时间.
    <ul>
      <li><code>Time.at 1_000_000_000</code> == 2001-09-09 09:46:40 +0800</li>
    </ul>
  </li>
  <li>interval.to_f &gt;= 1_000_000_000: 此时方法断定传入的参数是未来的某个时间点, eg:  <code>Time.now + 1.day</code>
    <ul>
      <li>如果传入的时间点是过去的时间点, 那么才 <code>item</code>中会删除<code>at</code></li>
    </ul>
  </li>
</ul>

<p>虽然<code>Worker.perform_at</code>和<code>Worker.perform_in</code>是完全相同的方法, 但是我们在使用时还是尽量遵循方法的语义选择两者中更符合使用逻辑的方法.</p>

<p>以上三种创建异步任务的方式, 最终都执行了<code>Worker.client_push</code>方法. 该方法接受一个哈希参数, 参数大致形式如下:</p>

<pre><code class="language-ruby">{
  class: "Platform::ActiveUserWorker",
  args: ["2018-03-09"],
  at: '60.0'
 }
</code></pre>

<p>在方法的实现中, 首先获取上下文中的<code>Redis</code>线程池, 并将传入的<code>item</code>对象压入<code>Redis</code>队列中</p>

<pre><code class="language-ruby">[3] pry(main)&gt; $ Sidekiq::Worker::ClassMethods#client_push

From: /sidekiq-5.0.5/lib/sidekiq/worker.rb @ line 136:
Owner: Sidekiq::Worker::ClassMethods
Visibility: public
Number of lines: 9

def client_push(item) # :nodoc:
  # Redis 连接池
  pool = Thread.current[:sidekiq_via_pool] || get_sidekiq_options['pool'.freeze] || Sidekiq.redis_pool
  # stringify
  item.keys.each do |key|
    item[key.to_s] = item.delete(key)
  end

  Sidekiq::Client.new(pool).push(item)
end
</code></pre>

<p><code>client_push</code>方法最后调用了<code>Sidekiq::Client.new</code> 实例化一个<code>Sidekiq::Client</code>, 并将<code>item</code>  压入到<code>Redis</code>队列.</p>

<pre><code class="language-ruby">[4] pry(main)&gt; $ Sidekiq::Client#push

From: /sidekiq-5.0.5/lib/sidekiq/client.rb @ line 69:
Owner: Sidekiq::Client
Visibility: public
Number of lines: 9

def push(item)
  normed = normalize_item(item)
  payload = process_single(item['class'.freeze], normed)

  if payload
    # 此时传入的 payload 只有一个
    raw_push([payload])
    payload['jid'.freeze]
  end
end

def normalize_item(item)
  # 省略错误处理
  # 如果传入的 item 没有携带某些参数时, 就采用系统默认的参数
  normalized_hash(item['class'])
    .each{ |key, value| item[key] = value if item[key].nil? }

  item['class'] = item['class'].to_s
  item['queue'] = item['queue'].to_s
  item['jid'] ||= SecureRandom.hex(12)
  item['created_at'] ||= Time.now.to_f
  item
end

# 获取默认参数
def normalized_hash(item_class)
  if item_class.is_a?(Class)
    # 省略错误处理(需要普通的 SomeWorker include Sidekiq::Worker)
    item_class.get_sidekiq_options
  else
    Sidekiq.default_worker_options
  end
end

# Sidekiq 提供了两个默认参数
DEFAULT_WORKER_OPTIONS = {
  'retry' =&gt; true,
  'queue' =&gt; 'default'
}


# 每个中间件对传入的哈希进行处理之后,返回 item
# 具体实现请见 ·又见中间件·
def process_single(worker_class, item)
  queue = item['queue']

  middleware.invoke(worker_class, item, queue, @redis_pool) do
    item
  end
end
</code></pre>

<p>从代码的注释我们可以知道,  <code>Sidekiq::Client#push</code>方法接受的哈希参数包括以下内容:</p>

<ul>
  <li>queue: 具名队列, 默认为 <code>default</code></li>
  <li>class: 被调用的<code>worker</code></li>
  <li>args: 传给<code>Worker.perform</code>的参数, 必须是 <code>JSON-serializable</code>, 而且必须是一个数组</li>
  <li>at: 计划执行的时间点, 必须是 <code>Numeric</code></li>
  <li>retry: 如果任务失败是否重试标志, 默认为 <code>true</code></li>
</ul>

<p>从<code>Worker.perform_async</code>到<code>Client#push</code>方法, 都对即将加入到<code>Redis</code>队列的哈希进行处理, 从添加<code>at</code>字段到字符串化、再到<code>Client#normalize_item</code>方法中添加默认参数<code>retry</code>、<code>queue</code>, <code>jid</code>、<code>created_at</code>. 经过 <code>process_single</code>的处理, 传入 <code>raw_push</code>的哈希值大致如下:</p>

<pre><code class="language-json">{
 "jobstr":
     {
      "class": "Platform::ActiveUserWorker",
      "args": ["2018-03-09"],
      "retry": true,
      "queue": "default",
      "jid": "f2c20ffd382925563ffbc6b0",
      "created_at": 1520524801.3932867,
      "enqueued_at": 1520524801.3934016
     }
}
</code></pre>

<p>所有添加异步任务的方法最终都调用了私有方法<code>Client#raw_push</code> , 此方法继续调用<code>atomc_push</code>向<code>Redis</code>添加数据.</p>

<pre><code class="language-ruby">def raw_push(payloads)
  # #
  @redis_pool.with do |conn|
    conn.multi do
      atomic_push(conn, payloads)
    end
  end
  true
end
</code></pre>

<p>添加数据时会分两种情况:</p>

<ul>
  <li>当异步任务再未来的某一个时间点进行安排时, 此任务就会加入到一个有序集合 <code>schedule</code>
    <ul>
      <li>有序集合的 <code>score</code>自然是异步任务执行的时刻
​</li>
    </ul>
  </li>
  <li>当任务为立即执行任务时:
    <ul>
      <li>设置当前异步任务入队的时间<code>enqueued_at</code></li>
      <li>Sidekiq将<code>payload</code>所属的<strong>队列</strong>加入到一个大队列 <code>queues</code>的集合中</li>
      <li>将负载 <code>payload</code>直接压入 <code>"#queue:#{q}"</code>队列中等待消费者的拉取.</li>
    </ul>
  </li>
</ul>

<pre><code class="language-ruby">From: sidekiq-5.0.5/lib/sidekiq/client.rb @ line 191:
Owner: Sidekiq::Client
Visibility: private
Number of lines: 17

def atomic_push(conn, payloads)
  # 根据传入的负载是否有 at key
  if payloads.first['at'.freeze]
    conn.zadd('schedule'.freeze, payloads.map do |hash|
      at = hash.delete('at'.freeze).to_s
      # 传入的 payload 需要转成 JSON 格式
      # [score, payload]
      [at, Sidekiq.dump_json(hash)]
    end)
  else
    q = payloads.first['queue'.freeze]
    now = Time.now.to_f
    to_push = payloads.map do |entry|
      entry['enqueued_at'.freeze] = now
      Sidekiq.dump_json(entry)
    end
    conn.sadd('queues'.freeze, q)
    conn.lpush("queue:#{q}", to_push)
  end
end
</code></pre>

<h3 id="redis的存储">Redis的存储</h3>

<p>无论是立即执行还是未来计划的异步任务都会进入<code>Redis</code>的队列中, 但是它们之间的存储还是有所区别.</p>

<ul>
  <li><code>Worker.perform_at/in</code>会将任务以<code>[at, payload]</code>的形式加入到<code>schedules</code>有序集合中</li>
  <li><code>Worker.perform_async</code>将负载直接加入到指定的队列 <code>"queue:#{q}"中, 并向整个</code>Sidekiq<code>的队伍集合</code>queues`中添加该队列</li>
</ul>

<p>所有的<code>payload</code>都包含一个异步任务需要执行的全部信息:</p>

<ul>
  <li>
    <p>执行的队列: queue</p>
  </li>
  <li>
    <p>异步队列的类 <code>class</code></p>
  </li>
  <li>参数 <code>args</code>: 将传入 <code>Worker.perform</code>方法
    <ul>
      <li><code>sidekiq_options</code>中的默认参数: <code>retry</code> 、 <code>queue</code></li>
    </ul>
  </li>
  <li>
    <p><code>jid</code>: 任务唯一标识符, 通过<code>SecureRandom.hex(12)</code>生成</p>
  </li>
  <li>
    <p>enqueued_at: 入队时间</p>
  </li>
  <li>
    <p><code>created_at</code>: 创建时间</p>

    <p>​</p>

    <p><img src="" alt="payload" /></p>

    <p>​</p>
  </li>
</ul>

<p>接下来我们就从<code>Sidekiq</code>启动画面着手, 还是我们的<code>Sidekiq</code>源码解读之旅吧!</p>

<h2 id="启动">启动</h2>

<p>每当我们启动一个<code>Sidekiq</code>服务时, 令人印象深刻地就是在命令行中出现了一个功夫少年:</p>

<pre><code>
         m,
         `$b
    .ss,  $$:         .,d$
    `$$P,d$P'    .,md$P"'
     ,$$$$$bmmd$$$P^'
   .d$$$$$$$$$$P'
   $$^' `"^$$$'       ____  _     _      _    _
   $:     ,$$:       / ___|(_) __| | ___| | _(_) __ _
   `b     :$$        \___ \| |/ _` |/ _ \ |/ / |/ _` |
          $$:         ___) | | (_| |  __/   &lt;| | (_| |
          $$         |____/|_|\__,_|\___|_|\_\_|\__, |
        .d$$                                       |_|


</code></pre>

<p>我们可以通过如下指令找到运行<code>sidekiq</code>的bin文件:</p>

<pre><code class="language-ruby">$ where sidekiq
/Users/bobo/.rvm/gems/ruby-2.4.2/bin/sidekiq
/usr/local/bin/sidekiq
</code></pre>

<p>我们就从 <code>bin/sidekiq.rb</code> 文件开始我们的源码之旅:</p>

<pre><code class="language-ruby">require_relative '../lib/sidekiq/cli'

begin
  cli = Sidekiq::CLI.instance # &lt;==== just skip
  cli.parse
  cli.run # &lt;======== here we go
rescue =&gt; e
  raise e if $DEBUG
  STDERR.puts e.message
  STDERR.puts e.backtrace.join("\n")
  exit 1
end
</code></pre>

<p>启动文件首先是创建一个<code>CLI</code>对象, 执行<code>CLI#parse</code>方法对参数进行解析, 其中包括队列的配置, worker数量的配置, 在此不展开. 紧接着调用<code>CLI#run</code>方法. 让我们继续往下分析, 打开一个<code>CLI#run</code>方法:</p>

<pre><code class="language-ruby">def run
  # 打印控制台 banner 信息, 打印日志及运行环境
  # 信号处理

  self_read, self_write = IO.pipe
  require 'sidekiq/launcher'
  @launcher = Sidekiq::Launcher.new(options)
  begin
    launcher.run # &lt;======= here we go
    while readable_io = IO.select([self_read])
      signal = readable_io.first[0].gets.strip
      handle_single(signal)
    end
  rescue Interrupt
    # 进程接收到的信号处理以及退出逻辑
    launcher.stop
  	exit(0)
  end
end
</code></pre>

<h3 id="从-launcher-到-manager">从 Launcher 到 Manager</h3>

<p><code>CLI#run</code>方法首先是实例化一个<code>Sidekiq::Launcher</code>对象, 紧随其后调用了<code>Launcher#run</code>方法, <code>Launcher#run</code>方法又做了哪些事情呢?</p>

<pre><code class="language-ruby"># lib/launcher.rb
def run
  @thread = safe_thread("heartbeat", &amp;method(:start_heartbeat))
  @poller.start
  @manager.start
end
</code></pre>

<p><code>Launcher#run</code>方法首先通过<code>safe_thread</code>创建了一个新线程, 线程主要负责执行<code>start_heartbeat</code>方法, 其实就是心跳代码, 负责定时检查<code>sidekiq</code>的健康状态, 暂且不表.</p>

<pre><code class="language-ruby"># lib/launcher.rb
def safe_thread(name, &amp;block)
  Thread.new do
    Thread.current['sidekiq_label'] = name
    watchdog(name, &amp;block)
  end
end

def watchdog(last_words)
  yield
rescue Exception =&gt; ex
  handle_exception(ex, { context: last_words })
  raise ex
end
</code></pre>

<p><code>Launcher#run</code>第二行和第三行代码分别启动了<code>@poller</code>以及<code>@manager</code>. 这两个实例是从创建的?</p>

<p>让我们回顾一下前面的<code>lib/cli.rb</code>中的<code>CLI#run</code>方法, 它会负责创建<code>Sidekiq::Launcher</code>的实例, 让我们来看一下<code>Sidekiq::Launcher#initialize</code>定义:</p>

<pre><code class="language-ruby"># lib/launcher.rb
def initialize(options)
  @manager = Sidekiq::Manager.new(options)
  @poller = Sidekiq::Scheduled::Poller.new
  @done = false
  @options = options
end
</code></pre>

<p>我们可以看到, <code>@manager</code>是在创建<code>Sidekiq::Launcher</code>实例的过程中同步创建的<code>Sidekiq::Manager</code>实例.</p>

<p>同理, <code>@poller</code>是同步创建的<code>Sidekiq::Scheduled::Poller</code>实例.</p>

<p>我们首先来看一下<code>@poller.start</code>的逻辑:</p>

<pre><code class="language-ruby"># lib/scheduled.rb
def start
  @thread ||= safe_thread("scheduler") do
    initial_wait

    while !@done
      enqueue
      wait
    end
    Sidekiq.logger.info("Scheduler exiting...")
  end
end
</code></pre>

<p>我们可以看到 <code>Sidekiq::Scheduled::Poller#start</code>方法创建了一个新线程, 在线程中执行了两部分代码:</p>

<ul>
  <li>初始化等待值</li>
  <li>在一个循环中不断的<code>enqueue</code>以及<code>wait</code></li>
</ul>

<p>PS: <code>Sidekiq::Scheduled::Poller#start</code>方法在线程创建完毕之后就会立刻返回, 至于新启动的新线程中的逻辑, 请前往下面的章节<code>Sidekiq::Scheduled::Poller</code>作更深一步分析.</p>

<p>我们继续查看一下<code>@manager</code>的启动到底做了什么:</p>

<pre><code class="language-ruby"># lib/manager.rb
def start
  @workers.each do |x|
    x.start
  end
end
</code></pre>

<p>这里的 <code>@workers</code>是什么? 我们来看一下<code>Sidekiq::Manager#initialize</code>方法:</p>

<pre><code class="language-ruby"># lib/manager.rb
def initialize(options={})
   @options = options
   @count = options[:concurrency] || 25

   @done = false
   @workers = Set.new
   @count.times do
     # 创建 Processor 实例时传入的参数就是 Manager 实例
     @workers &lt;&lt; Processor.new(self)
   end
   # Mutex
   @plock = Mutex.new
 end
</code></pre>

<p>原来如此, 在创建了<code>Sidekiq::Manager</code>实例之后, 又同步创建了多个<code>Sidekiq::Processor</code>的实例, 实例的个数取决于<code>options[:concurrency] || 25</code>, 也就是配置的<code>concurrency</code>的值, 缺省值为<code>25</code>. 至此, 我们知晓 sidekiq中的<code>worker</code>数量就在此设置, <code>Sidekiq::Manager</code>按照配置的数量创建指定数量的 <code>worker</code>.</p>

<p>继续来看我们的<code>Sidekiq::Manager#start</code>方法. 简而言之, <code>Sidekiq::Manager</code>在 <code>start</code>的时候就只做了一件事: 调用其管理的所有的<code>worker</code>的<code>start</code>方法, 就是<code>Sidekiq::Processor#start</code>.</p>

<pre><code class="language-ruby"># lib/processor.rb
def start
  @thread ||= safe_thread("processor", &amp;method(:run))
end
</code></pre>

<p>又是熟悉的味道, 在这里又调用了<code>safe_thread</code>来创建一个新线程, 这就意味着每个<code>worker</code>都是基于自己的一个新线程的, 在这个新线程中执行的是私有方法 <code>Sidekiq::Processor#run</code>:</p>

<pre><code class="language-ruby"># lib/processor.rb
def run
  begin
    while !@done
      process_one
    end
    @mgr.processor_stopped(self)
  rescue Sidekiq::Shutdown
    @mgr.processor_stopped(self)
  rescue Exception =&gt; ex
    @mgr.processor_died(self, ex)
  end
end
</code></pre>

<p>在一个<code>while</code>循环中, 只调用了一个<code>Sidekiq::Processor#process_one</code>实例方法. 顾名思义, 这里是说每个<code>worker</code>(Processor 实例)在没被结束之前, 都重复处理一个新的任务.</p>

<p><code>Sidekiq::Processor#process_one</code>又做了什么工作? 怎么决定应该先处理那个任务? 这就会在后面章节<code>Sidekiq::Processor才是做工的!</code>深入挖掘.</p>

<h3 id="流程时序">流程时序</h3>

<p>我们来总结一下<code>Sidekiq</code>启动之后的处理流程</p>

<p><img src="" alt="Sidekiq start" /></p>

<ol>
  <li>首先创建<code>Sidekiq::CLI</code>实例, 并执行其<code>run</code>方法</li>
  <li><code>Sidekiq::CLI</code>的实例在执行<code>#run</code>过程中, 创建了<code>Sidekiq::Launcher</code>实例, 并调用其<code>#run</code>方法</li>
  <li><code>Sidekiq::Launcher</code>的实例在创建后, 同步创建了<code>Sidekiq::Scheduled::Poller</code>的实例以及<code>Sidekiq::Manager</code>的实例. 在其执行<code>Sidekiq::Launcher::start</code>过程中, 分别调用了这两个实例的<code>start</code>方法</li>
  <li><code>Sidekiq::Scheduled::Poller</code>的实例在执行<code>start</code>过程中, 创建了一个内部循环执行的线程, 不断执行<code>enqueue</code> -&gt; <code>wait</code></li>
  <li><code>Sidekiq::Manager</code>的实例在创建后, 同步创建若干个指定的<code>worker</code>, 也就是<code>Sidekiq::Processor</code>的实例, 并在执行<code>start</code>方法的过程中对每个<code>worker</code>执行<code>start</code></li>
  <li><code>Sidekiq::Processor</code>实例<code>worker</code>在执行<code>start</code>方法的过程中创建了一个新的线程, 在其中循环执行<code>process_one</code></li>
</ol>

<p>以上就是<code>Sidekiq</code>的主要启动过程, 后续分别针对:</p>

<ul>
  <li>Sidekiq::Scheduled::Poller</li>
  <li>Sidekiq::Manager</li>
</ul>

<p>深入研究.</p>

<h2 id="定时任务拉取器">定时任务拉取器</h2>

<p>我们从<code>Sidekiq::Scheduled::Poller#start</code>方法继续我们的源码之旅:</p>

<pre><code class="language-ruby"># lib/scheduled.rb
def start
  @thread ||= safe_thread("scheduler") do
    initial_wait

    while !@done
      enqueue
      wait
    end
    Sidekiq.logger.info("Scheduler exiting...")
  end
end
</code></pre>

<p>我们可以看到, <code>start</code>方法的核心就在<code>while</code>循环中, 在循环之前调用了<code>initial_wait</code>方法:</p>

<pre><code class="language-ruby">INITIAL_WAIT = 10

def initial_wait
  # Have all processes sleep between 5-15 seconds.  
  # 10 seconds to give time for the heartbeat to register
  # (if the poll interval is going to be calculated by the number of workers)
  # 5 random seconds to ensure they don't all hit Redis at the same time.
  total = 0
  total += INITIAL_WAIT unless Sidekiq.options[:poll_interval_average]
  total += (5 * rand)

  @sleeper.pop(total)
  rescue Timeout::Error
end
</code></pre>

<p>结合注释我们可以看出, <code>initial_wait</code>为了避免所有进程在后续逻辑中同时触发<code>Redis IO</code>而做的设计.</p>

<p>这里是为了防止类似雪崩之类的系统故障出现. 让当前进程随机等待一定范围的时间, 从而就可以跟其他进程错开了.</p>

<p>即随其后, 我们来研究一下<code>while</code>循环体中的方法:</p>

<pre><code class="language-ruby">while !@done
  enqueue
  wait
end
</code></pre>

<p>继续查看<code>enqueue</code>的实现:</p>

<pre><code class="language-ruby">def enqueue
  begin
    @enq.enqueue_jobs
  rescue =&gt; ex
    # Most likely a problem with redis networking.
    # Punt and try again at the next interval
    logger.error ex.message
    handle_exception(ex)
  end
end

</code></pre>

<p><code>enqueue</code>只是调用了实例变量<code>@enq</code>的<code>enqueue_jobs</code>方法而已. <code>@enq</code>是在初始化<code>Sidekiq::Scheduled::Poller</code>实例对象中创建的:</p>

<pre><code class="language-ruby">def initialize
  @enq = (Sidekiq.options[:scheduled_enq] || Sidekiq::Scheduled::Enq).new
  @sleeper = ConnectionPool::TimedStack.new
  @done = false
  @thread = nil
end
</code></pre>

<p>缺省的情况下, <code>@enq</code>就是<code>Sidekiq::Scheduled::Enq</code>的实例, 让我们来看一下<code>@enq</code>的实例方法<code>enqueue_jobs</code>:</p>

<pre><code class="language-ruby"># lib/scheduled.rb
SETS = %w(retry schedule)

def enqueue_jobs(now=Time.now.to_f.to_s, sorted_sets=SETS)
  Sidekiq.redis do |conn|
    sorted_sets.each do |sorted_set|
      while job = conn.zrangebyscore(sorted_set, '-inf', now, :limit =&gt; [0, 1]).first do
        if conn.zrem(sorted_set, job)
          Sidekiq::Client.push(Sidekiq.load_json(job))
          Sidekiq::Logging.logger.debug { "enqueued #{sorted_set}: #{job}" }
        end
      end
    end
  end
end
</code></pre>

<p>我把原代码中的注释移除, 让我们来一步步研究<code>enqueue_jobs</code>是如何将定时任务和重试任务推入指定的队列中去的.</p>

<p>首先传入<code>enqueue_jobs</code>的<code>now</code>默认为当前时间,<code>sorted_sets</code>默认为<code>["retry", "schedule"]</code>.</p>

<ul>
  <li>
    <p>retry: 重试任务队列</p>
  </li>
  <li>
    <p>schedule: 定时任务队列</p>

    <p>在<code>Sidekiq</code>中, 重试任务和定时任务实质上都是<code>scheduled jobs</code>. 这两个队列使用了<code>Redis</code>中有序集合类型, 进入队列的任务以其执行时间作为数据的<code>score</code>, 写入<code>Redis</code>之后按照其<code>score</code>排序, 也就是按照任务的计划执行时间排序.</p>
  </li>
</ul>

<p><code>Sidekiq</code>分别针对<code>retry</code>队列和<code>	schedule</code>队列做了一个循环, 循环体内每次通过<code>Redis</code>的<code>ZRANGEBYSCORE</code>命令取出一个计划时间小于等于当前时间的任务:</p>
<pre><code class="language-ruby">job = conn.zrangebyscore(sorted_set, '-inf'.freeze, now, :limit =&gt; [0, 1]).first
</code></pre>

<p>拿到一个<code>job</code>之后, 将其从原队列中移除, 并调用<code>Sidekiq::Client.push</code>  方法将此任务加到指定队列中.</p>

<p>此时<code>job</code>可以看作是马上执行的任务, 可以直接被推入指定的队列</p>

<p><code>job</code>中的内容就是我们之前分析过的哈希 <code>payload</code>:</p>

<pre><code class="language-json">{
  "class": "Platform::ActiveUserWorker",
  "args": ["2018-03-09"],
  "retry": true,
  "queue": "default",
  "jid": "f2c20ffd382925563ffbc6b0",
  "created_at": 1520524801.3932867,
  "enqueued_at": 1520524801.3934016
}
</code></pre>

<p>至此, 我们就知晓了<code>enqueue_jobs</code>就是分别从<code>retry有序集合</code>和<code>schedule</code>有序集合中取出已经到达计划时间的任务, 并将其一一加入到原来的队列.</p>

<p>PS: <strong>定时任务以及重试任务的计划时间只是计划加进执行中队列的时间, 并非执行时间, 执行的时间取决于队列的长度以及队列的执行速度了</strong>.</p>

<p>接着我们的<code>enqueue_jobs</code>, 后面调用<code>wait</code>方法:</p>

<pre><code class="language-ruby"># lib/scheduled.rb
def wait
  @sleeper.pop(random_poll_interval)
rescue Timeout::Error
  # expected
rescue =&gt; ex
  # if poll_interval_average hasn't been calculated yet, we can
  # raise an error trying to reach Redis.
  logger.error ex.message
  handle_exception(ex)
  sleep 5
end
</code></pre>

<p><code>wait</code>方法只是做了一个休眠, 休眠的实现依赖<code>@sleeper</code>的<code>pop</code>方法的实现.</p>

<p><code>@sleeper</code>是在<code>Sidekiq::Scheduled::Poller#initialize</code>的实现的, 它是<code>ConnectionPool::TimeStack</code>的实例, 其<code>pop</code>方法会阻塞当前代码的执行, 直到有值返回或者到达指定的超时时间, 这里<code>Sidekiq</code>就利用了其阻塞的特性, 作为<code>wait</code>方法休眠器的实现.</p>

<p>休眠时间<code>random_poll_interval</code>不固定. 一般来说, 如果没有自行配置, 每次拉取的时间间隔大约在7.5秒–22.5秒</p>

<h3 id="小结">小结</h3>

<p>从本小节的源码分析来看, 我们可以知晓<code>Sidekiq</code>对定时任务和重试任务都一视同仁,处理流程如下:</p>

<ol>
  <li>所有定时任务(包括重试任务)以其计划时间为<code>score</code>,加入到<code>retry</code>和<code>schedule</code>有序集合中</li>
  <li>sidekiq的定时任务拉取器从<code>retry</code>以及<code>schedule</code>有序集合中取出已到达计划时间的任务, 并将其加入该任务计划的队列中, 后续的执行则和普通队列中的任务一致.</li>
  <li>拉取器会每隔随机事件进行休眠, 然后继续从步骤2开始, 周而复始</li>
</ol>

<p>=&gt; 定时任务<code>perform_in</code>以及<code>perform_at</code>计划时间都不是确切的时间!只是允许计划任务加入到普通队列的时间, 具体执行时间还得由队列的长度以及队列的处理速度决定.</p>

<h2 id="sidekiqprocessor-才是做工的">Sidekiq::Processor 才是做工的!</h2>

<p>本小节我们来深入研究一下<code>Sidekiq</code>中做苦力的那个<code>worker</code>.</p>

<p><code>worker</code>核心实现在于<code>process_one</code></p>

<pre><code class="language-ruby"># lib/processor.rb
def process_one
  @job = fetch  #&lt;===== here we go
  process(@job) if @job # &lt;=== next step
  @job = nil
end
</code></pre>

<p>通过调用<code>fetch</code>方法抓取一个任务, 当任务成功获取后, 就将其最为参数传入<code>process</code>方法中去, 由<code>process</code>实际执行任务; 如果没有获取到任务, 则直接重新尝试获取新的任务</p>

<pre><code># lib/processor.rb
def fetch
  j = get_one
  if j &amp;&amp; @done
    j.requeue
    nil
  else
    j
  end
end
</code></pre>

<p><code>fetch</code>方法中的<code>j</code>仿佛又回到了大学期间写<code>C</code>语言的那段时光.</p>

<p><code>fetch</code>方法通过<code>get_one</code>方法从队列中获取任务.</p>

<p>当获取任务之后, 判断当前<code>worker</code>是否已经停止(@done == true), 如果是就将任务重新压入队列中;否则就返回抓取到的一个任务.</p>

<pre><code class="language-ruby"># lib/processor.rb
def get_one
  begin
    work = @strategy.retrieve_work
    # 省略 logger
    work
  rescue Sidekiq::Shutdown
  rescue =&gt; ex
    handle_fetch_exception(ex)
  end
end
</code></pre>

<p>核心代码就是<code>work = @strategy.retrive_work</code>.</p>

<p><code>@strategy</code>必然来自<code>Sidekiq::Processor#initialize</code> 方法:</p>

<pre><code class="language-ruby"># lib/processor.rb
def initialize(mgr)
  # ...
  @strategy = (mgr.options[:fetch] || Sidekiq::BasicFetch).new(mgr.options)
end
</code></pre>

<p>默认情况下使用<code>Sidekiq::BasicFetch</code>类生成一个<code>@strategy</code>实例.</p>

<p>让我们查看一下这个策略类的<code>retrive_work</code>方法:</p>

<pre><code class="language-ruby"># lib/fetch.rb
def retrieve_work
  # 返回值有两个(key, value) queue_name, job =&gt; work
  work = Sidekiq.redis { |conn| conn.brpop(*queues_cmd) } # &lt;===== here we go
  UnitOfWork.new(*work) if work
end
</code></pre>

<p><code>Sidekiq::BasicFetch</code>抓取任务的逻辑是直接通过 <code>Redis BRPOP</code> 命令从所有队列中阻塞地取出第一个任务:</p>

<blockquote>
  <p>BRPOP is a blocking list pop primitive. It is the blocking version of RPOP because it blocks the connection when there are no elements to pop from any of the given lists. An element is popped from the tail of the first list that is non-empty, with the given keys being checked in the order that they are given.</p>

  <p><code>BRPOP key1 [key2 key3 ....] timeout</code></p>
</blockquote>

<p>我们来查看一下<code>queues_cmd</code>此方法究竟做了什么?</p>

<pre><code class="language-ruby"># Creating the Redis#brpop command takes into account any
# configured queue weights. By default Redis#brpop returns
# data from the first queue that has pending elements. We
# recreate the queue command each time we invoke Redis#brpop
# to honor weights and avoid queue starvation.
def queues_cmd
  if @strictly_ordered_queues
    @queues
  else
    queues = @queues.shuffle.uniq # here we go
    queues &lt;&lt; TIMEOUT
    queues
  end
end
</code></pre>

<p>上述代码中的两个实例变量设置于<code>Sidekiq::BasicFetch#initialize</code>:</p>

<pre><code class="language-ruby">def initialize(options)
  @strictly_ordered_queues = !!options[:strict]
  # 读取 `sidekiq` 配置文件中的 `:queues`选项
  @queues = options[:queues].map { |q| "queue:#{q}" }
  if @strictly_ordered_queues
    @queues = @queues.uniq
    @queues &lt;&lt; TIMEOUT
  end
end
</code></pre>

<p>默认情况下我们没有设置<code>options[:strict]</code>, 因此 <code>queue_cmd</code>进入<code>else</code>分支.</p>

<pre><code class="language-ruby">queues = @queues.shuffle.uniq
</code></pre>

<p>这里的<code>@queues</code>来自于<code>options[:queues]</code>中的配置.</p>

<p>让我们来分析一下这个配置到底来自哪里:</p>

<p><img src="" alt="options" /></p>

<p>最终我们在<code>Sidekiq::CLI</code>中调用<code>parse</code>设置<code>options</code>参数的.</p>

<pre><code class="language-ruby">def parse_queue(opts, q, weight=nil)
  [weight.to_i, 1].max.times do
   (opts[:queues] ||= []) &lt;&lt; q
  end
  opts[:strict] = false if weight.to_i &gt; 0
end
</code></pre>

<p><code>Sidekiq</code>在解析<code>:queues</code>的相关配置时, 会按照每个队列及其权重, 生成了一个重复次数等于队列权重的队列的新数组. 看一下我们项目的配置文件<code>sidekiq.yml</code>:</p>

<pre><code class="language-yaml">:queues:
  - [default, 2]
  - [review, 5]
  - [finance, 3]

</code></pre>

<p>根据队列的权重, 生成的数组中就会有同等数量的队列:</p>

<pre><code class="language-ruby">%w(default default review review review review review finance finance finance)
</code></pre>

<p>这里的权重主要用于后面确定每个不同队列被处理到的优先权的比重.</p>

<p>让我们继续讨论:</p>

<pre><code class="language-ruby">queues = @queues.shuffle.uniq
queues &lt;&lt; TIMEOUT
</code></pre>

<p>每次<code>worker</code>在请求信的任务时, <code>Sidekiq</code>都会按照原来的<code>@queues</code>执行<code>shuffle</code>方法. <code>shuffle</code>方法将数组元素随机排序, 亦即“洗牌”. 结合前面的权重, 每个队列洗牌后排在第一位的概率与其权重挂钩.</p>

<p>最后的<code>uniq</code>方法确保队列名称没有重复,避免<code>Redis</code>在执行<code>BRPOP</code>命令时重复检查同一队列.</p>

<p>这里使用<code>BRPOP</code>命令还有一个好处,就是当前面优先级的队列里面没有任务时, 可以依次将机会给后面的队列.</p>

<p>第二行<code>queues &lt;&lt; TIMEOUT</code>则是在<code>BRPOP</code>命令末尾追加超时设置, 也就是<code>Redis</code>命令最多阻塞2秒, 超时则直接放弃.</p>

<p>了解了如何获取任务之后, 任务通过<code>Sidekiq::BasicFetch::UnitOfwork</code>结构化实例后返回给调用方:</p>

<pre><code class="language-ruby">UnitOfWork = Struct.new(:queue, :job) do
  def acknowledge
    # nothing to do
  end

  def queue_name
    queue.sub(/.*queue:/, '')
  end

  def requeue
    Sidekiq.redis do |conn|
      conn.rpush("queue:#{queue_name}", job)
    end
  end
end
</code></pre>

<p>让我们重新回到<code>Sidekiq::Processor#process_one</code></p>

<pre><code class="language-ruby"># lib/processor.rb
def process_one
  @job = fetch
  process(@job) if @job  # here we go
  @job = nil
end
</code></pre>

<p><code>fetch</code>方法返回一个结构体化的实例对象, 然后交给<code>process</code>全权处理:</p>

<pre><code class="language-ruby"># lib/processor.rb
# 移除了一些异常处理代码
def process(work)
  jobstr = work.job
  queue = work.queue_name

  ack = false
  begin
    job_hash = Sidekiq.load_json(jobstr)
    ack = true
    # dispatch 返回经过中间件处理过的一个 SomeWorker实例
    dispatch(job_hash, queue) do |worker|
      # 此处的解释见 `又见中间件`
      Sidekiq.server_middleware.invoke(worker, job_hash, queue) do
        execute_job(worker, cloned(job_hash['args']))
      end
    end
  ensure
    work.acknowledge if ack
  end
end


</code></pre>

<p>我们传入的参数<code>work</code>中就包含之前被压入队列的任务信息,包括队列名称, 任务对应的类, 任务调用所需要的参数,等等.</p>

<pre><code class="language-json">{
  "class": "Platform::ActiveUserWorker",
  "args": ["2018-03-09"],
  "retry": true,
  "queue": "default",
  "jid": "f2c20ffd382925563ffbc6b0",
  "created_at": 1520524801.3932867,
  "enqueued_at": 1520524801.3934016
}
</code></pre>
<p>根据这些信息我们重新实例化任务对象, 并且将实例化的任务对象<code>worker</code>以及任务参数都传递给<code>execute_job</code>调用.</p>

<p>让我们一睹<code>execute_job</code>的实现:</p>

<pre><code class="language-ruby">def execute_job(worker, cloned_args)
  worker.perform(*cloned_args)
end
</code></pre>

<p>原来如此嘛, 我们使用<code>	Sidekiq</code>创建的某个<code>Worker</code>, 最终在此处调用.</p>

<p>至此, 任务的调度过程就到此为止, 剩下的就是周而复始的重复了.</p>

<h3 id="小结-1">小结</h3>

<p>经过上面的分析, 我们可以明白<code>Sidekiq</code>中<code>worker</code>的工作原理:</p>

<ol>
  <li>按照配置文件中设置的队列名称及其权重, 每次重新排列等待处理队列顺序, 高权重的队列有更高的优先级</li>
  <li>将重新排列的队列按顺序传递给<code>Redis BRPOP</code>命令, 同时设置2秒超时</li>
  <li><code>Sidekiq</code>将从队列中获取到实例化的任务, 并且根据携带的参数调用了具体任务的<code>perform</code>方法</li>
</ol>

<h2 id="又遇中间件">又遇中间件</h2>

<p>我们前面在探究<code>Sidekiq::Processor#process</code>方法时有个关键的<code>中间件</code>代码片段:</p>

<pre><code class="language-ruby">Sidekiq.server_middleware.invoke(worker, job_hash, queue) do
  execute_job(worker, cloned(job_hash['args']))
end
</code></pre>

<p>让我们来看一下<code>server_middleware</code>方法:</p>

<pre><code class="language-ruby">def self.server_middleware
  @server_chain ||= default_server_middleware
  yield @server_chain if block_given?
  @server_chain
end
</code></pre>

<p>默认情况下 <code>@server_chain</code>为<code>default_server_middleware</code>:</p>

<pre><code class="language-ruby">def self.default_server_middleware
  Middleware::Chain.new
end
</code></pre>

<p>这里并没有发现内置的中间件, 这是因为<code>sidekiq 5.0.0</code>版本以上的移除了原来存在的<code>RetryJobs</code>以及<code>Logging</code>:</p>

<blockquote>
  <ul>
    <li><strong>BREAKING CHANGE</strong> Job dispatch was refactored for safer integration with
Rails 5.  The <strong>Logging</strong> and <strong>RetryJobs</strong> server middleware were removed and
functionality integrated directly into Sidekiq::Processor.  These aren’t
commonly used public APIs so this shouldn’t impact most users.
      <pre><code>Sidekiq::Middleware::Server::RetryJobs -&gt; Sidekiq::JobRetry
Sidekiq::Middleware::Server::Logging -&gt; Sidekiq::JobLogger
</code></pre>
    </li>
  </ul>
</blockquote>

<p>从<code>Sidekiq</code>更新日志可以看出, 原来的两个内置中间件现在已经直接移到了<code>Sidekiq::Processor类中</code>.</p>

<p>让我们来看一下<code>Sidekiq::Processor#dispatch</code>方法的实现:</p>

<pre><code class="language-ruby">def dispatch(job_hash, queue)
  # since middleware can mutate the job hash
  # we clone here so we report the original
  # job structure to the Web UI
  pristine = cloned(job_hash)

  Sidekiq::Logging.with_job_hash_context(job_hash) do
    @retrier.global(pristine, queue) do
      @logging.call(job_hash, queue) do
        stats(pristine, queue) do
          # Rails 5 requires a Reloader to wrap code execution.  In order to
          # constantize the worker and instantiate an instance, we have to call
          # the Reloader.  It handles code loading, db connection management, etc.
          # Effectively this block denotes a "unit of work" to Rails.
          @reloader.call do
            klass  = constantize(job_hash['class'])
            worker = klass.new
            worker.jid = job_hash['jid']
            @retrier.local(worker, pristine, queue) do
              yield worker
            end
          end
        end
      end
    end
  end
end
</code></pre>

<p>原来的Sidekiq::Processor::<code>Logger</code>中间件以及<code>Sidekiq::Processor::Retry</code>放在了这里处理, 我们直接看一下<code>local</code>方法:</p>

<pre><code class="language-ruby">def local(worker, msg, queue)
  yield
rescue Skip =&gt; ex
  raise ex
rescue Sidekiq::Shutdown =&gt; ey
  # ignore, will be pushed back onto queue during hard_shutdown
  raise ey
rescue Exception =&gt; e
  # ignore, will be pushed back onto queue during hard_shutdown
  raise Sidekiq::Shutdown if exception_caused_by_shutdown?(e)

  if msg['retry'] == nil
    msg['retry'] = worker.class.get_sidekiq_options['retry']
  end

  raise e unless msg['retry']
  attempt_retry(worker, msg, queue, e)
  # We've handled this error associated with this job, don't
  # need to handle it at the global level
  raise Skip
end
</code></pre>

<p>关注点还是在代码的最后<code>attempt_retry</code>. 此处表示当执行中的任务出现异常时, 除去停机的因素以及禁用了重试机制后, 尝试进行下次重试运行.</p>

<pre><code class="language-ruby"># lib/processor.rb
# 移除一些无关紧要的配置
def attempt_retry(worker, msg, queue, exception)
  max_retry_attempts = retry_attempts_from(msg['retry'], @max_retries)

  count = if msg['retry_count']
    msg['retried_at'] = Time.now.to_f
    msg['retry_count'] += 1
  else
    msg['failed_at'] = Time.now.to_f
    msg['retry_count'] = 0
  end

  if count &lt; max_retry_attempts
    delay = delay_for(worker, count, exception)
    logger.debug { "Failure! Retry #{count} in #{delay} seconds" }
    retry_at = Time.now.to_f + delay
    payload = Sidekiq.dump_json(msg)
    Sidekiq.redis do |conn|
      conn.zadd('retry', retry_at.to_s, payload)
    end
  else
    # Goodbye dear message, you (re)tried your best I'm sure.
    retries_exhausted(worker, msg, exception)
  end
end
</code></pre>

<p><code>Sidekiq</code>在捕获异常之后, 首先检查此任务是否已经重试过. 如果之前已经重试, 就在原来计数的基础上<code>+1</code>, 同时更新重试时间; 如果之前没有重试过, 就初始化重试次数为0, 设定初次失败的时间.</p>

<p>随后<code>Sidekiq</code>检查重试的累积次数是否已经超过了最大限制次数, 如果已经超过, 则放弃重试, 毕竟努力了这么多次还失败, 还是<code>go to dead</code>吧; 如果没有超过最大限制次数, 说明还有机会成功, 此任务就会被压入<code>retry</code>队列中.</p>

<p>关于下次重试的时间<code>delay_for</code>本篇文章就不再涉及, 有兴趣的同学可以深入研究一下.</p>

<h3 id="小结-2">小结</h3>

<ul>
  <li><code>Sidekiq</code>在执行任务时, 通过与<code>Rack</code>类似的中间件机制即使捕获失败的任务, 针对允许再次重试的任务, 按照一定的策略计算重试时间</li>
</ul>

<h2 id="总结">总结</h2>

<p>关于<code>Sidekiq</code>源码的解读暂时告一段落. 整个源码很少有弄不懂的地方, 代码的风格也很<code>Ruby</code>, 没有过多的奇异技巧.</p>

<p><code>Sidekiq</code>与<code>Redis</code>的队列和有序集合等数据结构的结合恰到好处, 我们可以通过<code>Sidekiq</code>来加深对<code>Redis</code>的认识, 还可以从中学习如何高效地结合<code>Redis</code>实现业务逻辑.</p>

<p>解读的过程中有一些和我们架构不甚相关的逻辑处理和异常处理都被忽略, 这也是阅读一份源码需要注意的地方,.我们要从大局出发, 将整个框架的组织结构和大的模块理清楚, 然后针对关键的方法深入挖掘.</p>

<h2 id="再会">再会</h2>

<p>本篇文章主要从<code>架构</code>入手, 着重分析了<code>Sidekiq</code>异步任务的调度和实现, 关于多线程以及<code>Unix</code>信号等相关的知识我打算再下一篇文章中详细解读, 敬请期待~</p>

  ]]></description>
</item>

<item>
  <title>TCP Socket 编程 -- 网络架构模式</title>
  <link>//tcp-scokets-arch</link>
  <author>nju520</author>
  <pubDate>2018-03-15T00:00:00+08:00</pubDate>
  <guid>//tcp-scokets-arch</guid>
  <description><![CDATA[
  <p>前面的两篇<code>TCP Socket</code>系列文章涵盖了<code>TCP Socket</code>的基础知识和必备技能, 接下来的部分我们将转向最佳实践和真实案例.</p>

<p>如果你的任务就用<code>Ruby</code>写一个简单的<code>FTP</code> 服务器, 那么仅了解前两篇文章是有所帮助的, 但是这些知识无法让你创造出伟大的软件.</p>

<p>尽管你了解建造模块, 但是你还不知道架构网络应用程序的常见方式, 如何处理并发? 如何处理错误? 处理缓慢的客户端的最好方式是什么? 如何最有效地利用资源?</p>

<p>这类问题正是本篇文章所阐述的. 接下来我们要学习六中网络架构模式, 然后把它们应用到一个案例项目中.</p>

<h2 id="ftp-服务器">FTP 服务器</h2>

<p>与其用一堆图标和抽象的描述, 我更喜欢的说明问题的方式就是采用一个能够实现的案例项目并采用不同的架构重复实现它. 这样才能深刻理解不同架构之间的差异.</p>

<p>出于这个原因, 我要编写一个包含了部分<code>FTP</code>功能的服务器.</p>

<ul>
  <li>
    <p>为什么只包含部分功能呢? 因为我希望将注意力放在<strong>架构模式</strong>,而非协议实现上.</p>
  </li>
  <li>
    <p>为什么选择<code>FTP</code>呢? 因为这样就不用再编写单独的客户端程序就可以测试了. 现成的<code>FTP</code>足够我们测试了.</p>
  </li>
</ul>

<blockquote>
  <p><code>FTP</code>协议就代表文件传输协议(File Transfer Protocol) , 通过运行在<code>TCP</code>之上, 用于两台计算机之间传送文件.</p>
</blockquote>

<p><code>FTP</code>有点像是在浏览文件系统. <code>FTP</code>同时使用两个<code>TCP</code>套接字.</p>

<ul>
  <li>控制套接字(control_socket): 用于在服务器和客户端之间发送<code>FTP</code>命令和参数</li>
  <li>读写数据套接字(connection socket): 每当要传送文件数据时, 就会使用一个新的套接字.</li>
</ul>

<p>分为两个套接字的好处, 使得在传送文件的同时仍然可以在<code>控制套接字</code>上继续处理命令.</p>

<p>我们先来实现这个<code>FTP</code>服务器. 它定义了一些常用的方法, 用于写入格式化的<code>FTP</code>响应以及建立控制套接字. 它还提供了一个<code>CommandHandler</code>类, 封装了基于每个连接的单独命令的处理. 这一点很重要, 同一个服务器上的每个连接可能有不同的工作目录, <code>CommandHandler</code>类也考虑到了这一点.</p>

<pre><code class="language-ruby">module FTP
  class CommandHandler
    # 必须是双引号的 \r\n
    CRLF = "\r\n"

    attr_reader :connection

    def initialize(connection)
      @connection = connection
    end

    def pwd
      @pwd || Dir.pwd
    end

    # 处理具体指令, 根据指令返回对应的数据结果

    def handle(data)
      command = data[0..3].strip.upcase
      options = data[4..-1].strip

      puts "#{show_time} command: #{command}  options: #{options}"

      case command
      when 'USER'
        # 可以接收匿名的用户
        "#{show_time} 230 Logged in anonymously"

      when 'SYST'
        # 用户名?
        "#{show_time} 215 UNIX Working With FTP"

      when 'CWD'
        if File.directory?(options)
          @pwd = options
          "#{show_time} 250 directory change to #{pwd}"
        else
          "#{show_time} 550 directory not found"
        end

      when 'PWD'
        "#{show_time} 257 \"#{pwd}\" is the current directory"

      when 'PORT'
        parts = options.split(',')
        ip_address = parts[0..3].join('.')
        port = Integer(parts[4]) * 256 + Integer(parts[5])

        # 启动一个新的 `socket`, 作为 client 来响应 `FTP`客户端的请求
        @data_socket = TCPSocket.new(ip_address, port)
        "#{show_time} 200 Active connection established (#{port})"

      when 'HeHe'
        parts = options.split(',')
        address_family = parts[0]
        ip_address = parts[2..5].join('.')
        port = Integer(parts[7]) * 256 + Integer(parts[8])

        # 启动一个新的 `socket`, 作为 client 来响应 `FTP`客户端的请求
        @data_socket = TCPSocket.new(ip_address, port)
        "#{show_time} 200 Long Port Active connection established (#{port})"

      when 'RETR'
        file = File.open(File.join(pwd, options), 'r')
        connection.respond "125 Data transfer starting #{file.size} bytes"

        bytes = IO.copy_stream(file, @data_socket)
        @data_socket.close

        "#{show_time} 226 Closing data connection, sent #{bytes} bytes"

      when 'LIST'
        connection.respond '125 Opening data connection for file list'

        result = Dir.entries(pwd).join(CRLF)
        @data_socket.write(result)
        @data_socket.close

        "#{show_time} 226 Closing data connection, sent #{result.size} bytes"

      when 'QUIT'
        "#{show_time} 221 Ciao"
      else
        "#{show_time} 502 Don't know how to respond to #{command}"
      end

    end

    private
    def show_time
      "[#{Time.now.strftime("%Y-%m-%d %H:%M")}]"
    end
  end
end

</code></pre>

<p>再接下来的几个小节我们分别实现不同架构的服务器.</p>

<h2 id="串行化">串行化</h2>

<p>我们要学习的第一个网络架构模式就是处理请求的<code>串行化模型</code>.</p>

<h3 id="流程">流程</h3>

<p>在串行化架构中, 所有的客户端连接都是依次进行处理的. 因为不涉及并发, 多个客户端不会同时接受服务.</p>

<p>串行化架构的处理流程很直观:</p>

<ol>
  <li>客户端连接</li>
  <li>客户端/服务器交换请求及响应</li>
  <li>客户端断开连接</li>
  <li>返回步骤1</li>
</ol>

<h3 id="实现">实现</h3>

<pre><code class="language-ruby"># serial.rb
#  串行化架构处理流程
# 1. 客户端连接
# 2. 客户端/服务器 交换请求并响应
# 3. 客户端断开连接
# 4. 返回步骤一重复下一此连接

require 'socket'
require_relative 'command_handler'

module FTP
  CRLF = '\r\n'

  class Serial

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def gets
      @client.gets(CRLF)
    end

    def respond(message)
      @client.write(message)
      @client.write(CRLF)
    end

    def run
      loop do
        @client = @control_socket.accept
        respond '220 OHAI'

        # 创建一个新的 `socket` 连接来单独处理请求
        handler = CommandHandler.new(self)

        loop do
          # 接收来自客户端的请求
          request = gets
          if request
            respond handler.handle(request)
          else
            @client.close
            break
          end
        end
      end
    end

  end
end

# 初始化我们的一个服务器实例
server = FTP::Serial.new(4481)

# 启动服务器
server.run

</code></pre>

<p><code>FTP::Serial</code>类只负责联网和并发操作, 协议处理部分交给<code>FTP::CommandHandler</code>类的方法来处理. 接下来你会经常看到这种模式.</p>

<p>让我们从头开始分析串行化架构模式.</p>

<pre><code class="language-ruby">class Serial

  def initialize(port = 21)
    @control_socket = TCPServer.new(port)
    trap(:INT) {exit}
  end

  def gets
    @client.gets(CRLF)
  end

  def respond(message)
    @client.write(message)
    @client.write(CRLF)
  end
end
</code></pre>

<p>这三个方法属于这类特定实现的样板代码<code>boilerplate</code>.</p>

<ul>
  <li>
    <p>initialize: 打开一个套接字, 由该套接字接受客户端连接</p>
  </li>
  <li>
    <p>gets: 将<code>gets</code>委托给当前客户端连接. 它传递了一个明确的分隔符, 用以保证在具有不同默认分隔符的平台之间的可移植性.</p>
  </li>
  <li>
    <p>respond: 用来写入格式化过的<code>FTP</code>响应. <code>message</code>中包含了整数类型的响应代码以及对应的字符串详细. 当<code>FTP客户端</code>收到<code>\r\n</code>组合时, 它就知道已经获得了完整的响应信息.</p>

    <p>​</p>
  </li>
</ul>

<pre><code class="language-ruby">def run
  loop do
    @client = @control_socket.accept
    respond '220 OHAI'

    handler = CommandHandler.new(self)
  end
end
</code></pre>

<p>这是服务器的主循环, 所有的处理逻辑都发生在外部主循环之内.</p>

<p>循环中唯一调用<code>accept</code>就在此. 它接受一个来自<code>@control_socket</code>的连接, 后者在<code>initialize</code>中进行初始化. 代码响应<code>220</code>是属于<code>FTP</code>规定的, 表示<code>Service ready for new user</code>, <code>FTP</code>服务要求服务器在接受一个新的客户端连接之后要打声招呼.</p>

<p>最后一处为该连接进行<code>CommandHandler</code>的初始化. 该类封装了服务器上的每个连接的当前状态( 当前工作目录). 我们可以将接入的请求交给<code>handler</code>对象, 然后获得对应的响应.</p>

<p>这部分代码是串行化代码只进行并发的绊脚石. 进行处理时, 服务器没发继续接受新的连接, 更谈不上实现并发了. 当我们学到其他模式如何应对这种情况时, 就会明显看出它们之间的差异了.</p>

<pre><code class="language-ruby">loop do
  request = gets

  if request
    respond handler.handle(request)
  else
    @client.close
    break
  end
end
</code></pre>

<p>这部分完成了我们的<code>FTP服务器</code>的串行化实现.</p>

<p>在内部循环中, 使用<code>gets</code>从客户端套接字中获取带有显式分隔符的请求, 然后将请求交给<code>handler</code>来处理,由它为客户端构造对应的响应信息.</p>

<h3 id="运行">运行</h3>

<p>鉴于这是一个功能完善的<code>FTP服务器</code>, 我们实际上可以运行该服务器, 使用标准的<code>FTP客户端</code>进行连接, 来看一下它的表现:</p>

<pre><code class="language-shell"># 开启 `FTP服务器`
$ ruby serial.rb


# 开启 标准的`FTP客户端`
$ ftp -a -v localhost 4481

# 输入指令
$ pwd

$ cd /var/log


</code></pre>

<p>我们可以通过查看系统进程信息来看一下<code>串行化架构</code>的进程模式:</p>

<pre><code class="language-shell">λ lsof -i:4481
COMMAND   PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME
ruby    73426 bobo    9u  IPv6 0x60dd91188c3b4949      0t0  TCP *:4481 (LISTEN)
ruby    73426 bobo   10u  IPv6 0x60dd91188c3b6049      0t0  TCP localhost:4481-&gt;localhost:62166 (ESTABLISHED)
gftp    73435 bobo    3u  IPv4 0x60dd9118a7de4731      0t0  TCP localhost:62166-&gt;localhost:4481 (ESTABLISHED)
gftp    73435 bobo    4u  IPv4 0x60dd9118a7de4731      0t0  TCP localhost:62166-&gt;localhost:4481 (ESTABLISHED)
gftp    73491 bobo    3u  IPv4 0x60dd9118a7dee091      0t0  TCP localhost:62168-&gt;localhost:4481 (ESTABLISHED)
gftp    73491 bobo    4u  IPv4 0x60dd9118a7dee091      0t0  TCP localhost:62168-&gt;localhost:4481 (ESTABLISHED)

</code></pre>

<p>我们通过指令<code>lsof -i:4481</code>查看端口 <code>4481</code>上的进程:</p>

<ul>
  <li><code>73426</code>: 此进程为控制套接字进行, 负责接受客户端的请求并且返回指令和参数
    <ul>
      <li>第二行的<code>PID</code>	仍然是<code>73426</code>, 这说明串行架构并没有开辟新的进程来处理请求, 而是在同一个进程下.</li>
    </ul>
  </li>
  <li>73435: 我们运行的第一个<code>FTP客户端</code>, 负责向<code>FTP服务器</code>发送请求</li>
  <li>73491: 我们运行的第二个<code>FTP客户端</code>. 我还注意到只有第一个客户端退出时, 服务器才会响应第二个客户端的请求.</li>
</ul>

<blockquote>
  <p>Mac OS High Sierra 已经把<code>FTP</code> 命令行工具移除, 只能使用<code>sftp</code>访问, 我们可以使用如下方式安装:</p>

  <pre><code class="language-shell">$ brew install inetutils

$ brew link --overwrite inetutils

# 安装成功后将下面路径加入到 ~/.zshrc
export PATH="/usr/local/opt/inetutils/libexec/gnubin:$PATH"

MANPATH="/usr/local/opt/inetutils/libexec/gnuman:$MANPATH"

就可以直接使用 `ftp`命令并可以通过 `man`来查看帮助
</code></pre>
</blockquote>

<h3 id="思考">思考</h3>

<p>很难明确地归纳每种模式的优劣, 因为这完全取决于我们的需求. 我会尽力解释每种模式最适用的场景及其所做出的一些权衡.</p>

<p><strong>串行化架构</strong> 最大的优势在于它的简单性. 没有锁, 没有共享状态, 处理完一个连接之后才能处理另外一个. 在资源使用方面亦是如此: 一个实例处理一个连接, 一个萝卜一个坑, 绝不多消耗资源.</p>

<p><strong>串行化架构</strong> 最大的劣势就是不能并发操作. 及时时当前连接处于空闲, 也不能处理等待的连接. 同样, 如果某个连接使用的链路速度不佳, 或者在发送请求之间暂停, 那么服务器就只能保持阻塞, 直到连接关闭.</p>

<p>对接下来更有意思的模式而言,  <strong>串行化模式</strong> 仅仅只是一个起点而已.</p>

<h2 id="单连接进程">单连接进程</h2>

<blockquote>
  <p>这是首个可以对请求进行并行处理的网络架构</p>
</blockquote>

<h3 id="流程-1">流程</h3>

<p>要支持并发处理, 只需要将串行化架构略加修改即可. 接受连接的代码不需要改动, 处理来自套接字数据的逻辑<code>CommandHandler</code>也保持不变.</p>

<p>相关改动出现在<strong>接受连接</strong>之后, 服务器会<code>fork</code>出一个子进程, 这个子进程的唯一目的就是在处理新连接. 连接处理完毕之后就退出.</p>

<blockquote>
  <p>进程衍生:</p>

  <p>只要我们使用命令 <code>ruby myapp.rb</code>启动程序, 就会生成一个新的<code>Ruby</code>进程来载入并执行代码.</p>

  <p>如果在程序中使用<code>fork</code>, 那实际上就是在运行期间创建了一个新进程. <code>fork</code>可以使我们获得两个一模一样的进程. 新创建的进程被视为“孩子”; 原先的进程被视为“双亲”. 一旦<code>fork</code>完成, 就拥有了两个进程,它们可以各行其道.</p>

  <p>这一点及其重要, 它意味着我们可以 <code>accept</code>一个连接, <code>fork</code>一个子进程, 这个子进程就会自动获得一份客户端连接的副本. 无需其他设置、数据共享或者锁, 直接就可以开始并行处理了.</p>
</blockquote>

<p>让我们来理清事件流程:</p>

<ol>
  <li>一个连接抵达服务器</li>
  <li>主服务器进程接受该连接</li>
  <li>主进程衍生出一个和服务器主进程一模一样的新子进程</li>
  <li>服务器主进程返回步骤1, 由子进程并行处理连接</li>
</ol>

<p>得益于内核语义, 这些进程是并行执行的. 子进程处理连接时, 原先的父进程可以继续接受新连接, 衍生出新的子进程对新连接进行处理.</p>

<p>不管何时, 总是有一个父进程等着接受连接, 但是会有多个子进程分别处理单个连接.</p>

<h3 id="实现-1">实现</h3>

<pre><code class="language-ruby">#  串行化架构处理流程
# 1. 一个连接抵达芙蕖
# 2. 主服务器进程接受该连接
# 3. 主进程衍生出和服务器一模一样的子进程
# 4. 服务器主进程返回步骤 1, 由子进程并行处理连接


require 'socket'
require_relative 'command_handler'

module FTP
  CRLF = '\r\n'

  class ProcessPerConnection

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def gets
      @client.gets(CRLF)
    end

    def respond(message)
      @client.write(message)
      @client.write(CRLF)
    end

    def run
      loop do
        @client = @control_socket.accept

        pid = fork do
          respond '220 OHAI'

          handler = CommandHandler.new(self)
          loop do
            request = gets

            if request
              respond handler.handle(request)
            else
              @client.close
              break
            end
          end
        end

        Process.detach(pid)

      end
    end

  end
end

# 初始化我们的一个服务器实例
server = FTP::ProcessPerConnection.new(4481)

# 启动服务器
server.run

</code></pre>

<p>如你所见, 大部分代码都没有变动. 最大的不同在于内循环被放在了一个<code>fork</code>调用中</p>

<pre><code class="language-ruby">@client = @control_socket.accept

pid = fork do
  respond '220 OHAI'

  handler = CommandHandler.new(self)
  #...
end
</code></pre>

<p>使用<code>accept</code>接受连接之后, 服务器进程立刻使用代码块来调用<code>fork</code>. 新的子进程会对该代码块进行求值, 然后退出.</p>

<p>这意味着每一个接入的连接都由一个独立的进程处理. 父进程不会对代码块求值, 它只会沿着自己的执行路径进行.</p>

<pre><code class="language-ruby">Process.detach(pid)
</code></pre>

<p>我们在最后调用了<code>Process.detach</code>. 在一个进程退出之后, 它并不会被完全清除, 直到其父进程查询该进程的退出状态. 在这里我们并不关心子进程的退出状态是什么, 所有提前把它与父进程分离. 确保子进程退出后, 所占用的资源能够完全清除.</p>

<p>让我运行 <code>lsof -wni tcp:4481</code>查看一下端口<code>4481</code>的情况吧:</p>

<pre><code class="language-shell">λ lsof -wni tcp:4481
COMMAND   PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME
ruby    84347 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84347 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
ruby    84347 bobo   11u  IPv6 0x60dd91188c3b6049      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63002 (ESTABLISHED)
ruby    84347 bobo   12u  IPv6 0x60dd91188c3b6609      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63017 (ESTABLISHED)
gftp    84355 bobo    3u  IPv4 0x60dd9118a6cb3351      0t0  TCP 127.0.0.1:62997-&gt;127.0.0.1:4481 (ESTABLISHED)
gftp    84355 bobo    4u  IPv4 0x60dd9118a6cb3351      0t0  TCP 127.0.0.1:62997-&gt;127.0.0.1:4481 (ESTABLISHED)
ruby    84356 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84356 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
gftp    84373 bobo    3u  IPv4 0x60dd91188bda2731      0t0  TCP 127.0.0.1:63002-&gt;127.0.0.1:4481 (ESTABLISHED)
gftp    84373 bobo    4u  IPv4 0x60dd91188bda2731      0t0  TCP 127.0.0.1:63002-&gt;127.0.0.1:4481 (ESTABLISHED)
ruby    84374 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84374 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
ruby    84374 bobo   11u  IPv6 0x60dd91188c3b6049      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63002 (ESTABLISHED)
gftp    84859 bobo    3u  IPv4 0x60dd91188fc9bcb1      0t0  TCP 127.0.0.1:63017-&gt;127.0.0.1:4481 (ESTABLISHED)
gftp    84859 bobo    4u  IPv4 0x60dd91188fc9bcb1      0t0  TCP 127.0.0.1:63017-&gt;127.0.0.1:4481 (ESTABLISHED)
ruby    84860 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84860 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
ruby    84860 bobo   11u  IPv6 0x60dd91188c3b6049      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63002 (ESTABLISHED)
ruby    84860 bobo   12u  IPv6 0x60dd91188c3b6609      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63017 (ESTABLISHED)

</code></pre>

<p>从端口情况可以看出, 我打开了三个客户端,   每打开一个客户端, 我们的<code>FTP服务器</code>就会开辟一个新的进程来处理客户端请求, 主进程继续循环接受客户端连接.</p>

<h3 id="思考-1">思考</h3>

<p><strong>单连接进程</strong> 有很多优势.</p>

<ul>
  <li>
    <p>简单. 为了能够<strong>并行处理</strong>多个客户端, 只需要在串行化实现的基础上增加及少量的代码即可</p>
  </li>
  <li>
    <p>这种并行操作不难理解. <code>fork</code>实际上提供了一个子进程所需要的所有东西的副本. 我们不需要留心边界情况, 没有锁和竞争条件, 只是简单的分离而已.</p>

    <p>一个明显的劣势就是, 对于<code>fork</code>出的子进程的数量没有施加限制. 如果客户端的数量不大, 这倒没什么大问题, 但是如果生成了上百个进程, 那么我们的系统可能会崩溃了. 这方面可以使用我们接下来要实现的<code>preforking</code>模式来解决.</p>

    <p>还有一点, 对于不同的操作环境, 使用<code>fork</code>可能会出现问题. 只有<code>Unix</code>系统才支持<code>fork</code>, 这意味着<code>Windows</code>或者<code>JRuby</code>就没发使用<code>fork</code>了.</p>

    <p>我们究竟该使用<code>进程</code>还是<code>线程</code>, 这个问题留到下一小节来讨论, 届时我们会接触到线程.</p>
  </li>
</ul>

<h2 id="单连接线程">单连接线程</h2>

<h3 id="讲解">讲解</h3>

<p><strong>单连接线程模式</strong> 和上一节的 <strong>单连接进程模式</strong> 非常相似. 不同之处就在于, 它是生成新线程, 而非新进程</p>

<blockquote>
  <p>线程与进程</p>

  <p>线程和进程都可以用于并行操作, 但是方式大不相同, 究竟使用哪个取决于实际情况.</p>

  <p><strong>生成(spawn)</strong>: 就生成而言, 线程的生成成本要低得多. 生成一个进程需要创建原始进程所拥有的一切资源的副本. 线程以进程为单位, 多个线程都存在于同一个进程中. 由于多个线程共享存在, 无需创建副本, 因而线程的生成速度要快得多.</p>

  <p><strong>同步(sync)</strong>: 因为线程共享内存, 当使用会被多个线程访问的数据结构时, 一定要多加小心. 这通常意味着要在线程之间使用互斥量(mutex)、枷锁以及同步访问. 进程就无需如此了, 因为每个进程都有自己的一份资源副本.</p>

  <p><strong>并行(p)</strong>: 两者都提供了由内核实现的并行计算能力. 关于<code>MRI</code>中的线程并行需要注意的一件重要的事情: 解释器对当前执行环境使用了一个<strong>全局锁</strong>. 因为线程以进程为单位, 这意味着它们都运行在一个解释器中. 即使使用了多线程, <code>MRI</code>也使得它们无法实现真正的并行. 在另外一些<code>Ruby</code>实现中, 如<code>JRuby</code>或者<code>Rubinius2.0</code>, 就不存在这样的问题.</p>

  <p>进程没有这方面的麻烦, 因为每次都是生成新的进程, 它都会获得自己的一份<code>Ruby解释器</code>的副本, 所以也就无需全局锁. 在<code>MRI</code> zhong , <strong>只有进程才能实现真正的并发</strong></p>

  <p>关于并行和线程还要说明一点. 即使是<code>MRI</code>使用了全局解释器🔒, 它对线程的处理也非常巧妙. 如果某个线程阻塞在<code>IO</code>上, <code>Ruby</code>能够让其他的线程继续执行.</p>

  <p>总而言之, 线程是轻量级的, 进程是重量级的. 两者都用于并行操作, 两者都有各自适用的环境.</p>
</blockquote>

<h3 id="实现-2">实现</h3>

<pre><code class="language-ruby">#  单连接线程架构处理流程
# 1. 启动一个线程池, 初始化一个 `control_socket`
# 2. 每接受一个新的连接请求时, 创建一个新线程来处理
# 3. `control_socket` 继续返回 2 等待接受新的连接

require 'socket'
require_relative 'command_handler'

module FTP

  Connection = Struct.new(:client) do
    CRLF = "\r\n"

    def gets
      client.gets(CRLF)
    end

    def respond(message)
      client.write(message)
      client.write(CRLF)
    end

    def close
      client.close
    end
  end

  class ThreadPerConnection

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) { exit }
    end

    def run
      Thread.abort_on_exception = true

      loop do
        # 接受客户端请求
        conn = Connection.new(@control_socket.accept)

        Thread.new do
          conn.respond '220 OHAI'

          handler = FTP::CommandHandler.new(conn)
          loop do
            request = conn.gets

            if request
              conn.respond handler.handle(request)
            else
              conn.close
              break
            end
          end
        end
      end
    end # end of run

  end
end

# 初始化我们的一个服务器实例
server = FTP::ThreadPerConnection.new(4481)

# 启动服务器
server.run

</code></pre>

<p>之前的样板代码被我放到了<code>Connection</code>类中, 而不是直接定义在服务器类中:</p>

<pre><code class="language-ruby">connection = Struct.new(:client) do
  def gets
  # ..
  end

  def respond(message)
  # ..
  end

  def close
  # ..
  end
end
</code></pre>

<p><code>run</code>方法我们也采用创建线程的模式:</p>

<pre><code class="language-ruby">def run
  Thread.abort_on_exception = true

  loop do
    # 接受客户端请求
    conn = Connection.new(@control_socket.accept)

    Thread.new do
      conn.respond '220 OHAI'

      handler = FTP::CommandHandler.new(conn)
      loop do
        request = conn.gets

        if request
          conn.respond handler.handle(request)
        else
          conn.close
          break
        end
      end
    end
  end
end # end of run
</code></pre>

<p>这其中有两处关键的不同.</p>

<ul>
  <li>采用 <code>Thread.new</code>生成了一个线程</li>
  <li>从<code>accept</code>返回的客户端套接字被传给<code>Connection.new</code>; 每个线程均获得自己的<code>Connection</code> 实例</li>
</ul>

<p>使用线程时, 每个线程使用一个全新的<code>Connection</code>实例非常重要. 如果我们像以前那样, 简单地将客户端套接字分配给一个实例变量, 那么它会在所有的活动现场之间共享. 因为这些线程是从一个共享的<code>FTP服务器</code>  实例中生成的, 所有它们会共享该实例的内部状态.</p>

<p>这与同进程打交道有着显著差别, 在后者中每个进程都会获得内存中所有资源的副本.</p>

<blockquote>
  <p>之所以很多开发者声称线程编程不容易, 其中一个原因便是状态共享. 如果你使用线程进行套接字编程, 有一条简单的经验: 让每个线程获得它自己的连接对象.</p>
</blockquote>

<h3 id="思考-2">思考</h3>

<p><strong>单连接线程模式</strong> 与 <strong>单连接进程模式</strong> 有很多共同的优势: 代码修改量少, 很容易理解.</p>

<p>尽管使用线程会引入锁以及同步问题, 但是这里我们并不用担心这个问题, 因为每个连接都是由单个独立线程来处理的.</p>

<p>该模式较 <strong>单连接进程</strong> 的一个优势就是线程占用资源少, 因而获得数量上的增加. 比起进程, 它能够为客户端服务提供更好的并发性.</p>

<p>不过先等等, 别忘了<code>MRI GIL</code>使得这一优势无法变成现实. 归根结底, 没有哪个模式能够所向披靡, 每一种模式都应该思考、尝试、检验.</p>

<p><strong>单连接线程模式</strong> 与 <strong>单连接进程模式</strong> 都有一个共同的劣势: 线程数会不断增加, 直到系统不堪重负.</p>

<p>如果你的服务器要处理持续增加的连接, 系统可能难以在所有的活动线程上进行维护和切换.</p>

<p>这可以通过限制活动线程数解决.</p>

<h2 id="preforking">Preforking</h2>

<h3 id="讲解-1">讲解</h3>

<p><code>Preforking</code>模式是建立在<strong>单连接进程模式</strong>的基础上.</p>

<p>它依赖进程作为并行操作的手段, 但并不为每个接入的连接衍生出对应的子进程, 而是在服务器启动后, 连接到达之前就预先衍生出一批进程.</p>

<h4 id="处理流程">处理流程</h4>

<ol>
  <li>主服务器进程创建一个侦听套接字</li>
  <li>主服务器进程衍生出一大批子进程</li>
  <li>每个子进程在共享套接字上接受连接, 然后独立进行处理</li>
  <li>主服务器进行密切关注子进程</li>
</ol>

<p>这个流程的重点在于, 主服务器进程打开侦听套接字, 却并不接受该套接字之上的连接. 它随后衍生出预定义数量的一批子进程, 每个子进程都有一份侦听套接字的副本. 子进程在各自的侦听套接字上调用<code>accept</code>, 不再考虑父进程.</p>

<p>这个模式的精妙之处在于, 无需担心负载均衡或者子进程连接的同步, 因为内核已经替我们完成这个工作了.</p>

<p>对于多个进程试图在同一个套接字的不同副本上接受(accept)连接的问题, 内核会均衡负载并确保只有一个套接字副本可以接受某个特定的连接</p>

<h3 id="实现-3">实现</h3>

<pre><code class="language-ruby"># Preforking

require 'socket'
require_relative 'command_handler'

module FTP
  CRLF = "\r\n"
  CONCURRENCY = 4

  class Preforking

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def gets
      @client.gets(CRLF)
    end

    def respond(message)
      @client.write(message)
      @client.write(CRLF)
    end

    def run
      child_pids = []

      CONCURRENCY.times do
        child_pids &lt;&lt; span_child
      end

      trap(:INT) {
        child_pids.each do |child_pid|
          begin
            Process.kill(:INT, child_pid)
          rescue Errno::ESRCH
          end
        end

        exit
      }

      loop do
        pid = Process.wait
        $stderr.puts "[#{Time.now.stftime("%Y-%m-%d %H:%M")}] Process #{pid} quit unexpectedly"

        child_pids.delete(pid)
        child_pids &lt;&lt; span_child
      end

    end # end of run

    def span_child
      fork do
        loop do
          @client = @control_socket.accept
          respond '220 OHAI'

          handler = CommandHandler.new(self)
          loop do
            request = gets

            if request
              respond handler.handle(request)
            else
              @client.close
              break
            end
          end
        end
      end
    end # end of span_child

  end
end

# 初始化我们的一个服务器实例
server = FTP::Preforking.new(4481)

# 启动服务器
server.run

</code></pre>

<p>我们先来看一下 <code>run</code>方法:</p>

<p>我们会在<code>run</code> 方法中多次调用了<code>spawn_child</code>方法, 具体次数基于我们自定义的<code>CONCURRENCY</code>中的值而定. <code>spawn_child</code>会<code>fork</code>一个新进程然后返回其进程<code>id</code>, 该值是唯一的.</p>

<p>生成子进程后, 父进程为<code>INT</code>信息定义了一个信号处理器. 当你键入<code>Ctrl+C</code>时, 进程就会收到该信号. 这个信号处理器仅用于将父进程接收到的<code>INT</code>信号转发给它的子进程.</p>

<p>因为子进程独立于父进程存在, 即使是父进程结束了, 子进程也不会收到影响. 所以对于父进程而言, 在退出之前清理自己的子进程就很有必要.</p>

<p>信号处理完之后, 父进程就进入了<code>Process.wait</code>循环. 该方法会一直阻塞到有子进程退出为止.</p>

<p><code>Process.wait</code>返回退出子进程的<code>pid</code>.因为子进程并不应该退出, 所有我们将<code>子进程异常退出</code>视为一场情况.</p>

<p>随后在<code>STDERR</code>上打印一条信息并生成一个新的子进程代替.</p>

<p>在一些<code>Preforking</code>服务器中, 尤其是<code>Unicorn</code>, 父进程承担了更为活跃的角色, 它还负责监视自己的子进程. 例如父进程可能会查看是否有哪个子进程耗费了太多的时间处理请求. 如果是, 父进程会终止该进进程并生成新的子进程取代它.</p>

<p>我们再来看一下<code>spawn_child</code>方法:</p>

<p>这种方法的核心部分应该很熟悉了. 这次它被放入了<code>fork</code>和<code>loop</code>外. 因此新进程在调用<code>accept</code>之前就已经衍生出来了. 最外层的循环确保每个连接处理并关闭后, 继续处理新的连接. 通过这种方法, 每个子进程都处于它们各自的<code>接受连接</code>循环中.</p>

<h3 id="思考-3">思考</h3>

<p><code>Preforking</code>不用在每个连接期间进行<code>fork</code>. 进程衍生的成本可不少.在单连接进程架构中, 每个连接都要承担由此带来的开销.</p>

<p>由于<code>Preforking</code>在<code>accept</code>连接之前就生成了所有连接, 因而避免了进程过量的情况.</p>

<p>比起与<code>Preforking</code>类似的线程模式, 这个模式的一个优势就是完全隔离.</p>

<p>因为每个进程都拥有包括<code>Ruby</code>解释器在哪的所有资源的副本, 单个进程中的故障不会影响其他进程.</p>

<p>因为线程共享资源以及内存空间, 单线程故障可能会无法预测地影响到其他线程.</p>

<p><code>Preforking</code>的一个劣势就是: 衍生的进程越多, 消耗的内存也越多.</p>

<p>进程可不是免费的午餐. 考虑到每个衍生的进程都会获得所有资源的一份副本, 我们可以预料到每一次进程衍生, 内存占用率就要增加100%(以父进程为基准).</p>

<p>按照这种衍生方式, 占用<code>100MB</code>内存的进程在衍生出4个子进程之后将占用<code>500MB</code>内存.</p>

<p>即使这样, 也才4个并发连接.</p>

<h2 id="线程池">线程池</h2>

<p>线程池模式之于 <code>Preforking</code>, 一如单连接线程与单连接进程之间的关系. 同<code>Preforking</code>类似, 线程池在服务器启动后会生成一批线程, 将处理连接的任务交给独立的线程来完成.</p>

<p><strong>线程池模式</strong> 处理流程和<code>Preforking</code>一样, 只需要把“进程”修改为“线程”就行了.</p>

<pre><code class="language-ruby"># ThreadPool

require 'socket'
require 'thread'
require_relative 'command_handler'

module FTP
  Connection = Struct.new(:client) do
    CRLF = "\r\n"

    def gets
      client.gets(CRLF)
    end

    def respond(message)
      client.write(message)
      client.write(CRLF)
    end

    def close
      client.close
    end
  end

  class ThreadPool
    CONCURRENCY = 25

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def run
      Thread.abort_on_exception = true
      threads = ThreadGroup.new


      CONCURRENCY.times do
        threads.add spawn_thread
      end

      sleep
    end

    def spawn_thread
      Thread.new do
        loop do
          conn = Connection.new(@control_socket.accept)
          conn.respond '220 OHAI'

          handler = CommandHandler.new(self)

          loop do
            request = conn.gets

            if request
              conn.respond handler.handle(request)
            else
              conn.close
              break
            end
          end
        end
      end
    end # end of spawn_thread

  end
end

# 初始化我们的一个服务器实例
server = FTP::ThreadPool.new(4481)

# 启动服务器
server.run

</code></pre>

<p>这里在此出现了两个方法: 一个用来生成线程, 一个用来封装线程生成以及线程从未.</p>

<p>因为我们使用的是线程,因此还需要使用<code>Connnection</code>类.</p>

<pre><code class="language-ruby">def run
  Thread.abort_on_exception = true
  threads = ThreadGroup.new


  CONCURRENCY.times do
    threads.add spawn_thread
  end

  sleep
end
</code></pre>

<p><code>run</code> 方法创建了一个<code>ThreadGroup</code>实例跟踪所有的线程. <code>ThreadGroup</code>有点像一个可对线程进行操作的数组. 我们可以 向<code>ThreadGroup</code>中加入线程, 当某个线程成员执行结束之后, 它就会从这个线程组中丢弃.</p>

<p>我可以使用<code>ThreadGroup#list</code>获得组中当前所有活动现场列表.在这个实现中, 我们其实并没有用到这个技巧.</p>

<p>同上一节的<strong>Preforking</strong>类似, 我们依据<code>CONCURRENCY</code>的值多次调用<code>spawn_thread</code>. 注意这里的<code>CONCURRENCY</code>的值要比<code>Preforking</code>中的高. 这还是因为线程的开销更小一些, 所有我们可以使用更多的线程. 要记住的是<code>MRI GIL</code>减少了一部分由此带来的收益.</p>

<p>方法的最后我们调用了<code>sleep</code>来避免方法退出. 当线程池中的线程有工作任务时, 主线程保持空闲. 理论上它可以监视线程池, 不过这里我们只是使用了<code>sleep</code>不让其退出.</p>

<p><code>spawn_thread</code>方法平淡无奇, 没什么出彩之处, 它和 <code>Preforking</code>中<code>spawn_child</code>一样. 生成一个线程, 重复执行连接处理代码.内核会确保一个连接只能由单个线程接受.</p>

<h3 id="思考-4">思考</h3>

<p>有关线程池模式大部分的思路内容和<code>Preforking</code>一样.</p>

<p>除了那些线程和进程之间显而易见的权衡之外, 线程池模式不需要每次处理连接时都生成线程, 也没有什么令人抓狂的锁或者竞争条件, 但却仍提供了并行处理能力.</p>

<h2 id="事件驱动">事件驱动</h2>

<p>迄今为止我没看到的这些模式其实都是串行化模式的变体而已. 其他的几种模式实际上使用的结构和串行化相同, 只不过包装了线程或者进程.</p>

<p><strong>事件驱动</strong>模式采用的是一种和之前完全不同的方法.</p>

<h3 id="讲解-2">讲解</h3>

<p><strong>事件驱动模式</strong>(基于Reactor模式)如今可谓风头正劲. 它也是EventMachine、Twisted、Node.js以及Nginx等库的核心所在.</p>

<p>该模式结合了单线程和单进程, 它至少可以达到之前模式所提供的并行操作级别.</p>

<p>它以一个中央连接复用器(被称为<code>Reactor</code>核心)为核心. 连接生命周期中的每个阶段都被分解成单个的事件, 这些事件之间可以按照任意的次序交错并处理. 连接的不同阶段只是一些IO操作而已:</p>

<p><code>accept</code> 、<code>read </code>、<code>write</code> 、<code>close</code>.</p>

<p>中央复用器监视所有活动连接的事件, 在触发事件时分派相关的代码.</p>

<p>下面是事件驱动模式的工作流程:</p>

<ol>
  <li>服务器监视侦听套接字, 等待接入的连接</li>
  <li>将接入的新连接加入到<strong>套接字列表</strong>中进行监视</li>
  <li>服务器现在要监视活动连接以及侦听套接字</li>
  <li>当某个活动连接可读时, 服务器从该连接读取一块数据并分派相关的回调函数</li>
  <li>当某个活动连接仍然可读时, 服务器读取另一块数据并再次分派给相关的回调函数.</li>
  <li>服务器收到另外一个新连接, 将其加入套接字列表进行监视.</li>
  <li>服务器注意到第一个连接已经可以写入, 因而将响应信息写入该连接.</li>
</ol>

<p>记住: <strong>所有的一切都发生在单个线程中</strong>. 第一个连接仍在读/写过程中, 服务器就可以<code>accept</code>新连接了.</p>

<p>服务器将每次操作分隔成小块, 这样属于多连接的不同事件就可以彼此交错了</p>

<h3 id="实现-4">实现</h3>

<pre><code class="language-ruby">require 'socket'
require_relative 'command_handler'

module FTP
  class Evented
    CHUNK_SIZE = 1024 * 16

    class Connection
      CRLF = "\r\n"
      attr_reader :client

      def initialize(io)
        @client = io
        @request, @response = "", ""
        @handler = CommandHandler.new(self)

        respond "220 OHAI"
        # 写数据
        on_writable
      end

      # 处理数据并发送响应
      def on_data(data)
        @request &lt;&lt; data

        if @request.end_with?(CRLF)
          # 调用 `handle` 来处理此次请求并将返回的数据写入到 `response`
          respond @handler.handle(@request)
          @request = ""
        end
      end

      def respond(message)
        @response &lt;&lt; message + CRLF
        # 立即加载可以写入的任何内容
        # 其余部分将在下次套接字可写入时充实
        on_writable
      end

      def on_writable
        bytes = client.write_nonblock(@response)
        @response.slice!(0, bytes)
      end

      def monitor_for_reading?
        true
      end

      def monitor_for_writing?
        !(@response.empty?)
      end
    end # end of Connection

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) { exit }
    end

    def run
      @handles = {}

      loop do
        to_read  = @handles.values.select(&amp;:monitor_for_reading?).map(&amp;:client)
        to_write = @handles.values.select(&amp;:monitor_for_writing?).map(&amp;:client)
        readables, writables = IO.select(to_read + [@control_socket], to_write)

        readables.each do |socket|
          # 侦听套接字负责侦听
          if socket == @control_socket
            io = @control_socket.accept
            connection = Connection.new(io)
            @handles[io.fileno] = connection
          # 其余读套接字负责读取数据
          else
            connection = @handles[socket.fileno]

            begin
              data = socket.read_nonblock(CHUNK_SIZE)
              connection.on_data(data)
            # 没有数据可读时就重试, 实际上啥也没做, `each` 循环继续到下一个 `socket`
            rescue Errno::EAGAIN
            rescue EOFError
              # 当读取到 `EOF` 时就删除此 socket
              @handles.delete(socket.fileno)
            end
          end
        end # end of readables

        writables.each do |socket|
          connection = @handles[socket.fileno]
          # 往 socket 写入数据
          connection.on_writable
        end
      end # end of loop
    end # end of run
  end # end of Evented
end

server = FTP::Evented.new(4481)

server.run

</code></pre>

<p>这个实采用了一种同之前那些实现不同的手法. 我们把代码分解成几个部分研究.</p>

<pre><code class="language-ruby">class Connection
# ..
end
</code></pre>

<p>我们定义了一个<code>Connection</code>类作为事件驱动服务器.</p>

<p>在前面几个线程模式的示例中, 我们用<code>Connection</code>类保持进程间的状态隔离. 这个示例并没有使用线程, 为什么需要<code>Connection</code>类呢?</p>

<p>所有基于进程的模式都使用进程隔离连接. 不管利用即成的方法如何, 它们总是确保无论何时都由单个独立的进程处理单个连接, 所有每个连接基本上是由一个进程描述.</p>

<p><strong>事件驱动模式</strong> 用的是单线程, 但是可以同时处理多个用户连接, 所有它需要使用一个对象来描述每个独立的连接, 这样就不会破坏连接各自的状态.</p>

<pre><code class="language-ruby">class Connection
  CRLF = "\r\n"
  attr_reader :client

  def initialize
    @client = io
      @request, @response = "", ""
      @handler = CommandHandler.new(self)

      respond "220 OHAI"
      on_writable
  end
end
</code></pre>

<p><code>Connection</code>类的开始部分看起来有些眼熟.</p>

<p><code>Connection</code>类将底层的<code>IO</code>对象存储在它的<code>@client</code>实例变量中. 外界可以通过<code>attr_reader</code>对其进行访问.</p>

<p>当连接初始化完毕后, 它会像从前一样获得自己的<code>CommandHandler</code>实例. 随后它写入<code>FTP</code>所要求的定制的<code>hello</code>响应. 不过并非直接写入客户端连接, 而是将响应的主体信息写入<code>@response</code>变量.</p>

<p>下面我们将会看到这将引发<code>Reactor</code>接管操作并将数据发送到客户端.</p>

<pre><code class="language-ruby"># 处理数据并发送响应
def on_data(data)
  @request &lt;&lt; data

  if @request.end_with?(CRLF)
    # 完成此次请求
    respond @handler.handle(@request)
    @request = ""
  end
end

def respond(message)
  @response &lt;&lt; message + CRLF
  # 立即加载可以写入的任何内容
  # 其余部分将在下次套接字可写入时充实
  on_writable
end

def on_writable
  bytes = client.write_nonblock(@response)
  @response.slice!(0, bytes)
end
</code></pre>

<p><code>Connection</code>类定义了若干与<code>Reactor</code>核心进行交换的生命周期方法.</p>

<p>例如, 当<code>Reactor</code>从客户端连接读取数据时, 它触发<code>on_data</code>处理数据.在<code>on_data</code>内部, 检查接受到的是否是一个完整的请求, 如果是会请求<code>@handler</code>建立对应的响应并将其赋给<code>@response</code>.</p>

<p>当客户端连接可以进行写入时就调用<code>on_writable</code>方法. 这就要和<code>@response</code> 变量打交道了. 它将<code>@response</code>中的内容写入客户端连接. 根据能够写入的字节数, 将成功写入的数据从<code>@response</code>中移除.</p>

<p>这样,随后的写操作就只会写入<code>@response</code>中本次没能写入的部分内容. 如果能够写入全部内容, 那么<code>@response</code>就变成了一个空字符串, 就无法再进行写操作了.</p>

<pre><code class="language-ruby">def monitor_for_reading?
  true
end

def monitor_for_writing?
  !(@response.empty?)
end
</code></pre>

<p><code>monitor_for_reading</code>以及<code>monitor_for_writing</code>这两个方法被<code>Reactor</code>用来查询是否应该监视特定连接的读写状态. 在本例中, 只要有新的数据, 我们都希望进行读取. 如果<code>@response</code>有内容可写, 我们希望获知可以进行写入的时机. 如果<code>@response</code>中没有内容, 即使是客户端连接可以写入, <code>Reactor</code>也不会发出通知.</p>

<p><strong>这就是	<code>Reactor</code>核心的工作内容</strong>.</p>

<p><code>@handler</code>看起来像是这样:</p>

<pre><code class="language-ruby">{12 =&gt; #&lt;FTP::Evented::Connection::hehe&gt;}
</code></pre>

<p>其中键对应的是文件描述符编号, 值对应的是<code>Connection</code>对象.</p>

<pre><code class="language-ruby">to_read  = @handles.values.select(&amp;:monitor_for_reading?).map(&amp;:client)
to_write = @handles.values.select(&amp;:monitor_for_writing?).map(&amp;:client)
readables, writables = IO.select(to_read + [@control_socket], to_write)
</code></pre>

<p>主循环<code>run</code>中我们首先查询每个活动连接, 看是否需要使用之前介绍的生命周期方法对其进行读/写监视.</p>

<p>对于有需要的连接, 它获取其底层<code>IO</code>对象的引用.</p>

<p><code>Reactor</code>随后将这些<code>IO</code>实例传给不带超时参数的<code>IO.select</code>.</p>

<p><code>IO.select</code>会一直阻塞到某个受监控的套接字出现值得关注的事件为止.</p>

<p>⚠️: <code>Reactor</code>还会监视<code>@control_socket</code>是否可读, 以便检测到新接入的客户端连接.</p>

<p><code>  Reactor</code>根据它从<code>IO.select</code>  中接收到的事件触发对应的方法.</p>

<pre><code class="language-ruby">readables.each do |socket|
  # 侦听套接字负责侦听
  if socket == @control_socket
    io = @control_socket.accept
    connection = Connection.new(io)
    @handles[io.fileno] = connection
  # 其余读套接字负责读取数据
  else
    connection = @handles[socket.fileno]

    begin
      data = socket.read_nonblock(CHUNK_SIZE)
      connection.on_data(data)
    rescue Errno::EAGAIN # 没有数据可读时就重试, 实际上啥也没做, `each` 循环继续到下一个 `socket`
    rescue EOFError
      # 当读取到 `EOF` 时就删除此 socket
      @handles.delete(socket.fileno)
    end
  end
end # end of readables
</code></pre>

<p>首先处理可读的套接字. 如果<code>@control_socket</code>可读,就意味着出现了一个新的客户端连接. <code>Reactor</code>调用<code>accept</code>接受连接, 建立一个新的<code>Connection</code>并将其放入<code>@handles</code>散列中, 这样就可以在下一次的<code>each</code>循环中进行监视了.</p>

<p>接下来要处理可读的套接字是普通的客户端连接的情况.</p>

<p>在这种情况下, 代码会尝试读取数据, 触发对应的<code>Connection</code>的<code>on_data</code>方法. 如果读取出现阻塞(Errno::EAGAIN), 不做任何处理, 让事件落空为止.如果客户端断开连接(EOFError), 那么要确保从<code>@handles</code>散列中删除相应的条目, 使得对应的对象可以被回收并不再受到监视.</p>

<pre><code class="language-ruby">writables.each do |socket|
  connection = @handles[socket.fileno]
  # 往 socket 写入数据
  connection.on_writable
end
</code></pre>

<p>最后通过触发<code>Connection#on_writable</code>方法处理可写的套接字.</p>

<h3 id="思考-5">思考</h3>

<p><strong>事件驱动模式</strong> 同其他模式有着显著的不同, 因而也就产生了尤为不同的优势和劣势.</p>

<p>首先, 该模式以极高的并发处理能力而闻名, 能够处理成千上万的并发连接. 光这一点就让其他模式无法望其项背, 因为他们都受到进程/线程数量的限制.</p>

<p>如果服务器需要生成5000个线程来处理5000个连接, 服务器估计不堪重负. 就处理并发连接而言, 事件驱动模式可谓一枝独秀并广为流传.</p>

<p>它主要的劣势是所施加的变成模型. 一方面这个模型更简单, 因为无需处理众多线程和进程. 这意味着就不存在共享内存、同步、越界进程等等.</p>

<p>但是考虑到所有的并发都发生在单个线程内部, 有一条非常重要的规则必须遵循: <strong>绝对不能阻塞<code>Reactor</code></strong>.</p>

<p>要诠释着一点,让我们来仔细查看一下实现代码. 在<code>CommandHandler</code>类中, 当处理<code>FTP</code>文件传输命令(RETR)时,它实际上打开了一个套接字, 以流的方式发送数据, 然后关闭套接字. 重要的是这个套接字是在<code>Reactor</code>主循环之外使用的, <code>Reactor</code>对其一无所知.</p>

<p>假设客户端在一条速度缓慢的连接上请求文件传输, 这会对<code>Reactor</code>造成什么影响呢?</p>

<p>考虑到一切都运行在同一个线程之内, 单个迟缓的客户端连接会阻塞住整个<code>Reactor</code>.当<code>Reactor</code>在<code>Connection</code>上触发某个方法时, <code>Reactor</code>会一直阻塞到该方法返回为止.</p>

<p>由于<code>on_data</code>方法委托给了<code>CommandHandler</code>, 当它以数据流的方式向客户端进行文件传输时, <code>Reactor</code>一直处于阻塞. 在这期间, 无法读取其他数据, 也就无法接受新的连接.</p>

<p>应用程序需要达成的任何事情都应该快速完成, 这一点非常重要. 我们如何使用<code>Reactor</code>处理缓慢的连接呢?</p>

<p><strong>利用<code>Reactor</code>自身</strong></p>

<p>如果你采用该模式, 那就需要确保所有阻塞式<code>IO</code>都由<code>Reactor</code>自己来处理. 在这个例子中就意味着由 <code>CommandHandler</code>所使用的套接字需要被封装到<code>Connection</code>的子类中, 它定义了自己的一套<code>on_data</code>和<code>on_writable</code>方法.</p>

<p>当<code>Reactor</code>可以向缓慢的连接中写入数据时, 它就会触发响应的<code>on_writable</code>方法, 该方法能够在没有阻塞的情况下尽可能多的向客户端写入数据. 这样<code>Reactor</code>就可以在等待这个缓慢的远程连接的同时继续处理其他连接, 一旦那条远程连接再次可用, 仍可对其进行处理.</p>

<p>简而言之, 事件驱动模式提供了一些显而易见的优势, 真正简化了套接字编程的某些方面. 另一方面, 它需要你重新考虑自己的应用程序设计的全部<code>IO</code>操作. 该模式所带来的益处很容易被一些迟钝的代码或者含有阻塞式<code>IO</code>的第三方代码块搞得烟消云散.</p>

<h2 id="混合模式">混合模式</h2>

<h2 id="再会">再会</h2>

  ]]></description>
</item>

<item>
  <title>TCP Socket 编程 -- 非阻塞式 IO</title>
  <link>//tcp-scokets-no-block</link>
  <author>nju520</author>
  <pubDate>2018-03-15T00:00:00+08:00</pubDate>
  <guid>//tcp-scokets-no-block</guid>
  <description><![CDATA[
  <h2 id="非阻塞式-io">非阻塞式 <code>IO</code></h2>

<h3 id="网络请求瓶颈">网络请求瓶颈!!</h3>

<h3 id="非阻塞式读操作">非阻塞式读操作</h3>

<p>还记得我们之前学过的<code>Socket#read</code>吗? <code>它会一直保持阻塞, 直到接收到</code>EOF`或者获得指定的最小字节数为止.</p>

<p>如果客户端没有发送<code>EOF</code>, 就可能会导致阻塞. 这种情况虽然可以通过<code>readpartial</code>暂时解决, <code>readpartial</code>会立刻返回所有的可用数据. 但是如果没有数据可用, 那么<code>readpartial</code>也会陷入阻塞状态.</p>

<p>我们可以使用<code>read_nonblock</code>来实现非阻塞式读操作.</p>

<p>和<code>readpartial</code> 非常类似, <code>read_nonblock</code>需要一个整数的参数, 指定需要读取的最大字节数. 如果可用的数据小于最大字节数, 那就只返回可用数据.</p>

<pre><code class="language-ruby">require 'socket'

Socket.tcp_server_loop(4481) do |conn|
  loop do
    begin
      puts conn.read_nonblock(1024 * 4)
    rescue Errno::EAGAIN
      puts "no data, just retry"
      sleep 1
      retry
    rescue EOFError
      break
    end
  end

  conn.close
end

</code></pre>

<p>运行我们之前的客户端命令:</p>

<pre><code class="language-shell">$ tail -f /var/log/system.log | nc localhost 4481
</code></pre>

<p>即使没有向服务器发送数据, <code>read_nonblock</code>调用仍然会立即返回. 事实上它产生了一个<code>Errno::EAGAIN</code>异常.</p>

<blockquote>
  <p>Errno::EAGAIN: 文件被标记用于非阻塞式<code>IO</code>, 表示无数据可读</p>
</blockquote>

<p>原来如此, 这样 <code>read_nonblock</code>就不同于<code>readpartial</code>了, 后者在这种情况下就会阻塞.</p>

<p>如果你碰到这种情况如何应对? 上面的例子中, 我们进入下一个循环并不断重试<code>retry</code>. 这只是为了演示, 并非正确的做法.</p>

<p>对被阻塞的读操作进行重试的正确方式应该采用<code>IO.select</code>:</p>

<pre><code class="language-ruby">loop do
  begin puts conn.read_nonblock(1024 * 4)
  rescue Errno::EAGAIN
    puts "===== not data, just wait IO.select return readable sockets"
    IO.select([conn])
    retry
  rescue EOFError
    break
  end
end
</code></pre>

<p>使用套接字数组作为<code>IO.select</code>调用的第一个参数将会造成阻塞, 直到某个套接字变得可读为止. 所以应该仅当某个套接字变得可读时才去重试, 否则就是浪费系统资源.</p>

<blockquote>
  <p>IO.select 实际上也是阻塞式操作, 直到有可读/可写的套接字返回, 否则它就一直阻塞.</p>
</blockquote>

<p>在本例种, 我们使用了非阻塞方法重新实现了阻塞式的<code>read</code>方法, 这本身并没有什么用处, 但是<code>IO.select</code>给我们提供了很多灵活性, 我们在进行其他工作的同时监控多个套接字或者定期检查它们的可读性.</p>

<p>在后文中会着重分析<code>IO.select</code></p>

<h3 id="非阻塞式写操作">非阻塞式写操作</h3>

<p>非阻塞式写操作和我们之前调用的<code>write</code>有所不同. 最明显的一处就是: <code>write_nonblock</code>可能会返回部分写入的结果, 而<code>write</code>调用总是将我发送给它的数据全部写入.</p>

<p>这是因为<code>write_nonblock</code>碰到了某种使它出现阻塞的情况, 因此也就没发进行写入, 所有返回了整数值, 告诉我们写入了多少数据. 我们还要将剩下没有写入的数据继续写入.</p>

<pre><code class="language-ruby">
</code></pre>

<ul>
  <li>如果一次调用没发写入所有的请求的数据, 就应该试着继续写入没有写完的部分</li>
  <li>如果底层的<code>write</code>处于阻塞状态, 就应该捕获<code>Errno::EAGAIN</code>异常, 并调用<code>IO.select</code>, 它可以告诉我们何时某个套接字可写.</li>
</ul>

<h4 id="什么情况下写操作会阻塞">什么情况下写操作会阻塞</h4>

<ol>
  <li><code>TCP</code>连接的接收端还没有确认接收到对方的数据, 而发送端已经发送了所运行发送的数据量. <code>TCP</code>使用拥塞控制算法确保网络不会被分组所淹没. 如果数据花费了很长时间才到达<code>TCP</code>连接的接收端, 那么就不要发送超出网络处理能力的数据以免网络过载.</li>
  <li><code>TCP</code>连接的接收端无力处理更多的数据. 即使是另一端已经确认接收到了数据, 它仍清空自己的数据窗口, 以便重新接入其他数据.如果接收端没有处理它接收的数据, 那么拥塞控制算法就会强制发送端阻塞, 直到客户端可以接收更多的数据为止.</li>
</ol>

<h2 id="连接复用">连接复用</h2>

<blockquote>
  <p>连接复用是指同时处理多个活动套接字, 这不是指并行处理, 也和多线程无关.</p>
</blockquote>

<p>想象一下如何编写一个需要随时处理多条<code>TCP</code>连接中的可用数据服务器. 我们可以使用刚刚学会的有关非阻塞式<code>IO</code>的知识来避免在特定的套接字上陷入停滞.</p>

<pre><code class="language-ruby"># 创建一个连接数组
connections = [&lt;TCPSocket&gt;, &lt;TCPSocket&gt;, &lt;TCPSocket&gt;

loop do
  # 处理每个连接
  connections.each do |conn|
    begin
      # 采用非阻塞的方式从每个连接中进行读取
      # 处理接收到的数据
      data = conn.read_nonblock(4096)
      process(data)
      # 不然就进行下一次的尝试
    resuce Errno::EAGAIN
    end
  end
end
</code></pre>

<p>虽然上述代码行得通, 但是需要频繁地执行尝试循环.</p>

<p>每一次调用<code>read_nonblock</code>都要使用至少一个系统调用, 如果没有数据可读, 服务器就会浪费大量处理的周期.</p>

<p>如前所述, <code>read_nonblock</code>会调用底层的<code>select</code>.</p>

<p>现在我们可以使用<code>Ruby</code>的一个包装器, 让我们按照自己的意图直接调用底层的<code>select</code>.</p>

<pre><code class="language-ruby"># 创建一个连接数组
connections = [&lt;TCPSocket&gt;, &lt;TCPSocket&gt;, &lt;TCPSocket&gt;

loop do
  loop do
    # 调用底层的 `select` 查询 `socket` 连接的读写状态 
    ready = IO.slect(connections)

    #得到可进行读操作的 socket 连接
    readable_conns = ready[0]
    writable_conns = ready[1]

    readable_conns.each do |conn|
      data = conn.readpartial(4096)
      process(data)
    end
  end
end

</code></pre>

<p>我们使用<code>IO.select</code>可极大降低处理多个连接的开销.</p>

<p><code>IO.select</code>的作用就是接收若干<code>IO</code>对象, 然后告知哪一个可以进行读写, 这样我们就不必像刚才那样一直重试了.</p>

<p>让我们来深入研究一下<code>IO.select</code>.</p>

<p>**<code>IO.select</code>可以告诉我们文件描述符何时可以读写.它会阻塞. **</p>

<p><em>*<code>IO.select</code>是一个同步方法</em>. 按照目前的方式来使用它会造成阻塞, 直到传入的某个<code>IO</code> 对象状态发生变化, 这时候它就会立刻返回. 如果有多个对象状态发生变化, 那么它们就会通过嵌套数组返回*</p>

<p><code>IO.select</code>可以接收四个参数:</p>

<ul>
  <li>希望从中进行读取的<code>IO</code>对象数组</li>
  <li>希望从中进行写入的<code>IO</code>对象数组</li>
  <li>超时的<code>IO</code>对象数组</li>
  <li>超时时间(单位 秒). 它可以避免 <code>IO.selct</code>永远地阻塞下去. 如果在 <code>IO</code>状态发生变化之前就已经超时, 那么 <code>IO.select</code>就会返回 <code>nil</code>.</li>
</ul>

<pre><code class="language-ruby">ready = IO.select(for_reading, for_writing, for_writing)
</code></pre>

<p>它返回一个三个数组:</p>

<ul>
  <li>可以进行无拥塞读取的<code>IO</code>对象数组</li>
  <li>可以进行无拥塞写入的<code>IO</code>对象数组</li>
  <li>适用于异常条件的<code>IO</code>对象数组</li>
</ul>

<h4 id="高性能复用">高性能复用</h4>

<p><code>IO.select</code>来自<code>Ruby</code>的核心代码库. 它是在<code>Ruby</code>中进行复用的唯一手段. 大多数现代操作系统支持多种复用方法.  <code>select</code>几乎总是最古老的, 也是用的最少的那个.</p>

<h2 id="超时">超时</h2>

<p>超时其实就是忍耐. 你愿意在套接字连接上等待多长时间呢?套接字读取呢? 套接字写入呢?</p>

<p>所有这些答案都视你的忍耐力而定. 高性能网络程序通常都不愿意等待那些没完没了的操作.</p>

<p><code>Ruby</code>有自己自带的<code>timeout</code>库, 它提供了一种通用的超时机制, 但是操作系统也有一套针对套接字的超时机制, 效果更好而且更直观.</p>

<p>虽然操作系统提供了自带的套接字超时处理机制, 可以通过套接字选项<code>SNDTIMEO</code>以及<code>RCVTIMO</code>进行设置. 不过自<code>Ruby1.9</code>之后, 这个特性就不能再使用了. 由于<code>Ruby</code>在有线程存在时对于阻塞式<code>IO</code>所采用的处理方式. 它将<code>poll</code>相关的套接字进行了包装, 这样操作系统自带的套接字超时就没有优势了.</p>

<p>还是请我们的老朋友<code>IO.select</code>出场. 之前我们知道了如何使用<code>IO.select</code>, 现在来看一下最后一个参数的使用:</p>

<pre><code class="language-ruby">require 'socket'
require 'timeout'

# 超时时间设置为 5 秒
timeout = 5

Socket.tcp_server_loop(4481) do |conn|
  begin
    # 发起一个初始化 read 
    # 因为要求套接字上有被请求的数据, 有数据可读时可以避免使用 select
    conn.read_nonblock(1024 * 4)
  rescue Errno::EAGAIN
    # 监视是否可读
    if IO.select([conn], nil, nil, timeout)
      # IO.select 会将套接字返回, 我们可以打印出来看一下, 不返回 nil 就意味着套接字可读
      puts conn.read_nonblock(1024 * 4)
      retry
    else
      # 否则就会 raise 一个 Timeout::Error 
      raise Timeout::Error
    end
  end

  conn.close
end

</code></pre>

<p>运行我们之前使用的指令:</p>

<pre><code class="language-shell">tail -f /var/log/system.log | nc localhost 4481		
</code></pre>

<p>如果系统日志没有, 并且套接字等待的时间超过我们设定的<code>timeout</code>, 程序就会<code>raise</code>一个<code>Timeout::Error</code>.</p>

<pre><code class="language-ruby">read_timeout.rb:15:in `rescue in block in &lt;main&gt;': Timeout::Error (Timeout::Error)
	from read_timeout.rb:8:in `block in &lt;main&gt;'
</code></pre>

<p>这些基于超时的<code>IO.select</code>机制使用广泛, 甚至在<code>Ruby</code>的标准库中也能看到, 它们比操作系统自带的套接字超时处理机制的稳定性更高.</p>


  ]]></description>
</item>

<item>
  <title>TCP Socket 编程 -- 基础</title>
  <link>//tcp-scokets</link>
  <author>nju520</author>
  <pubDate>2018-03-10T00:00:00+08:00</pubDate>
  <guid>//tcp-scokets</guid>
  <description><![CDATA[
  <p>网络编程归根结底是关于共享和通信的, 很大程度上要归功于一组特定地套接字编程API的出现.  <code>Berkely Socket API</code>真正经受住了时间的考验, 它之所以能够屹立不倒的原因就是<strong>我可以在无需了解底层协议的情况下使用套接字</strong>. <code>Bekeley Socket API</code>是一种编程<code>API</code>, 它运作在实际的协议实现之上. 它所关注的是连接两个端点<code>endpoint</code>共享数据, 而非处理分组和序列号等底层操作.</p>

<p>本文主要演示<code>Ruby</code>所提供的套接字<code>API</code>的包装类 <code>Wrapper Class</code>, 并采用工具 <code>netcat</code>创建一个随意的连接.</p>

<blockquote>
  <p>netcat 是 Unix 一款优秀的工具, 可以用于创建<code>TCP</code> <code>UDP</code>连接并进行监听.</p>
</blockquote>

<h2 id="建立套接字">建立套接字</h2>

<p>采用<code>Ruby</code>可以非常方便的创建一个套接字:</p>

<pre><code class="language-ruby">require 'socket'

socket = Socket.new(Socket::AF_INET, Socket::SOCK_STREAM)
</code></pre>

<p>上述代码在 <code>INET</code>域创建一个类型为<code>STREAM</code> 的套接字. <code>INET</code>是<code> internet</code>的缩写, 特指<code>IPV4</code>版本的套接字.</p>

<p><code>STREAM</code>表示使用数据流进行通信, 该功能由<code>TCP</code>提供. 如果我们指定的是<code>DGRAM</code>	(datagram, 数据报), 则表示<code>UDP</code>套接字.</p>

<p>在 <code>Ruby</code>语言中我们还可以使用<code>syntactic sugar</code>(语法糖)来创建套接字.</p>

<pre><code class="language-ruby">require 'socket'
socket = Socket.new(:INET6, :STREAM)
</code></pre>

<p><code>Ruby</code>编程中我们可以使用<code>Symbol</code>来代替常量来描述各种选项.</p>

<p>上述代码创建了一个在<code>IPV6</code>域创建<code>TCP</code>套接字的实例.</p>

<h3 id="端点">端点</h3>

<p>在两个套接字之间进行通信, 就需要知道如何找到对方. 这就很像我们打电话: 如果我想和某个人进行交流, 必须知道对方的电话号码.</p>

<p>套接字使用<code>IP地址</code>将消息发往指定的主机. 主机由唯一的<code>IP地址</code>来标识, <code>IP地址</code>是由点号连接的4组不大于255的数字.</p>

<p>配置了<code>IP地址</code>的主机可以像另一台同样配置了<code>IP地址</code>的主机发送数据.</p>

<blockquote>
  <p>我知道想要与之对话的主机的地址后, 就很容易使用套接字通信了. 但是如何才能获取那个地址呢? 需要把它背下来还是写在纸上? 谢天谢地, 都不需要.</p>

  <p>我们使用<code>DNS</code>域名解析协议来获取主机名对应的<code>IP地址</code>. <code>DNS</code>是用来将主机名映射到 <code>IP地址</code>的系统.有了它我们就只需要记住主机的名字, 比如 <code>google.com</code>, 随后可以让<code>DNS</code>将主机名解析成地址. 即使地址发生了变化, 主机名总能够将我们指向正确的位置. nice!</p>
</blockquote>

<p><img src="" alt="DNS" /></p>

<h3 id="环回地址">环回地址</h3>

<p><code>IP地址</code>未必总指向远端主机. 当我们在开发阶段时, 通常需要连接自己本地主机上的套接字.</p>

<p>多数系统都定义了<code>loopback interface</code> (环回接口). 和网卡接口不同的是, 这是一个和硬件无关、完全虚拟的接口. 发送到环回接口上的数据立即会在同一个接口上被接收. 同一台主机上的两项服务若使用环回地址而非分配的主机地址, 就可以绕开<code>TCP/IP</code>协议栈的下层.</p>

<p>通过<code>ping</code>环回地址, 我们还可以测试本地主机上的<code>TCP/IP</code>配置</p>

<p>配合环回地址, 我可以将网络搭建在本地主机中.</p>

<p>环回接口对应的主机名是<code>localhost</code>, 对应的<code>IP地址</code>通常是 <code>127.0.0.1</code>. 这些定义都可以在系统的<code>hosts</code>文件找到.</p>

<h3 id="端口">端口</h3>

<p>对于端点而言, 除了<code>IP地址</code>之外,还有另外一个重要的定义–端口号. 继续我们打电话的例子: 如果我要和办公楼的某人进行通话, 就得拨通他们办公楼的电话号码, 然后再拨分机号. 端口号就是套接字端点的“分机号“.</p>

<p>对于每个套接字而言, <code>IP地址</code>和<code>端口号</code>的组合必须是唯一的. 所以在同一个侦听端口上可以有两个套接字, 一个使用<code>IPV4</code>地址, 另一个使用<code>IPV6</code>地址, 但是两个套接字不能都使用同一个<code>IPV4</code>地址.</p>

<p>若没有端口号, 一台主机一次只能够支持一个套接字. 将每个活动套接字与特定的端口进行绑定, 主机便可以同时支持上千个套接字.</p>

<h3 id="建立连接">建立连接</h3>

<p><code>TCP</code>在两个端点之间建立连接. 端点可能处于同一台主机, 也可能处于不同的主机中. 不管哪一种情况, 背后的原理都是一样的.</p>

<p>当我创建套接字时 这个套接字必须担任以下角色之一:</p>

<ul>
  <li>发起者(initiator)</li>
  <li>侦听者(listener)</li>
</ul>

<p>少了侦听套接字, 就无法发起连接; 没有连接的发起者, 也就没有必要进行侦听.</p>

<p>在网络编程中, <strong>通常将从事侦听的套接字称为“服务器”, 将发起连接的套接字称为“客户端”</strong>.</p>

<p>下一节我们着重阐述它们各自的生命周期.</p>

<h2 id="服务器生命周期">服务器生命周期</h2>

<p>服务器套件字用于侦听连接而非发起连接. 其典型的生命周期如下:</p>

<ul>
  <li>new: 创建</li>
  <li>bind: 绑定</li>
  <li>listen: 监听</li>
  <li>accept: 接受请求</li>
  <li>close: 关闭连接</li>
</ul>

<pre><code class="language-ruby">require 'socket'
# 创建服务器套接字
server = Socket.new(:INET, :STREAM)

# 创建C结构体来保存用于侦听的地址
# 使用 0.0.0.0, 我们可以侦听到每一个接口的 socket 请求
addr = Socket.pack_sockaddr_in(4481, '0.0.0.0')

# 绑定 侦听的地址
server.bind(addr)

# 侦听, 参数为侦听队列最大长度
server.listen(128)

# 接受连接
connection, _ = server.accept

</code></pre>

<p>以上我们开启了一个服务器 套接字, 如果运行代码会发现上述代码没有立刻退出!</p>

<p>没错, <code>accept</code>方法会一直阻塞到有连接到达.</p>

<p>让我们采用<code>netcat</code>发起一个连接:</p>

<pre><code class="language-shell">$ echo Working with TCP Socket | nc localhost 4481
</code></pre>

<p>运行结果就是<code>nc</code>成功发起一个客户端请求, 服务器成功接收请求后<code>Ruby</code>程序顺利退出. 最精彩的不在于此, 而在于连接已经建立, 一起顺利!</p>

<h3 id="accept">accept</h3>

<p><code>accept</code>调用是阻塞式的. 在它接收到一个新的连接之前, 它会一直阻塞当前线程.</p>

<blockquote>
  <p><code>accept</code>只不过就是将还未处理的连接从队列中弹出而已. 如果队列为空, 那么它就一直等, 直到有连接被加入到队列为止.</p>
</blockquote>

<p><code>accept</code>调用返回一个数组:</p>

<ul>
  <li>第一个元素为已经建立好的连接</li>
  <li><code>Addrinfo</code>对象: 该对象描述了客户端连接的远程地址</li>
</ul>

<pre><code class="language-ruby">conn, _ = server.accept

puts "connection class: #{conn.class}"

puts "server fileno: #{server.fileno}"

puts "connection fileno: #{conn.fileno}"

puts "local address: #{conn.local_address.inspect}"

puts "remote address: ##{conn.remote_address.inspect}"

</code></pre>

<p>当服务器获得一个连接时, 它就会输出:</p>

<pre><code class="language-powershell">connection class: Socket
server fileno: 8
connection fileno: 9
local address: #&lt;Addrinfo: 127.0.0.1:4481 TCP&gt;
remote address: ##&lt;Addrinfo: 127.0.0.1:58447 TCP&gt;
</code></pre>

<h4 id="连接类">连接类</h4>

<p>尽管<code>accept</code>返回了一个“连接”, 但是上述输出告诉我们并没有特殊的连接类(connection class). 一个连接实际上就是<code>Socket</code> 的实例.</p>

<h4 id="文件描述符">文件描述符</h4>

<p><code>accept</code>调用返回一个<code>Socket</code>实例, 这个连接的文件描述符编号和服务器套接字不一样.</p>

<blockquote>
  <p>文件描述符编号是内核用于跟踪当前进程所打开文件的一种方法</p>

  <p>套接字就是文件. 至少在 Unix 世界中, 所有的一切都被视为文件, 这包括文件系统中的文件以及管道、 套接字、打印机, 等等</p>
</blockquote>

<p><code>accept</code>调用返回了一个不同于服务器套接字的<code>Socket</code>实例. 这个<code>Socket</code>实例描述了特定的连接.</p>

<p>每个连接都由一个全新的<code>Socket</code>对象描述, 那么服务器套接字就可以保持不变吗不停地接受新的连接.</p>

<h4 id="连接地址">连接地址</h4>

<p><code>accept</code>调用返回的<code>Socket</code>对象知晓两个地址:</p>

<ul>
  <li>本地地址</li>
  <li>远程地址</li>
</ul>

<p>其中远程地址也可以从<code>accept</code> 第二个参数中获取, 也可以从返回的<code>Socket</code>对象中获取.</p>

<p><strong>每一个TCP连接都由 本地主机、本地端口、远程主机、远程端口 这组唯一的组合定义</strong></p>

<h4 id="accept-循环">accept 循环</h4>

<p>在前面的代码中, 服务器接受了一个请求之后退出.在编写真正的服务器代码时, 只要还有接入的连接, 我们肯定希望不停地侦听. 我们可以轻松地通过 <code>loop</code>来实现:</p>

<pre><code class="language-ruby"># !/usr/bin/env ruby

require 'socket'

server = Socket.new(:INET, :STREAM)

addr = Socket.pack_sockaddr_in(4481, '0.0.0.0')

server.bind(addr)

server.listen(128)

loop do
  conn, _ = server.accept
  # 处理请求
  puts "deal with conn"
  conn.close
end

</code></pre>

<p>这是使用<code>Ruby</code>编写服务器一种常见方式.</p>

<p>由于这种方式在实际中应用广泛, <code>Ruby</code>在其基础上提供了一些语法糖, 稍后我们会采用更简洁地方式重写服务器端的逻辑.</p>

<h3 id="关闭连接">关闭连接</h3>

<p>一旦服务器接受了某个连接并处理完毕, 那么最后一件事情就是关闭该连接. 这才算完成了一个连接 “
创建 –  处理 – 关闭” 的生命周期.</p>

<h4 id="退出时关闭">退出时关闭</h4>

<p>为什么需要<code>close</code>? 当程序退出时, 系统会帮我们关闭所有打开的文件描述符(包括套接字). 为什么还要我们自动手动关闭呢? 有两个很好的理由:</p>

<ul>
  <li>资源使用. 如果我使用了套接字却没有关闭它, 那么那些我不再使用的套接字的引用很可能依然保留着. 在<code>Ruby</code>中, 垃圾收集器时我的好伙伴, 它可以帮助我们清理用不着的连接. 不过保持自己所用的资源的完全控制权, 丢掉不再需要的东西总是一个不错的选择.</li>
  <li>打开文件的数量限制. 所有进程都只能打开一定数量的文件. 保留无用的连接会使进程逐步逼近这个上限值.</li>
</ul>

<h4 id="关闭方式">关闭方式</h4>

<p>由于套接字运行双向通信(读 &amp; 写). 实际上可以只关闭其中一个通道</p>

<pre><code class="language-ruby">conn, _ = server.accept
# 该连接随后不需要写入数据, 但是可能仍需要读取数据
conn.close_write

# 该连接此时不需要进行任何数据的读写
conn.close_read
</code></pre>

<p>关闭写操作流<code>write stream</code> 会发送一个 <code>EOF</code>到套接字的另一端.</p>

<p><code>close_write</code>以及<code>close_read</code>方法都在底层利用<code>shutdown</code>. <code>shutdown</code>和<code>close</code>有明显不同:</p>

<ul>
  <li>close: 会关闭调用它的套接字实例. 如果该套接字在系统中还有其他副本, 那么这些副本不会被关闭, 所占用的资源也不会被回收.</li>
  <li>shutdown: 完全关闭在当前套接字及其副本上的通信, 但是它不会回收套接字所使用过的资源. 每个套接字实例仍需要 <code>close</code>来关闭</li>
</ul>

<blockquote>
  <p>连接副本: 获得一个文件描述符最常见的方法就是利用 <code>Process.fork</code>方法. 该方法创建了一个全新的进程, 这个进程和当前进程一模一样. 除了拥有当前进程在内存中的所有内容之外, 新进程还通过 dup 获得了所有已打开的文件描述符的副本.</p>

  <p>除此之外, 我们还可以使用 <code>Socket#dup</code>创建文件描述符的副本.</p>
</blockquote>

<pre><code class="language-ruby">conn, _ = server.accept

# 创建所有连接副本上的通信
copy = conn.dup

# 关闭所有连接副本的通信
conn.shutdown

# 关闭原始连接, 副本会在垃圾收集器进行收集时关闭
conn.close
</code></pre>

<h3 id="ruby-包装器">Ruby 包装器</h3>

<p>对于<code>Rubyist</code>来说, 我们都热爱<code>Ruby</code>提供的优雅与法. 它用来创建及使用服务器套接字的扩展会让人爱不释手.</p>

<pre><code class="language-ruby"># !/usr/bin/env ruby

require 'socket'

# 创建侦听套接字
# 返回两个 TCP 套接字, 一个可以通过 IPV4 连接, 另一个可以通过 IPV6 连接
servers = Socket.tcp_server_sockets(4481)

# 进入无限循环, 接受并处理连接
Socket.accept_loop(servers) do |conn|
  # 处理连接
  conn.close
end
</code></pre>

<h2 id="客户端生命周期">客户端生命周期</h2>

<p>客户端的生命周期要比服务器端一些:</p>

<ul>
  <li>new:  创建</li>
  <li>bind: 绑定</li>
  <li>connect: 连接</li>
  <li>close: 关闭</li>
</ul>

<h3 id="绑定">绑定</h3>

<p>在服务器部分, 我们使用特定的地址和端口去调用 <code>bind</code>. <strong>很少有服务器不用<code>bind</code>, 也很少有客户端使用<code>bind</code></strong>.</p>

<p>客户端一般从临时端口范围内获得一个随机端口号.</p>

<blockquote>
  <p>客户端之所以不需要调用 bind, 因为它们无需通过某个已知端口访问.</p>

  <p>而服务器要绑定到特定端口的原因是, 客户端需要通过特定的端口访问到服务器.</p>

  <p>以 FTP 为例. 她的熟知端口为 21. 因此FTP读物应该绑定到该端口, 这样客户端就知道从哪里获取FTP服务了. 客户端可以从任意端口发起连接, 客户端选择的端口号不会影响到服务器.</p>
</blockquote>

<pre><code class="language-ruby">require 'socket'

client = Socket.new(:INET, :STREAM)
# 发起到 google.com 端口 80 的连接
remote_addr = Socket.pack_sockaddr_in(80, 'google.com')

client.connect(remote_addr)

</code></pre>

<p>该代码片段是从本地的临时端口向在 <code>google.com</code>	的 80 端口进行侦听的套接字发起 <code>TCP</code>连接</p>

<p>让我们来尝尝语法糖的味道:</p>

<pre><code class="language-ruby">require 'socket'

client = TCPSocket.new('google.com', 80)

# 我们还可以使用 Socket.tcp 构建客户端, 并在代码块中写入处理逻辑

Socket.tcp('google.com', 80) do |conn|
  conn.write("GET / HTTP/1.1\r\n")
  conn.close
end
</code></pre>

<h2 id="套接字读写操作">套接字读写操作</h2>

<p>上面的部分都是关于建立连接, 连接两个端点的内容. 尽管这本身挺有意思, 但是如果连接上没有交换的连接, 实际上我们什么有意义的事情也没有做. 本节就来介绍一下连接之后的数据交换.  我们不仅可以建立服务器和客户端的连接, 还能够让它们进行数据交换.</p>

<p>我们可以将<code>TCP</code>连接想象成一串连接了本地套接字和远程套接字的管子, 我们可以沿着管子发送、接收数据. 这种想象有助于增进我们对<code>TCp</code>的理解. <code>Berkeley</code>套接字<code>API</code>就是这样设计的, 我们同样以这种方式对身边的世界进行建模, 解决各类问题.</p>

<h3 id="套接字读操作">套接字读操作</h3>

<p>从套接字读起数据最简单的方法就是 <code>read</code>:</p>

<pre><code class="language-ruby"># server
require 'socket'

Socket.tcp_server_loop(4481) do |conn|
  # 服务器套接字从连接中读取数据
  puts conn.read

  # 完成读取之后关闭连接, 让客户端知道不用再等待数据返回
  conn.close
end

</code></pre>

<p>我们在另一个终端下面运行下面的<code>netcat</code>命令,  就会在 <code>Ruby服务器</code>中看到我们发送的数据:</p>

<pre><code class="language-shell">$ echo heheda | nc localhost 4481
</code></pre>

<blockquote>
  <p>上面的 <code>read</code>和我们使用<code>File.read</code>类似, 这是因为<code>Ruby</code>的各种套接字以及<code>File</code>在<code>IO</code>都有一个共同的父类. <code>Ruby</code>中所有的<code>IO</code>对象(套接字、管道、文件…)都有一套通用的接口, 支持 <code>read</code>、  <code>write</code>、 <code>flush</code>等方法.</p>

  <p>这并不是<code>Ruby</code>的创新.底层的<code>read</code>、<code>write</code>等系统调用都可以作用于文件、套接字、管道之上. 这种抽象源自操作系统核心本身. <strong>一切皆文件</strong></p>
</blockquote>

<h3 id="阻塞">阻塞</h3>

<p>我们运行下面命令不停地向服务器发送数据:</p>

<pre><code class="language-shell">tail -f /var/log/system.log | nc localhost 4481
</code></pre>

<p>服务器将永远不会停止读取数据, 也永远不会退出.</p>

<p>造成这种 是 <code>EOF(end-of-file)</code>. 我们先使用一种不太成熟的解决方法.</p>

<p><code>tail -f</code> 根据就不会停止发送数据. 如果 <code>tail -f </code>没有数据可以发送, 它就会一直等到有数据为止. 这使得连接<code>netcat</code>的管道一直处于打开状态, 因此 <code>netcat</code>也会永远都不停止向服务器发送数据.</p>

<p>服务器的<code>read</code>就会一直被阻塞着, 直到有客户端发送完整数据为止.</p>

<h4 id="设置读取长度">设置读取长度</h4>

<p>我们可以指定最小的读取长度. 这样就不用等客户端结束发送才停止读取数据, 而是告诉服务器特定的数据量, 然后返回:</p>

<pre><code class="language-ruby"># server
require 'socket'

ONE_KB = 1024

Socket.tcp_server_loop(4481) do |conn|
  # 以 1KB 为单位进行读取
  while data = conn.read(ONE_KB) do
    puts data
  end

  conn.close
end

</code></pre>

<p>运行客户端命令</p>

<pre><code class="language-shell">$ tail -f /var/log/system.log | nc localhost 4481
</code></pre>

<p>上面的代码会使服务器在<code>netcat</code>命令运行的同时, 以<code>1KB</code>为单位打印数据.</p>

<h4 id="阻塞的本质">阻塞的本质</h4>

<p><code>read</code>调用会一直阻塞, 直到获取了完整长度的数据为止. 如果读取了一部分数据, 但是不足<code>1KB</code>,那么<code>read</code>会一直阻塞, 直至获得完整的<code>1KB</code>数据为止.</p>

<p>采用这种方法实际上有可能导致死锁. 如果服务器试图从连接中读取<code>1KB</code>的数据, 而客户端只发送了<code>500B</code>就不再发送了, 那么服务器就会一直傻等着那没有发送的<code>500B</code>.</p>

<h6 id="我们可以采用两种方式补救">我们可以采用两种方式补救:</h6>

<ul>
  <li>客户端发送完<code>500B</code>后再发送一个<code>EOF</code></li>
  <li>服务器采用部分读取的方式</li>
</ul>

<h5 id="eof-事件">EOF 事件</h5>

<p>当在连接上调用<code>read</code>并接收到<code>EOF</code>事件时, 我们就可以断定不会再有数据, 可以停止读取了.</p>

<blockquote>
  <p>EOF: end of file(文件结尾). 记住一句话: 在<code>Unix</code>世界中, 一切皆是文件.</p>
</blockquote>

<p><code>EOF</code>并不代表某种字符序列, 他可以使用<code>shutdown</code>或者<code>close</code>来表明自己不需要再写入任何数据, 这就会导致一个<code>EOF</code>事件被发送给在另一端进行读操作的进程. 这样读数据的进程就知道不会再有数据到达了.</p>

<p>我们从头审视并解决上一小节的问题: 如果服务器希望接收<code>1KB</code>的数据, 而客户端只发了<code>500B</code>.</p>

<p>一种改进方法就是客户端发送<code>500B</code>, 然后再发送一个<code>EOF</code> 事件. 服务器接收到该事件后就停止读取, 即使是还未接收够<code>1KB</code>.</p>

<blockquote>
  <p>EOF 代表不再有数据到达了.</p>

  <p>当我调用<code>File#read</code>时, 它会一直进行数据读取, 直到没有数据为止. 一旦读完整个文件, 它会接收到一个<code>EOF</code>事件并返回已读取到的数据</p>
</blockquote>

<h5 id="部分读取">部分读取</h5>

<p>上面的方式多少有些偷懒: 当我调用<code>read</code>时, 在返回数据之前它会一直等待, 直到获得所需要的最小长度或者是<code>EOF</code>. 还有另外一种读取方式: <code>readpartial</code>.</p>

<p><code>readpartial</code>并不会阻塞, 而是立刻返回可用的数据.调用<code>readpartial</code>需要传入一直整数, 来指定最大的长度</p>

<h3 id="套接字写操作">套接字写操作</h3>

<p>套接字写操作和读操作类似</p>

<pre><code class="language-ruby">require 'socket'

Socket.tcp_server_loop(4481) do |conn|
  puts conn.readpartial(100)
  conn.write('Welcome')
  conn.close
end

</code></pre>

<h2 id="第一个客户端--服务器">第一个客户端 &amp; 服务器</h2>

<p>前面几个小节讲述了<code>Socket</code> 建立以及读写操作等内容. 是时候运用我们所学知识来编写一个网络服务器和客户端了.</p>

<h3 id="服务器">服务器</h3>

<p>就服务器而言, 我打算编写一种全新的<code>NoSQL</code>解决方案, 它将作为<code>Ruby</code>散列表之上的一个网络层, 我们称之为 <code>CloudHash</code>.</p>

<pre><code class="language-ruby"># 服务器端

# 接收客户端发来的请求
# SET key value =&gt; 设置 hash[key] = value
# GET key       =&gt; 返回 hash[key]
require 'socket'

module CloudHash
  class Server

    def initialize(port)
      @server = TCPServer.new(port)
      @storage = {}
      puts "Listening on port: #{@server.local_address.ip_port}"
    end

    def run
      Socket.accept_loop(@server) do |conn|
        handle(conn)
        conn.close
      end
    end

    def handle(conn)
      # 从连接中读取指令, 直到读到 `EOF` 为止
      request = conn.read

      conn.write process(request)
    end

    # SET key value
    # GET key
    def process(request)
      command, key, value = request.split
      case command.upcase
      when 'SET'
        @storage[key] = value
      when 'GET'
        @storage[key]
      end
    end

  end
end
server = CloudHash::Server.new(4481)

server.run

</code></pre>

<h3 id="客户端">客户端</h3>

<pre><code class="language-ruby"># 客户端

require 'socket'

module CloudHash
  class Client
    class &lt;&lt; self
      attr_accessor :host, :port

      def get(key)
        request "GET #{key}"
      end

      def set(key, value)
        request "SET #{key} #{value}"
      end

      def request(string)
        # 为每一个请求操作创建一个新的 `socket` 连接
        @client = TCPSocket.new(host, port)
        @client.write(string)

        #客户端发送完请求后可以关闭写操作
        @client.close_write

        # 客户端读取服务器响应, 直到读取到 `EOF` 为止
        @client.read
      end

    end
  end
end

CloudHash::Client.host = 'localhost'
CloudHash::Client.port = 4481

puts CloudHash::Client.set 'language', 'Ruby'
puts CloudHash::Client.set 'age', '25'
puts CloudHash::Client.get 'language'
puts CloudHash::Client.get 'age'

</code></pre>

<h3 id="运行">运行</h3>

<pre><code class="language-shell">$ ruby server.rb

$ ruby client.rb
</code></pre>

<p>我们使用网络<code>API</code>将<code>Ruby</code>散列表进行了包装, 不过仅仅是涵盖了简单的读写器而已.</p>

<p>总的来说, <code>CloudHash</code>还是比较简陋. 比如说我们的客户端必须为每一个发送的请求发起一个新的连接.</p>

<p>如果我想连续发送一批请求, 那么每个请求都会占用一个连接. 它处理一条来自客户端套接字命令, 然后关闭.</p>

<p>建立连接会产生不小的开销, 我们完成可以让<code>CloudHash</code>在同一个连接上处理多个请求.</p>

<p>我们的<code>CloudHash</code>有很多地方可以改进:</p>

<ul>
  <li>客户端/服务器可以使用不需要发送<code>EOF</code> 来分隔消息的<code> DRY协议</code>进行通信. 这样可以在单个连接上发送多个请求, 而服务器依旧可以依次处理每个客户端连接.</li>
  <li>可以加入某种形式的并发来解决大量请求</li>
</ul>

<h2 id="再会">再会</h2>

<p>本篇文章主要讲述了<code>Socket</code>的基础知识, 并实现了一个<code>Ruby Hash</code>  网络服务器. 我会在接下来的两篇文章继续阐述 <code>Socket</code>编程.</p>

  ]]></description>
</item>


  </channel>
</rss>
