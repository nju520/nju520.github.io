<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    
    <title>hwbnju.com</title>
    
    <link>http://hwbnju.com</link>
    <description>nju520's Blog</description>
    <language>en-uk</language>
    <managingEditor> nju520</managingEditor>
    <atom:link href="rss" rel="self" type="application/rss+xml" />
    
<item>
  <title>TCP Socket 编程 -- 网络架构模式</title>
  <link>//tcp-scokets-arch</link>
  <author>nju520</author>
  <pubDate>2018-03-15T00:00:00+08:00</pubDate>
  <guid>//tcp-scokets-arch</guid>
  <description><![CDATA[
  <p>前面的两篇<code>TCP Socket</code>系列文章涵盖了<code>TCP Socket</code>的基础知识和必备技能, 接下来的部分我们将转向最佳实践和真实案例.</p>

<p>如果你的任务就用<code>Ruby</code>写一个简单的<code>FTP</code> 服务器, 那么仅了解前两篇文章是有所帮助的, 但是这些知识无法让你创造出伟大的软件.</p>

<p>尽管你了解建造模块, 但是你还不知道架构网络应用程序的常见方式, 如何处理并发? 如何处理错误? 处理缓慢的客户端的最好方式是什么? 如何最有效地利用资源?</p>

<p>这类问题正是本篇文章所阐述的. 接下来我们要学习六中网络架构模式, 然后把它们应用到一个案例项目中.</p>

<h2 id="ftp-服务器">FTP 服务器</h2>

<p>与其用一堆图标和抽象的描述, 我更喜欢的说明问题的方式就是采用一个能够实现的案例项目并采用不同的架构重复实现它. 这样才能深刻理解不同架构之间的差异.</p>

<p>出于这个原因, 我要编写一个包含了部分<code>FTP</code>功能的服务器.</p>

<ul>
  <li>
    <p>为什么只包含部分功能呢? 因为我希望将注意力放在<strong>架构模式</strong>,而非协议实现上.</p>
  </li>
  <li>
    <p>为什么选择<code>FTP</code>呢? 因为这样就不用再编写单独的客户端程序就可以测试了. 现成的<code>FTP</code>足够我们测试了.</p>
  </li>
</ul>

<blockquote>
  <p><code>FTP</code>协议就代表文件传输协议(File Transfer Protocol) , 通过运行在<code>TCP</code>之上, 用于两台计算机之间传送文件.</p>
</blockquote>

<p><code>FTP</code>有点像是在浏览文件系统. <code>FTP</code>同时使用两个<code>TCP</code>套接字.</p>

<ul>
  <li>控制套接字(control_socket): 用于在服务器和客户端之间发送<code>FTP</code>命令和参数</li>
  <li>读写数据套接字(connection socket): 每当要传送文件数据时, 就会使用一个新的套接字.</li>
</ul>

<p>分为两个套接字的好处, 使得在传送文件的同时仍然可以在<code>控制套接字</code>上继续处理命令.</p>

<p>我们先来实现这个<code>FTP</code>服务器. 它定义了一些常用的方法, 用于写入格式化的<code>FTP</code>响应以及建立控制套接字. 它还提供了一个<code>CommandHandler</code>类, 封装了基于每个连接的单独命令的处理. 这一点很重要, 同一个服务器上的每个连接可能有不同的工作目录, <code>CommandHandler</code>类也考虑到了这一点.</p>

<pre><code class="language-ruby">module FTP
  class CommandHandler
    # 必须是双引号的 \r\n
    CRLF = "\r\n"

    attr_reader :connection

    def initialize(connection)
      @connection = connection
    end

    def pwd
      @pwd || Dir.pwd
    end

    # 处理具体指令, 根据指令返回对应的数据结果

    def handle(data)
      command = data[0..3].strip.upcase
      options = data[4..-1].strip

      puts "#{show_time} command: #{command}  options: #{options}"

      case command
      when 'USER'
        # 可以接收匿名的用户
        "#{show_time} 230 Logged in anonymously"

      when 'SYST'
        # 用户名?
        "#{show_time} 215 UNIX Working With FTP"

      when 'CWD'
        if File.directory?(options)
          @pwd = options
          "#{show_time} 250 directory change to #{pwd}"
        else
          "#{show_time} 550 directory not found"
        end

      when 'PWD'
        "#{show_time} 257 \"#{pwd}\" is the current directory"

      when 'PORT'
        parts = options.split(',')
        ip_address = parts[0..3].join('.')
        port = Integer(parts[4]) * 256 + Integer(parts[5])

        # 启动一个新的 `socket`, 作为 client 来响应 `FTP`客户端的请求
        @data_socket = TCPSocket.new(ip_address, port)
        "#{show_time} 200 Active connection established (#{port})"

      when 'HeHe'
        parts = options.split(',')
        address_family = parts[0]
        ip_address = parts[2..5].join('.')
        port = Integer(parts[7]) * 256 + Integer(parts[8])

        # 启动一个新的 `socket`, 作为 client 来响应 `FTP`客户端的请求
        @data_socket = TCPSocket.new(ip_address, port)
        "#{show_time} 200 Long Port Active connection established (#{port})"

      when 'RETR'
        file = File.open(File.join(pwd, options), 'r')
        connection.respond "125 Data transfer starting #{file.size} bytes"

        bytes = IO.copy_stream(file, @data_socket)
        @data_socket.close

        "#{show_time} 226 Closing data connection, sent #{bytes} bytes"

      when 'LIST'
        connection.respond '125 Opening data connection for file list'

        result = Dir.entries(pwd).join(CRLF)
        @data_socket.write(result)
        @data_socket.close

        "#{show_time} 226 Closing data connection, sent #{result.size} bytes"

      when 'QUIT'
        "#{show_time} 221 Ciao"
      else
        "#{show_time} 502 Don't know how to respond to #{command}"
      end

    end

    private
    def show_time
      "[#{Time.now.strftime("%Y-%m-%d %H:%M")}]"
    end
  end
end

</code></pre>

<p>再接下来的几个小节我们分别实现不同架构的服务器.</p>

<h2 id="串行化">串行化</h2>

<p>我们要学习的第一个网络架构模式就是处理请求的<code>串行化模型</code>.</p>

<h3 id="流程">流程</h3>

<p>在串行化架构中, 所有的客户端连接都是依次进行处理的. 因为不涉及并发, 多个客户端不会同时接受服务.</p>

<p>串行化架构的处理流程很直观:</p>

<ol>
  <li>客户端连接</li>
  <li>客户端/服务器交换请求及响应</li>
  <li>客户端断开连接</li>
  <li>返回步骤1</li>
</ol>

<h3 id="实现">实现</h3>

<pre><code class="language-ruby"># serial.rb
#  串行化架构处理流程
# 1. 客户端连接
# 2. 客户端/服务器 交换请求并响应
# 3. 客户端断开连接
# 4. 返回步骤一重复下一此连接

require 'socket'
require_relative 'command_handler'

module FTP
  CRLF = '\r\n'

  class Serial

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def gets
      @client.gets(CRLF)
    end

    def respond(message)
      @client.write(message)
      @client.write(CRLF)
    end

    def run
      loop do
        @client = @control_socket.accept
        respond '220 OHAI'

        # 创建一个新的 `socket` 连接来单独处理请求
        handler = CommandHandler.new(self)

        loop do
          # 接收来自客户端的请求
          request = gets
          if request
            respond handler.handle(request)
          else
            @client.close
            break
          end
        end
      end
    end

  end
end

# 初始化我们的一个服务器实例
server = FTP::Serial.new(4481)

# 启动服务器
server.run

</code></pre>

<p><code>FTP::Serial</code>类只负责联网和并发操作, 协议处理部分交给<code>FTP::CommandHandler</code>类的方法来处理. 接下来你会经常看到这种模式.</p>

<p>让我们从头开始分析串行化架构模式.</p>

<pre><code class="language-ruby">class Serial

  def initialize(port = 21)
    @control_socket = TCPServer.new(port)
    trap(:INT) {exit}
  end

  def gets
    @client.gets(CRLF)
  end

  def respond(message)
    @client.write(message)
    @client.write(CRLF)
  end
end
</code></pre>

<p>这三个方法属于这类特定实现的样板代码<code>boilerplate</code>.</p>

<ul>
  <li>
    <p>initialize: 打开一个套接字, 由该套接字接受客户端连接</p>
  </li>
  <li>
    <p>gets: 将<code>gets</code>委托给当前客户端连接. 它传递了一个明确的分隔符, 用以保证在具有不同默认分隔符的平台之间的可移植性.</p>
  </li>
  <li>
    <p>respond: 用来写入格式化过的<code>FTP</code>响应. <code>message</code>中包含了整数类型的响应代码以及对应的字符串详细. 当<code>FTP客户端</code>收到<code>\r\n</code>组合时, 它就知道已经获得了完整的响应信息.</p>

    <p>​</p>
  </li>
</ul>

<pre><code class="language-ruby">def run
  loop do
    @client = @control_socket.accept
    respond '220 OHAI'

    handler = CommandHandler.new(self)
  end
end
</code></pre>

<p>这是服务器的主循环, 所有的处理逻辑都发生在外部主循环之内.</p>

<p>循环中唯一调用<code>accept</code>就在此. 它接受一个来自<code>@control_socket</code>的连接, 后者在<code>initialize</code>中进行初始化. 代码响应<code>220</code>是属于<code>FTP</code>规定的, 表示<code>Service ready for new user</code>, <code>FTP</code>服务要求服务器在接受一个新的客户端连接之后要打声招呼.</p>

<p>最后一处为该连接进行<code>CommandHandler</code>的初始化. 该类封装了服务器上的每个连接的当前状态( 当前工作目录). 我们可以将接入的请求交给<code>handler</code>对象, 然后获得对应的响应.</p>

<p>这部分代码是串行化代码只进行并发的绊脚石. 进行处理时, 服务器没发继续接受新的连接, 更谈不上实现并发了. 当我们学到其他模式如何应对这种情况时, 就会明显看出它们之间的差异了.</p>

<pre><code class="language-ruby">loop do
  request = gets

  if request
    respond handler.handle(request)
  else
    @client.close
    break
  end
end
</code></pre>

<p>这部分完成了我们的<code>FTP服务器</code>的串行化实现.</p>

<p>在内部循环中, 使用<code>gets</code>从客户端套接字中获取带有显式分隔符的请求, 然后将请求交给<code>handler</code>来处理,由它为客户端构造对应的响应信息.</p>

<h3 id="运行">运行</h3>

<p>鉴于这是一个功能完善的<code>FTP服务器</code>, 我们实际上可以运行该服务器, 使用标准的<code>FTP客户端</code>进行连接, 来看一下它的表现:</p>

<pre><code class="language-shell"># 开启 `FTP服务器`
$ ruby serial.rb


# 开启 标准的`FTP客户端`
$ ftp -a -v localhost 4481

# 输入指令
$ pwd 

$ cd /var/log


</code></pre>

<p>我们可以通过查看系统进程信息来看一下<code>串行化架构</code>的进程模式:</p>

<pre><code class="language-shell">λ lsof -i:4481
COMMAND   PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME
ruby    73426 bobo    9u  IPv6 0x60dd91188c3b4949      0t0  TCP *:4481 (LISTEN)
ruby    73426 bobo   10u  IPv6 0x60dd91188c3b6049      0t0  TCP localhost:4481-&gt;localhost:62166 (ESTABLISHED)
gftp    73435 bobo    3u  IPv4 0x60dd9118a7de4731      0t0  TCP localhost:62166-&gt;localhost:4481 (ESTABLISHED)
gftp    73435 bobo    4u  IPv4 0x60dd9118a7de4731      0t0  TCP localhost:62166-&gt;localhost:4481 (ESTABLISHED)
gftp    73491 bobo    3u  IPv4 0x60dd9118a7dee091      0t0  TCP localhost:62168-&gt;localhost:4481 (ESTABLISHED)
gftp    73491 bobo    4u  IPv4 0x60dd9118a7dee091      0t0  TCP localhost:62168-&gt;localhost:4481 (ESTABLISHED)

</code></pre>

<p>我们通过指令<code>lsof -i:4481</code>查看端口 <code>4481</code>上的进程:</p>

<ul>
  <li><code>73426</code>: 此进程为控制套接字进行, 负责接受客户端的请求并且返回指令和参数
    <ul>
      <li>第二行的<code>PID</code>	仍然是<code>73426</code>, 这说明串行架构并没有开辟新的进程来处理请求, 而是在同一个进程下.</li>
    </ul>
  </li>
  <li>73435: 我们运行的第一个<code>FTP客户端</code>, 负责向<code>FTP服务器</code>发送请求</li>
  <li>73491: 我们运行的第二个<code>FTP客户端</code>. 我还注意到只有第一个客户端退出时, 服务器才会响应第二个客户端的请求.</li>
</ul>

<blockquote>
  <p>Mac OS High Sierra 已经把<code>FTP</code> 命令行工具移除, 只能使用<code>sftp</code>访问, 我们可以使用如下方式安装:</p>

  <pre><code class="language-shell">$ brew install inetutils

$ brew link --overwrite inetutils

# 安装成功后将下面路径加入到 ~/.zshrc
export PATH="/usr/local/opt/inetutils/libexec/gnubin:$PATH"

MANPATH="/usr/local/opt/inetutils/libexec/gnuman:$MANPATH"

就可以直接使用 `ftp`命令并可以通过 `man`来查看帮助
</code></pre>
</blockquote>

<h3 id="思考">思考</h3>

<p>很难明确地归纳每种模式的优劣, 因为这完全取决于我们的需求. 我会尽力解释每种模式最适用的场景及其所做出的一些权衡.</p>

<p><strong>串行化架构</strong>最大的优势在于它的简单性. 没有锁, 没有共享状态, 处理完一个连接之后才能处理另外一个. 在资源使用方面亦是如此: 一个实例处理一个连接, 一个萝卜一个坑, 绝不多消耗资源.</p>

<p><strong>串行化架构</strong>最大的劣势就是不能并发操作. 及时时当前连接处于空闲, 也不能处理等待的连接. 同样, 如果某个连接使用的链路速度不佳, 或者在发送请求之间暂停, 那么服务器就只能保持阻塞, 直到连接关闭.</p>

<p>对接下来更有意思的模式而言,  <strong>串行化模式</strong>仅仅只是一个起点而已.</p>

<h2 id="单连接进程">单连接进程</h2>

<blockquote>
  <p>这是首个可以对请求进行并行处理的网络架构</p>
</blockquote>

<h3 id="流程-1">流程</h3>

<p>要支持并发处理, 只需要将串行化架构略加修改即可. 接受连接的代码不需要改动, 处理来自套接字数据的逻辑<code>CommandHandler</code>也保持不变.</p>

<p>相关改动出现在<strong>接受连接</strong>之后, 服务器会<code>fork</code>出一个子进程, 这个子进程的唯一目的就是在处理新连接. 连接处理完毕之后就退出.</p>

<blockquote>
  <p>进程衍生:</p>

  <p>只要我们使用命令 <code>ruby myapp.rb</code>启动程序, 就会生成一个新的<code>Ruby</code>进程来载入并执行代码.</p>

  <p>如果在程序中使用<code>fork</code>, 那实际上就是在运行期间创建了一个新进程. <code>fork</code>可以使我们获得两个一模一样的进程. 新创建的进程被视为“孩子”; 原先的进程被视为“双亲”. 一旦<code>fork</code>完成, 就拥有了两个进程,它们可以各行其道.</p>

  <p>这一点及其重要, 它意味着我们可以 <code>accept</code>一个连接, <code>fork</code>一个子进程, 这个子进程就会自动获得一份客户端连接的副本. 无需其他设置、数据共享或者锁, 直接就可以开始并行处理了.</p>
</blockquote>

<p>让我们来理清事件流程:</p>

<ol>
  <li>一个连接抵达服务器</li>
  <li>主服务器进程接受该连接</li>
  <li>主进程衍生出一个和服务器主进程一模一样的新子进程</li>
  <li>服务器主进程返回步骤1, 由子进程并行处理连接</li>
</ol>

<p>得益于内核语义, 这些进程是并行执行的. 子进程处理连接时, 原先的父进程可以继续接受新连接, 衍生出新的子进程对新连接进行处理.</p>

<p>不管何时, 总是有一个父进程等着接受连接, 但是会有多个子进程分别处理单个连接.</p>

<h3 id="实现-1">实现</h3>

<pre><code class="language-ruby">#  串行化架构处理流程
# 1. 一个连接抵达芙蕖
# 2. 主服务器进程接受该连接
# 3. 主进程衍生出和服务器一模一样的子进程
# 4. 服务器主进程返回步骤 1, 由子进程并行处理连接


require 'socket'
require_relative 'command_handler'

module FTP
  CRLF = '\r\n'

  class ProcessPerConnection

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def gets
      @client.gets(CRLF)
    end

    def respond(message)
      @client.write(message)
      @client.write(CRLF)
    end

    def run
      loop do
        @client = @control_socket.accept

        pid = fork do
          respond '220 OHAI'

          handler = CommandHandler.new(self)
          loop do
            request = gets

            if request
              respond handler.handle(request)
            else
              @client.close
              break
            end
          end
        end

        Process.detach(pid)

      end
    end

  end
end

# 初始化我们的一个服务器实例
server = FTP::ProcessPerConnection.new(4481)

# 启动服务器
server.run

</code></pre>

<p>如你所见, 大部分代码都没有变动. 最大的不同在于内循环被放在了一个<code>fork</code>调用中</p>

<pre><code class="language-ruby">@client = @control_socket.accept

pid = fork do
  respond '220 OHAI'

  handler = CommandHandler.new(self)
  #...
end
</code></pre>

<p>使用<code>accept</code>接受连接之后, 服务器进程立刻使用代码块来调用<code>fork</code>. 新的子进程会对该代码块进行求值, 然后退出.</p>

<p>这意味着每一个接入的连接都由一个独立的进程处理. 父进程不会对代码块求值, 它只会沿着自己的执行路径进行.</p>

<pre><code class="language-ruby">Process.detach(pid)
</code></pre>

<p>我们在最后调用了<code>Process.detach</code>. 在一个进程退出之后, 它并不会被完全清除, 直到其父进程查询该进程的退出状态. 在这里我们并不关心子进程的退出状态是什么, 所有提前把它与父进程分离. 确保子进程退出后, 所占用的资源能够完全清除.</p>

<p>让我运行 <code>lsof -wni tcp:4481</code>查看一下端口<code>4481</code>的情况吧:</p>

<pre><code class="language-shell">λ lsof -wni tcp:4481
COMMAND   PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME
ruby    84347 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84347 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
ruby    84347 bobo   11u  IPv6 0x60dd91188c3b6049      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63002 (ESTABLISHED)
ruby    84347 bobo   12u  IPv6 0x60dd91188c3b6609      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63017 (ESTABLISHED)
gftp    84355 bobo    3u  IPv4 0x60dd9118a6cb3351      0t0  TCP 127.0.0.1:62997-&gt;127.0.0.1:4481 (ESTABLISHED)
gftp    84355 bobo    4u  IPv4 0x60dd9118a6cb3351      0t0  TCP 127.0.0.1:62997-&gt;127.0.0.1:4481 (ESTABLISHED)
ruby    84356 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84356 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
gftp    84373 bobo    3u  IPv4 0x60dd91188bda2731      0t0  TCP 127.0.0.1:63002-&gt;127.0.0.1:4481 (ESTABLISHED)
gftp    84373 bobo    4u  IPv4 0x60dd91188bda2731      0t0  TCP 127.0.0.1:63002-&gt;127.0.0.1:4481 (ESTABLISHED)
ruby    84374 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84374 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
ruby    84374 bobo   11u  IPv6 0x60dd91188c3b6049      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63002 (ESTABLISHED)
gftp    84859 bobo    3u  IPv4 0x60dd91188fc9bcb1      0t0  TCP 127.0.0.1:63017-&gt;127.0.0.1:4481 (ESTABLISHED)
gftp    84859 bobo    4u  IPv4 0x60dd91188fc9bcb1      0t0  TCP 127.0.0.1:63017-&gt;127.0.0.1:4481 (ESTABLISHED)
ruby    84860 bobo    9u  IPv6 0x60dd91188c3b6bc9      0t0  TCP *:4481 (LISTEN)
ruby    84860 bobo   10u  IPv6 0x60dd91188c3b4949      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:62997 (ESTABLISHED)
ruby    84860 bobo   11u  IPv6 0x60dd91188c3b6049      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63002 (ESTABLISHED)
ruby    84860 bobo   12u  IPv6 0x60dd91188c3b6609      0t0  TCP 127.0.0.1:4481-&gt;127.0.0.1:63017 (ESTABLISHED)

</code></pre>

<p>从端口情况可以看出, 我打开了三个客户端,   每打开一个客户端, 我们的<code>FTP服务器</code>就会开辟一个新的进程来处理客户端请求, 主进程继续循环接受客户端连接.</p>

<h3 id="思考-1">思考</h3>

<p><strong>单连接进程</strong>有很多优势.</p>

<ul>
  <li>
    <p>简单. 为了能够<strong>并行处理</strong>多个客户端, 只需要在串行化实现的基础上增加及少量的代码即可</p>
  </li>
  <li>
    <p>这种并行操作不难理解. <code>fork</code>实际上提供了一个子进程所需要的所有东西的副本. 我们不需要留心边界情况, 没有锁和竞争条件, 只是简单的分离而已.</p>

    <p>一个明显的劣势就是, 对于<code>fork</code>出的子进程的数量没有施加限制. 如果客户端的数量不大, 这倒没什么大问题, 但是如果生成了上百个进程, 那么我们的系统可能会崩溃了. 这方面可以使用我们接下来要实现的<code>preforking</code>模式来解决.</p>

    <p>还有一点, 对于不同的操作环境, 使用<code>fork</code>可能会出现问题. 只有<code>Unix</code>系统才支持<code>fork</code>, 这意味着<code>Windows</code>或者<code>JRuby</code>就没发使用<code>fork</code>了.</p>

    <p>我们究竟该使用<code>进程</code>还是<code>线程</code>, 这个问题留到下一小节来讨论, 届时我们会接触到线程.</p>
  </li>
</ul>

<h2 id="单连接线程">单连接线程</h2>

<h3 id="讲解">讲解</h3>

<p><strong>单连接线程模式</strong>和上一节的<strong>单连接进程模式</strong>非常相似. 不同之处就在于, 它是生成新线程, 而非新进程</p>

<blockquote>
  <p>线程与进程</p>

  <p>线程和进程都可以用于并行操作, 但是方式大不相同, 究竟使用哪个取决于实际情况.</p>

  <p><strong>生成(spawn)</strong>: 就生成而言, 线程的生成成本要低得多. 生成一个进程需要创建原始进程所拥有的一切资源的副本. 线程以进程为单位, 多个线程都存在于同一个进程中. 由于多个线程共享存在, 无需创建副本, 因而线程的生成速度要快得多.</p>

  <p><strong>同步(sync)</strong>: 因为线程共享内存, 当使用会被多个线程访问的数据结构时, 一定要多加小心. 这通常意味着要在线程之间使用互斥量(mutex)、枷锁以及同步访问. 进程就无需如此了, 因为每个进程都有自己的一份资源副本.</p>

  <p><strong>并行(p)</strong>: 两者都提供了由内核实现的并行计算能力. 关于<code>MRI</code>中的线程并行需要注意的一件重要的事情: 解释器对当前执行环境使用了一个<strong>全局锁</strong>. 因为线程以进程为单位, 这意味着它们都运行在一个解释器中. 即使使用了多线程, <code>MRI</code>也使得它们无法实现真正的并行. 在另外一些<code>Ruby</code>实现中, 如<code>JRuby</code>或者<code>Rubinius2.0</code>, 就不存在这样的问题.</p>

  <p>进程没有这方面的麻烦, 因为每次都是生成新的进程, 它都会获得自己的一份<code>Ruby解释器</code>的副本, 所以也就无需全局锁. 在<code>MRI</code> zhong , <strong>只有进程才能实现真正的并发</strong></p>

  <p>关于并行和线程还要说明一点. 即使是<code>MRI</code>使用了全局解释器🔒, 它对线程的处理也非常巧妙. 如果某个线程阻塞在<code>IO</code>上, <code>Ruby</code>能够让其他的线程继续执行.</p>

  <p>总而言之, 线程是轻量级的, 进程是重量级的. 两者都用于并行操作, 两者都有各自适用的环境.</p>
</blockquote>

<h3 id="实现-2">实现</h3>

<pre><code class="language-ruby">#  单连接线程架构处理流程
# 1. 启动一个线程池, 初始化一个 `control_socket`
# 2. 每接受一个新的连接请求时, 创建一个新线程来处理
# 3. `control_socket` 继续返回 2 等待接受新的连接

require 'socket'
require_relative 'command_handler'

module FTP

  Connection = Struct.new(:client) do
    CRLF = "\r\n"

    def gets
      client.gets(CRLF)
    end

    def respond(message)
      client.write(message)
      client.write(CRLF)
    end

    def close
      client.close
    end
  end

  class ThreadPerConnection

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) { exit }
    end

    def run
      Thread.abort_on_exception = true

      loop do
        # 接受客户端请求
        conn = Connection.new(@control_socket.accept)

        Thread.new do
          conn.respond '220 OHAI'

          handler = FTP::CommandHandler.new(conn)
          loop do
            request = conn.gets

            if request
              conn.respond handler.handle(request)
            else
              conn.close
              break
            end
          end
        end
      end
    end # end of run

  end
end

# 初始化我们的一个服务器实例
server = FTP::ThreadPerConnection.new(4481)

# 启动服务器
server.run

</code></pre>

<p>之前的样板代码被我放到了<code>Connection</code>类中, 而不是直接定义在服务器类中:</p>

<pre><code class="language-ruby">connection = Struct.new(:client) do
  def gets
  # ..
  end

  def respond(message)
  # ..
  end

  def close
  # ..
  end
end
</code></pre>

<p><code>run</code>方法我们也采用创建线程的模式:</p>

<pre><code class="language-ruby">def run
  Thread.abort_on_exception = true

  loop do
    # 接受客户端请求
    conn = Connection.new(@control_socket.accept)

    Thread.new do
      conn.respond '220 OHAI'

      handler = FTP::CommandHandler.new(conn)
      loop do
        request = conn.gets

        if request
          conn.respond handler.handle(request)
        else
          conn.close
          break
        end
      end
    end
  end
end # end of run
</code></pre>

<p>这其中有两处关键的不同.</p>

<ul>
  <li>采用 <code>Thread.new</code>生成了一个线程</li>
  <li>从<code>accept</code>返回的客户端套接字被传给<code>Connection.new</code>; 每个线程均获得自己的<code>Connection</code> 实例</li>
</ul>

<p>使用线程时, 每个线程使用一个全新的<code>Connection</code>实例非常重要. 如果我们像以前那样, 简单地将客户端套接字分配给一个实例变量, 那么它会在所有的活动现场之间共享. 因为这些线程是从一个共享的<code>FTP服务器</code>  实例中生成的, 所有它们会共享该实例的内部状态.</p>

<p>这与同进程打交道有着显著差别, 在后者中每个进程都会获得内存中所有资源的副本.</p>

<blockquote>
  <p>之所以很多开发者声称线程编程不容易, 其中一个原因便是状态共享. 如果你使用线程进行套接字编程, 有一条简单的经验: 让每个线程获得它自己的连接对象.</p>
</blockquote>

<h3 id="思考-2">思考</h3>

<p><strong>单连接线程模式</strong>与<strong>单连接进程模式</strong>有很多共同的优势: 代码修改量少, 很容易理解.</p>

<p>尽管使用线程会引入锁以及同步问题, 但是这里我们并不用担心这个问题, 因为每个连接都是由单个独立线程来处理的.</p>

<p>该模式较<strong>单连接进程</strong>的一个优势就是线程占用资源少, 因而获得数量上的增加. 比起进程, 它能够为客户端服务提供更好的并发性.</p>

<p>不过先等等, 别忘了<code>MRI GIL</code>使得这一优势无法变成现实. 归根结底, 没有哪个模式能够所向披靡, 每一种模式都应该思考、尝试、检验.</p>

<p><strong>单连接线程模式</strong>与<strong>单连接进程模式</strong>都有一个共同的劣势: 线程数会不断增加, 直到系统不堪重负.</p>

<p>如果你的服务器要处理持续增加的连接, 系统可能难以在所有的活动线程上进行维护和切换.</p>

<p>这可以通过限制活动线程数解决.</p>

<h2 id="preforking">Preforking</h2>

<h3 id="讲解-1">讲解</h3>

<p><code>Preforking</code>模式是建立在<strong>单连接进程模式</strong>的基础上.</p>

<p>它依赖进程作为并行操作的手段, 但并不为每个接入的连接衍生出对应的子进程, 而是在服务器启动后, 连接到达之前就预先衍生出一批进程.</p>

<h4 id="处理流程">处理流程</h4>

<ol>
  <li>主服务器进程创建一个侦听套接字</li>
  <li>主服务器进程衍生出一大批子进程</li>
  <li>每个子进程在共享套接字上接受连接, 然后独立进行处理</li>
  <li>主服务器进行密切关注子进程</li>
</ol>

<p>这个流程的重点在于, 主服务器进程打开侦听套接字, 却并不接受该套接字之上的连接. 它随后衍生出预定义数量的一批子进程, 每个子进程都有一份侦听套接字的副本. 子进程在各自的侦听套接字上调用<code>accept</code>, 不再考虑父进程.</p>

<p>这个模式的精妙之处在于, 无需担心负载均衡或者子进程连接的同步, 因为内核已经替我们完成这个工作了.</p>

<p>对于多个进程试图在同一个套接字的不同副本上接受(accept)连接的问题, 内核会均衡负载并确保只有一个套接字副本可以接受某个特定的连接</p>

<h3 id="实现-3">实现</h3>

<pre><code class="language-ruby"># Preforking

require 'socket'
require_relative 'command_handler'

module FTP
  CRLF = "\r\n"
  CONCURRENCY = 4

  class Preforking

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def gets
      @client.gets(CRLF)
    end

    def respond(message)
      @client.write(message)
      @client.write(CRLF)
    end

    def run
      child_pids = []

      CONCURRENCY.times do
        child_pids &lt;&lt; span_child
      end

      trap(:INT) {
        child_pids.each do |child_pid|
          begin
            Process.kill(:INT, child_pid)
          rescue Errno::ESRCH
          end
        end

        exit
      }

      loop do
        pid = Process.wait
        $stderr.puts "[#{Time.now.stftime("%Y-%m-%d %H:%M")}] Process #{pid} quit unexpectedly"

        child_pids.delete(pid)
        child_pids &lt;&lt; span_child
      end

    end # end of run

    def span_child
      fork do
        loop do
          @client = @control_socket.accept
          respond '220 OHAI'

          handler = CommandHandler.new(self)
          loop do
            request = gets

            if request
              respond handler.handle(request)
            else
              @client.close
              break
            end
          end
        end
      end
    end # end of span_child

  end
end

# 初始化我们的一个服务器实例
server = FTP::Preforking.new(4481)

# 启动服务器
server.run

</code></pre>

<p>我们先来看一下 <code>run</code>方法:</p>

<p>我们会在<code>run</code> 方法中多次调用了<code>spawn_child</code>方法, 具体次数基于我们自定义的<code>CONCURRENCY</code>中的值而定. <code>spawn_child</code>会<code>fork</code>一个新进程然后返回其进程<code>id</code>, 该值是唯一的.</p>

<p>生成子进程后, 父进程为<code>INT</code>信息定义了一个信号处理器. 当你键入<code>Ctrl+C</code>时, 进程就会收到该信号. 这个信号处理器仅用于将父进程接收到的<code>INT</code>信号转发给它的子进程.</p>

<p>因为子进程独立于父进程存在, 即使是父进程结束了, 子进程也不会收到影响. 所以对于父进程而言, 在退出之前清理自己的子进程就很有必要.</p>

<p>信号处理完之后, 父进程就进入了<code>Process.wait</code>循环. 该方法会一直阻塞到有子进程退出为止.</p>

<p><code>Process.wait</code>返回退出子进程的<code>pid</code>.因为子进程并不应该退出, 所有我们将<code>子进程异常退出</code>视为一场情况.</p>

<p>随后在<code>STDERR</code>上打印一条信息并生成一个新的子进程代替.</p>

<p>在一些<code>Preforking</code>服务器中, 尤其是<code>Unicorn</code>, 父进程承担了更为活跃的角色, 它还负责监视自己的子进程. 例如父进程可能会查看是否有哪个子进程耗费了太多的时间处理请求. 如果是, 父进程会终止该进进程并生成新的子进程取代它.</p>

<p>我们再来看一下<code>spawn_child</code>方法:</p>

<p>这种方法的核心部分应该很熟悉了. 这次它被放入了<code>fork</code>和<code>loop</code>外. 因此新进程在调用<code>accept</code>之前就已经衍生出来了. 最外层的循环确保每个连接处理并关闭后, 继续处理新的连接. 通过这种方法, 每个子进程都处于它们各自的<code>接受连接</code>循环中.</p>

<h3 id="思考-3">思考</h3>

<p><code>Preforking</code>不用在每个连接期间进行<code>fork</code>. 进程衍生的成本可不少.在单连接进程架构中, 每个连接都要承担由此带来的开销.</p>

<p>由于<code>Preforking</code>在<code>accept</code>连接之前就生成了所有连接, 因而避免了进程过量的情况.</p>

<p>比起与<code>Preforking</code>类似的线程模式, 这个模式的一个优势就是完全隔离.</p>

<p>因为每个进程都拥有包括<code>Ruby</code>解释器在哪的所有资源的副本, 单个进程中的故障不会影响其他进程.</p>

<p>因为线程共享资源以及内存空间, 单线程故障可能会无法预测地影响到其他线程.</p>

<p><code>Preforking</code>的一个劣势就是: 衍生的进程越多, 消耗的内存也越多.</p>

<p>进程可不是免费的午餐. 考虑到每个衍生的进程都会获得所有资源的一份副本, 我们可以预料到每一次进程衍生, 内存占用率就要增加100%(以父进程为基准).</p>

<p>按照这种衍生方式, 占用<code>100MB</code>内存的进程在衍生出4个子进程之后将占用<code>500MB</code>内存.</p>

<p>即使这样, 也才4个并发连接.</p>

<h2 id="线程池">线程池</h2>

<p>线程池模式之于 <code>Preforking</code>, 一如单连接线程与单连接进程之间的关系. 同<code>Preforking</code>类似, 线程池在服务器启动后会生成一批线程, 将处理连接的任务交给独立的线程来完成.</p>

<p><strong>线程池模式</strong>处理流程和<code>Preforking</code>一样, 只需要把“进程”修改为“线程”就行了.</p>

<pre><code class="language-ruby"># ThreadPool

require 'socket'
require 'thread'
require_relative 'command_handler'

module FTP
  Connection = Struct.new(:client) do
    CRLF = "\r\n"

    def gets
      client.gets(CRLF)
    end

    def respond(message)
      client.write(message)
      client.write(CRLF)
    end

    def close
      client.close
    end
  end

  class ThreadPool
    CONCURRENCY = 25

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) {exit}
    end

    def run
      Thread.abort_on_exception = true
      threads = ThreadGroup.new


      CONCURRENCY.times do
        threads.add spawn_thread
      end

      sleep
    end

    def spawn_thread
      Thread.new do
        loop do
          conn = Connection.new(@control_socket.accept)
          conn.respond '220 OHAI'

          handler = CommandHandler.new(self)

          loop do
            request = conn.gets

            if request
              conn.respond handler.handle(request)
            else
              conn.close
              break
            end
          end
        end
      end
    end # end of spawn_thread

  end
end

# 初始化我们的一个服务器实例
server = FTP::ThreadPool.new(4481)

# 启动服务器
server.run

</code></pre>

<p>这里在此出现了两个方法: 一个用来生成线程, 一个用来封装线程生成以及线程从未.</p>

<p>因为我们使用的是线程,因此还需要使用<code>Connnection</code>类.</p>

<pre><code class="language-ruby">def run
  Thread.abort_on_exception = true
  threads = ThreadGroup.new


  CONCURRENCY.times do
    threads.add spawn_thread
  end

  sleep
end
</code></pre>

<p><code>run</code> 方法创建了一个<code>ThreadGroup</code>实例跟踪所有的线程. <code>ThreadGroup</code>有点像一个可对线程进行操作的数组. 我们可以 向<code>ThreadGroup</code>中加入线程, 当某个线程成员执行结束之后, 它就会从这个线程组中丢弃.</p>

<p>我可以使用<code>ThreadGroup#list</code>获得组中当前所有活动现场列表.在这个实现中, 我们其实并没有用到这个技巧.</p>

<p>同上一节的<strong>Preforking</strong>类似, 我们依据<code>CONCURRENCY</code>的值多次调用<code>spawn_thread</code>. 注意这里的<code>CONCURRENCY</code>的值要比<code>Preforking</code>中的高. 这还是因为线程的开销更小一些, 所有我们可以使用更多的线程. 要记住的是<code>MRI GIL</code>减少了一部分由此带来的收益.</p>

<p>方法的最后我们调用了<code>sleep</code>来避免方法退出. 当线程池中的线程有工作任务时, 主线程保持空闲. 理论上它可以监视线程池, 不过这里我们只是使用了<code>sleep</code>不让其退出.</p>

<p><code>spawn_thread</code>方法平淡无奇, 没什么出彩之处, 它和 <code>Preforking</code>中<code>spawn_child</code>一样. 生成一个线程, 重复执行连接处理代码.内核会确保一个连接只能由单个线程接受.</p>

<h3 id="思考-4">思考</h3>

<p>有关线程池模式大部分的思路内容和<code>Preforking</code>一样.</p>

<p>除了那些线程和进程之间显而易见的权衡之外, 线程池模式不需要每次处理连接时都生成线程, 也没有什么令人抓狂的锁或者竞争条件, 但却仍提供了并行处理能力.</p>

<h2 id="事件驱动">事件驱动</h2>

<p>迄今为止我没看到的这些模式其实都是串行化模式的变体而已. 其他的几种模式实际上使用的结构和串行化相同, 只不过包装了线程或者进程.</p>

<p><strong>事件驱动</strong>模式采用的是一种和之前完全不同的方法.</p>

<h3 id="讲解-2">讲解</h3>

<p><strong>事件驱动模式</strong>(基于Reactor模式)如今可谓风头正劲. 它也是EventMachine、Twisted、Node.js以及Nginx等库的核心所在.</p>

<p>该模式结合了单线程和单进程, 它至少可以达到之前模式所提供的并行操作级别.</p>

<p>它以一个中央连接复用器(被称为<code>Reactor</code>核心)为核心. 连接生命周期中的每个阶段都被分解成单个的事件, 这些事件之间可以按照任意的次序交错并处理. 连接的不同阶段只是一些IO操作而已:</p>

<p><code>accept</code> 、<code>read </code>、<code>write</code> 、<code>close</code>.</p>

<p>中央复用器监视所有活动连接的事件, 在触发事件时分派相关的代码.</p>

<p>下面是事件驱动模式的工作流程:</p>

<ol>
  <li>服务器监视侦听套接字, 等待接入的连接</li>
  <li>将接入的新连接加入到<strong>套接字列表</strong>中进行监视</li>
  <li>服务器现在要监视活动连接以及侦听套接字</li>
  <li>当某个活动连接可读时, 服务器从该连接读取一块数据并分派相关的回调函数</li>
  <li>当某个活动连接仍然可读时, 服务器读取另一块数据并再次分派给相关的回调函数.</li>
  <li>服务器收到另外一个新连接, 将其加入套接字列表进行监视.</li>
  <li>服务器注意到第一个连接已经可以写入, 因而将响应信息写入该连接.</li>
</ol>

<p>记住: <strong>所有的一切都发生在单个线程中</strong>. 第一个连接仍在读/写过程中, 服务器就可以<code>accept</code>新连接了.</p>

<p>服务器将每次操作分隔成小块, 这样属于多连接的不同事件就可以彼此交错了</p>

<h3 id="实现-4">实现</h3>

<pre><code class="language-ruby">require 'socket'
require_relative 'command_handler'

module FTP
  class Evented
    CHUNK_SIZE = 1024 * 16

    class Connection
      CRLF = "\r\n"
      attr_reader :client

      def initialize(io)
        @client = io
        @request, @response = "", ""
        @handler = CommandHandler.new(self)

        respond "220 OHAI"
        # 写数据
        on_writable
      end

      # 处理数据并发送响应
      def on_data(data)
        @request &lt;&lt; data

        if @request.end_with?(CRLF)
          # 调用 `handle` 来处理此次请求并将返回的数据写入到 `response`
          respond @handler.handle(@request)
          @request = ""
        end
      end

      def respond(message)
        @response &lt;&lt; message + CRLF
        # 立即加载可以写入的任何内容
        # 其余部分将在下次套接字可写入时充实
        on_writable
      end

      def on_writable
        bytes = client.write_nonblock(@response)
        @response.slice!(0, bytes)
      end

      def monitor_for_reading?
        true
      end

      def monitor_for_writing?
        !(@response.empty?)
      end
    end # end of Connection

    def initialize(port = 21)
      @control_socket = TCPServer.new(port)
      trap(:INT) { exit }
    end

    def run
      @handles = {}

      loop do
        to_read  = @handles.values.select(&amp;:monitor_for_reading?).map(&amp;:client)
        to_write = @handles.values.select(&amp;:monitor_for_writing?).map(&amp;:client)
        readables, writables = IO.select(to_read + [@control_socket], to_write)

        readables.each do |socket|
          # 侦听套接字负责侦听
          if socket == @control_socket
            io = @control_socket.accept
            connection = Connection.new(io)
            @handles[io.fileno] = connection
          # 其余读套接字负责读取数据
          else
            connection = @handles[socket.fileno]

            begin
              data = socket.read_nonblock(CHUNK_SIZE)
              connection.on_data(data)
            # 没有数据可读时就重试, 实际上啥也没做, `each` 循环继续到下一个 `socket`
            rescue Errno::EAGAIN
            rescue EOFError
              # 当读取到 `EOF` 时就删除此 socket
              @handles.delete(socket.fileno)
            end
          end
        end # end of readables

        writables.each do |socket|
          connection = @handles[socket.fileno]
          # 往 socket 写入数据
          connection.on_writable
        end
      end # end of loop
    end # end of run
  end # end of Evented
end

server = FTP::Evented.new(4481)

server.run

</code></pre>

<p>这个实采用了一种同之前那些实现不同的手法. 我们把代码分解成几个部分研究.</p>

<pre><code class="language-ruby">class Connection
# ..
end
</code></pre>

<p>我们定义了一个<code>Connection</code>类作为事件驱动服务器.</p>

<p>在前面几个线程模式的示例中, 我们用<code>Connection</code>类保持进程间的状态隔离. 这个示例并没有使用线程, 为什么需要<code>Connection</code>类呢?</p>

<p>所有基于进程的模式都使用进程隔离连接. 不管利用即成的方法如何, 它们总是确保无论何时都由单个独立的进程处理单个连接, 所有每个连接基本上是由一个进程描述.</p>

<p><strong>事件驱动模式</strong>用的是单线程, 但是可以同时处理多个用户连接, 所有它需要使用一个对象来描述每个独立的连接, 这样就不会破坏连接各自的状态.</p>

<pre><code class="language-ruby">class Connection
  CRLF = "\r\n"
  attr_reader :client

  def initialize
    @client = io
      @request, @response = "", ""
      @handler = CommandHandler.new(self)

      respond "220 OHAI"
      on_writable
  end
end
</code></pre>

<p><code>Connection</code>类的开始部分看起来有些眼熟.</p>

<p><code>Connection</code>类将底层的<code>IO</code>对象存储在它的<code>@client</code>实例变量中. 外界可以通过<code>attr_reader</code>对其进行访问.</p>

<p>当连接初始化完毕后, 它会像从前一样获得自己的<code>CommandHandler</code>实例. 随后它写入<code>FTP</code>所要求的定制的<code>hello</code>响应. 不过并非直接写入客户端连接, 而是将响应的主体信息写入<code>@response</code>变量.</p>

<p>下面我们将会看到这将引发<code>Reactor</code>接管操作并将数据发送到客户端.</p>

<pre><code class="language-ruby"># 处理数据并发送响应
def on_data(data)
  @request &lt;&lt; data

  if @request.end_with?(CRLF)
    # 完成此次请求
    respond @handler.handle(@request)
    @request = ""
  end
end

def respond(message)
  @response &lt;&lt; message + CRLF
  # 立即加载可以写入的任何内容
  # 其余部分将在下次套接字可写入时充实
  on_writable
end

def on_writable
  bytes = client.write_nonblock(@response)
  @response.slice!(0, bytes)
end
</code></pre>

<p><code>Connection</code>类定义了若干与<code>Reactor</code>核心进行交换的生命周期方法.</p>

<p>例如, 当<code>Reactor</code>从客户端连接读取数据时, 它触发<code>on_data</code>处理数据.在<code>on_data</code>内部, 检查接受到的是否是一个完整的请求, 如果是会请求<code>@handler</code>建立对应的响应并将其赋给<code>@response</code>.</p>

<p>当客户端连接可以进行写入时就调用<code>on_writable</code>方法. 这就要和<code>@response</code> 变量打交道了. 它将<code>@response</code>中的内容写入客户端连接. 根据能够写入的字节数, 将成功写入的数据从<code>@response</code>中移除.</p>

<p>这样,随后的写操作就只会写入<code>@response</code>中本次没能写入的部分内容. 如果能够写入全部内容, 那么<code>@response</code>就变成了一个空字符串, 就无法再进行写操作了.</p>

<pre><code class="language-ruby">def monitor_for_reading?
  true
end

def monitor_for_writing?
  !(@response.empty?)
end
</code></pre>

<p><code>monitor_for_reading</code>以及<code>monitor_for_writing</code>这两个方法被<code>Reactor</code>用来查询是否应该监视特定连接的读写状态. 在本例中, 只要有新的数据, 我们都希望进行读取. 如果<code>@response</code>有内容可写, 我们希望获知可以进行写入的时机. 如果<code>@response</code>中没有内容, 即使是客户端连接可以写入, <code>Reactor</code>也不会发出通知.</p>

<p><strong>这就是	<code>Reactor</code>核心的工作内容</strong>.</p>

<p><code>@handler</code>看起来像是这样:</p>

<pre><code class="language-ruby">{12 =&gt; #&lt;FTP::Evented::Connection::hehe&gt;}
</code></pre>

<p>其中键对应的是文件描述符编号, 值对应的是<code>Connection</code>对象.</p>

<pre><code class="language-ruby">to_read  = @handles.values.select(&amp;:monitor_for_reading?).map(&amp;:client)
to_write = @handles.values.select(&amp;:monitor_for_writing?).map(&amp;:client)
readables, writables = IO.select(to_read + [@control_socket], to_write)
</code></pre>

<p>主循环<code>run</code>中我们首先查询每个活动连接, 看是否需要使用之前介绍的生命周期方法对其进行读/写监视.</p>

<p>对于有需要的连接, 它获取其底层<code>IO</code>对象的引用.</p>

<p><code>Reactor</code>随后将这些<code>IO</code>实例传给不带超时参数的<code>IO.select</code>.</p>

<p><code>IO.select</code>会一直阻塞到某个受监控的套接字出现值得关注的事件为止.</p>

<p>⚠️: <code>Reactor</code>还会监视<code>@control_socket</code>是否可读, 以便检测到新接入的客户端连接.</p>

<p><code>  Reactor</code>根据它从<code>IO.select</code>  中接收到的事件触发对应的方法.</p>

<pre><code class="language-ruby">readables.each do |socket|
  # 侦听套接字负责侦听
  if socket == @control_socket
    io = @control_socket.accept
    connection = Connection.new(io)
    @handles[io.fileno] = connection
  # 其余读套接字负责读取数据
  else
    connection = @handles[socket.fileno]

    begin
      data = socket.read_nonblock(CHUNK_SIZE)
      connection.on_data(data)
    rescue Errno::EAGAIN # 没有数据可读时就重试, 实际上啥也没做, `each` 循环继续到下一个 `socket`
    rescue EOFError
      # 当读取到 `EOF` 时就删除此 socket
      @handles.delete(socket.fileno)
    end
  end
end # end of readables
</code></pre>

<p>首先处理可读的套接字. 如果<code>@control_socket</code>可读,就意味着出现了一个新的客户端连接. <code>Reactor</code>调用<code>accept</code>接受连接, 建立一个新的<code>Connection</code>并将其放入<code>@handles</code>散列中, 这样就可以在下一次的<code>each</code>循环中进行监视了.</p>

<p>接下来要处理可读的套接字是普通的客户端连接的情况.</p>

<p>在这种情况下, 代码会尝试读取数据, 触发对应的<code>Connection</code>的<code>on_data</code>方法. 如果读取出现阻塞(Errno::EAGAIN), 不做任何处理, 让事件落空为止.如果客户端断开连接(EOFError), 那么要确保从<code>@handles</code>散列中删除相应的条目, 使得对应的对象可以被回收并不再受到监视.</p>

<pre><code class="language-ruby">writables.each do |socket|
  connection = @handles[socket.fileno]
  # 往 socket 写入数据
  connection.on_writable
end
</code></pre>

<p>最后通过触发<code>Connection#on_writable</code>方法处理可写的套接字.</p>

<h3 id="思考-5">思考</h3>

<p><strong>事件驱动模式</strong>同其他模式有着显著的不同, 因而也就产生了尤为不同的优势和劣势.</p>

<p>首先, 该模式以极高的并发处理能力而闻名, 能够处理成千上万的并发连接. 光这一点就让其他模式无法望其项背, 因为他们都受到进程/线程数量的限制.</p>

<p>如果服务器需要生成5000个线程来处理5000个连接, 服务器估计不堪重负. 就处理并发连接而言, 事件驱动模式可谓一枝独秀并广为流传.</p>

<p>它主要的劣势是所施加的变成模型. 一方面这个模型更简单, 因为无需处理众多线程和进程. 这意味着就不存在共享内存、同步、越界进程等等.</p>

<p>但是考虑到所有的并发都发生在单个线程内部, 有一条非常重要的规则必须遵循: <strong>绝对不能阻塞<code>Reactor</code></strong>.</p>

<p>要诠释着一点,让我们来仔细查看一下实现代码. 在<code>CommandHandler</code>类中, 当处理<code>FTP</code>文件传输命令(RETR)时,它实际上打开了一个套接字, 以流的方式发送数据, 然后关闭套接字. 重要的是这个套接字是在<code>Reactor</code>主循环之外使用的, <code>Reactor</code>对其一无所知.</p>

<p>假设客户端在一条速度缓慢的连接上请求文件传输, 这会对<code>Reactor</code>造成什么影响呢?</p>

<p>考虑到一切都运行在同一个线程之内, 单个迟缓的客户端连接会阻塞住整个<code>Reactor</code>.当<code>Reactor</code>在<code>Connection</code>上触发某个方法时, <code>Reactor</code>会一直阻塞到该方法返回为止.</p>

<p>由于<code>on_data</code>方法委托给了<code>CommandHandler</code>, 当它以数据流的方式向客户端进行文件传输时, <code>Reactor</code>一直处于阻塞. 在这期间, 无法读取其他数据, 也就无法接受新的连接.</p>

<p>应用程序需要达成的任何事情都应该快速完成, 这一点非常重要. 我们如何使用<code>Reactor</code>处理缓慢的连接呢?</p>

<p><strong>利用<code>Reactor</code>自身</strong></p>

<p>如果你采用该模式, 那就需要确保所有阻塞式<code>IO</code>都由<code>Reactor</code>自己来处理. 在这个例子中就意味着由 <code>CommandHandler</code>所使用的套接字需要被封装到<code>Connection</code>的子类中, 它定义了自己的一套<code>on_data</code>和<code>on_writable</code>方法.</p>

<p>当<code>Reactor</code>可以向缓慢的连接中写入数据时, 它就会触发响应的<code>on_writable</code>方法, 该方法能够在没有阻塞的情况下尽可能多的向客户端写入数据. 这样<code>Reactor</code>就可以在等待这个缓慢的远程连接的同时继续处理其他连接, 一旦那条远程连接再次可用, 仍可对其进行处理.</p>

<p>简而言之, 事件驱动模式提供了一些显而易见的优势, 真正简化了套接字编程的某些方面. 另一方面, 它需要你重新考虑自己的应用程序设计的全部<code>IO</code>操作. 该模式所带来的益处很容易被一些迟钝的代码或者含有阻塞式<code>IO</code>的第三方代码块搞得烟消云散.</p>

<h2 id="混合模式">混合模式</h2>

<h2 id="再会">再会</h2>

  ]]></description>
</item>

<item>
  <title>WEBrick 源码分析</title>
  <link>//rack-webrick</link>
  <author>nju520</author>
  <pubDate>2018-03-09T00:00:00+08:00</pubDate>
  <guid>//rack-webrick</guid>
  <description><![CDATA[
  <p><code>WEBrick</code>是<code>Rack</code>自带的一个 <code>Web Server</code>, 历史悠久, 代码量一共才 4000多行. 本文就从源码入手, 解读 <code>WEBrick</code>实现原理, 并从多线程和<code>IO</code>的角度来分析 <code>WEBrick</code> 的优缺点.</p>

<h2 id="源码分析">源码分析</h2>

<p>我们知道 <code>WEBrick</code>是<code>Rack</code>自带的 <code>WEB Server</code>,  它的<code>Handler</code>是在<code>Rack</code>中实现的, 它的运行也是从这个<code>Handler</code>开始的.</p>

<pre><code class="language-ruby">[2] pry(main)&gt; $ Rack::Handler::WEBrick.run

From: **/gems/rack-2.0.3/lib/rack/handler/webrick.rb @ line 25:
Owner: #&lt;Class:Rack::Handler::WEBrick&gt;
Visibility: public
Number of lines: 11

def self.run(app, options={})
  environment  = ENV['RACK_ENV'] || 'development'
  default_host = environment == 'development' ? 'localhost' : nil

  options[:BindAddress] = options.delete(:Host) || default_host
  options[:Port] ||= 8080
  @server = ::WEBrick::HTTPServer.new(options)
  @server.mount "/", Rack::Handler::WEBrick, app
  yield @server  if block_given?
  @server.start
end
</code></pre>

<p>我在 <code>Rack</code>协议以及应用中介绍<code>Rack</code>的实现原理时, 最终就调用到上述<code>run</code>方法. 我们就从此方法开始解读<code>WEBrick</code>的源码.</p>

<p>在<code>run</code>方法中, 先处理传入的一些参数比如 <code>host</code> <code>port</code> <code>enviroment</code>. 在这之后会使用<code>WEBrick</code>提供的<code>HTTPServer</code>创建一个 <code>server</code>实例.  <code>@server</code>实例会调用<code>mount</code>在根路由上挂载应用程序<code>app</code>和 <code>Rack::Handler::WEBrick</code>. 最后调用 <code>#start</code>方法启动服务器.</p>

<h3 id="初始化服务器">初始化服务器</h3>

<p><code>HTTPServer</code>初始化分为两个阶段, 首先是调用父类的 <code>initialize</code>方法, 进行一些配置; 然后是其本身的初始化. 在<code>HTTPServer</code>构造器中, 会配置当前服务器能够处理的 <code>HTTP</code>版本并出示还一个新的<code>MountTable</code>实例.</p>

<pre><code class="language-ruby">[2] pry(main)&gt; require 'webrick'
=&gt; true
[3] pry(main)&gt; $ WEBrick::HTTPServer#initialize

From: **/lib/ruby/2.4.0/webrick/httpserver.rb @ line 46:
Owner: WEBrick::HTTPServer
Visibility: private
Number of lines: 19

  class HTTPServer &lt; ::WEBrick::GenericServer
	#...
    def initialize(config={}, default=Config::HTTP)
      # 调用父类 `GenericServer` 初始化方法
      super(config, default)
      @http_version = HTTPVersion::convert(@config[:HTTPVersion])

      #创建一个 `MountTable`实例
      @mount_tab = MountTable.new
      if @config[:DocumentRoot]
        mount("/", HTTPServlet::FileHandler, @config[:DocumentRoot],
              @config[:DocumentRootOptions])
      end

      unless @config[:AccessLog]
        @config[:AccessLog] = [
          [ $stderr, AccessLog::COMMON_LOG_FORMAT ],
          [ $stderr, AccessLog::REFERER_LOG_FORMAT ]
        ]
      end

      @virtual_hosts = Array.new
    end
  end
</code></pre>

<p><code>WEBrick::HTTPServer</code>父类<code>WEBrick::GenericServer</code>中初始化用于监听端口号的 <code>socket</code>连接:</p>

<pre><code class="language-ruby">From: **/lib/ruby/2.4.0/webrick/server.rb @ line 89:
Owner: WEBrick::GenericServer
Visibility: private
Number of lines: 26

#.方法有删减, 去除一些不必要的配置
def initialize(config={}, default=Config::General)
  @config = default.dup.update(config)
  @status = :Stop
  @config[:Logger] ||= Log::new
  @logger = @config[:Logger]

  
  @listeners = []
  unless @config[:DoNotListen]
    if @config[:Listen]
      warn(":Listen option is deprecated; use GenericServer#listen")
    end
    # 在此创建一系列的 `listeners`
    listen(@config[:BindAddress], @config[:Port])
    if @config[:Port] == 0
      @config[:Port] = @listeners[0].addr[1]
    end
  end
end

##
# Adds listeners from +address+ and +port+ to the server.  See
# WEBrick::Utils::create_listeners for details.

def listen(address, port)
  @listeners += Utils::create_listeners(address, port)
end

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

[8] pry(main)&gt; $ WEBrick::Utils.create_listeners

From: **/lib/ruby/2.4.0/webrick/utils.rb @ line 61:
Owner: #&lt;Class:WEBrick::Utils&gt;
Visibility: public
Number of lines: 13

def create_listeners(address, port)
  unless port
    raise ArgumentError, "must specify port"
  end
  # 创建一组 `socket`
  sockets = Socket.tcp_server_sockets(address, port)
  sockets = sockets.map {|s|
    s.autoclose = false
    # 为文件描述符`s.fileno`创建一个新的 `TCPServer`实例
    ts = TCPServer.for_fd(s.fileno)
    # 关闭 当前 `socket`
    s.close
    ts
  }
  return sockets
end
</code></pre>

<p>每一个服务器在初始化期间都会创建一系列的<code>listeners</code>用于监听地址和端口号组成的元组.</p>

<p><code>Socket#tcp_server_scokets</code>会创建一组<code>scoket</code>, 实际上返回两个套接字, 一个可以通过<code>IPV4</code>连接, 一个可以通过<code>IPV6</code>连接,两者都在同一个端口上进行侦听. 通过<code>TCPServer.for_fd</code>	我们又基于<code>socket#fileno</code>创建了 <code>TCPServer</code> 的实例. 最后<code>create_listeners</code>返回数组形式的<code>TCPServer</code>实例.</p>

<h3 id="挂载应用">挂载应用</h3>

<p>在使用<code>WEBrick</code>启动服务的时候, 第二个阶段就是将<code>Handler</code>和<code>Rack应用程序</code>挂载到根路由下</p>

<pre><code class="language-ruby">@server.mount "/", Rack::Handler::WEBrick, app
</code></pre>

<p><code>WEBrick::HTTPServer#mount</code>方法非常简单. 在<code>初始化服务器</code>阶段我们曾创建了一个<code>MountTable</code>的实例, 这一步只是将传入的多个参数放到这个表中:</p>

<pre><code class="language-ruby">[9] pry(main)&gt; $ WEBrick::HTTPServer#mount

From: **/lib/ruby/2.4.0/webrick/httpserver.rb @ line 155:
Owner: WEBrick::HTTPServer
Visibility: public
Number of lines: 4

def mount(dir, servlet, *options)
  @logger.debug(sprintf("%s is mounted on %s.", servlet.inspect, dir))
  @mount_tab[dir] = [ servlet, options ]
end

mount '/', Rack::Handler::WEBrick, app
mount '/admin', Rack::Hanlder::WEBrick, admin_app
mount '/worker', Rack::Handler::WEBrick, worker_app
</code></pre>

<p><code>MountTable</code>实际上是一个包含从路由到<code>Rack 应用App</code>的映射表</p>

<p><img src="MountTable" alt="映射" /></p>

<p>当初始化 <code>MountTable</code>时会调用<code>MountTable#compile</code>方法. <code>MountTable</code>会将表中的所有键按照加入顺序的逆序拼接成一个如下的正则表达式用来匹配传入的路由:</p>

<pre><code class="language-ruby">^(/|/admin|/user)(?=/|$)
</code></pre>

<p>上述正则表达式在使用时如果匹配到了指定的路由就会返回<code>$&amp;</code>和<code>$</code>两部分.</p>

<ul>
  <li><code>$&amp;</code>: 匹配的整个文本</li>
  <li><code>$</code>匹配文本后面的字符串</li>
</ul>

<pre><code class="language-ruby">[12] pry(main)&gt; $ WEBrick::HTTPServer::MountTable#initialize

From: **/lib/ruby/2.4.0/webrick/httpserver.rb @ line 234:
Owner: WEBrick::HTTPServer::MountTable
Visibility: private
Number of lines: 4

def initialize
  @tab = Hash.new
  compile
end

def compile
  k = @tab.keys
  k.sort!
  k.reverse!
  k.collect!{|path| Regexp.escape(path) }
  @scanner = Regexp.new("^(" + k.join("|") +")(?=/|$)")
end
</code></pre>

<h3 id="启动服务器">启动服务器</h3>

<p>在<code>Rack::Handler::WEBrick</code>中的<code>.run</code>方法第一阶段进行<code>@server</code>的初始化工作, 并将<code>Handler</code>挂载到根路由上, 最后执行	<code>#start</code>方法启动服务器:</p>

<pre><code class="language-ruby">From: **/lib/ruby/2.4.0/webrick/server.rb @ line 152:
Owner: WEBrick::GenericServer
Visibility: public
Number of lines: 64

##
# Starts the server and runs the +block+ for each connection.  This method
# does not return until the server is stopped from a signal handler or
# another thread using #stop or #shutdown.
# 方法有删减, 主要是移除日志打印
def start(&amp;block)
  raise ServerError, "already started." if @status != :Stop

  setup_shutdown_pipe

  server_type.start{
    @logger.info "#{self.class}#start: pid=#{$$} port=#{@config[:Port]}"
    @status = :Running
    # 执行回调
    call_callback(:StartCallback)

    shutdown_pipe = @shutdown_pipe

    thgroup = ThreadGroup.new
    begin
      while @status == :Running
        begin
          sp = shutdown_pipe[0]
          # 监听一组`Socket`
          if svrs = IO.select([sp, *@listeners])
            # for_reading TCPSocket
            svrs[0].each{|svr|
              @tokens.pop          # blocks while no token is there.
              # accept 连接
              if sock = accept_client(svr)
                # 开启新的线程处理请求
                th = start_thread(sock, &amp;block)
                th[:WEBrickThread] = true
                thgroup.add(th)
              else
                @tokens.push(nil)
              end
            }
          end
        rescue Errno::EBADF, Errno::ENOTSOCK, IOError =&gt; ex
          # if the listening socket was closed in GenericServer#shutdown,
          # IO::select raise it.
        rescue StandardError =&gt; ex
          msg = "#{ex.class}: #{ex.message}\n\t#{ex.backtrace[0]}"
          @logger.error msg
        rescue Exception =&gt; ex
          @logger.fatal ex
          raise
        end
      end
    ensure
      cleanup_shutdown_pipe(shutdown_pipe)
      cleanup_listener
      @status = :Shutdown
      @logger.info "going to shutdown ..."
      # 管理线程
      thgroup.list.each{|th| th.join if th[:WEBrickThread] }
      call_callback(:StopCallback)
      @logger.info "#{self.class}#start done."
      @status = :Stop
    end
  }
end

</code></pre>

<p>上述代码包括处理服务器的关闭, 接收 <code>socket</code>请求, 我们可以把接收并处理<code>socket</code>请求抽象出来</p>

<pre><code class="language-ruby">def start(&amp;block)
  raise ServerError, "already started." if @status != :Stop

  @status = :Running
  begin
    while @status == :Running
      begin
        if svrs = IO.select([*@listeners], nil, nil, 2.0)
          svrs[0].each{ |svr|
            sock = accept_client(svr)
            start_thread(sock, &amp;block)
          }
        end
      rescue Errno::EBADF, Errno::ENOTSOCK, IOError, StandardError =&gt; ex
      rescue Exception =&gt; ex
        raise
      end
    end
  ensure
    cleanup_listener
    @status = :Stop
  end
end
</code></pre>

<p>关键部分为 <code>IO.select</code>. <code>IO.select</code>方法对一组<code>Socket</code>进行监听, 当有消息需要处理时就依次执行<code>#accept_client</code>和<code>#start_thread</code>两个方法处理来自客户端的请求.</p>

<pre><code class="language-ruby">From: **/lib/ruby/2.4.0/webrick/server.rb @ line 254:
Owner: WEBrick::GenericServer
Visibility: private
Number of lines: 14

def accept_client(svr)
  sock = nil
  begin
    sock = svr.accept
    sock.sync = true
    Utils::set_non_blocking(sock)
  rescue Errno::ECONNRESET, Errno::ECONNABORTED,
         Errno::EPROTO, Errno::EINVAL
  rescue StandardError =&gt; ex
    msg = "#{ex.class}: #{ex.message}\n\t#{ex.backtrace[0]}"
    @logger.error msg
  end
  return sock
end
</code></pre>

<p><code>WEBrick::GenericServer#accept_client</code>方法中调用<code>accept</code> 获得一个<code>TCP</code>客户端的<code>Socket</code>,通过设置<code>set_non_blocking</code>将该<code>Socket</code>变为非阻塞的, 最后在方法末尾返回创建的<code>Socket</code>.</p>

<pre><code class="language-ruby">From: **/lib/ruby/2.4.0/webrick/server.rb @ line 278:
Owner: WEBrick::GenericServer
Visibility: private
Number of lines: 32
#代码有删减, 移除日志打印、异常处理等
def start_thread(sock, &amp;block)
  Thread.start{
    begin
      Thread.current[:WEBrickSocket] = sock
      # 回调
      call_callback(:AcceptCallback, sock)
      # 处理请求
      block ? block.call(sock) : run(sock)
    ensure
      @tokens.push(nil)
      Thread.current[:WEBrickSocket] = nil
      sock.close
    end
  }
end
</code></pre>

<p><code>WEBrick::GenericServer#start_thread</code>方法会开启一个新的线程, 在此线程中处理<code>HTTP 请求</code></p>

<h3 id="处理请求">处理请求</h3>

<p>处理<code>HTTP</code> 请求的逻辑并不是由通过服务器<code>GenericServer</code>处理, 它只处理通用的逻辑. 对于<code>HTTP</code>请求的处理都是在<code>HTTPServer#run</code>方法中完成:</p>

<pre><code class="language-ruby">From: **/lib/ruby/2.4.0/webrick/httpserver.rb @ line 69:
Owner: WEBrick::HTTPServer
Visibility: public
Number of lines: 52

# 代码有删减, 移除日志打印和一些异常处理和回调处理
def run(sock)
  while true
    res = HTTPResponse.new(@config)
    req = HTTPRequest.new(@config)
    server = self
    begin
      timeout = @config[:RequestTimeout]
      while timeout &gt; 0
        break if sock.to_io.wait_readable(0.5)
        break if @status != :Running
        timeout -= 0.5
      end
      raise HTTPStatus::EOFError if timeout &lt;= 0 || @status != :Running
      raise HTTPStatus::EOFError if sock.eof?
      # 解析请求
      req.parse(sock)
      res.request_method = req.request_method
      res.request_uri = req.request_uri
      res.request_http_version = req.http_version
      res.keep_alive = req.keep_alive?
      # 处理响应
      # 此方法中就会涉及我们之前分析的`Rack`以及`Middleware`
      server.service(req, res)
    ensure
      if req.request_line
        if req.keep_alive? &amp;&amp; res.keep_alive?
          req.fixup()
        end
        # 发送响应
        res.send_response(sock)
        server.access_log(@config, req, res)
      end
    end
    break if @http_version &lt; "1.1"
    break unless req.keep_alive?
    break unless res.keep_alive?
  end
end
</code></pre>

<p><code>WEBrick::HTTPServer#run</code>主要工作涉及三个方面:</p>

<ul>
  <li>等待监听的<code>Socket</code>变成 <code>readable</code></li>
  <li>执行<code>#parse</code>方法解析<code>Socket</code>上的数据</li>
  <li>最后调用<code>#service</code>方法完成处理请求的响应</li>
</ul>

<p>我们依次解读:</p>

<h4 id="监听-socket">监听 <code>Socket</code></h4>

<pre><code class="language-ruby">sock.to_io.wait_readable
</code></pre>

<h4 id="解析-request">解析 <code>request</code></h4>

<p>调用<code>parse</code>对请求<code>request</code>进行解析:</p>

<pre><code class="language-ruby">From: **/lib/ruby/2.4.0/webrick/httprequest.rb @ line 192:
Owner: WEBrick::HTTPRequest
Visibility: public
Number of lines: 47

def parse(socket=nil)
  @socket = socket
  begin
    @peeraddr = socket.respond_to?(:peeraddr) ? socket.peeraddr : []
    @addr = socket.respond_to?(:addr) ? socket.addr : []
  rescue Errno::ENOTCONN
    raise HTTPStatus::EOFError
  end

  read_request_line(socket)
  
  return if @request_method == "CONNECT"
  return if @unparsed_uri == "*"

  begin
    setup_forwarded_info
    # 设置一些 实例属性, 为后续处理请求做准备
    @request_uri = parse_uri(@unparsed_uri)
    @path = HTTPUtils::unescape(@request_uri.path)
    @path = HTTPUtils::normalize_path(@path)
    @host = @request_uri.host
    @port = @request_uri.port
    @query_string = @request_uri.query
    @script_name = ""
    @path_info = @path.dup
  rescue
    raise HTTPStatus::BadRequest, "bad URI `#{@unparsed_uri}'."
  end

  if /close/io =~ self["connection"]
    @keep_alive = false
  elsif /keep-alive/io =~ self["connection"]
    @keep_alive = true
  elsif @http_version &lt; "1.1"
    @keep_alive = false
  else
    @keep_alive = true
  end
end
</code></pre>

<p>上述代码主要是对<code>HTTP</code>请求的解析, 具体内容还要参阅源码.</p>

<h4 id="处理-service">处理 <code>service</code></h4>

<p>在处理完<code>HTTP请求</code>之后, 就可以执行<code>#service</code>来响应该<code>HTTP请求</code>了:</p>

<pre><code class="language-ruby">From: **/lib/ruby/2.4.0/webrick/httpserver.rb @ line 125:
Owner: WEBrick::HTTPServer
Visibility: public
Number of lines: 17

# 移除 OPTIONS 请求的逻辑代码
def service(req, res)

  servlet, options, script_name, path_info = search_servlet(req.path)
  raise HTTPStatus::NotFound, "`#{req.path}' not found." unless servlet
  req.script_name = script_name
  req.path_info = path_info
  # 返回一个 `servlet`实例
  si = servlet.get_instance(self, *options)
  @logger.debug(format("%s is invoked.", si.class.name))
  # 调用实例的 `service`
  si.service(req, res)
end

def search_servlet(path)
  script_name, path_info = @mount_tab.scan(path)
  servlet, options = @mount_tab[script_name]
  if servlet
    [ servlet, options, script_name, path_info ]
  end
end

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
[29] pry(main)&gt; $ WEBrick::HTTPServer::MountTable#scan

From: **/lib/ruby/2.4.0/webrick/httpserver.rb @ line 258:
Owner: WEBrick::HTTPServer::MountTable
Visibility: public
Number of lines: 4

def scan(path)
  @scanner =~ path
  [ $&amp;, $' ]
end
</code></pre>

<p>通过调用<code>search_servlet</code>定位到之前注册的<code>Handler</code>以及<code>Rack应用程序</code>.</p>

<p>得到了<code>Handler</code>之后, 通过<code>get_instance</code>获得一个新的实例, 随后又调用了该<code>Rack::Handler::WEBrick</code>的<code>service</code>方法:</p>

<pre><code class="language-ruby">From: **/gems/rack-2.0.3/lib/rack/handler/webrick.rb @ line 57:
Owner: Rack::Handler::WEBrick
Visibility: public
Number of lines: 61

def service(req, res)
  res.rack = true
  # 将 `request`的 `meta_vars`赋值给 `env`(环境变量)
  env = req.meta_vars
  env.delete_if { |k, v| v.nil? }

  # 请求携带的内容
  rack_input = StringIO.new(req.body.to_s)
  rack_input.set_encoding(Encoding::BINARY)

  # 更新 env
  env.update(
    RACK_VERSION      =&gt; Rack::VERSION,
    RACK_INPUT        =&gt; rack_input,
    RACK_ERRORS       =&gt; $stderr,
    RACK_MULTITHREAD  =&gt; true,
    RACK_MULTIPROCESS =&gt; false,
    RACK_RUNONCE      =&gt; false,
    RACK_URL_SCHEME   =&gt; ["yes", "on", "1"].include?(env[HTTPS]) ? "https" : "http",
    RACK_IS_HIJACK    =&gt; true,
    RACK_HIJACK       =&gt; lambda { raise NotImplementedError, "only partial hijack is supported."},
    RACK_HIJACK_IO    =&gt; nil
  )

  env[HTTP_VERSION] ||= env[SERVER_PROTOCOL]
  env[QUERY_STRING] ||= ""
  unless env[PATH_INFO] == ""
    path, n = req.request_uri.path, env[SCRIPT_NAME].length
    env[PATH_INFO] = path[n, path.length-n]
  end
  env[REQUEST_PATH] ||= [env[SCRIPT_NAME], env[PATH_INFO]].join

  # 关键部分: Rack应用 接收 env 返回一个三元数组
  status, headers, body = @app.call(env)
  begin
    res.status = status.to_i
    io_lambda = nil
    headers.each { |k, vs|
      if k == RACK_HIJACK
        io_lambda = vs
      elsif k.downcase == "set-cookie"
        res.cookies.concat vs.split("\n")
      else
        # Since WEBrick won't accept repeated headers,
        # merge the values per RFC 1945 section 4.2.
        res[k] = vs.split("\n").join(", ")
      end
    }

    if io_lambda
      rd, wr = IO.pipe
      res.body = rd
      res.chunked = true
      io_lambda.call wr
    elsif body.respond_to?(:to_path)
      res.body = ::File.open(body.to_path, 'rb')
    else
      # 将 body中的数据依次加入到 `res.body`中
      body.each { |part|
        res.body &lt;&lt; part
      }
    end
  ensure
    body.close  if body.respond_to? :close
  end
end
</code></pre>

<p>上述代码主要完成以下几个工作:</p>

<ul>
  <li>构建<code>Rack应用</code>的环境变量<code>env</code>.</li>
  <li>调用<code>#call</code> 返回一个三元数组: [status, headers, body]</li>
  <li>对返回的三个元素进行处理, 填充此次请求的 <code>response</code></li>
</ul>

<h4 id="发送-响应">发送 响应</h4>

<p>我们的 <code>response</code>构造成功后, 下一步就要将数据发送给请求的客户端</p>

<pre><code class="language-ruby">From: lib/webrick/httpserver.rb @ line 69:
Owner: WEBrick::HTTPServer

def run(sock)
  while true
    res = HTTPResponse.new(@config)
    req = HTTPRequest.new(@config)
    server = self
    begin
      # ...
    ensure
      # 发送响应
      res.send_response(sock) if req.request_line
    end
  end
end


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
[35] pry(main)&gt; $ WEBrick::HTTPResponse#send_response
From: **/lib/ruby/2.4.0/webrick/httpresponse.rb @ line 205:
Owner: WEBrick::HTTPResponse
Visibility: public
Number of lines: 13

def send_response(socket)
  begin
    setup_header()
    # 发送头部数据
    send_header(socket)
    # 发送 body 数据
    send_body(socket)
  rescue Errno::EPIPE, Errno::ECONNRESET, Errno::ENOTCONN =&gt; ex
    @logger.debug(ex)
    @keep_alive = false
  rescue Exception =&gt; ex
    @logger.error(ex)
    @keep_alive = false
  end
end

def setup_header
  # 处理 chunked 的请求
  app_chunking = rack &amp;&amp; @header['transfer-encoding'] == 'chunked'
  @chunked = app_chunking if app_chunking
  _rack_setup_header
  @chunked = false if app_chunking
end


def send_header(socket) # :nodoc:
  if @http_version.major &gt; 0
    data = status_line()
    @header.each{|key, value|
      tmp = key.gsub(/\bwww|^te$|\b\w/){ $&amp;.upcase }
      data &lt;&lt; "#{tmp}: #{value}" &lt;&lt; CRLF
    }
    @cookies.each{|cookie|
      data &lt;&lt; "Set-Cookie: " &lt;&lt; cookie.to_s &lt;&lt; CRLF
    }
    data &lt;&lt; CRLF
    # 最终调用 _write_data 写入数据
    _write_data(socket, data)
  end
end


def send_body(socket) # :nodoc:
  if @body.respond_to? :readpartial then
    send_body_io(socket)
  else
    send_body_string(socket)
  end
end
    
    
</code></pre>

<p>上述所有的 <code>send_*</code>方法最终都会调用 <code>_write_data</code>, 往 <code>socket</code>中写入数据</p>

<pre><code class="language-ruby">From: **/lib/ruby/2.4.0/webrick/httpresponse.rb @ line 464:
Owner: WEBrick::HTTPResponse
Visibility: private
Number of lines: 3

def _write_data(socket, data)
  socket &lt;&lt; data
end
</code></pre>

<p>至此, 我们的 <code>Web Server</code>经过以下几步完成一个客户端请求的处理</p>

<ul>
  <li>
    <p>解析<code>HTTP请求</code></p>
  </li>
  <li>
    <p>调用<code>Rack应用程序</code></p>
  </li>
  <li>
    <p>构造<code>Response</code></p>
  </li>
  <li>
    <p>向 <code>Socket</code>写入数据</p>

    <p>​</p>
  </li>
</ul>

<h2 id="拓展知识">拓展知识</h2>

<h3 id="ioselect">IO.select</h3>

<blockquote>
  <p>连接复用是指同时处理多个活动套接字. 这里并不是指并行处理, 也和多线程无关.</p>
</blockquote>

<p>我们可以使用<code>IO.select</code>来处理多个<code>TCP</code>连接:</p>

<pre><code class="language-ruby">connections = [&lt;TCPSocket&gt;, &lt;TCPSocket&gt;, &lt;TCPSocket&gt;]

loop do
  ready = IO.select(connections)
  readable_connections = ready[0]
  readable_connections.each do |conn|
    data = conn.readpartial(4096)
    process(data)
  end
end
</code></pre>

<p><code>IO.select</code>的作用就是接受若干个<code>IO</code>对象, 然后告知哪一个可以进行读写, 这样我们就不必一直<code>retry</code>.</p>

<p><code>IO.select</code>是一个同步方法调用. 按照它的设计来使用就会造成阻塞, 直到传入的<code>IO</code>对象状态发生变化, 此时它会立刻返回.  如果多个对象状态发生变化, 那么全部都通过嵌套数组立刻返回.</p>

<p>来看一下 <code>IO.slect</code>的参数:</p>

<pre><code class="language-ruby">IO.select(read_array[, write_array[, error_array[, timeout]]] )
</code></pre>

<ul>
  <li>read_array: 希望从中读取的<code>IO</code> 对象数组</li>
  <li>write_array:  希望进行写入的<code>IO</code>对象数组</li>
  <li>error_array: 在异常条件下使用的<code>IO</code>对象数组</li>
  <li>timeout: 超时时间(秒). 它可以避免<code>IO.select</code>永久地阻塞下去</li>
</ul>

<p><code>IO.select</code>返回一个三元数组:</p>

<ul>
  <li>可以进行无拥塞读取的<code>IO</code>对象数组</li>
  <li>可以进行无拥塞写入的<code>IO</code>对象数组</li>
  <li>适用异常条件的对象数组</li>
</ul>

<p><code>IO.select</code>来自<code>Ruby</code>的核心代码库. 它是<code>Ruby</code>中进行连接复用的唯一手段. 大多数现代操作系统都支持多种复用方法, <code>select</code>几乎总是这些方法最古老, 也是使用最少的那个.</p>

<p><code>IO.select</code>在少数情况下表现还不错, 但是其性能同它所监视的连接数呈线性关系. 监视的连接数越多, 性能就越差. 而且<code>select(2)</code>系统受到<code>FD_SETSIZE</code>的限制. <code>select</code>无法对编号大于<code>FD_SETSIZE</code>的文件描述符进行监视.</p>

<p><code>Linux</code>的<code>epoll</code>以及<code>BSD</code>的<code>kqueue</code>的系统调用比<code>select</code>效果会更好, 功能更先进. 像<code>EventMachine</code>这种高性能联网工具在可能的情况下更倾向于使用<code>epoll</code>或者<code>kqueue</code>.</p>

<h3 id="ruby-thread">Ruby Thread</h3>

<blockquote>
  <p>每个正在系统上运行的程序都是一个进程.</p>

  <p>每个进程包含一到多个线程.</p>
</blockquote>

<p>线程是程序中一个单一的顺序控制流程, 在单个程序同时运行时运行多个线程完成不同的工作, 称为多线程.</p>

<p><code>Ruby</code>中我们可以通过<code>Thread</code>类来创建多线程, <code>Ruby</code>的多线程是一个轻量级的, 可以以高效的方式来实现并行.</p>

<h4 id="创建多线程">创建多线程</h4>

<pre><code class="language-ruby"># 主线程 1 
# 创建子线程
Thread.new {
  # 子线程的执行代码
}

# 主线程1 执行代码
</code></pre>

<h4 id="线程的生命周期">线程的生命周期</h4>

<ol>
  <li>线程的创建可以使用<code>Thread.new</code>、 <code>Thread.start</code> 、 <code>Thread.fork</code> 三个方法</li>
  <li>创建线程后无需启动, 线程会自动执行</li>
  <li><code>Thread</code>类定义了一些方法来操纵线程, 线程执行<code>Thread.new</code>中的代码块</li>
  <li>线程代码块中最后一个语句是线程的值, 可以通过线程的方法来调用. 如果线程执行完毕, 则返回线程值, 否则不返回, 知道线程执行完毕</li>
  <li><code>Thread.current</code>方法返回当前线程对象, <code>Thread.main</code>返回主线程.</li>
  <li>通过<code>Thread.join</code>方法来执行线程, 这个方法就会挂起主线程, 直到当前子线程执行完毕</li>
</ol>

<p>线程的五种状态</p>

<table>
  <thead>
    <tr>
      <th>线程状态</th>
      <th>返回值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Runnable</td>
      <td>run</td>
    </tr>
    <tr>
      <td>Sleeping</td>
      <td>Sleeeping</td>
    </tr>
    <tr>
      <td>Aborting</td>
      <td>aborting</td>
    </tr>
    <tr>
      <td>Terminated normally</td>
      <td>false</td>
    </tr>
    <tr>
      <td>Terminated with exception</td>
      <td>nil</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h4 id="线程的同步控制">线程的同步控制</h4>

<ul>
  <li>通过<code>Metex</code>类实现线程同步</li>
  <li>监管数据交交接的<code>Queue</code>类实现线程同步</li>
  <li>使用<code>ConditionVariable</code>实现同步控制</li>
</ul>

<ol>
  <li>
    <p>通过<code>Metex</code>类实现线程同步</p>

    <p>如果多个线程时钟同时需要访问一个程序变量, 我们可以使用<code>lock</code>锁定此变量</p>
  </li>
  <li>
    <p>监管数据交接的<code>Queue</code>类实现线程同步</p>

    <p><code>Queue</code>类就是表示一个支持线程的队列, 能够同步对队列末尾进行访问. 不同的线程可以使用同一个队列, 而不用担心这个队列中的数据是否能够同步.</p>
  </li>
  <li>
    <p>使用<code>ConditionablVariable</code>实现同步控制</p>

    <p>这样可以在一些致命的资源竞争部分挂起线程直至油可用的资源为止</p>

    <pre><code class="language-ruby">#encoding:gbk
require "thread"
puts "thread synchronize by ConditionVariable"

mutex = Mutex.new
resource = ConditionVariable.new

a = Thread.new {
  mutex.synchronize {
    # 这个线程目前需要resource这个资源
    resource.wait(mutex) 
    puts "get resource"
  }
}

b = Thread.new {
  mutex.synchronize {
    #线程b完成对resourece资源的使用并释放resource
    resource.signal
  }
}

a.join
puts "complete"
</code></pre>

    <p><code>mutex</code>是声明的一个资源, 然后通过<code>ConditionVariable</code>来控制申请和释放资源.</p>

    <p><code>b</code>线程完成了某些工作之后释放资源<code>resource.signal</code>, 这样<code>a</code>线程就可以获得一个<code>mutex</code>资源然后执行</p>
  </li>
</ol>

<h4 id="线程常用方法">线程常用方法</h4>

<h5 id="类方法">类方法</h5>

<table>
  <thead>
    <tr>
      <th>Thread.abort_on_exception</th>
      <th>如果设置为<code>true</code>, 一旦某线程因异常而终止时, 整个解释器就会被中断</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Thread.current</td>
      <td>返回当前运行中的线程</td>
    </tr>
    <tr>
      <td>Thread.new {|args| balabal}</td>
      <td>生成新线程时携带传入的参数</td>
    </tr>
    <tr>
      <td>Thread.pass</td>
      <td>将线程的运行权交给其他线程, 不会改变运行中的线程状态, 而是将控制权交给其他可运行的线程</td>
    </tr>
    <tr>
      <td>Thread.stop</td>
      <td>将当前线程挂起, 直到其他线程使用 run 再次唤醒当前线程</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h5 id="线程实例方法">线程实例方法</h5>

<table>
  <thead>
    <tr>
      <th>thread[name]=</th>
      <th>设置线程内 <code>name</code>对应的固有数据的值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>thread.run</td>
      <td>重新启动被挂起的线程,与<code>wakeup</code>不同的是, 它将立即进行线程的切换</td>
    </tr>
    <tr>
      <td>thread.wakeup</td>
      <td>将被挂起(stop)的线程的状态改为可执行(run)状态</td>
    </tr>
    <tr>
      <td>thread.join</td>
      <td>挂起当前线程(一般在主线程中调用, 子线程均正常运行结束后主线程再重新启动)</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="io-模型">IO 模型</h2>

<p>通过解读 <code>WEBrick</code>源码, 我们已经熟悉了整个 <code>Web Server</code>的工作原理.</p>

<p>当我们启动一个 <code>Web Server</code>服务时只会启动一个进程, 该进程会在指定的 <code>ip</code>和 <code>port</code>上使用 <code>IO.select</code>监听来自用户的所有 <code>HTTP请求</code>.</p>

<p><img src="" alt="WEB SERVER " /></p>

<p>当<code>IO.select</code>接收到来自用户的请求时, 会为每一个请求创建一个新的线程 <code>Thread.new</code> 并在新的线程中对 <code>HTTP</code>请求进行处理.</p>

<p>由于 <code>WEBrick</code>在运行时只会启动一个进程, 没有其他的守护进程, 所以它不够健壮, 无法在发送问题时重启持续对外界提供服务.</p>

<p>虽然 <code>WEBrick</code>有一些性能问题, 但是作为 <code>Ruby</code>自带的<code>Web Server</code>, 无论是开发还是学习都是值得研究的.</p>

<h2 id="总结">总结</h2>

<p><code>WEBrick</code>是<code>Ruby</code>内置的<code>Web Server</code>, 目前主要使用在<code>开发</code>环境下, 在生产环境下开发者往往选择性能更好, 更健壮的 <code>Unicorn</code>和 <code>Puma</code>. 现在研究<code>WEBrick</code>的源码和实现可以帮助我们熟悉<code>Ruby Web Server</code>具备的基本功能以及<code>Web Server</code>处理请求的基本流程. 在这之后, 我们就可以继续深入分析更复杂的<code>Web Server</code>, 更复杂的<code>IO</code>模型了.</p>

<h2 id="reference">Reference</h2>


  ]]></description>
</item>


  </channel>
</rss>
