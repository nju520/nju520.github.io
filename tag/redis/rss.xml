<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    
    <title>nju520.me</title>
    
    <link>http://localhost:4000</link>
    <description>nju520's Blog</description>
    <language>en-uk</language>
    <managingEditor> nju520</managingEditor>
    <atom:link href="rss" rel="self" type="application/rss+xml" />
    
<item>
  <title>Sidekiq 如何处理异步任务</title>
  <link>//sidekiq</link>
  <author>nju520</author>
  <pubDate>2017-08-28T00:00:00+08:00</pubDate>
  <guid>//sidekiq</guid>
  <description><![CDATA[
  <p><a href="https://github.com/mperham/sidekiq">Sidekiq</a> 是 Ruby 和 Rails 项目中常用的后台任务处理系统，其本身提供的 API 十分简洁，源代码也非常易于阅读，是一个轻量级的异步处理组件；虽然其本身没有提供太多复杂的功能，但是它的使用和部署非常简单。在这篇文章中，我们将对 Sidekiq 的实现原理进行介绍和分析。</p>

<p><img src="https://img.nju520.me/2017-08-28-Sidekiq-Cover.jpg-1000width" alt="Sidekiq-Cover" /></p>

<p>文章中并不会详细介绍 Sidekiq 的使用，也并不是一篇 Sidekiq 的教程，在这里我们会介绍任务的入队过程、Sidekiq 任务在 Redis 中的存储方式和消费者对任务的处理过程，除此之外，文章将介绍 Sidekiq 中间件的实现以及任务重试的原理。</p>

<h2 id="概述">概述</h2>

<p>在具体分析介绍 Sidekiq 的实现原理之前，我们需要对整个组件的使用过程进行概述，保证我们对 Sidekiq 的结构有一个总体上的了解。</p>

<pre><code class="language-ruby">class HardWorker
  include Sidekiq::Worker
  def perform(name, count)
    # do something
  end
end

HardWorker.perform_async('bob', 5)
</code></pre>

<p>在这里，我们直接照搬 Sidekiq Wiki 中 <a href="https://github.com/mperham/sidekiq/wiki/Getting-Started">Getting Started</a> 部分的代码简单展示下它是如何使用的，当我们执行 <code>HardWorker.perform_async</code> 方法时，Sidekiq 的 Worker 会将一个异步任务以 JSON 的形式将相关的信息加入 Redis 中并等待消费者对任务的拉取和处理。</p>

<p><img src="https://img.nju520.me/2017-08-28-Sidekiq-Arch.jpg-1000width" alt="Sidekiq-Arch" /></p>

<p>Sidekiq 的消费者有三个部分组成，分别是 <code>Manager</code>、<code>Processor</code> 和 <code>Poller</code>；他们三者会相互协作共同完成对 Redis 中任务消费的过程。</p>

<blockquote>
  <p>需要注意的是，Sidekiq 中的 <code>Sidekiq::Worker</code> 并不是真正用于处理任务的 Worker，负责执行执行任务的类型其实是 <code>Sidekiq::Processor</code>；在文章中，当我们提到 Sidekiq Worker 时，其实说的是 <code>Sidekiq::Processor</code>，当我们使用了形如 <code>Sidekiq::Worker</code> 或者 <code>Worker</code> 的形式时，我们说的就是对应的类。</p>
</blockquote>

<h2 id="异步任务的入队">异步任务的入队</h2>

<p>当我们对需要异步执行的任务调用类似 <code>Worker.perform_async</code> 的方法时，Sidekiq 其实并不会真正去创建一个 <code>HardWorker</code> 等 <code>Worker</code> 的对象，它实际上会调用 <code>Worker.client_push</code> 方法并将当前的 <code>class</code> 和 <code>args</code> 参数传进去，也就是需要异步执行的类和参数：</p>

<pre><code class="language-ruby">def perform_async(*args)
  client_push('class'.freeze =&gt; self, 'args'.freeze =&gt; args)
end
</code></pre>

<p>除了 <code>Worker.perform_async</code> 之外，<code>Worker</code> 还提供了另外一对用于<strong>在一段时间之后或者某个时间点</strong>执行相应任务的方法 <code>Worker.perform_at</code> 和 <code>Worker.perform_in</code>：</p>

<pre><code class="language-ruby">def perform_in(interval, *args)
  int = interval.to_f
  now = Time.now.to_f
  ts = (int &lt; 1_000_000_000 ? now + int : int)
  item = { 'class'.freeze =&gt; self, 'args'.freeze =&gt; args, 'at'.freeze =&gt; ts }
  item.delete('at'.freeze) if ts &lt;= now
  client_push(item)
end
alias_method :perform_at, :perform_in
</code></pre>

<p>为了使用同一个接口支持两种不同的安排方式（时间点和多久之后），方法内部对传入的 <code>internal</code> 进行了判断，当 <code>interval.to_f &lt; 1_000_000_000</code> 时就会在一段时间之后执行任务，否则就会以时间点的方式执行任务，虽然 <code>Worker.perform_at</code> 和 <code>Worker.perform_in</code> 是完全相同的方法，不过我们在使用时还是尽量遵循方法的语义选择两者中更符合逻辑的方法。</p>

<p><img src="https://img.nju520.me/2017-08-28-Client-Push-Item.jpg-1000width" alt="Client-Push-Item" /></p>

<p>两种创建异步任务的方式，最终都执行了 <code>Worker.client_push</code> 方法并传入了一个哈希，其中可能包含以上三个部分的内容；在方法的实现中，它获取了上下文中的 Redis 池并将传入的 <code>item</code> 对象传入 Redis 中：</p>

<pre><code class="language-ruby">def client_push(item)
  pool = Thread.current[:sidekiq_via_pool] || get_sidekiq_options['pool'.freeze] || Sidekiq.redis_pool
  item.keys.each do |key|
    item[key.to_s] = item.delete(key)
  end
  Sidekiq::Client.new(pool).push(item)
end
</code></pre>

<p>简单整理一下，从 <code>Worker.perform_async</code> 方法到 <code>Client#push</code> 方法整个过程都在对即将加入到 Redis 中队列的哈希进行操作，从添加 <code>at</code> 字段到字符串化、再到 <code>Client#normalize_item</code> 方法中添加 <code>jid</code> 和 <code>created_at</code> 字段。</p>

<pre><code class="language-ruby">def push(item)
  normed = normalize_item(item)
  payload = process_single(item['class'.freeze], normed)

  if payload
    raw_push([payload])
    payload['jid'.freeze]
  end
end
</code></pre>

<p>所有添加异步任务的方法最终都调用了私有方法 <code>Client#raw_push</code> 以及 <code>Client#atomic_push</code> 向 Redis 中添加数据，在这时会有两种不同的情况发生，当异步任务需要在未来的某一时间点进行安排时，它会加入 Redis 的一个有序集合：</p>

<pre><code class="language-ruby">def atomc_push(conn, payloads)
  if payloads.first['at'.freeze]
    conn.zadd('schedule'.freeze, payloads.map do |hash|
                at = hash.delete('at'.freeze).to_s
                [at, Sidekiq.dump_json(hash)]
              end)
  else
    # ...
  end
end
</code></pre>

<p>在这个有序集合中，Sidekiq 理所应当地将 <code>schedule</code> 作为权重，而其他的全部字段都以 JSON 的格式作为负载传入；但是当 Sidekiq 遇到需要立即执行的异步任务时，实现就有一些不同了：</p>

<pre><code class="language-ruby">def atomc_push(conn, payloads)
  if payloads.first['at'.freeze]
  # ...
  else
    q = payloads.first['queue'.freeze]
    now = Time.now.to_f
    to_push = payloads.map do |entry|
      entry['enqueued_at'.freeze] = now
      Sidekiq.dump_json(entry)
    end
    conn.sadd('queues'.freeze, q)
    conn.lpush("queue:#{q}", to_push)
  end
end
</code></pre>

<p>除了设置当前任务的入队时间 <code>enqueued_at</code> 之外，Sidekiq 将队列加入到一个大队列 <code>queues</code> 的集合中，并且将负载直接推到 <code>"queue:#{q}"</code> 数组中等待消费者的拉取，我们稍微梳理一下两种安排异步队列方法的调用过程：</p>

<p><img src="https://img.nju520.me/2017-08-28-Async-Schedule.jpg-1000width" alt="Async-Schedule" /></p>

<h3 id="redis-中的存储">Redis 中的存储</h3>

<p>无论是立即执行还是需要安排的异步任务都会进入 Redis 的队列中，但是它们之间还是有一些区别的，<code>Worker.perform_in/at</code> 会将任务以 <code>[at, args]</code> 的形式加入到 <code>schedules</code> 有序集中，而
<code>Worker.perform_async</code> 将负载加入到指定的队列，并向整个 Sidekiq 的队列集合 <code>queues</code> 中添加该队列。</p>

<p><img src="https://img.nju520.me/2017-08-28-Perform-async-in-Redis.jpg-1000width" alt="Perform-async-in-Redis" /></p>

<p>所有的 <code>payload</code> 中都包含了一个异步任务需要执行的全部信息，包括该任务的执行的队列 <code>queue</code>、异步队列的类 <code>class</code>、参数 <code>args</code> 以及 <code>sidekiq_options</code> 中的全部参数。</p>

<p><img src="https://img.nju520.me/2017-08-28-Job-in-Redis.jpg-1000width" alt="Job-in-Redis" /></p>

<p>除了上述参数，一个异步任务还包含诸如 <code>created_at</code>、<code>enqueued_at</code> 等信息，也有一个通过 <code>SecureRandom.hex(12)</code> 生成的任务唯一标识符 <code>jid</code>。</p>

<h2 id="sidekiq-的启动过程">Sidekiq 的启动过程</h2>

<p>作者对于 Sidekiq 印象最深刻的就是它在命令行启动的时候输出的一个字符画，我们能在 <code>cli.rb</code> 的 <code>Cli.banner</code> 方法中找到这个字符画：</p>

<pre><code>         m,
         `$b
    .ss,  $$:         .,d$
    `$$P,d$P'    .,md$P"'
     ,$$$$$bmmd$$$P^'
   .d$$$$$$$$$$P'
   $$^' `"^$$$'       ____  _     _      _    _
   $:     ,$$:       / ___|(_) __| | ___| | _(_) __ _
   `b     :$$        \___ \| |/ _` |/ _ \ |/ / |/ _` |
          $$:         ___) | | (_| |  __/   &lt;| | (_| |
          $$         |____/|_|\__,_|\___|_|\_\_|\__, |
        .d$$                                       |_|
</code></pre>

<p>这一节也将介绍 Sidekiq 的启动过程，在 <code>bin</code> 文件夹中的 sidekiq 文件包含的内容就是在命令行执行 <code>sidekiq</code> 时执行的代码：</p>

<pre><code class="language-ruby">begin
  cli = Sidekiq::CLI.instance
  cli.parse
  cli.run
rescue =&gt; e
  # ...
end
</code></pre>

<p>这里的代码就是创建了一个 <code>CLI</code> 对象，执行 <code>CLI#parse</code> 方法对参数进行解析，最后调用 <code>CLI#run</code> 方法：</p>

<pre><code class="language-ruby">def run
  print_banner

  self_read, self_write = IO.pipe
  # ...

  launcher = Sidekiq::Launcher.new(options)
  begin
    launcher.run
    while readable_io = IO.select([self_read])
      signal = readable_io.first[0].gets.strip
      handle_signal(signal)
    end
  rescue Interrupt
    launcher.stop
  end
end
</code></pre>

<h3 id="从-launcher-到-manager">从 Launcher 到 Manager</h3>

<p><code>CLI#run</code> 在执行最开始就会打印 banner，也就是我们在每次启动 Sidekiq 时看到的字符画，而在之后会执行 <code>Launcher#run</code> 运行用于处理异步任务的 <code>Processor</code> 等对象。</p>

<p><img src="https://img.nju520.me/2017-08-28-Launcher-Poller-Manager-Processors.jpg-1000width" alt="Launcher-Poller-Manager-Processors" /></p>

<p>每一个 <code>Launcher</code> 都会启动一个 <code>Manager</code> 对象和一个 <code>Poller</code>，其中 <code>Manager</code> 同时管理了多个 <code>Processor</code> 对象，这些不同的类之间有着如上图所示的关系。</p>

<pre><code class="language-ruby">def run
  @thread = safe_thread("heartbeat", &amp;method(:start_heartbeat))
  @poller.start
  @manager.start
end
</code></pre>

<p><code>Manager</code> 会在初始化时根据传入的 <code>concurrency</code> 的值创建对应数量的 <code>Processor</code>，默认的并行数量为 25；当执行 <code>Manager#start</code> 时，就会启动对应数量的<strong>线程</strong>和处理器开始对任务进行处理：</p>

<pre><code class="language-ruby">class Manager
  def start
    @workers.each do |x|
      x.start
    end
  end
end

class Processor
  def start
    @thread ||= safe_thread("processor", &amp;method(:run))
  end
end
</code></pre>

<p>从 <code>Launcher</code> 的启动到现在只是一个调用 <code>initialize</code> 和 <code>start</code> 方法的过程，再加上 Sidekiq 源代码非常简单，所以阅读起没有丝毫的难度，也就不做太多的解释了。</p>

<h3 id="并行模型">并行模型</h3>

<p>当处理器开始执行 <code>Processor#run</code> 方法时，就开始对所有的任务进行处理了；从总体来看，Sidekiq 使用了多线程的模型对任务进行处理，每一个 <code>Processor</code> 都是使用了 <code>safe_thread</code> 方法在一个新的线程里面运行的：</p>

<pre><code class="language-ruby">def safe_thread(name, &amp;block)
  Thread.new do
    Thread.current['sidekiq_label'.freeze] = name
    watchdog(name, &amp;block)
  end
end
</code></pre>

<p>在使用 Sidekiq 时，我们也会在不同的机器上开启多个 Sidekiq Worker，也就是说 Sidekiq 可以以多进程、多线程的方式运行，同时处理大量的异步任务。</p>

<p><img src="https://img.nju520.me/2017-08-28-Sidekiq-Multi-Processes.jpg-1000width" alt="Sidekiq-Multi-Processes" /></p>

<p>到目前为止，我们已经分析了异步任务的入队以及 Sidekiq Worker 的启动过程了，接下来即将分析 Sidekiq 对异步任务的处理过程。</p>

<h3 id="主题的订阅">『主题』的订阅</h3>

<p>作为一个 Sidekiq Worker 进程，它在启动时就会决定选择订阅哪些『主题』去执行，比如当我们使用下面的命令时：</p>

<pre><code class="language-sh">&gt; sidekiq -q critical,2 -q default
</code></pre>

<p><code>CLI#parse</code> 方法会对传入的 <code>-q</code> 参数进行解析，但是当执行 <code>sidekiq</code> 命令却没有传入队列参数时，Sidekiq 只会订阅 <code>default</code> 队列中的任务：</p>

<pre><code class="language-ruby">def parse(args=ARGV)
  # ...
  validate!
  # ...
end

def validate!
  options[:queues] &lt;&lt; 'default' if options[:queues].empty?
end
</code></pre>

<p>同时，默认情况下的队列的优先级都为 <code>1</code>，高优先级的队列在当前的任务中可以得到更多的执行机会，实现的方法是通过增加同一个 <code>queues</code> 集合中高优先级队列的数量，我们可以在 <code>CLI#parse_queue</code> 中找到实现这一功能的代码：</p>

<pre><code class="language-ruby">def parse_queue(opts, q, weight=nil)
  [weight.to_i, 1].max.times do
    (opts[:queues] ||= []) &lt;&lt; q
  end
  opts[:strict] = false if weight.to_i &gt; 0
end
</code></pre>

<p>到这里，其实我们就完成了设置过程中 Sidekiq Worker 『主题』订阅的功能了，我们将在后面 <a href="#执行任务">执行任务</a> 的部分具体介绍 Sidekiq 是如何使用这些参数的。</p>

<h2 id="异步任务的处理">异步任务的处理</h2>

<p>从异步任务的入队一节中，我们可以清楚地看到使用 <code>#perform_async</code> 和 <code>#perform_in</code> 两种方法创建的数据结构 <code>payload</code> 最终以不同的方式进入了 Redis 中，所以在这里我们将异步任务的处理分为定时任务和『立即』任务两个部分，分别对它们不同的处理方式进行分析。</p>

<h3 id="定时任务">定时任务</h3>

<p>Sidekiq 使用 <code>Scheduled::Poller</code> 对 Redis 中 <code>schedules</code> 有序集合中的负载进行处理，其中包括 <code>retry</code> 和 <code>schedule</code> 两个有序集合中的内容。</p>

<p><img src="https://img.nju520.me/2017-08-28-Redis-Sorted-Set.jpg-1000width" alt="Redis-Sorted-Set" /></p>

<p>在 <code>Poller</code> 被 <code>Scheduled::Poller</code> 启动时会调用 <code>#start</code> 方法开始对上述两个有序集合轮训，<code>retry</code> 中包含了所有重试的任务，而 <code>schedule</code> 就是被安排到指定时间执行的定时任务了：</p>

<pre><code class="language-ruby">def start
  @thread ||= safe_thread("scheduler") do
    initial_wait
    while !@done
      enqueue
      wait
    end
  end
end
</code></pre>

<p><code>Scheduled::Poller#start</code> 方法内部执行了一个 <code>while</code> 循环，在循环内部也只包含入队和等待两个操作，用于入队的方法最终调用了 <code>Scheduled::Poll::Enq#enqueue_jobs</code> 方法：</p>

<pre><code class="language-ruby">def enqueue_jobs(now=Time.now.to_f.to_s, sorted_sets=SETS)
  Sidekiq.redis do |conn|
    sorted_sets.each do |sorted_set|
      while job = conn.zrangebyscore(sorted_set, '-inf'.freeze, now, :limit =&gt; [0, 1]).first do
        if conn.zrem(sorted_set, job)
          Sidekiq::Client.push(Sidekiq.load_json(job))
        end
      end
    end
  end
end
</code></pre>

<p>传入的 <code>SETS</code> 其实就是 <code>retry</code> 和 <code>schedule</code> 构成的数组，在上述方法中，Sidekiq 通过一个 <code>Redis#zrangebyscore</code> 和 <code>Redis#zrem</code> 将集合中小于当前时间的任务全部加到立即任务中，最终调用是在前面已经提到过的 <code>Client#push</code> 方法将任务推到指定的队列中。</p>

<p><img src="https://img.nju520.me/2017-08-28-Redis-Sidekiq-Poller.jpg-1000width" alt="Redis-Sidekiq-Poller" /></p>

<p>由于 <code>Scheduled::Poller</code> 并不是不停地对 Redis 中的数据进行处理的，因为当前进程一直都在执行 <code>Poller#enqueue</code> 其实是一个非常低效的方式，所以 Sidekiq 会在每次执行 <code>Poller#enqueue</code> 之后，执行 <code>Poller#wait</code> 方法，随机等待一段时间：</p>

<pre><code class="language-ruby">def wait
  @sleeper.pop(random_poll_interval)
  # ...
end

def random_poll_interval
  poll_interval_average * rand + poll_interval_average.to_f / 2
end
</code></pre>

<p>随机等待时间的范围在 <code>[0.5 * poll_interval_average, 1.5 * poll_interval_average]</code> 之间；通过随机的方式，Sidekiq 可以避免在多个线程处理任务时，短时间内 Redis 接受大量的请求发生延迟等问题，能够保证从长期来看 Redis 接受的请求数是平均的；同时因为 <code>Scheduled::Poller</code> 使用了 <code>#enqueue</code> 加 <code>#wait</code> 对 Redis 中的数据进行消费，所以没有办法保证任务会在指定的时间点执行，<strong>执行的时间一定比安排的时间要晚</strong>，这也是我们在使用 Sidekiq 时需要注意的。</p>

<blockquote>
  <p>随机等待的时间其实不止与 <code>poll_interval_average</code> 有关，在默认情况下，它是当前进程数的 15 倍，在有 30 个 Sidekiq 线程时，每个线程会每隔 225 ~ 675s 的时间请求一次。</p>
</blockquote>

<h3 id="执行任务">执行任务</h3>

<p>定时任务是由 <code>Scheduled::Poller</code> 进行处理的，将其中需要执行的异步任务加入到指定的队列中，而这些任务最终都会在 <code>Processor#run</code> 真正被执行：</p>

<pre><code class="language-ruby">def run
  begin
    while !@done
      process_one
    end
    @mgr.processor_stopped(self)
  rescue Exception =&gt; ex
    # ...
  end
end
</code></pre>

<p>当处理结束或者发生异常时会调用 <code>Manager#processor_stopped</code> 或者 <code>Manager#processor_died</code> 方法对 <code>Processor</code> 进行处理；在处理任务时其实也分为两个部分，也就是 <code>#fetch</code> 和 <code>#process</code> 两个方法：</p>

<pre><code class="language-ruby">def process_one
  @job = fetch
  process(@job) if @job
  @job = nil
end
</code></pre>

<p>我们先来看一下整个方法的调用栈，任务的获取从 <code>Processor#process_one</code> 一路调用下来，直到 <code>BasicFetch#retrive_work</code> 返回了 <code>UnitOfWork</code> 对象，返回的对象会经过分发最后执行对应类的 <code>#perform</code> 传入参数真正运行该任务：</p>

<pre><code>Processor#process_one
├── Processor#fetch
│   └── Processor#get_one
│       └── BasicFetch#retrive_work
│           ├── Redis#brpop
│           └── UnitOfWork#new
└── Processor#process
    ├── Processor#dispatch
    ├── Processor#execute_job
    └── Worker#perform
</code></pre>

<p>对于任务的获取，我们需要关注的就是 <code>BasicFetch#retrive_work</code> 方法，他会从 Redis 中相应队列的有序数组中 <code>Redis#brpop</code> 出一个任务，然后封装成 <code>UnitOfWork</code> 对象后返回。</p>

<pre><code class="language-ruby">def retrieve_work
  work = Sidekiq.redis { |conn| conn.brpop(*queues_cmd) }
  UnitOfWork.new(*work) if work
end
</code></pre>

<p><code>#queues_cmd</code> 这个实例方法其实就用到了在主题的订阅一节中的 <code>queues</code> 参数，该参数会在 <code>Processor</code> 初始化是创建一个 <code>BasicFetch</code> 策略对象，最终在 <code>BasicFetch#queues_cmd</code> 方法调用时返回一个类似下面的数组：</p>

<pre><code class="language-ruby">queue:high
queue:high
queue:high
queue:low
queue:low
queue:default
</code></pre>

<p>这样就可以实现了队列的优先级这一个功能了，返回的 <code>UnitOfWork</code> 其实是一个通过 <code>Struct.new</code> 创建的结构体，它会在 <code>Processor#process</code> 方法中作为资源被处理：</p>

<pre><code class="language-ruby">def process(work)
  jobstr = work.job
  queue = work.queue_name

  begin
    # ...

    job_hash = Sidekiq.load_json(jobstr)
    dispatch(job_hash, queue) do |worker|
      Sidekiq.server_middleware.invoke(worker, job_hash, queue) do
        execute_job(worker, cloned(job_hash['args'.freeze]))
      end
    end
  rescue Exception =&gt; ex
    # ...
  end
end
</code></pre>

<p>该方法对任务的执行其实总共有四个步骤：</p>

<ol>
  <li>将 Redis 中存储的字符串加载为 JSON；</li>
  <li>执行 <code>Processor#dispatch</code> 方法并在内部提供方法重试等功能，同时也实例化一个 <code>Sidekiq::Worker</code> 对象；</li>
  <li>依次执行服务端的中间件，可能会对参数进行更新；</li>
  <li>调用 <code>Processor#execute_job</code> 方法执行任务；</li>
</ol>

<p>而最后调用的时用于执行任务的方法 <code>Processor#execute_job</code>，它的实现也是到目前为止最为简单的方法之一了：</p>

<pre><code class="language-ruby">def execute_job(worker, cloned_args)
  worker.perform(*cloned_args)
end
</code></pre>

<p>该方法在<strong>线程</strong>中执行了客户端创建的 <code>Worker</code> 类的实例方法 <code>#perform</code> 并传入了经过两侧中间件处理后的参数。</p>

<h3 id="小结">小结</h3>

<p>到目前为止，Sidekiq Worker 对任务的消费过程就是圆满的了，从客户端创建一个拥有 <code>#perform</code> 方法的 <code>Worker</code> 到消费者去执行该方法形成了一个闭环，完成了对任务的调度。</p>

<p><img src="https://img.nju520.me/2017-08-28-Client-Redis-Sidekiq-Worker.jpg-1000width" alt="Client-Redis-Sidekiq-Worker" /></p>

<p>Sidekiq 是一个非常轻量级的任务调度系统，它使用 Redis 作为整个系统的消息队列，在两侧分别建立了生产者和消费者的模块，不过除了这几个比较重要的模块，Sidekiq 中还有一些功能是我们无法忽略的，比如中间件、兼容 ActiveJob 甚至是测试的实现，都是我们需要去了解的；接下来，我们将介绍和分析主干之外的『分叉』功能。</p>

<h2 id="中间件">中间件</h2>

<p>中间件模块是 Sidekiq 为我们在整个任务的处理流程提供的两个钩子，一个是在客户端的钩子，另一个在 Sidekiq Worker 中。</p>

<p><img src="https://img.nju520.me/2017-08-28-Middlewares-Client-Redis-Sidekiq-Worker.jpg-1000width" alt="Middlewares-Client-Redis-Sidekiq-Worker" /></p>

<p>中间件的使用其实非常简单，我们默认所有的中间件都会拥有一个实例方法 <code>#call</code> 并接受 <code>worker</code>、<code>job</code> 和 <code>queue</code> 三个参数，在使用时也只需要直接调用 <code>Chain#add</code> 方法将其加入数组就可以了：</p>

<pre><code class="language-ruby">class AcmeCo::MyMiddleware
  def call(worker, job, queue)
    # ...
  end
end

# config/initializers/sidekiq.rb
Sidekiq.configure_server do |config|
  config.server_middleware do |chain|
    chain.add AcmeCo::MyMiddleware
  end
end
</code></pre>

<p>Sidekiq 将中间件分为了客户端和服务端两个部分，这两个部分的中间件其实并不是严格意义上的在执行之前，由于执行时间点的不同，导致它们有不同的功能：</p>

<ul>
  <li>服务端中间件是『包围』了任务执行过程的，我们可以在中间件中使用 <code>begin</code>、<code>rescue</code> 语句，这样当任务出现问题时，我们就可以拿到异常了；</li>
  <li>客户端中间件在任务即将被推入 Redis 之前运行，它能够阻止任务进入 Redis 并且允许我们在任务入队前对其进行修改和停止；</li>
</ul>

<p>当我们对 Sidekiq 中间的使用都有一定的了解时，就可以开始分析中间件的实现了。</p>

<h3 id="实现">实现</h3>

<p>无论是异步任务真正进入队列之前，还是在客户端处理，跟任务有关的信息都会先通过一个预处理流程，客户端和服务端两个中间件的链式调用都使用 <code>Middleware::Chain</code> 中的类进行处理的：</p>

<pre><code class="language-ruby">class Chain
  include Enumerable
  attr_reader :entries

  def initialize
    @entries = []
    yield self if block_given?
  end

  def remove(klass); end
  def add(klass, *args); end
  def prepend(klass, *args); end
  def insert_before(oldklass, newklass, *args); end
  def insert_after(oldklass, newklass, *args); end
end
</code></pre>

<p>每一个 <code>Middleware::Chain</code> 中都包含一系列的 <code>Entry</code>，其中存储了中间件的相关信息，无论是客户端还是服务端都会在执行之前对每一个异步任务的参数执行 <code>invoke</code> 方法调用 <code>Middleware::Chain</code> 对象中的所有中间件：</p>

<pre><code class="language-ruby">def invoke(*args)
  chain = retrieve.dup
  traverse_chain = lambda do
    if chain.empty?
      yield
    else
      chain.shift.call(*args, &amp;traverse_chain)
    end
  end
  traverse_chain.call
end

</code></pre>

<p><code>Chain#invoke</code> 会对其持有的每一个中间件都执行 <code>#call</code> 方法，中间件都可以对异步任务的参数进行改变或者进行一些记录日志等操作，最后执行传入的 block 并返回结果。</p>

<p><img src="https://img.nju520.me/2017-08-28-Sidekiq-Middlewares.jpg-1000width" alt="Sidekiq-Middlewares" /></p>

<p>当异步队列入队时，就会执行 <code>Client#process_single</code> 方法调用 Sidekiq 载入中的全部中间件最后返回新的 <code>item</code> 对象：</p>

<pre><code class="language-ruby">def process_single(worker_class, item)
  queue = item['queue'.freeze]
  middleware.invoke(worker_class, item, queue, @redis_pool) do
    item
  end
end
</code></pre>

<p>每一个 Sidekiq Worker 在处理中间件时也基本遵循相同的逻辑，如 <code>#process</code> 方法先先执行各种中间件，最后再运行 block 中的内容。</p>

<pre><code class="language-ruby">def process(work)
  jobstr = work.job
  queue = work.queue_name

  begin
    # ...

    job_hash = Sidekiq.load_json(jobstr)
    Sidekiq.server_middleware.invoke(worker, job_hash, queue) do
      execute_job(worker, cloned(job_hash['args'.freeze]))
    end
  rescue Exception =&gt; ex
    # ...
  end
end
</code></pre>

<p>在 <code>#execute_job</code> 方法执行期间，由于异步任务可能抛出异常，在这时，我们注册的中间件就可以根据情况对异常进行捕获并选择是否对异常进行处理或者抛给上层了。</p>

<h2 id="任务的重试">任务的重试</h2>

<p>Sidekiq 中任务的重试是由 <code>JobRetry</code> 负责的，<code>Prcessor</code> 中的 <code>#dispatch</code> 方法中调用了 <code>JobRetry#global</code> 方法捕获在异步任务执行过程中发生的错误：</p>

<pre><code class="language-ruby">def dispatch(job_hash, queue)
  pristine = cloned(job_hash)

  # ...
  @retrier.global(pristine, queue) do
    klass  = constantize(job_hash['class'.freeze])
    worker = klass.new
    worker.jid = job_hash['jid'.freeze]
    @retrier.local(worker, pristine, queue) do
      yield worker
    end
  end
end
</code></pre>

<p>任务的执行过程分别调用了两个 <code>JobRetry</code> 的方法 <code>#global</code> 和 <code>#local</code>，这两个方法在实现上差不多，都将执行异步任务的 block 包在了一个 <code>begin</code>、<code>rescue</code> 中，选择在合适的时间重试：</p>

<pre><code class="language-ruby">def local(worker, msg, queue)
  yield
# ...
rescue Exception =&gt; e
  raise Sidekiq::Shutdown if exception_caused_by_shutdown?(e)

  if msg['retry'] == nil
    msg['retry'] = worker.class.get_sidekiq_options['retry']
  end

  raise e unless msg['retry']
  attempt_retry(worker, msg, queue, e)
  raise Skip
end
</code></pre>

<p>如果我们在定义 <code>Worker</code> 时就禁用了重试，那么在这里就会直接抛出上层的异常，否则就会进入 <code>#attempt_retry</code> 方法安排任务进行重试：</p>

<pre><code class="language-ruby">def attempt_retry(worker, msg, queue, exception)
  max_retry_attempts = retry_attempts_from(msg['retry'], @max_retries)

  msg['queue'] = if msg['retry_queue']
                   msg['retry_queue']
                 else
                   queue
                 end

  count = if msg['retry_count']
            msg['retried_at'] = Time.now.to_f
            msg['retry_count'] += 1
          else
            msg['failed_at'] = Time.now.to_f
            msg['retry_count'] = 0
          end

  if count &lt; max_retry_attempts
    delay = delay_for(worker, count, exception)
    retry_at = Time.now.to_f + delay
    payload = Sidekiq.dump_json(msg)
    Sidekiq.redis do |conn|
      conn.zadd('retry', retry_at.to_s, payload)
    end
  else
    retries_exhausted(worker, msg, exception)
  end
end
</code></pre>

<p>在上面其实我们提到过，<code>Poller</code> 每次会从两个有序集合 <code>retry</code> 和 <code>schedule</code> 中查找到时的任务加入到对应的队列中，在 <code>#attempt_retry</code> 方法中，就可以找到看到 <code>retry</code> 队列中的元素是如何加入的了。</p>

<p>当任务的重试次数超过了限定的重试次数之后，就会执行 <code>#retries_exhausted</code> 以及 <code># send_to_morgue</code> 这一方法，将任务的负载加入 <code>DeadSet</code> 对象中：</p>

<pre><code class="language-ruby">def send_to_morgue(msg)
  payload = Sidekiq.dump_json(msg)
  DeadSet.new.kill(payload)
end
</code></pre>

<p>这样整个任务的重试过程就结束了，Sidekiq 使用 <code>begin</code>、<code>rescue</code> 捕获整个流程中出现的异常，并根据传入的 <code>retry_count</code> 参数进行重试，调度过程还是非常简洁也非常容易理解的。</p>

<h2 id="总结">总结</h2>

<p>作为一个 Ruby 社区中广泛被使用的异步任务处理的依赖，它的实现是很简单的并且其源代码非常易于阅读，整体的架构也非常清晰。</p>

<p><img src="https://img.nju520.me/2017-08-28-Middlewares-Client-Redis-Sidekiq-Worker.jpg-1000width" alt="Middlewares-Client-Redis-Sidekiq-Worker" /></p>

<p>使用键值的内存数据库 Redis 作为客户端和 Worker 之间的桥梁，Redis 的使用简化了 Sidekiq 的很多逻辑，同时对中间件的支持也使其有着良好的扩展性，不过正其实现简单，所以例如任务取消以及定时任务这种比较常见的功能其本身都没有实现，有的是 Sidekiq 本身设计问题导致的，有的需要另外的插件，不过在绝大多数情况下，Sidekiq 都能完全满足我们的需要，解决绝大多数的问题。</p>

<h2 id="references">References</h2>

<ul>
  <li><a href="https://github.com/mperham/sidekiq">Sidekiq</a></li>
  <li><a href="https://ruby-china.org/topics/31470">Sidekiq 任务调度流程分析</a></li>
</ul>

  ]]></description>
</item>

<item>
  <title>Redis 是如何处理命令的（客户端）</title>
  <link>//redis-cli</link>
  <author>nju520</author>
  <pubDate>2016-12-23T23:23:15+08:00</pubDate>
  <guid>//redis-cli</guid>
  <description><![CDATA[
  <p>在使用 Redis 的过程中经常会好奇，在 Redis-Cli 中键入 <code>SET KEY MSG</code> 并回车之后，Redis 客户端和服务是如何对命令进行解析处理的，而在内部的实现过程是什么样的。</p>

<p>这两篇文章会分别介绍 Redis 客户端和服务端分别对命令是如何处理的，本篇文章介绍的是 Redis 客户端如何处理输入的命令、向服务发送命令以及取得服务端回复并输出到终端等过程。</p>

<p><img src="https://img.nju520.me/2016-12-23-redis-client-server.jpg-1000width" alt="redis-client-serve" /></p>

<p>文章中会将 Redis 服务看做一个输入为 Redis 命令，输出为命令执行结果的黑箱，对从命令到结果的过程不做任何解释，只会着眼于客户端的逻辑，也就是上图中的 1 和 4 两个过程。</p>

<h2 id="从-main-函数开始">从 main 函数开始</h2>

<p>与其它的 C 语言框架/服务类似，Redis 的客户端 <code>redis-cli</code> 也是从 <code>main</code> 函数开始执行的，位于 <code>redis-cli.c</code> 文件的最后：</p>

<pre><code class="language-c">int main(int argc, char **argv) {
    ...
    if (argc == 0 &amp;&amp; !config.eval) {
        repl();
    }
    ...
}
</code></pre>

<p>在一般情况下，Redis 客户端都会进入 <code>repl</code> 模式，对输入进行解析；</p>

<blockquote>
  <p>Redis 中有好多模式，包括：Latency、Slave、Pipe、Stat、Scan、LRU test 等等模式，不过这些模式都不是这篇文章关注的重点，我们只会关注最常见的 repl 模式。</p>
</blockquote>

<pre><code class="language-c">static void repl(void) {
    char *line;
    int argc;
    sds *argv;

    ...

    while((line = linenoise(context ? config.prompt : "not connected&gt; ")) != NULL) {
        if (line[0] != '\0') {
            argv = cliSplitArgs(line,&amp;argc);

            if (argv == NULL) {
                printf("Invalid argument(s)\n");
                continue;
            }
            if (strcasecmp(argv[0],"???") == 0) {
                ...
            } else {
                issueCommandRepeat(argc, argv, 1);
            }
        }
    }
    exit(0);
}
</code></pre>

<p>在上述代码中，我们省略了大量的实现细节，只保留整个 <code>repl</code> 中循环的主体部分，方便进行理解和分析，在 <code>while</code> 循环中的条件你可以看到 <code>linenoise</code> 方法的调用，通过其中的 <code>prompt</code> 和 <code>not connected&gt; </code> 可以判断出，这里向终端中输出了提示符，同时会调用 <code>fgets</code> 从标准输入中读取字符串：</p>

<pre><code class="language-c">127.0.0.1:6379&gt;
</code></pre>

<p>全局搜一下 <code>config.prompt</code> 不难发现这一行代码，也就是控制命令行提示的 <code>prompt</code>：</p>

<pre><code class="language-c">anetFormatAddr(config.prompt, sizeof(config.prompt),config.hostip, config.hostport);
</code></pre>

<p>接下来执行的 <code>cliSplitArgs</code> 函数会将 <code>line</code> 中的字符串分割成几个不同的参数，然后根据字符串 <code>argv[0]</code> 的不同执行的命令，在这里省略了很多原有的代码：</p>

<pre><code class="language-c">if (strcasecmp(argv[0],"quit") == 0 ||
    strcasecmp(argv[0],"exit") == 0)
{
    exit(0);
} else if (argv[0][0] == ':') {
    cliSetPreferences(argv,argc,1);
    continue;
} else if (strcasecmp(argv[0],"restart") == 0) {
    ...
} else if (argc == 3 &amp;&amp; !strcasecmp(argv[0],"connect")) {
    ...
} else if (argc == 1 &amp;&amp; !strcasecmp(argv[0],"clear")) {
} else {
    issueCommandRepeat(argc, argv, 1);
}
</code></pre>

<p>在遇到 <code>quit</code>、<code>exit</code> 等跟<strong>客户端状态有关的命令</strong>时，就会直接执行相应的代码；否则就会将命令和参数 <code>issueCommandRepeat</code> 函数。</p>

<h3 id="追踪一次命令的执行">追踪一次命令的执行</h3>

<blockquote>
  <p>Redis Commit： <code>790310d89460655305bd615bc442eeaf7f0f1b38</code></p>

  <p>lldb： lldb-360.1.65</p>

  <p>macOS 10.11.6</p>
</blockquote>

<p>在继续分析 <code>issueCommandRepeat</code> 之前，我们先对 Redis 中的这部分代码进行调试追踪，在使用 <code>make</code> 编译了 Redis 源代码，启动 <code>redis-server</code> 之后；启动 lldb 对 Redis 客户端进行调试：</p>

<pre><code class="language-shell">$ lldb src/redis-cli
(lldb) target create "src/redis-cli"
Current executable set to 'src/redis-cli' (x86_64).
(lldb) b redis-cli.c:1290
Breakpoint 1: where = redis-cli`repl + 228 at redis-cli.c:1290, address = 0x0000000100008cd4
(lldb) process launch
Process 8063 launched: '~/redis/src/redis-cli' (x86_64)
127.0.0.1:6379&gt;
</code></pre>

<p>在 <code>redis-cli.c:1290</code> 也就是下面这行代码的地方打断点之后：</p>

<pre><code class="language-c">-&gt; 1290	        if (line[0] != '\0') {
</code></pre>

<p>执行 <code>process launch</code> 启动 <code>redis-cli</code>，然后输入 <code>SET KEY MSG</code> 回车以及 Ctrl-C：</p>

<blockquote>
  <p>在 lldb 中调试时，回车的输入经常会有问题，在这里输入 Ctrl-C 进入信号处理器，在通过 continue 命令进入断点：</p>
</blockquote>

<pre><code class="language-c">127.0.0.1:6379&gt; SET KEY MSG
^C
8063 stopped
* thread #1: tid = 0xa95147, 0x00007fff90923362 libsystem_kernel.dylib`read + 10, stop reason = signal SIGSTOP
    frame #0: 0x00007fff90923362 libsystem_kernel.dylib`read + 10
libsystem_kernel.dylib`read:
-&gt;  0x7fff90923362 &lt;+10&gt;: jae    0x7fff9092336c            ; &lt;+20&gt;
    0x7fff90923364 &lt;+12&gt;: movq   %rax, %rdi
    0x7fff90923367 &lt;+15&gt;: jmp    0x7fff9091c7f2            ; cerror
    0x7fff9092336c &lt;+20&gt;: retq
(lldb) c
Process 8063 resuming

Process 8063 stopped
* thread #1: tid = 0xa95147, 0x0000000100008cd4 redis-cli`repl + 228 at redis-cli.c:1290, queue = 'com.apple.main-thread', stop reason = breakpoint 1.1
    frame #0: 0x0000000100008cd4 redis-cli`repl + 228 at redis-cli.c:1290
   1287
   1288	    cliRefreshPrompt();
   1289	    while((line = linenoise(context ? config.prompt : "not connected&gt; ")) != NULL) {
-&gt; 1290	        if (line[0] != '\0') {
   1291	            argv = cliSplitArgs(line,&amp;argc);
   1292	            if (history) linenoiseHistoryAdd(line);
   1293	            if (historyfile) linenoiseHistorySave(historyfile);
(lldb)
</code></pre>

<p>输入两次 <code>n</code> 之后，打印 <code>argv</code> 和 <code>argc</code> 的值：</p>

<pre><code class="language-c">(lldb) p argc
(int) $1 = 3
(lldb) p *argv
(sds) $2 = 0x0000000100106cc3 "SET"
(lldb) p *(argv+1)
(sds) $3 = 0x0000000100106ce3 "KEY"
(lldb) p *(argv+2)
(sds) $4 = 0x0000000100106cf3 "MSG"
(lldb) p line
(char *) $5 = 0x0000000100303430 "SET KEY MSG\n"
</code></pre>

<p><code>cliSplitArgs</code> 方法成功将 <code>line</code> 中的字符串分隔成字符串参数，在多次执行 <code>n</code> 之后，进入 <code>issueCommandRepeat</code> 方法：</p>

<pre><code class="language-c">-&gt; 1334	                    issueCommandRepeat(argc-skipargs, argv+skipargs, repeat);
</code></pre>

<h2 id="对输入命令的处理">对输入命令的处理</h2>

<p>上一阶段执行 <code>issueCommandRepeat</code> 的函数调用栈中，会发现 Redis 并不会直接把所有的命令发送到服务端：</p>

<pre><code class="language-c">issueCommandRepeat
    cliSendCommand
        redisAppendCommandArgv
            redisFormatCommandArgv
            __redisAppendCommand
</code></pre>

<p>而是会在 <code>redisFormatCommandArgv</code> 中对所有的命令进行格式化处理，将字符串转换为符合 RESP 协议的数据。</p>

<h3 id="resp-协议">RESP 协议</h3>

<p>Redis 客户端与 Redis 服务进行通讯时，会使用名为 <strong>RESP</strong>（REdis Serialization Protocol） 的协议，它的使用非常简单，并且可以序列化多种数据类型包括整数、字符串以及数组等。</p>

<p>对于 RESP 协议的详细介绍可以看官方文档中的 <a href="https://redis.io/topics/protocol">Redis Protocol specification</a>，在这里对这个协议进行简单的介绍。</p>

<p>在将不同的数据类型序列化时，会使用第一个 byte 来表示当前数据的数据类型，以便在客户端或服务器在处理时能恢复原来的数据格式。</p>

<p><img src="https://img.nju520.me/2016-12-23-redis-resp-data-byte.jpg-1000width" alt="redis-resp-data-byte" /></p>

<p>举一个简单的例子，字符串 <code>OK</code> 以及错误<code>Error Message</code> 等不同种类的信息的 RESP 表示如下：</p>

<p><img src="https://img.nju520.me/2016-12-23-redis-resp-type-and-examples.jpg-1000width" alt="redis-resp-type-and-examples" /></p>

<p>在这篇文章中我们需要简单了解的就是 RESP “数据格式”的<strong>第一个字节用来表示数据类型</strong>，然后<strong>逻辑上属于不同部分的内容通过 CRLF（\r\n）分隔</strong>。</p>

<h3 id="数据格式的转换">数据格式的转换</h3>

<p>在 <code>redisFormatCommandArgv</code> 方法中几乎没有需要删减的代码，所有的命令都会以字符串数组的形式发送到客户端：</p>

<pre><code class="language-c">int redisFormatCommandArgv(char **target, int argc, const char **argv, const size_t *argvlen) {
    char *cmd = NULL;
    int pos;
    size_t len;
    int totlen, j;

    totlen = 1+intlen(argc)+2;
    for (j = 0; j &lt; argc; j++) {
        len = argvlen ? argvlen[j] : strlen(argv[j]);
        totlen += bulklen(len);
    }

    cmd = malloc(totlen+1);
    if (cmd == NULL)
        return -1;

    pos = sprintf(cmd,"*%d\r\n",argc);
    for (j = 0; j &lt; argc; j++) {
        len = argvlen ? argvlen[j] : strlen(argv[j]);
        pos += sprintf(cmd+pos,"$%zu\r\n",len);
        memcpy(cmd+pos,argv[j],len);
        pos += len;
        cmd[pos++] = '\r';
        cmd[pos++] = '\n';
    }
    assert(pos == totlen);
    cmd[pos] = '\0';

    *target = cmd;
    return totlen;
}
</code></pre>

<p><code>SET KEY MSG</code> 这一命令，经过这个方法的处理会变成：</p>

<pre><code class="language-c">*3\r\n$3\r\nSET\r\n$3\r\nKEY\r\n$3\r\nMSG\r\n
</code></pre>

<p>你可以这么理解上面的结果：</p>

<pre><code class="language-c">*3\r\n
    $3\r\nSET\r\n
    $3\r\nKEY\r\n
    $3\r\nMSG\r\n
</code></pre>

<p>这是一个由三个字符串组成的数组，数组中的元素是 <code>SET</code>、<code>KEY</code> 以及 <code>MSG</code> 三个字符串。</p>

<p>如果在这里打一个断点并输出 <code>target</code> 中的内容：</p>

<p><img src="https://img.nju520.me/2016-12-23-redis-lldb-cmd.png-1000width" alt="redis-lldb-cmd" /></p>

<p>到这里就完成了对输入命令的格式化，在格式化之后还会将当前命令写入全局的 <code>redisContext</code> 的 <code>write</code> 缓冲区 <code>obuf</code> 中，也就是在上面的缓冲区看到的第二个方法：</p>

<pre><code class="language-c">int __redisAppendCommand(redisContext *c, const char *cmd, size_t len) {
    sds newbuf;

    newbuf = sdscatlen(c-&gt;obuf,cmd,len);
    if (newbuf == NULL) {
        __redisSetError(c,REDIS_ERR_OOM,"Out of memory");
        return REDIS_ERR;
    }

    c-&gt;obuf = newbuf;
    return REDIS_OK;
}
</code></pre>

<h3 id="rediscontext">redisContext</h3>

<p>再继续介绍下一部分之前需要简单介绍一下 <code>redisContext</code> 结构体：</p>

<pre><code class="language-c">typedef struct redisContext {
    int err;
    char errstr[128];
    int fd;
    int flags;
    char *obuf;
    redisReader *reader;
} redisContext;
</code></pre>

<p>每一个 <code>redisContext</code> 的结构体都表示一个 Redis 客户端对服务的连接，而这个上下文会在每一个 redis-cli 中作为静态变量仅保存一个：</p>

<pre><code class="language-c">static redisContext *context;
</code></pre>

<p><code>obuf</code> 中包含了客户端未写到服务端的数据；而 <code>reader</code> 是用来处理 RESP 协议的结构体；<code>fd</code> 就是 Redis 服务对应的文件描述符；其他的内容就不多做解释了。</p>

<p>到这里，对命令的格式化处理就结束了，接下来就到了向服务端发送命令的过程了。</p>

<h2 id="向服务器发送命令">向服务器发送命令</h2>

<p>与对输入命令的处理差不多，向服务器发送命令的方法也在 <code>issueCommandRepeat</code> 的调用栈中，而且藏得更深，如果不仔细阅读源代码其实很难发现：</p>

<pre><code class="language-c">issueCommandRepeat
    cliSendCommand
        cliReadReply
            redisGetReply
               redisBufferWrite
</code></pre>

<p>Redis 在 <code>redisGetReply</code> 中完成对命令的发送：</p>

<pre><code class="language-c">int redisGetReply(redisContext *c, void **reply) {
    int wdone = 0;
    void *aux = NULL;

    if (aux == NULL &amp;&amp; c-&gt;flags &amp; REDIS_BLOCK) {
        do {
            if (redisBufferWrite(c,&amp;wdone) == REDIS_ERR)
                return REDIS_ERR;
        } while (!wdone);

        ...
        } while (aux == NULL);
    }

    if (reply != NULL) *reply = aux;
    return REDIS_OK;
}
</code></pre>

<p>上面的代码向 <code>redisBufferWrite</code> 函数中传递了全局的静态变量 <code>redisContext</code>，其中的 <code>obuf</code> 中存储了没有向 Redis 服务发送的命令：</p>

<pre><code class="language-c">int redisBufferWrite(redisContext *c, int *done) {
    int nwritten;

    if (sdslen(c-&gt;obuf) &gt; 0) {
        nwritten = write(c-&gt;fd,c-&gt;obuf,sdslen(c-&gt;obuf));
        if (nwritten == -1) {
            if ((errno == EAGAIN &amp;&amp; !(c-&gt;flags &amp; REDIS_BLOCK)) || (errno == EINTR)) {
            } else {
                __redisSetError(c,REDIS_ERR_IO,NULL);
                return REDIS_ERR;
            }
        } else if (nwritten &gt; 0) {
            if (nwritten == (signed)sdslen(c-&gt;obuf)) {
                sdsfree(c-&gt;obuf);
                c-&gt;obuf = sdsempty();
            } else {
                sdsrange(c-&gt;obuf,nwritten,-1);
            }
        }
    }
    if (done != NULL) *done = (sdslen(c-&gt;obuf) == 0);
    return REDIS_OK;
}
</code></pre>

<p>代码的逻辑其实十分清晰，调用 <code>write</code> 向 Redis 服务代表的文件描述符发送写缓冲区 <code>obuf</code> 中的数据，然后根据返回值做出相应的处理，如果命令发送成功就会清空 <code>obuf</code> 并将 <code>done</code> 指针标记为真，然后返回，这样就完成了向服务器发送命令这一过程。</p>

<p><img src="https://img.nju520.me/2016-12-23-redis-lldb-nwritten.png-1000width" alt="redis-lldb-nwritten" /></p>

<h2 id="获取服务器回复">获取服务器回复</h2>

<p>其实获取服务器回复和上文中的发送命令过程基本上差不多，调用栈也几乎完全一样：</p>

<pre><code class="language-c">issueCommandRepeat
    cliSendCommand
        cliReadReply
            redisGetReply
                redisBufferRead
                redisGetReplyFromReader
            cliFormatReplyRaw
            fwrite
</code></pre>

<p>同样地，在 <code>redisGetReply</code> 中获取服务器的响应：</p>

<pre><code class="language-c">int redisGetReply(redisContext *c, void **reply) {
    int wdone = 0;
    void *aux = NULL;

    if (aux == NULL &amp;&amp; c-&gt;flags &amp; REDIS_BLOCK) {
        do {
            if (redisBufferWrite(c,&amp;wdone) == REDIS_ERR)
                return REDIS_ERR;
        } while (!wdone);

        do {
            if (redisBufferRead(c) == REDIS_ERR)
                return REDIS_ERR;
            if (redisGetReplyFromReader(c,&amp;aux) == REDIS_ERR)
                return REDIS_ERR;
        } while (aux == NULL);
    }

    if (reply != NULL) *reply = aux;
    return REDIS_OK;
}
</code></pre>

<p>在 <code>redisBufferWrite</code> 成功发送命令并返回之后，就会开始等待服务端的回复，总共分为两个部分，一是使用 <code>redisBufferRead</code> 从服务端读取原始格式的回复（符合 RESP 协议）：</p>

<pre><code class="language-c">int redisBufferRead(redisContext *c) {
    char buf[1024*16];
    int nread;

    nread = read(c-&gt;fd,buf,sizeof(buf));
    if (nread == -1) {
        if ((errno == EAGAIN &amp;&amp; !(c-&gt;flags &amp; REDIS_BLOCK)) || (errno == EINTR)) {
        } else {
            __redisSetError(c,REDIS_ERR_IO,NULL);
            return REDIS_ERR;
        }
    } else if (nread == 0) {
        __redisSetError(c,REDIS_ERR_EOF,"Server closed the connection");
        return REDIS_ERR;
    } else {
        if (redisReaderFeed(c-&gt;reader,buf,nread) != REDIS_OK) {
            __redisSetError(c,c-&gt;reader-&gt;err,c-&gt;reader-&gt;errstr);
            return REDIS_ERR;
        }
    }
    return REDIS_OK;
}
</code></pre>

<p>在 <code>read</code> 从文件描述符中成功读取数据并返回之后，我们可以打印 <code>buf</code> 中的内容：</p>

<p><img src="https://img.nju520.me/2016-12-23-redis-lldb-read.png-1000width" alt="redis-lldb-read" /></p>

<p>刚刚向 <code>buf</code> 中写入的数据还需要经过 <code>redisReaderFeed</code> 方法的处理，截取正确的长度；然后存入 <code>redisReader</code> 中：</p>

<pre><code class="language-c">int redisReaderFeed(redisReader *r, const char *buf, size_t len) {
    sds newbuf;

    if (buf != NULL &amp;&amp; len &gt;= 1) {
        if (r-&gt;len == 0 &amp;&amp; r-&gt;maxbuf != 0 &amp;&amp; sdsavail(r-&gt;buf) &gt; r-&gt;maxbuf) {
            sdsfree(r-&gt;buf);
            r-&gt;buf = sdsempty();
            r-&gt;pos = 0;
            assert(r-&gt;buf != NULL);
        }

        newbuf = sdscatlen(r-&gt;buf,buf,len);
        if (newbuf == NULL) {
            __redisReaderSetErrorOOM(r);
            return REDIS_ERR;
        }

        r-&gt;buf = newbuf;
        r-&gt;len = sdslen(r-&gt;buf);
    }

    return REDIS_OK;
}
</code></pre>

<p>最后的 <code>redisGetReplyFromReader</code> 方法会从 <code>redisContext</code> 中取出 <code>reader</code>，然后反序列化 RESP 对象，最后打印出来。</p>

<p><img src="https://img.nju520.me/2016-12-23-process-end.png-1000width" alt="process-end" /></p>

<p>当我们从终端的输出中看到了 OK 以及这个命令的执行的时间时，<code>SET KEY MSG</code> 这一命令就已经处理完成了。</p>

<h2 id="总结">总结</h2>

<p>处理命令的过程在客户端还是比较简单的：</p>

<ol>
  <li>在一个 <code>while</code> 循环中，输出提示符；</li>
  <li>接收到输入命令时，对输入命令进行格式化处理；</li>
  <li>通过 <code>write</code> 发送到 Redis 服务，并调用 <code>read</code> 阻塞当前进程直到服务端返回为止；</li>
  <li>对服务端返回的数据反序列化；</li>
  <li>将结果打印到终端。</li>
</ol>

<p>用一个简单的图表示，大概是这样的：</p>

<p><img src="https://img.nju520.me/2016-12-23-redis-client-process-commands.jpg-1000width" alt="redis-client-process-commands" /></p>

<h2 id="references">References</h2>

<ul>
  <li><a href="https://redis.io/topics/protocol">Redis Protocol specification</a></li>
  <li><a href="http://nju520.me/redis-io-multiplexing/">Redis 和 I/O 多路复用</a></li>
  <li><a href="http://nju520.me/redis-eventloop">Redis 中的事件循环</a></li>
</ul>

<blockquote>

  <p>Source: http://nju520.me/redis-cli</p>
</blockquote>

  ]]></description>
</item>

<item>
  <title>Redis 中的事件循环</title>
  <link>//redis-eventloop</link>
  <author>nju520</author>
  <pubDate>2016-12-09T23:42:05+08:00</pubDate>
  <guid>//redis-eventloop</guid>
  <description><![CDATA[
  <p>在目前的很多服务中，由于需要持续接受客户端或者用户的输入，所以需要一个事件循环来等待并处理外部事件，这篇文章主要会介绍 Redis 中的事件循环是如何处理事件的。</p>

<p>在文章中，我们会先从 Redis 的实现中分析事件是如何被处理的，然后用更具象化的方式了解服务中的不同模块是如何交流的。</p>

<h2 id="aeeventloop">aeEventLoop</h2>

<p>在分析具体代码之前，先了解一下在事件处理中处于核心部分的 <code>aeEventLoop</code> 到底是什么：</p>

<p><img src="https://img.nju520.me/2016-12-09-reids-eventloop.png-1000width" alt="reids-eventloop" /></p>

<p><code>aeEventLoop</code> 在 Redis 就是负责保存待处理文件事件和时间事件的结构体，其中保存大量事件执行的上下文信息，同时持有三个事件数组：</p>

<ul>
  <li><code>aeFileEvent</code></li>
  <li><code>aeTimeEvent</code></li>
  <li><code>aeFiredEvent</code></li>
</ul>

<p><code>aeFileEvent</code> 和 <code>aeTimeEvent</code> 中会存储监听的文件事件和时间事件，而最后的 <code>aeFiredEvent</code> 用于存储待处理的文件事件，我们会在后面的章节中介绍它们是如何工作的。</p>

<h3 id="redis-服务中的-eventloop">Redis 服务中的 EventLoop</h3>

<p>在 <code>redis-server</code> 启动时，首先会初始化一些 redis 服务的配置，最后会调用 <code>aeMain</code> 函数陷入 <code>aeEventLoop</code> 循环中，等待外部事件的发生：</p>

<pre><code class="language-c">int main(int argc, char **argv) {
    ...

    aeMain(server.el);
}
</code></pre>

<p><code>aeMain</code> 函数其实就是一个封装的 <code>while</code> 循环，循环中的代码会一直运行直到 <code>eventLoop</code> 的 <code>stop</code> 被设置为 <code>true</code>：</p>

<pre><code class="language-c">void aeMain(aeEventLoop *eventLoop) {
    eventLoop-&gt;stop = 0;
    while (!eventLoop-&gt;stop) {
        if (eventLoop-&gt;beforesleep != NULL)
            eventLoop-&gt;beforesleep(eventLoop);
        aeProcessEvents(eventLoop, AE_ALL_EVENTS);
    }
}
</code></pre>

<p>它会不停尝试调用 <code>aeProcessEvents</code> 对可能存在的多种事件进行处理，而 <code>aeProcessEvents</code> 就是实际用于处理事件的函数：</p>

<pre><code class="language-c">int aeProcessEvents(aeEventLoop *eventLoop, int flags) {
    int processed = 0, numevents;

    if (!(flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_FILE_EVENTS)) return 0;

    if (eventLoop-&gt;maxfd != -1 ||
        ((flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_DONT_WAIT))) {
        struct timeval *tvp;

        #1：计算 I/O 多路复用的等待时间 tvp

        numevents = aeApiPoll(eventLoop, tvp);
        for (int j = 0; j &lt; numevents; j++) {
            aeFileEvent *fe = &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd];
            int mask = eventLoop-&gt;fired[j].mask;
            int fd = eventLoop-&gt;fired[j].fd;
            int rfired = 0;

            if (fe-&gt;mask &amp; mask &amp; AE_READABLE) {
                rfired = 1;
                fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);
            }
            if (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) {
                if (!rfired || fe-&gt;wfileProc != fe-&gt;rfileProc)
                    fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask);
            }
            processed++;
        }
    }
    if (flags &amp; AE_TIME_EVENTS) processed += processTimeEvents(eventLoop);
    return processed;
}
</code></pre>

<p>上面的代码省略了 I/O 多路复用函数的等待时间，不过不会影响我们对代码的理解，整个方法大体由两部分代码组成，一部分处理文件事件，另一部分处理时间事件。</p>

<blockquote>
  <p>Redis 中会处理两种事件：时间事件和文件事件。</p>
</blockquote>

<h3 id="文件事件">文件事件</h3>

<p>在一般情况下，<code>aeProcessEvents</code> 都会先<strong>计算最近的时间事件发生所需要等待的时间</strong>，然后调用 <code>aeApiPoll</code> 方法在这段时间中等待事件的发生，在这段时间中如果发生了文件事件，就会优先处理文件事件，否则就会一直等待，直到最近的时间事件需要触发：</p>

<pre><code class="language-c">numevents = aeApiPoll(eventLoop, tvp);
for (j = 0; j &lt; numevents; j++) {
    aeFileEvent *fe = &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd];
    int mask = eventLoop-&gt;fired[j].mask;
    int fd = eventLoop-&gt;fired[j].fd;
    int rfired = 0;

    if (fe-&gt;mask &amp; mask &amp; AE_READABLE) {
        rfired = 1;
        fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);
    }
    if (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) {
        if (!rfired || fe-&gt;wfileProc != fe-&gt;rfileProc)
            fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask);
    }
    processed++;
}
</code></pre>

<p>文件事件如果绑定了对应的读/写事件，就会执行对应的对应的代码，并传入事件循环、文件描述符、数据以及掩码：</p>

<pre><code class="language-c">fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);
fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask);
</code></pre>

<p>其中 <code>rfileProc</code> 和 <code>wfileProc</code> 就是在文件事件被创建时传入的函数指针：</p>

<pre><code class="language-c">int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData) {
    aeFileEvent *fe = &amp;eventLoop-&gt;events[fd];

    if (aeApiAddEvent(eventLoop, fd, mask) == -1)
        return AE_ERR;
    fe-&gt;mask |= mask;
    if (mask &amp; AE_READABLE) fe-&gt;rfileProc = proc;
    if (mask &amp; AE_WRITABLE) fe-&gt;wfileProc = proc;
    fe-&gt;clientData = clientData;
    if (fd &gt; eventLoop-&gt;maxfd)
        eventLoop-&gt;maxfd = fd;
    return AE_OK;
}
</code></pre>

<p>需要注意的是，传入的 <code>proc</code> 函数会在对应的 <code>mask</code> 位事件发生时执行。</p>

<h3 id="时间事件">时间事件</h3>

<p>在 Redis 中会发生两种时间事件：</p>

<ul>
  <li>一种是定时事件，每隔一段时间会执行一次；</li>
  <li>另一种是非定时事件，只会在某个时间点执行一次；</li>
</ul>

<p>时间事件的处理在 <code>processTimeEvents</code> 中进行，我们会分三部分分析这个方法的实现：</p>

<pre><code class="language-c">static int processTimeEvents(aeEventLoop *eventLoop) {
    int processed = 0;
    aeTimeEvent *te, *prev;
    long long maxId;
    time_t now = time(NULL);

    if (now &lt; eventLoop-&gt;lastTime) {
        te = eventLoop-&gt;timeEventHead;
        while(te) {
            te-&gt;when_sec = 0;
            te = te-&gt;next;
        }
    }
    eventLoop-&gt;lastTime = now;
</code></pre>

<p>由于对系统时间的调整会影响当前时间的获取，进而影响时间事件的执行；如果系统时间先被设置到了未来的时间，又设置成正确的值，这就会导致<strong>时间事件会随机延迟一段时间执行</strong>，也就是说，时间事件不会按照预期的安排尽早执行，而 <code>eventLoop</code> 中的 <code>lastTime</code> 就是用于检测上述情况的变量：</p>

<pre><code class="language-c">typedef struct aeEventLoop {
    ...
    time_t lastTime;     /* Used to detect system clock skew */
    ...
} aeEventLoop;
</code></pre>

<p>如果发现了系统时间被改变（小于上次 <code>processTimeEvents</code> 函数执行的开始时间），就会强制所有时间事件尽早执行。</p>

<pre><code class="language-c">    prev = NULL;
    te = eventLoop-&gt;timeEventHead;
    maxId = eventLoop-&gt;timeEventNextId-1;
    while(te) {
        long now_sec, now_ms;
        long long id;

        if (te-&gt;id == AE_DELETED_EVENT_ID) {
            aeTimeEvent *next = te-&gt;next;
            if (prev == NULL)
                eventLoop-&gt;timeEventHead = te-&gt;next;
            else
                prev-&gt;next = te-&gt;next;
            if (te-&gt;finalizerProc)
                te-&gt;finalizerProc(eventLoop, te-&gt;clientData);
            zfree(te);
            te = next;
            continue;
        }
</code></pre>

<p>Redis 处理时间事件时，不会在当前循环中直接移除不再需要执行的事件，而是会在当前循环中将时间事件的 <code>id</code> 设置为 <code>AE_DELETED_EVENT_ID</code>，然后再下一个循环中删除，并执行绑定的 <code>finalizerProc</code>。</p>

<pre><code class="language-c">        aeGetTime(&amp;now_sec, &amp;now_ms);
        if (now_sec &gt; te-&gt;when_sec ||
            (now_sec == te-&gt;when_sec &amp;&amp; now_ms &gt;= te-&gt;when_ms))
        {
            int retval;

            id = te-&gt;id;
            retval = te-&gt;timeProc(eventLoop, id, te-&gt;clientData);
            processed++;
            if (retval != AE_NOMORE) {
                aeAddMillisecondsToNow(retval,&amp;te-&gt;when_sec,&amp;te-&gt;when_ms);
            } else {
                te-&gt;id = AE_DELETED_EVENT_ID;
            }
        }
        prev = te;
        te = te-&gt;next;
    }
    return processed;
}
</code></pre>

<p>在移除不需要执行的时间事件之后，我们就开始通过比较时间来判断是否需要调用 <code>timeProc</code> 函数，<code>timeProc</code> 函数的返回值 <code>retval</code> 为时间事件执行的时间间隔：</p>

<ul>
  <li><code>retval == AE_NOMORE</code>：将时间事件的 <code>id</code> 设置为 <code>AE_DELETED_EVENT_ID</code>，等待下次 <code>aeProcessEvents</code> 执行时将事件清除；</li>
  <li><code>retval != AE_NOMORE</code>：修改当前时间事件的执行时间并重复利用当前的时间事件；</li>
</ul>

<p>以使用 <code>aeCreateTimeEvent</code> 一个创建的简单时间事件为例：</p>

<pre><code class="language-c">aeCreateTimeEvent(config.el,1,showThroughput,NULL,NULL)
</code></pre>

<p>时间事件对应的函数 <code>showThroughput</code> 在每次执行时会返回一个数字，也就是该事件发生的时间间隔：</p>

<pre><code class="language-c">int showThroughput(struct aeEventLoop *eventLoop, long long id, void *clientData) {
    ...
    float dt = (float)(mstime()-config.start)/1000.0;
    float rps = (float)config.requests_finished/dt;
    printf("%s: %.2f\r", config.title, rps);
    fflush(stdout);
    return 250; /* every 250ms */
}
</code></pre>

<p>这样就不需要重新 <code>malloc</code> 一块相同大小的内存，提高了时间事件处理的性能，并减少了内存的使用量。</p>

<p>我们对 Redis 中对时间事件的处理以流程图的形式简单总结一下：</p>

<p><img src="https://img.nju520.me/2016-12-09-process-time-event.png-1000width" alt="process-time-event" /></p>

<p>创建时间事件的方法实现其实非常简单，在这里不想过多分析这个方法，唯一需要注意的就是时间事件的 <code>id</code> 跟数据库中的大多数主键都是递增的：</p>

<pre><code class="language-c">long long aeCreateTimeEvent(aeEventLoop *eventLoop, long long milliseconds,
        aeTimeProc *proc, void *clientData,
        aeEventFinalizerProc *finalizerProc) {
    long long id = eventLoop-&gt;timeEventNextId++;
    aeTimeEvent *te;

    te = zmalloc(sizeof(*te));
    if (te == NULL) return AE_ERR;
    te-&gt;id = id;
    aeAddMillisecondsToNow(milliseconds,&amp;te-&gt;when_sec,&amp;te-&gt;when_ms);
    te-&gt;timeProc = proc;
    te-&gt;finalizerProc = finalizerProc;
    te-&gt;clientData = clientData;
    te-&gt;next = eventLoop-&gt;timeEventHead;
    eventLoop-&gt;timeEventHead = te;
    return id;
}
</code></pre>

<h2 id="事件的处理">事件的处理</h2>

<blockquote>
  <p>上一章节我们已经从代码的角度对 Redis 中事件的处理有一定的了解，在这里，我想从更高的角度来观察 Redis 对于事件的处理是怎么进行的。</p>
</blockquote>

<p>整个 Redis 服务在启动之后会陷入一个巨大的 while 循环，不停地执行 <code>processEvents</code> 方法处理文件事件 fe 和时间事件 te 。</p>

<blockquote>
  <p>有关 Redis 中的 I/O 多路复用模块可以看这篇文章 <a href="http://nju520.me/redis-io-multiplexing/">Redis 和 I/O 多路复用</a>。</p>
</blockquote>

<p>当文件事件触发时会被标记为 “红色” 交由 <code>processEvents</code> 方法处理，而时间事件的处理都会交给 <code>processTimeEvents</code> 这一子方法：</p>

<p><img src="https://img.nju520.me/2016-12-09-redis-eventloop-proces-event.png-1000width" alt="redis-eventloop-proces-event" /></p>

<p>在每个事件循环中 Redis 都会先处理文件事件，然后再处理时间事件直到整个循环停止，<code>processEvents</code> 和 <code>processTimeEvents</code> 作为 Redis 中发生事件的消费者，每次都会从“事件池”中拉去待处理的事件进行消费。</p>

<h3 id="文件事件的处理">文件事件的处理</h3>

<p>由于文件事件触发条件较多，并且 OS 底层实现差异性较大，底层的 I/O 多路复用模块使用了 <code>eventLoop-&gt;aeFiredEvent</code> 保存对应的文件描述符以及事件，将信息传递给上层进行处理，并抹平了底层实现的差异。</p>

<p>整个 I/O 多路复用模块在事件循环看来就是一个输入事件、输出 <code>aeFiredEvent</code> 数组的一个黑箱：</p>

<p><img src="https://img.nju520.me/2016-12-09-eventloop-file-event-in-redis.png-1000width" alt="eventloop-file-event-in-redis" /></p>

<p>在这个黑箱中，我们使用 <code>aeCreateFileEvent</code>、 <code>aeDeleteFileEvent</code> 来添加删除需要监听的文件描述符以及事件。</p>

<p>在对应事件发生时，当前单元格会“变色”表示发生了可读（黄色）或可写（绿色）事件，调用 <code>aeApiPoll</code> 时会把对应的文件描述符和事件放入 <code>aeFiredEvent</code> 数组，并在 <code>processEvents</code> 方法中执行事件对应的回调。</p>

<h3 id="时间事件的处理">时间事件的处理</h3>

<p>时间事件的处理相比文件事件就容易多了，每次 <code>processTimeEvents</code> 方法调用时都会对整个 <code>timeEventHead</code> 数组进行遍历：</p>

<p><img src="https://img.nju520.me/2016-12-09-process-time-events-in-redis.png-1000width" alt="process-time-events-in-redis" /></p>

<p>遍历的过程中会将时间的触发时间与当前时间比较，然后执行时间对应的 <code>timeProc</code>，并根据 <code>timeProc</code> 的返回值修改当前事件的参数，并在下一个循环的遍历中移除不再执行的时间事件。</p>

<h2 id="总结">总结</h2>

<blockquote>
  <p>笔者对于文章中两个模块的展示顺序考虑了比较久的时间，最后还是觉得，目前这样的顺序更易于理解。</p>
</blockquote>

<p>Redis 对于事件的处理方式十分精巧，通过传入函数指针以及返回值的方式，将时间事件移除的控制权交给了需要执行的处理器 <code>timeProc</code>，在 <code>processTimeEvents</code> 设置 <code>aeApiPoll</code> 超时时间也十分巧妙，充分地利用了每一次事件循环，防止过多的无用的空转，并且保证了该方法不会阻塞太长时间。</p>

<p>事件循环的机制并不能时间事件准确地在某一个时间点一定执行，往往会比实际约定处理的时间稍微晚一些。</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://redis.io/topics/internals-rediseventlib">Redis Event Library</a></li>
  <li><a href="http://key-value-stories.blogspot.com/2015/01/redis-core-implementation.html">Redis Core Implementation</a></li>
  <li><a href="http://nju520.me/redis-io-multiplexing/">Redis 和 I/O 多路复用</a></li>
  <li><a href="http://redisbook.com">Redis 设计与实现</a></li>
</ul>

<h2 id="其它">其它</h2>

<blockquote>

  <p>Source: http://nju520.me/redis-eventloop</p>
</blockquote>

  ]]></description>
</item>

<item>
  <title>Redis 和 I/O 多路复用</title>
  <link>//redis-io-multiplexing</link>
  <author>nju520</author>
  <pubDate>2016-11-26T14:07:18+08:00</pubDate>
  <guid>//redis-io-multiplexing</guid>
  <description><![CDATA[
  <p>最近在看 UNIX 网络编程并研究了一下 Redis 的实现，感觉 Redis 的源代码十分适合阅读和分析，其中 I/O 多路复用（mutiplexing）部分的实现非常干净和优雅，在这里想对这部分的内容进行简单的整理。</p>

<h2 id="几种-io-模型">几种 I/O 模型</h2>

<p>为什么 Redis 中要使用 I/O 多路复用这种技术呢？</p>

<p>首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 <strong>I/O 多路复用</strong>就是为了解决这个问题而出现的。</p>

<h3 id="blocking-io">Blocking I/O</h3>

<p>先来看一下传统的阻塞 I/O 模型到底是如何工作的：当使用 <code>read</code> 或者 <code>write</code> 对某一个<strong>文件描述符（File Descriptor 以下简称 FD)</strong>进行读写时，如果当前 FD 不可读或不可写，整个 Redis 服务就不会对其它的操作作出响应，导致整个服务不可用。</p>

<p>这也就是传统意义上的，也就是我们在编程中使用最多的阻塞模型：</p>

<p><img src="https://img.nju520.me/2016-11-26-blocking-io.png-1000width" alt="blocking-io" /></p>

<p>阻塞模型虽然开发中非常常见也非常易于理解，但是由于它会影响其他 FD 对应的服务，所以在需要处理多个客户端任务的时候，往往都不会使用阻塞模型。</p>

<h3 id="io-多路复用">I/O 多路复用</h3>

<blockquote>
  <p>虽然还有很多其它的 I/O 模型，但是在这里都不会具体介绍。</p>
</blockquote>

<p>阻塞式的 I/O 模型并不能满足这里的需求，我们需要一种效率更高的 I/O 模型来支撑 Redis 的多个客户（redis-cli），这里涉及的就是 I/O 多路复用模型了：</p>

<p><img src="https://img.nju520.me/2016-11-26-I:O-Multiplexing-Model.png-1000width" alt="I:O-Multiplexing-Mode" /></p>

<p>在 I/O 多路复用模型中，最重要的函数调用就是 <code>select</code>，该方法的能够同时监控多个文件描述符的可读可写情况，当其中的某些文件描述符可读或者可写时，<code>select</code> 方法就会返回可读以及可写的文件描述符个数。</p>

<blockquote>
  <p>关于 <code>select</code> 的具体使用方法，在网络上资料很多，这里就不过多展开介绍了；</p>

  <p>与此同时也有其它的 I/O 多路复用函数 <code>epoll/kqueue/evport</code>，它们相比 <code>select</code> 性能更优秀，同时也能支撑更多的服务。</p>
</blockquote>

<h2 id="reactor-设计模式">Reactor 设计模式</h2>

<p>Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符）</p>

<p><img src="https://img.nju520.me/2016-11-26-redis-reactor-pattern.png-1000width" alt="redis-reactor-pattern" /></p>

<p>文件事件处理器使用 I/O 多路复用模块同时监听多个 FD，当 <code>accept</code>、<code>read</code>、<code>write</code> 和 <code>close</code> 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器。</p>

<p>虽然整个文件事件处理器是在单线程上运行的，但是通过 I/O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，提高了网络通信模型的性能，同时也可以保证整个 Redis 服务实现的简单。</p>

<h2 id="io-多路复用模块">I/O 多路复用模块</h2>

<p>I/O 多路复用模块封装了底层的 <code>select</code>、<code>epoll</code>、<code>avport</code> 以及 <code>kqueue</code> 这些 I/O 多路复用函数，为上层提供了相同的接口。</p>

<p><img src="https://img.nju520.me/2016-11-26-ae-module.jpg-1000width" alt="ae-module" /></p>

<p>在这里我们简单介绍 Redis 是如何包装 <code>select</code> 和 <code>epoll</code> 的，简要了解该模块的功能，整个 I/O 多路复用模块抹平了不同平台上 I/O 多路复用函数的差异性，提供了相同的接口：</p>

<ul>
  <li><code>static int  aeApiCreate(aeEventLoop *eventLoop)</code></li>
  <li><code>static int  aeApiResize(aeEventLoop *eventLoop, int setsize)</code></li>
  <li><code>static void aeApiFree(aeEventLoop *eventLoop)</code></li>
  <li><code>static int  aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask)</code></li>
  <li><code>static void aeApiDelEvent(aeEventLoop *eventLoop, int fd, int mask) </code></li>
  <li><code>static int  aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp)</code></li>
</ul>

<p>同时，因为各个函数所需要的参数不同，我们在每一个子模块内部通过一个 <code>aeApiState</code> 来存储需要的上下文信息：</p>

<pre><code class="language-c">// select
typedef struct aeApiState {
    fd_set rfds, wfds;
    fd_set _rfds, _wfds;
} aeApiState;

// epoll
typedef struct aeApiState {
    int epfd;
    struct epoll_event *events;
} aeApiState;
</code></pre>

<p>这些上下文信息会存储在 <code>eventLoop</code> 的 <code>void *state</code> 中，不会暴露到上层，只在当前子模块中使用。</p>

<h3 id="封装-select-函数">封装 select 函数</h3>

<blockquote>
  <p><code>select</code> 可以监控 FD 的可读、可写以及出现错误的情况。</p>
</blockquote>

<p>在介绍 I/O 多路复用模块如何对 <code>select</code> 函数封装之前，先来看一下 <code>select</code> 函数使用的大致流程：</p>

<pre><code class="language-c">int fd = /* file descriptor */

fd_set rfds;
FD_ZERO(&amp;rfds);
FD_SET(fd, &amp;rfds)

for ( ; ; ) {
    select(fd+1, &amp;rfds, NULL, NULL, NULL);
    if (FD_ISSET(fd, &amp;rfds)) {
        /* file descriptor `fd` becomes readable */
    }
}
</code></pre>

<ol>
  <li>初始化一个可读的 <code>fd_set</code> 集合，保存需要监控可读性的 FD；</li>
  <li>使用 <code>FD_SET</code> 将 <code>fd</code> 加入 <code>rfds</code>；</li>
  <li>调用 <code>select</code> 方法监控 <code>rfds</code> 中的 FD 是否可读；</li>
  <li>当 <code>select</code> 返回时，检查 FD 的状态并完成对应的操作。</li>
</ol>

<p>而在 Redis 的 <code>ae_select</code> 文件中代码的组织顺序也是差不多的，首先在 <code>aeApiCreate</code> 函数中初始化 <code>rfds</code> 和 <code>wfds</code>：</p>

<pre><code class="language-c">static int aeApiCreate(aeEventLoop *eventLoop) {
    aeApiState *state = zmalloc(sizeof(aeApiState));
    if (!state) return -1;
    FD_ZERO(&amp;state-&gt;rfds);
    FD_ZERO(&amp;state-&gt;wfds);
    eventLoop-&gt;apidata = state;
    return 0;
}
</code></pre>

<p>而 <code>aeApiAddEvent</code> 和 <code>aeApiDelEvent</code> 会通过 <code>FD_SET</code> 和 <code>FD_CLR</code> 修改 <code>fd_set</code> 中对应 FD 的标志位：</p>

<pre><code class="language-c">static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) {
    aeApiState *state = eventLoop-&gt;apidata;
    if (mask &amp; AE_READABLE) FD_SET(fd,&amp;state-&gt;rfds);
    if (mask &amp; AE_WRITABLE) FD_SET(fd,&amp;state-&gt;wfds);
    return 0;
}
</code></pre>

<p>整个 <code>ae_select</code> 子模块中最重要的函数就是 <code>aeApiPoll</code>，它是实际调用 <code>select</code> 函数的部分，其作用就是在 I/O 多路复用函数返回时，将对应的 FD 加入 <code>aeEventLoop</code> 的 <code>fired</code> 数组中，并返回事件的个数：</p>

<pre><code class="language-c">static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) {
    aeApiState *state = eventLoop-&gt;apidata;
    int retval, j, numevents = 0;

    memcpy(&amp;state-&gt;_rfds,&amp;state-&gt;rfds,sizeof(fd_set));
    memcpy(&amp;state-&gt;_wfds,&amp;state-&gt;wfds,sizeof(fd_set));

    retval = select(eventLoop-&gt;maxfd+1,
                &amp;state-&gt;_rfds,&amp;state-&gt;_wfds,NULL,tvp);
    if (retval &gt; 0) {
        for (j = 0; j &lt;= eventLoop-&gt;maxfd; j++) {
            int mask = 0;
            aeFileEvent *fe = &amp;eventLoop-&gt;events[j];

            if (fe-&gt;mask == AE_NONE) continue;
            if (fe-&gt;mask &amp; AE_READABLE &amp;&amp; FD_ISSET(j,&amp;state-&gt;_rfds))
                mask |= AE_READABLE;
            if (fe-&gt;mask &amp; AE_WRITABLE &amp;&amp; FD_ISSET(j,&amp;state-&gt;_wfds))
                mask |= AE_WRITABLE;
            eventLoop-&gt;fired[numevents].fd = j;
            eventLoop-&gt;fired[numevents].mask = mask;
            numevents++;
        }
    }
    return numevents;
}
</code></pre>

<h3 id="封装-epoll-函数">封装 epoll 函数</h3>

<p>Redis 对 <code>epoll</code> 的封装其实也是类似的，使用 <code>epoll_create</code> 创建 <code>epoll</code> 中使用的 <code>epfd</code>：</p>

<pre><code class="language-c">static int aeApiCreate(aeEventLoop *eventLoop) {
    aeApiState *state = zmalloc(sizeof(aeApiState));

    if (!state) return -1;
    state-&gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-&gt;setsize);
    if (!state-&gt;events) {
        zfree(state);
        return -1;
    }
    state-&gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */
    if (state-&gt;epfd == -1) {
        zfree(state-&gt;events);
        zfree(state);
        return -1;
    }
    eventLoop-&gt;apidata = state;
    return 0;
}
</code></pre>

<p>在 <code>aeApiAddEvent</code> 中使用 <code>epoll_ctl</code> 向 <code>epfd</code> 中添加需要监控的 FD 以及监听的事件：</p>

<pre><code class="language-c">static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) {
    aeApiState *state = eventLoop-&gt;apidata;
    struct epoll_event ee = {0}; /* avoid valgrind warning */
    /* If the fd was already monitored for some event, we need a MOD
     * operation. Otherwise we need an ADD operation. */
    int op = eventLoop-&gt;events[fd].mask == AE_NONE ?
            EPOLL_CTL_ADD : EPOLL_CTL_MOD;

    ee.events = 0;
    mask |= eventLoop-&gt;events[fd].mask; /* Merge old events */
    if (mask &amp; AE_READABLE) ee.events |= EPOLLIN;
    if (mask &amp; AE_WRITABLE) ee.events |= EPOLLOUT;
    ee.data.fd = fd;
    if (epoll_ctl(state-&gt;epfd,op,fd,&amp;ee) == -1) return -1;
    return 0;
}
</code></pre>

<p>由于 <code>epoll</code> 相比 <code>select</code> 机制略有不同，在 <code>epoll_wait</code> 函数返回时并不需要遍历所有的 FD 查看读写情况；在 <code>epoll_wait</code> 函数返回时会提供一个 <code>epoll_event</code> 数组：</p>

<pre><code class="language-c">typedef union epoll_data {
    void    *ptr;
    int      fd; /* 文件描述符 */
    uint32_t u32;
    uint64_t u64;
} epoll_data_t;

struct epoll_event {
    uint32_t     events; /* Epoll 事件 */
    epoll_data_t data;
};
</code></pre>

<blockquote>
  <p>其中保存了发生的 <code>epoll</code> 事件（<code>EPOLLIN</code>、<code>EPOLLOUT</code>、<code>EPOLLERR</code> 和 <code>EPOLLHUP</code>）以及发生该事件的 FD。</p>
</blockquote>

<p><code>aeApiPoll</code> 函数只需要将 <code>epoll_event</code> 数组中存储的信息加入 <code>eventLoop</code> 的 <code>fired</code> 数组中，将信息传递给上层模块：</p>

<pre><code class="language-c">static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) {
    aeApiState *state = eventLoop-&gt;apidata;
    int retval, numevents = 0;

    retval = epoll_wait(state-&gt;epfd,state-&gt;events,eventLoop-&gt;setsize,
            tvp ? (tvp-&gt;tv_sec*1000 + tvp-&gt;tv_usec/1000) : -1);
    if (retval &gt; 0) {
        int j;

        numevents = retval;
        for (j = 0; j &lt; numevents; j++) {
            int mask = 0;
            struct epoll_event *e = state-&gt;events+j;

            if (e-&gt;events &amp; EPOLLIN) mask |= AE_READABLE;
            if (e-&gt;events &amp; EPOLLOUT) mask |= AE_WRITABLE;
            if (e-&gt;events &amp; EPOLLERR) mask |= AE_WRITABLE;
            if (e-&gt;events &amp; EPOLLHUP) mask |= AE_WRITABLE;
            eventLoop-&gt;fired[j].fd = e-&gt;data.fd;
            eventLoop-&gt;fired[j].mask = mask;
        }
    }
    return numevents;
}
</code></pre>

<h3 id="子模块的选择">子模块的选择</h3>

<p>因为 Redis 需要在多个平台上运行，同时为了最大化执行的效率与性能，所以会根据编译平台的不同选择不同的 I/O 多路复用函数作为子模块，提供给上层统一的接口；在 Redis 中，我们通过宏定义的使用，合理的选择不同的子模块：</p>

<pre><code class="language-c">#ifdef HAVE_EVPORT
#include "ae_evport.c"
#else
    #ifdef HAVE_EPOLL
    #include "ae_epoll.c"
    #else
        #ifdef HAVE_KQUEUE
        #include "ae_kqueue.c"
        #else
        #include "ae_select.c"
        #endif
    #endif
#endif
</code></pre>

<p>因为 <code>select</code> 函数是作为 POSIX 标准中的系统调用，在不同版本的操作系统上都会实现，所以将其作为保底方案：</p>

<p><img src="https://img.nju520.me/2016-11-26-redis-choose-io-function.jpg-1000width" alt="redis-choose-io-function" /></p>

<p>Redis 会优先选择时间复杂度为 $O(1)$ 的 I/O 多路复用函数作为底层实现，包括 Solaries 10 中的 <code>evport</code>、Linux 中的 <code>epoll</code> 和 macOS/FreeBSD 中的 <code>kqueue</code>，上述的这些函数都使用了内核内部的结构，并且能够服务几十万的文件描述符。</p>

<p>但是如果当前编译环境没有上述函数，就会选择 <code>select</code> 作为备选方案，由于其在使用时会扫描全部监听的描述符，所以其时间复杂度较差 $O(n)$，并且只能同时服务 1024 个文件描述符，所以一般并不会以 <code>select</code> 作为第一方案使用。</p>

<h2 id="总结">总结</h2>

<p>Redis 对于 I/O 多路复用模块的设计非常简洁，通过宏保证了 I/O 多路复用模块在不同平台上都有着优异的性能，将不同的 I/O 多路复用函数封装成相同的 API 提供给上层使用。</p>

<p>整个模块使 Redis 能以单进程运行的同时服务成千上万个文件描述符，避免了由于多进程应用的引入导致代码实现复杂度的提升，减少了出错的可能性。</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="http://man7.org/linux/man-pages/man2/select.2.html">Select-Man-Pages</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Reactor_pattern">Reactor-Pattern</a></li>
  <li><a href="https://people.eecs.berkeley.edu/~sangjin/2012/12/21/epoll-vs-kqueue.html">epoll vs kqueue</a></li>
</ul>

<h2 id="其它">其它</h2>

<blockquote>

  <p>Source: http://nju520.me/redis-io-multiplexing</p>
</blockquote>

  ]]></description>
</item>


  </channel>
</rss>
