<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    
    <title>nju520.me</title>
    
    <link>http://localhost:4000</link>
    <description>nju520's Blog</description>
    <language>en-uk</language>
    <managingEditor> nju520</managingEditor>
    <atom:link href="rss" rel="self" type="application/rss+xml" />
    
<item>
  <title>谈元编程与表达能力</title>
  <link>//metaprogramming</link>
  <author>nju520</author>
  <pubDate>2017-12-10T00:00:00+08:00</pubDate>
  <guid>//metaprogramming</guid>
  <description><![CDATA[
  <p>在这篇文章中，作者会介绍不同的编程语言如何增强自身的表达能力，在写这篇文章的时候其实就已经想到这可能不是一篇有着较多受众和读者的文章。不过作者仍然想跟各位读者分享一下对不同编程语言的理解，同时也对自己的知识体系进行简单的总结。</p>

<p><img src="https://img.nju520.me/2017-12-10-metaprogramming.png" alt="metaprogramming" /></p>

<p>当我们刚刚开始学习和了解编程这门手艺或者说技巧时，一切的知识与概念看起来都非常有趣，随着学习的深入和对语言的逐渐了解，我们可能会发现原来看起来无所不能的编程语言成为了我们的限制，尤其是在我们想要使用一些<strong>元编程</strong>技巧的时候，你会发现有时候语言限制了我们的能力，我们只能一遍一遍地写重复的代码来解决本可以轻松搞定的问题。</p>

<h2 id="元编程">元编程</h2>

<p>元编程（Metaprogramming）是计算机编程中一个非常重要、有趣的概念，<a href="https://en.wikipedia.org/wiki/Metaprogramming">维基百科</a> 上将元编程描述成一种计算机程序可以<strong>将代码看待成数据</strong>的能力。</p>

<blockquote>
  <p>Metaprogramming is a programming technique in which computer programs have the ability to treat programs as their data.</p>
</blockquote>

<p>如果能够将代码看做数据，那么代码就可以像数据一样在运行时被修改、更新和替换；元编程赋予了编程语言更加强大的表达能力，能够让我们将一些计算过程从运行时挪到编译时、通过编译期间的展开生成代码或者允许程序在运行时改变自身的行为。</p>

<p><img src="https://img.nju520.me/2017-12-10-metaprogramming-usage.png" alt="metaprogramming-usage" /></p>

<p>总而言之，<strong>元编程其实是一种使用代码生成代码的方式</strong>，无论是编译期间生成代码，还是在运行时改变代码的行为都是『生成代码』的一种，下面的代码其实就可以看作一种最简单的元编程技巧：</p>

<pre><code class="language-c">int main() {
    for(int i = 0; i &lt; 10; i++) {
        char *echo = (char*)malloc(6 * sizeof(char));
        sprintf(echo, "echo %d", i);
        system(echo);
    }
    return 0;
}
</code></pre>

<p>这里的代码其实等价于执行了以下的 shell 脚本，也可以说这里使用了 C 语言的代码生成来生成 shell 脚本：</p>

<pre><code class="language-shell">echo 0
echo 1
...
echo 9
</code></pre>

<h2 id="编译时和运行时">编译时和运行时</h2>

<p>现代的编程语言大都会为我们提供不同的元编程能力，从总体来看，根据『生成代码』的时机不同，我们将元编程能力分为两种类型，其中一种是编译期间的元编程，例如：宏和模板；另一种是运行期间的元编程，也就是运行时，它赋予了编程语言在运行期间修改行为的能力，当然也有一些特性既可以在编译期实现，也可以在运行期间实现。</p>

<p><img src="https://img.nju520.me/2017-12-10-compile-and-execute.png" alt="compile-and-execute" /></p>

<p>不同的语言对于泛型就有不一样的实现，Java 的泛型就是在编译期间实现的，它的泛型其实是伪泛型，在编译期间所有的泛型就会被编译器擦除（type erasure），生成的 Java 字节码是不包含任何的泛型信息的，但是 C# 对于泛型就有着不同的实现了，它的泛型类型在运行时进行替换，为实例化的对象保留了泛型的类型信息。</p>

<blockquote>
  <p>C++ 的模板其实与这里讨论的泛型有些类似，它会为每一个具体类型生成一份独立的代码，而 Java 的泛型只会生成一份经过类型擦除后的代码，总而言之 C++ 的模板完全是在编译期间实现的，而 Java 的泛型是编译期间和运行期间协作产生的；模板和泛型虽然非常类似，但是在这里提到的模板大都特指 C++ 的模板，而泛型这一概念其实包含了 C++ 的模板。</p>
</blockquote>

<p>虽然泛型和模板为各种编程语言提供了非常强大的表达能力，但是在这篇文章中，我们会介绍另外两种元编程能力：<em>宏</em>和<em>运行时</em>，前者是在编译期间完成的，而后者是在代码运行期间才发生的。</p>

<h2 id="宏macro">宏（Macro）</h2>

<p>宏是很多编程语言具有的特性之一，它是一个将输入的字符串映射成其他字符串的过程，这个映射的过程也被我们称作宏展开。</p>

<p><img src="https://img.nju520.me/2017-12-10-macro-expansion.png" alt="macro-expansion" /></p>

<p>宏其实就是一个在编译期间中定义的展开过程，通过预先定义好的宏，我们可以使用少量的代码完成更多的逻辑和工作，能够减少应用程序中大量的重复代码。</p>

<p>很多编程语言，尤其是编译型语言都实现了宏这个特性，包括 C、Elixir 和 Rust，然而这些语言却使用了不同的方式来实现宏；我们在这里会介绍两种不同的宏，一种是基于文本替换的宏，另一种是基于语法的宏。</p>

<p><img src="https://img.nju520.me/2017-12-10-different-kinds-of-macros.png" alt="different-kinds-of-macros" /></p>

<p>C、C++ 等语言使用基于文本替换的宏，而类似于 Elixir、Rust 等语言的宏系统其实都是基于语法树和语法元素的，它的实现会比前者复杂很多，应用也更加广泛。</p>

<p>在这一节的剩余部分，我们会分别介绍 C、Elixir 和 Rust 三种不同的编程语言实现的宏系统，它们的使用方法、适用范围和优缺点。</p>

<h3 id="c">C</h3>

<p>作者相信很多工程师入门使用的编程语言其实都是 C 语言，而 C 语言的宏系统看起来还是相对比较简单的，虽然在实际使用时会遇到很多非常诡异的问题。C 语言的宏使用的就是文本替换的方式，所有的宏其实并不是通过编译器展开的，而是由预编译器来处理的。</p>

<p><img src="https://img.nju520.me/2017-12-10-preprocessor.png" alt="preprocesso" /></p>

<p>编译器 GCC 根据『长相』将 C 语言中的宏分为两种，其中的一种宏与编程语言中定义变量非常类似：</p>

<pre><code class="language-c">#define BUFFER_SIZE 1024

char *foo = (char *)malloc(BUFFER_SIZE);
char *foo = (char *)malloc(1024);
</code></pre>

<p>这些宏的定义就是一个简单的标识符，它们会在预编译的阶段被预编译器替换成定义后半部分出现的<strong>字符</strong>，这种宏定义其实比较类似于变量的声明，我们经常会使用这种宏定义替代一些无意义的数字，能够让程序变得更容易理解。</p>

<p>另一种宏定义就比较像对函数的定义了，与其他 C 语言的函数一样，这种宏在定义时也会包含一些宏的参数：</p>

<pre><code class="language-c">#define plus(a, b) a + b
#define multiply(a, b) a * b
</code></pre>

<p>通过在宏的定义中引入参数，宏定义的内部就可以直接使用对应的标识符引入外界传入的参数，在定义之后我们就可以像使用函数一样使用它们：</p>

<pre><code class="language-c">#define plus(a, b) a + b
#define multiply(a, b) a * b

int main(int argc, const char * argv[]) {
    printf("%d", plus(1, 2));       // =&gt; 3
    printf("%d", multiply(3, 2));   // =&gt; 6
    return 0;
}
</code></pre>

<p>上面使用宏的代码与下面的代码是完全等价的，在预编译阶段之后，上面的代码就会被替换成下面的代码，也就是编译器其实是不负责宏展开的过程：</p>

<pre><code class="language-c">int main(int argc, const char * argv[]) {
    printf("%d", 1 + 2);    // =&gt; 3
    printf("%d", 3 * 2);    // =&gt; 6
    return 0;
}
</code></pre>

<p>宏的作用其实非常强大，基于文本替换的宏能做到很多函数无法做到的事情，比如使用宏根据传入的参数创建类并声明新的方法：</p>

<pre><code class="language-c">#define pickerify(KLASS, PROPERTY) interface \
    KLASS (Night_ ## PROPERTY ## _Picker) \
    @property (nonatomic, copy, setter = dk_set ## PROPERTY ## Picker:) DKColorPicker dk_ ## PROPERTY ## Picker; \
    @end \
    @implementation \
    KLASS (Night_ ## PROPERTY ## _Picker) \
    - (DKColorPicker)dk_ ## PROPERTY ## Picker { \
        return objc_getAssociatedObject(self, @selector(dk_ ## PROPERTY ## Picker)); \
    } \
    - (void)dk_set ## PROPERTY ## Picker:(DKColorPicker)picker { \
        objc_setAssociatedObject(self, @selector(dk_ ## PROPERTY ## Picker), picker, OBJC_ASSOCIATION_COPY_NONATOMIC); \
        [self setValue:picker(self.dk_manager.themeVersion) forKeyPath:@keypath(self, PROPERTY)];\
        NSMutableDictionary *pickers = [self valueForKeyPath:@"pickers"];\
        [pickers setValue:[picker copy] forKey:_DKSetterWithPROPERTYerty(@#PROPERTY)]; \
    } \
    @end

@pickerify(Button, backgroundColor);
</code></pre>

<p>上面的代码是我在一个 iOS 的开源库 <a href="https://github.com/nju520/DKNightVersion/blob/master/DKNightVersion/DKNightVersion.h#L57-L72">DKNightVersion</a> 中使用的代码，通过宏的文本替换功能，我们在这里创建了类、属性并且定义了属性的 getter/setter 方法，然而使用者对此其实是一无所知的。</p>

<p>C 语言中的宏只是提供了一些文本替换的功能再加上一些高级的 API，虽然它非常强大，但是强大的事物都是一把双刃剑，再加上 C 语言的宏从实现原理上就有一些无法避免的缺陷，所以在使用时还是要非常小心。</p>

<p>由于预处理器只是对宏进行替换，并没有做任何的语法检查，所以在宏出现问题时，编译器的报错往往会让我们摸不到头脑，不知道哪里出现了问题，还需要脑内对宏进行展开分析出现错误的原因；除此之外，类似于 <code>multiply(1+2, 3)</code> 的展开问题导致人和机器对于同一段代码的理解偏差，作者相信也广为人知了；更高级一些的<strong>分号吞噬</strong>、<strong>参数的重复调用</strong>以及<strong>递归引用时不会递归展开</strong>等问题其实在这里也不想多谈。</p>

<pre><code class="language-c">multiply(1+2, 3) // #=&gt; 1+2 * 3
</code></pre>

<h4 id="卫生宏">卫生宏</h4>

<p>然而 C 语言宏的实现导致的另一个问题却是非常严重的：</p>

<pre><code class="language-c">#define inc(i) do { int a = 0; ++i; } while(0)

int main(int argc, const char * argv[]) {
    int a = 4, b = 8;
    inc(a);
    inc(b);
    printf("%d, %d\n", a, b); // =&gt; 4, 9 !!
    return 0;
}
</code></pre>

<blockquote>
  <p>这一小节与卫生宏有关的 C 语言代码取自 <a href="https://en.wikipedia.org/wiki/Hygienic_macro">Hygienic macro</a> 中的代码示例。</p>
</blockquote>

<p>上述代码中的 <code>printf</code> 函数理应打印出 <code>5, 9</code> 然而却打印出了 <code>4, 9</code>，我们来将上述代码中使用宏的部分展开来看一下：</p>

<pre><code class="language-c">int main(int argc, const char * argv[]) {
    int a = 4, b = 8;
    do { int a = 0; ++a; } while(0);
    do { int a = 0; ++b; } while(0);
    printf("%d, %d\n", a, b); // =&gt; 4, 9 !!
    return 0;
}
</code></pre>

<p>这里的 <code>a = 0</code> 按照逻辑应该不发挥任何的作用，但是在这里却覆盖了上下文中 <code>a</code> 变量的值，导致父作用域中变量 <code>a</code> 的值并没有 <code>+1</code>，这其实就是因为 C 语言中实现的宏不是<em>卫生宏</em>（Hygiene macro）。</p>

<p>作者认为卫生宏（Hygiene macro）是一个非常让人困惑的翻译，它其实指一些<strong>在宏展开之后不会意外捕获上下文中标识符的宏</strong>，从定义中我们就可以看到 C 语言中的宏明显不是卫生宏，而接下来要介绍的两种语言的宏系统就实现了卫生宏。</p>

<h3 id="elixir">Elixir</h3>

<p>Elixir 是一门动态的函数式编程语言，它被设计用来构建可扩展、可维护的应用，所有的 Elixir 代码最终都会被编译成二进制文件运行在 Erlang 的虚拟机 Beam 上，构建在 Erlang 上的 Elixir 也继承了很多 Erlang 的优秀特性。然而在这篇文章中并不会展开介绍 Elixir 语言以及它的某些特点和应用，我们只想了解 Elixir 中的宏系统是如何使用和实现的。</p>

<p><img src="https://img.nju520.me/2017-12-10-elixir-logo.png" alt="elixir-logo" /></p>

<p>宏是 Elixir 具有强大表达能力的一个重要原因，通过内置的宏系统可以减少系统中非常多的重复代码，我们可以使用 <code>defmacro</code> 定义一个宏来实现 <code>unless</code> 关键字：</p>

<pre><code class="language-elixir">defmodule Unless do
  defmacro macro_unless(clause, do: expression) do
    quote do
      if(!unquote(clause), do: unquote(expression))
    end
  end
end
</code></pre>

<p>这里的 <code>quote</code> 和 <code>unquote</code> 是宏系统中最重要的两个函数，你可以从字面上理解 <code>quote</code> 其实就是在一段代码的两侧加上双引号，让这段代码变成字符串，而 <code>unquote</code> 会将传入的多个参数的文本<strong>原封不动</strong>的插入到相应的位置，你可以理解为 <code>unquote</code> 只是将 <code>clause</code> 和 <code>expression</code> 代表的字符串当做了返回值。</p>

<pre><code class="language-elixir">Unless.macro_unless true, do: IO.puts "this should never be printed"
</code></pre>

<p>上面的 Elixir 代码在真正执行之前会被替换成一个使用 <code>if</code> 的表达式，我们可以使用下面的方法获得宏展开之后的代码：</p>

<pre><code class="language-elixir">iex&gt; expr = quote do: Unless.macro_unless true, do: IO.puts "this should never be printed"
iex&gt; expr |&gt; Macro.expand_once(__ENV__) |&gt; Macro.to_string |&gt; IO.puts
if(!true) do
  IO.puts("this should never be printed")
end
:ok
</code></pre>

<p>当我们为 <code>quote</code> 函数传入一个表达式的时候，它会将当前的表达式转换成一个抽象语法树：</p>

<pre><code class="language-elixir">{{:., [], [{:__aliases__, [alias: false], [:Unless]}, :macro_unless]}, [],
 [true,
  [do: {{:., [], [{:__aliases__, [alias: false], [:IO]}, :puts]}, [],
    ["this should never be printed"]}]]}
</code></pre>

<p>在 Elixir 中，抽象语法数是可以直接通过下面的 <code>Code.eval_quoted</code> 方法运行：</p>

<pre><code class="language-elixir">iex&gt; Code.eval_quoted [expr]
** (CompileError) nofile:1: you must require Unless before invoking the macro Unless.macro_unless/2
    (elixir) src/elixir_dispatch.erl:97: :elixir_dispatch.dispatch_require/6
    (elixir) lib/code.ex:213: Code.eval_quoted/3
iex&gt; Code.eval_quoted [quote(do: require Unless), expr]
{[Unless, nil], []}
</code></pre>

<p>我们只运行当前的语法树，我们会发现当前的代码由于 <code>Unless</code> 模块没有加载导致宏找不到报错，所以我们在执行 <code>Unless.macro_unless</code> 之前需要先 <code>require</code> 对应的模块。</p>

<p><img src="https://img.nju520.me/2017-12-10-elixir-macro.png" alt="elixir-macro" /></p>

<p>在最开始对当前的宏进行定义时，我们就会发现宏其实输入的是一些语法元素，实现内部也通过 <code>quote</code> 和 <code>unquote</code> 方法对当前的语法树进行修改，最后返回新的语法树：</p>

<pre><code class="language-elixir">defmacro macro_unless(clause, do: expression) do
  quote do
    if(!unquote(clause), do: unquote(expression))
  end
end

iex&gt; expr = quote do: Unless.macro_unless true, do: IO.puts "this should never be printed"
{{:., [], [{:__aliases__, [alias: false], [:Unless]}, :macro_unless]}, [],
 [true,
  [do: {{:., [], [{:__aliases__, [alias: false], [:IO]}, :puts]}, [],
    ["this should never be printed"]}]]}

iex&gt; Macro.expand_once expr, __ENV__
{:if, [context: Unless, import: Kernel],
 [{:!, [context: Unless, import: Kernel], [true]},
  [do: {{:., [],
     [{:__aliases__, [alias: false, counter: -576460752303422687], [:IO]},
      :puts]}, [], ["this should never be printed"]}]]}
</code></pre>

<p>Elixir 中的宏相比于 C 语言中的宏更强大，这是因为它不是对代码中的文本直接进行替换，它能够为我们直接提供操作 Elixir 抽象语法树的能力，让我们能够参与到 Elixir 的编译过程，影响编译的结果；除此之外，Elixir 中的宏还是卫生宏（Hygiene Macro），宏中定义的参数并不会影响当前代码执行的上下文。</p>

<pre><code class="language-elixir">defmodule Example do
  defmacro hygienic do
    quote do
      val = 1
    end
  end
end

iex&gt; val = 42
42
iex&gt; Example.hygienic
1
iex&gt; val
42
</code></pre>

<p>在上述代码中，虽然宏内部的变量与当前环境上下文中的变量重名了，但是宏内部的变量并没有影响上下文中 <code>val</code> 变量的变化，所以 Elixir 中宏系统是『卫生的』，如果我们真的想要改变上下文中的变量，可以使用 <code>var!</code> 来做这件事情：</p>

<pre><code class="language-elixir">defmodule Example do
  defmacro unhygienic do
    quote do
      var!(val) = 2
    end
  end
end

iex&gt; val = 42
42
iex&gt; Example.unhygienic
2
iex&gt; val
2
</code></pre>

<p>相比于使用文本替换的 C 语言宏，Elixir 的宏系统解决了很多问题，例如：卫生宏，不仅如此，Elixir 的宏还允许我们修改当前的代码中的语法树，提供了更加强大的表达能力。</p>

<h3 id="rust">Rust</h3>

<p>Elixir 的宏系统其实已经足够强大了，不止避免了基于文本替换的宏带来的各种问题，我们还可以直接使用宏操作上下文的语法树，作者在一段时间内都觉得 Elixir 的宏系统是接触到的最强大的宏系统，直到开始学习 <a href="https://www.rust-lang.org/en-US/">Rust</a> 才发现更复杂的宏系统。</p>

<p><img src="https://img.nju520.me/2017-12-10-rust-logo.png" alt="rust-logo" /></p>

<p>Rust 是一门非常有趣的编程语言，它是一门有着极高的性能的系统级的编程语言，能够避免当前应用中发生的段错误并且保证线程安全和内存安全，但是这些都不是我们今天想要关注的事情，与 Elixir 一样，在这篇文章中我们仅仅关心 Rust 的宏系统到底是什么样的：</p>

<pre><code class="language-rust">macro_rules! foo {
    (x =&gt; $e:expr) =&gt; (println!("mode X: {}", $e));
    (y =&gt; $e:expr) =&gt; (println!("mode Y: {}", $e));
}
</code></pre>

<p>上面的 Rust 代码定义了一个名为 <code>foo</code> 的宏，我们在代码中需要使用 <code>foo!</code> 来调用上面定义的宏：</p>

<pre><code class="language-rust">fn main() {
    foo!(y =&gt; 3); // =&gt; mode Y: 3
}
</code></pre>

<p>上述的宏 <code>foo</code> 的主体部分其实会将传入的<strong>语法元素</strong>与宏中的条件进行模式匹配，如果匹配到了，就会返回条件右侧的表达式，到这里其实与 Elixir 的宏系统没有太大的区别，Rust 宏相比 Elixir 更强大主要在于其提供了更加灵活的匹配系统，在宏 <code>foo</code> 的定义中使用的 <code>$e:expr</code> 就会匹配一个表达式并将表达式绑定到 <code>$e</code> 这个上下文的变量中，除此之外，在 Rust 中我们还可以组合使用以下的匹配符：</p>

<p><img src="https://img.nju520.me/2017-12-10-rust-macro-matcher-and-example.png" alt="rust-macro-matcher-and-example" /></p>

<p>为了实现功能更强大的宏系统，Rust 的宏还提供了重复操作符和递归宏的功能，结合这两个宏系统的特性，我们能直接使用宏构建一个生成 HTML 的 DSL：</p>

<pre><code class="language-rust">macro_rules! write_html {
    ($w:expr, ) =&gt; (());

    ($w:expr, $e:tt) =&gt; (write!($w, "{}", $e));

    ($w:expr, $tag:ident [ $($inner:tt)* ] $($rest:tt)*) =&gt; {{
        write!($w, "&lt;{}&gt;", stringify!($tag));
        write_html!($w, $($inner)*);
        write!($w, "&lt;/{}&gt;", stringify!($tag));
        write_html!($w, $($rest)*);
    }};
}
</code></pre>

<p>在上述的 <code>write_html</code> 宏中，我们总共有三个匹配条件，其中前两个是宏的终止条件，第一个条件不会做任何的操作，第二个条件会将匹配到的 Token 树求值并写回到传入的字符串引用 <code>$w</code> 中，最后的条件就是最有意思的部分了，在这里我们使用了形如的 <code>$(...)*</code> 语法来<strong>匹配零个或多个相同的语法元素</strong>，例如 <code>$($inner:tt)*</code> 就是匹配零个以上的 Token 树（tt）；在右侧的代码中递归调用了 <code>write_html</code> 宏并分别传入 <code>$($inner)*</code> 和 <code>$($rest)*</code> 两个参数，这样我们的 <code>write_html</code> 就能够解析 DSL 了。</p>

<p>有了 <code>write_html</code> 宏，我们就可以直接使用形如 <code>html[head[title["Macros guide"]]</code> 的代码返回如下所示的 HTML：</p>

<pre><code class="language-html">&lt;html&gt;&lt;head&gt;&lt;title&gt;Macros guide&lt;/title&gt;&lt;/head&gt;&lt;/html&gt;
</code></pre>

<blockquote>
  <p>这一节中提供的与 Rust 宏相关的例子都取自 <a href="https://doc.rust-lang.org/book/first-edition/macros.html">官方文档</a> 中对宏的介绍这一部分内容。</p>
</blockquote>

<p>Rust 的宏系统其实是基于一篇 1986 年的论文 <a href="https://www.cs.indiana.edu/ftp/techreports/TR206.pdf">Macro-by-Example</a> 实现的，如果想要深入了解 Rust 的宏系统可以阅读这篇论文；Rust 的宏系统确实非常完备也足够强大，能够做很多我们使用 C 语言宏时无法做到的事情，极大地提高了语言的表达能力。</p>

<h2 id="运行时runtime">运行时（Runtime）</h2>

<p>宏是一种能在程序执行的预编译或者编译期间改变代码行为的能力，通过编译期的处理过程赋予编程语言元编程能力；而运行时，顾名思义一般是指<strong>面向对象</strong>的编程语言在程序运行的某一个时间的上下文，在这里我们想要介绍的运行时可以理解为<strong>能够在运行期间改变对象行为的机制</strong>。</p>

<p><img src="https://img.nju520.me/2017-12-10-phases.png" alt="phases" /></p>

<p>当相应的行为在当前对象上没有被找到时，运行时会提供一个改变当前对象行为的入口，在篇文章中提到的运行时不是广义上的运行时系统，它特指<strong>面向对象语言在方法决议的过程中为外界提供的入口，让工程师提供的代码也能参与到当前的方法决议和信息发送的过程</strong>。</p>

<p>在这一节中，我们将介绍的两个使用了运行时的面向对象编程语言 Objective-C 和 Ruby，它们有着相似的消息发送的流程，但是由于 OOP 模型实现的不同导致方法调用的过程稍微有一些差别；除此之外，由于 Objective-C 是需要通过编译器编译成二进制文件才能执行的，而 Ruby 可以直接被各种解释器运行，所以两者的元编程能力也会受到这一差别的影响，我们会在下面展开进行介绍。</p>

<h3 id="objective-c">Objective-C</h3>

<p>Objective-C 是一种通用的面向对象编程语言，它将 Smalltalk 消息发送的语法引入了 C 语言；ObjC 语言的面向对象模型其实都是运行在 ObjC Runtime 上的，整个运行时也为 ObjC 提供了方法查找的策略。</p>

<p><img src="https://img.nju520.me/2017-12-10-objc-class-hierachy.png" alt="objc-class-hierachy" /></p>

<p>如上图所示，我们有一个 <code>Dog</code> 类的实例，当我们执行了 <code>dog.wtf</code> 方法时，运行时会先向右再向上的方式在整个继承链中查找相应的方法是否存在，如果当前方法在整个继承链中都完全不存在就会进入<strong>动态方法决议</strong>和<strong>消息转发</strong>的过程。</p>

<p><img src="https://img.nju520.me/2017-12-10-objc-message-resolution-and-forwarding.png" alt="objc-message-resolution-and-forwarding" /></p>

<blockquote>
  <p>上述图片取自 <a href="https://nju520.me/racdelegateproxy">从代理到 RACSignal</a>，使用时对图片中的颜色以及字号稍作修改。</p>
</blockquote>

<p>当 ObjC 的运行时在方法查找的过程中已经查找到了上帝类 <code>NSObject</code> 时，仍然没有找到方法的实现就会进入上面的流程，先执行的 <code>+resolveInstanceMethod:</code> 方法就是一个可以为当前的类添加方法的入口：</p>

<pre><code class="language-objc">void dynamicMethodIMP(id self, SEL _cmd) { }

+ (BOOL)resolveInstanceMethod:(SEL)aSEL {
    if (aSEL == @selector(resolveThisMethodDynamically)) {
          class_addMethod([self class], aSEL, (IMP) dynamicMethodIMP, "v@:");
          return YES;
    }
    return [super resolveInstanceMethod:aSel];
}
</code></pre>

<p>在这里可以通过 <code>class_addMethod</code> 动态的为当前的类添加新的方法和对应的实现，如果错过了这个入口，我们就进入了消息转发的流程；在这里，我们有两种选择，一种情况是通过 <code>-forwardTargetForSelector:</code> 将当前方法的调用直接转发到其他方法上，另一种就是组合 <code>-methodSignatureForSelector:</code> 和 <code>-forwardInvocation:</code> 两个方法，直接执行一个 <code>NSInvocation</code> 对象。</p>

<pre><code class="language-objc">- (void)forwardInvocation:(NSInvocation *)anInvocation {
    if ([someOtherObject respondsToSelector:[anInvocation selector]]) {
        [anInvocation invokeWithTarget:someOtherObject];
    } else {
        [super forwardInvocation:anInvocation];
    }
}
</code></pre>

<p><code>-forwardTargetForSelector:</code> 方法只能简单地将方法直接转发给其他的对象，但是在 <code>-forwardInvocation:</code> 中我们可以得到一个 <code>NSInvocation</code> 实例，可以自由地选择需要执行哪些方法，并修改当前方法调用的上下文，包括：方法名、参数和目标对象。</p>

<p>虽然 Objective-C 的运行时系统能够为我们提供动态方法决议的功能，也就是某一个方法在编译期间哪怕不存在，我们也可以在运行时进行调用，这虽然听起来很不错，在很多时候我们都可以通过 <code>-performSelector:</code> 调用<strong>编译器看起来不存的方法</strong>，但是作为一门执行之前需要编译的语言，如果我们在 <code>+resolveInstanceMethod:</code> 中确实动态实现了一些方法，但是编译器在编译期间对这一切都毫不知情。</p>

<pre><code class="language-objectivec">void dynamicMethodIMP(id self, SEL _cmd) { }
+ (BOOL)resolveInstanceMethod:(SEL)aSEL {
    NSString *selector = NSStringFromSelector(aSEL);
    if ([selector hasPrefix:@"find"]) {
          class_addMethod([self class], aSEL, (IMP) dynamicMethodIMP, "v@:");
          return YES;
    }
    return [super resolveInstanceMethod:aSel];
}

- (void)func {
    [self findFoo];
    [self findBar];
    [self find];
}
</code></pre>

<p>从 <code>-func</code> 中调用的三个以 <code>find</code> 开头的方法其实会在运行期间添加到当前类上，但是编译器在编译期间对此一无所知，所以它会提示编译错误，在编译期间将可以运行的代码拦截了下来，这样的代码如果跳过编译器检查，直接运行是不会出问题的，但是代码的执行必须通过编译器编译，这一过程是无法跳过的。</p>

<p><img src="https://img.nju520.me/2017-12-10-objc-compile-and-execute.png" alt="objc-compile-and-execute" /></p>

<p>我们只能通过 <code>-performSelector:</code> 方法绕过编译器的检查，不过使用 <code>-performSelector:</code> 会为代码添加非常多的噪音：</p>

<pre><code class="language-objectivec">- (void)func {
    [self performSelector:@selector(findFoo)];
    [self performSelector:@selector(findBar)];
    [self performSelector:@selector(find)];
}
</code></pre>

<p>所以虽然 Objective-C 通过运行时提供了比较强大的元编程能力，但是由于代码执行时需要经过编译器的检查，所以在很多时候我们都没有办法直接发挥运行时为我们带来的好处，需要通过其他的方式完成方法的调用。</p>

<h3 id="ruby">Ruby</h3>

<p>除了 Objective-C 之外，Ruby 也提供了一些相似的运行时修改行为的特性，它能够在运行时修改自身特性的功能还是建立在它的 OOP 模型之上；Ruby 提供了一些在运行期间能够改变自身行为的入口和 API 可以帮助我们快速为当前的类添加方法或者实例变量。</p>

<p><img src="https://img.nju520.me/2017-12-10-ruby-class-hierachy.png" alt="ruby-class-hierachy" /></p>

<p>当我们调用 <code>Dog</code> 实例的一个方法时，Ruby 会先找到当前对象的类，然后在由 <code>superclass</code> 构成的链上查找并调用相应的方法，这是 OOP 中非常常见的，<strong>向右再向上</strong>的方法查找过程。</p>

<p>与 Objective-C 几乎相同，Ruby 也提供了类似与 <code>+resolveInstanceMethod:</code> 的方法，如果方法在整个继承链上都完全不存在时，就会调用 <code>#method_missing</code> 方法，并传入与这次方法调用有关的参数：</p>

<pre><code class="language-ruby">def method_missing(method, *args, &amp;block)
end
</code></pre>

<p>传入的参数包括方法的符号，调用原方法时传入的参数和 block，在这里我们就可以为当前的类添加方法了：</p>

<pre><code class="language-ruby">class Dog
  def method_missing(m, *args, &amp;block)
    if m.to_s.start_with? 'find'
      define_singleton_method(m) do |*args|
        puts "#{m}, #{args}"
      end
      send(m, *args, &amp;block)
    else
      super
    end
  end
end
</code></pre>

<p>通过 Ruby 提供的一些 API，例如 <code>define_method</code>、<code>define_singleton_method</code> 我们可以直接在运行期间快速改变对象的行为，在使用时也非常简单：</p>

<pre><code class="language-ruby">pry(main)&gt; d = Dog.new
=&gt; #&lt;Dog:0x007fe31e3f87a8&gt;
pry(main)&gt; d.find_by_name "dog"
find_by_name, ["dog"]
=&gt; nil
pry(main)&gt; d.find_by_name "dog", "another_dog"
find_by_name, ["dog", "another_dog"]
=&gt; nil
</code></pre>

<p>当我们调用以 <code>find</code> 开头的实例方法时，由于在当前实例的类以及父类上没有实现，所以就会进入 <code>#method_missing</code> 方法并为<strong>当前实例</strong>定义新的方法 <code>#find_by_name</code>。</p>

<blockquote>
  <p>注意：当前的 <code>#find_by_name</code> 方法只是定义在当前实例上的，存储在当前实例的单类上。</p>
</blockquote>

<p>由于 Ruby 是脚本语言，解释器在脚本执行之前不会对代码进行检查，所以哪怕在未执行期间并不存在的 <code>#find_by_name</code> 方法也不会导致解释器报错，在运行期间通过 <code>#define_singleton_method</code> 动态地
定义了新的 <code>#find_by_name</code> 方法修改了对象的行为，达到了为对象批量添加相似功能的目的。</p>

<h2 id="总结">总结</h2>

<p>在文章中介绍的两种不同的元编程能力，宏系统和运行时，前者通过预先定义好的一些宏规则，在预编译和编译期间对代码进行展开和替换，而后者提供了在运行期间改变代码行为的能力，两种方式的本质都是通过少量的代码生成一些非常相似的代码和逻辑，能够增强编程语言的表达能力并减少开发者的工作量。</p>

<p>无论是宏还是运行时其实都是简化程序中代码的一种手段，归根结底就是一种使用代码生成代码的思想，如果我们能够掌握这种元编程的思想并在编程中熟练的运用就能够很好地解决程序中一些诡异的问题，还能消灭重复的代码，提高我们运用以及掌控编程语言的能力，能够极大地增强编程语言的表达能力，所以元编程确实是一种非常重要并且需要学习的思想。</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://en.m.wikipedia.org/wiki/Metaprogramming">Metaprogramming</a></li>
  <li><a href="https://docs.microsoft.com/zh-cn/dotnet/csharp/programming-guide/generics/differences-between-cpp-templates-and-csharp-generics">C++ 模板和 C# 泛型之间的区别（C# 编程指南）</a></li>
  <li><a href="https://www.zhihu.com/question/33304378">C++ 模板和 Java 泛型有什么异同？</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Macro_(computer_science)">Macro (computer science)</a></li>
  <li><a href="https://elixir-lang.org/getting-started/meta/macros.html">Macros · Elixir Doc</a></li>
  <li><a href="https://gcc.gnu.org/onlinedocs/cpp/Macros.html">Macros · GCC</a></li>
  <li><a href="http://hbprotoss.github.io/posts/cyu-yan-hong-de-te-shu-yong-fa-he-ji-ge-keng.html">C 语言宏的特殊用法和几个坑</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Hygienic_macro">Hygienic macro</a></li>
  <li><a href="https://elixirschool.com/en/lessons/advanced/metaprogramming/">Metaprogramming · ElixirSchool</a></li>
  <li><a href="https://doc.rust-lang.org/book/first-edition/macros.html">Macros · Rust Doc</a></li>
  <li><a href="https://www.cs.indiana.edu/ftp/techreports/TR206.pdf">Macro-by-Example</a></li>
  <li><a href="https://www.rust-lang.org/en-US/">Rust</a></li>
  <li><a href="https://nju520.me/message">从源代码看 ObjC 中消息的发送</a></li>
  <li><a href="https://developer.apple.com/library/content/documentation/Cocoa/Conceptual/ObjCRuntimeGuide/Articles/ocrtDynamicResolution.html">Dynamic Method Resolution</a></li>
  <li><a href="https://developer.apple.com/library/content/documentation/Cocoa/Conceptual/ObjCRuntimeGuide/Articles/ocrtForwarding.html#//apple_ref/doc/uid/TP40008048-CH105-SW1">Message Forwarding</a></li>
  <li><a href="https://nju520.me/racdelegateproxy">从代理到 RACSignal</a></li>
  <li><a href="https://developer.apple.com/documentation/objectivec/nsobject/1418500-resolveinstancemethod">resolveInstanceMethod(_:)</a></li>
  <li><a href="http://rubylearning.com/satishtalim/ruby_method_missing.html">Ruby Method Missing</a></li>
  <li><a href="https://www.leighhalliday.com/ruby-metaprogramming-method-missing">Ruby Metaprogramming - Method Missing</a></li>
</ul>


  ]]></description>
</item>

<item>
  <title>Docker 核心技术与实现原理</title>
  <link>//docker</link>
  <author>nju520</author>
  <pubDate>2017-11-30T00:00:00+08:00</pubDate>
  <guid>//docker</guid>
  <description><![CDATA[
  <p>提到虚拟化技术，我们首先想到的一定是 Docker，经过四年的快速发展 Docker 已经成为了很多公司的标配，也不再是一个只能在开发阶段使用的玩具了。作为在生产环境中广泛应用的产品，Docker 有着非常成熟的社区以及大量的使用者，代码库中的内容也变得非常庞大。</p>

<p><img src="https://img.nju520.me/2017-11-30-docker-logo.png" alt="docker-logo" /></p>

<p>同样，由于项目的发展、功能的拆分以及各种奇怪的改名 <a href="https://github.com/moby/moby/pull/32691">PR</a>，让我们再次理解 Docker 的的整体架构变得更加困难。</p>

<p>虽然 Docker 目前的组件较多，并且实现也非常复杂，但是本文不想过多的介绍 Docker 具体的实现细节，我们更想谈一谈 Docker 这种虚拟化技术的出现有哪些核心技术的支撑。</p>

<p><img src="https://img.nju520.me/2017-11-30-docker-core-techs.png" alt="docker-core-techs" /></p>

<p>首先，Docker 的出现一定是因为目前的后端在开发和运维阶段确实需要一种虚拟化技术解决开发环境和生产环境环境一致的问题，通过 Docker 我们可以将程序运行的环境也纳入到版本控制中，排除因为环境造成不同运行结果的可能。但是上述需求虽然推动了虚拟化技术的产生，但是如果没有合适的底层技术支撑，那么我们仍然得不到一个完美的产品。本文剩下的内容会介绍几种 Docker 使用的核心技术，如果我们了解它们的使用方法和原理，就能清楚 Docker 的实现原理。</p>

<h2 id="namespaces">Namespaces</h2>

<p>命名空间 (namespaces) 是 Linux 为我们提供的用于分离进程树、网络接口、挂载点以及进程间通信等资源的方法。在日常使用 Linux 或者 macOS 时，我们并没有运行多个完全分离的服务器的需要，但是如果我们在服务器上启动了多个服务，这些服务其实会相互影响的，每一个服务都能看到其他服务的进程，也可以访问宿主机器上的任意文件，这是很多时候我们都不愿意看到的，我们更希望运行在同一台机器上的不同服务能做到<strong>完全隔离</strong>，就像运行在多台不同的机器上一样。</p>

<p><img src="https://img.nju520.me/2017-11-30-multiple-servers-on-linux.png" alt="multiple-servers-on-linux" /></p>

<p>在这种情况下，一旦服务器上的某一个服务被入侵，那么入侵者就能够访问当前机器上的所有服务和文件，这也是我们不想看到的，而 Docker 其实就通过 Linux 的 Namespaces 对不同的容器实现了隔离。</p>

<p>Linux 的命名空间机制提供了以下七种不同的命名空间，包括 <code>CLONE_NEWCGROUP</code>、<code>CLONE_NEWIPC</code>、<code>CLONE_NEWNET</code>、<code>CLONE_NEWNS</code>、<code>CLONE_NEWPID</code>、<code>CLONE_NEWUSER</code> 和 <code>CLONE_NEWUTS</code>，通过这七个选项我们能在创建新的进程时设置新进程应该在哪些资源上与宿主机器进行隔离。</p>

<h3 id="进程">进程</h3>

<p>进程是 Linux 以及现在操作系统中非常重要的概念，它表示一个正在执行的程序，也是在现代分时系统中的一个任务单元。在每一个 *nix 的操作系统上，我们都能够通过 <code>ps</code> 命令打印出当前操作系统中正在执行的进程，比如在 Ubuntu 上，使用该命令就能得到以下的结果：</p>

<pre><code class="language-shell">$ ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 Apr08 ?        00:00:09 /sbin/init
root         2     0  0 Apr08 ?        00:00:00 [kthreadd]
root         3     2  0 Apr08 ?        00:00:05 [ksoftirqd/0]
root         5     2  0 Apr08 ?        00:00:00 [kworker/0:0H]
root         7     2  0 Apr08 ?        00:07:10 [rcu_sched]
root        39     2  0 Apr08 ?        00:00:00 [migration/0]
root        40     2  0 Apr08 ?        00:01:54 [watchdog/0]
...
</code></pre>

<p>当前机器上有很多的进程正在执行，在上述进程中有两个非常特殊，一个是 <code>pid</code> 为 1 的 <code>/sbin/init</code> 进程，另一个是 <code>pid</code> 为 2 的 <code>kthreadd</code> 进程，这两个进程都是被 Linux 中的上帝进程 <code>idle</code> 创建出来的，其中前者负责执行内核的一部分初始化工作和系统配置，也会创建一些类似 <code>getty</code> 的注册进程，而后者负责管理和调度其他的内核进程。</p>

<p><img src="https://img.nju520.me/2017-11-30-linux-processes.png" alt="linux-processes" /></p>

<p>如果我们在当前的 Linux 操作系统下运行一个新的 Docker 容器，并通过 <code>exec</code> 进入其内部的 <code>bash</code> 并打印其中的全部进程，我们会得到以下的结果：</p>

<pre><code class="language-shell">root@iZ255w13cy6Z:~# docker run -it -d ubuntu
b809a2eb3630e64c581561b08ac46154878ff1c61c6519848b4a29d412215e79
root@iZ255w13cy6Z:~# docker exec -it b809a2eb3630 /bin/bash
root@b809a2eb3630:/# ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 15:42 pts/0    00:00:00 /bin/bash
root         9     0  0 15:42 pts/1    00:00:00 /bin/bash
root        17     9  0 15:43 pts/1    00:00:00 ps -ef
</code></pre>

<p>在新的容器内部执行 <code>ps</code> 命令打印出了非常干净的进程列表，只有包含当前 <code>ps -ef</code> 在内的三个进程，在宿主机器上的几十个进程都已经消失不见了。</p>

<p>当前的 Docker 容器成功将容器内的进程与宿主机器中的进程隔离，如果我们在宿主机器上打印当前的全部进程时，会得到下面三条与 Docker 相关的结果：</p>

<pre><code class="language-shell">UID        PID  PPID  C STIME TTY          TIME CMD
root     29407     1  0 Nov16 ?        00:08:38 /usr/bin/dockerd --raw-logs
root      1554 29407  0 Nov19 ?        00:03:28 docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --shim docker-containerd-shim --runtime docker-runc
root      5006  1554  0 08:38 ?        00:00:00 docker-containerd-shim b809a2eb3630e64c581561b08ac46154878ff1c61c6519848b4a29d412215e79 /var/run/docker/libcontainerd/b809a2eb3630e64c581561b08ac46154878ff1c61c6519848b4a29d412215e79 docker-runc
</code></pre>

<p>在当前的宿主机器上，可能就存在由上述的不同进程构成的进程树：</p>

<p><img src="https://img.nju520.me/2017-11-30-docker-process-group.png" alt="docker-process-group" /></p>

<p>这就是在使用 <code>clone(2)</code> 创建新进程时传入 <code>CLONE_NEWPID</code> 实现的，也就是使用 Linux 的命名空间实现进程的隔离，Docker 容器内部的任意进程都对宿主机器的进程一无所知。</p>

<pre><code class="language-go">containerRouter.postContainersStart
└── daemon.ContainerStart
    └── daemon.createSpec
        └── setNamespaces
            └── setNamespace
</code></pre>

<p>Docker 的容器就是使用上述技术实现与宿主机器的进程隔离，当我们每次运行 <code>docker run</code> 或者 <code>docker start</code> 时，都会在下面的方法中创建一个用于设置进程间隔离的 Spec：</p>

<pre><code class="language-go">func (daemon *Daemon) createSpec(c *container.Container) (*specs.Spec, error) {
	s := oci.DefaultSpec()

	// ...
	if err := setNamespaces(daemon, &amp;s, c); err != nil {
		return nil, fmt.Errorf("linux spec namespaces: %v", err)
	}

	return &amp;s, nil
}
</code></pre>

<p>在 <code>setNamespaces</code> 方法中不仅会设置进程相关的命名空间，还会设置与用户、网络、IPC 以及 UTS 相关的命名空间：</p>

<pre><code class="language-go">func setNamespaces(daemon *Daemon, s *specs.Spec, c *container.Container) error {
	// user
	// network
	// ipc
	// uts

	// pid
	if c.HostConfig.PidMode.IsContainer() {
		ns := specs.LinuxNamespace{Type: "pid"}
		pc, err := daemon.getPidContainer(c)
		if err != nil {
			return err
		}
		ns.Path = fmt.Sprintf("/proc/%d/ns/pid", pc.State.GetPID())
		setNamespace(s, ns)
	} else if c.HostConfig.PidMode.IsHost() {
		oci.RemoveNamespace(s, specs.LinuxNamespaceType("pid"))
	} else {
		ns := specs.LinuxNamespace{Type: "pid"}
		setNamespace(s, ns)
	}

	return nil
}
</code></pre>

<p>所有命名空间相关的设置 <code>Spec</code> 最后都会作为 <code>Create</code> 函数的入参在创建新的容器时进行设置：</p>

<pre><code class="language-go">daemon.containerd.Create(context.Background(), container.ID, spec, createOptions)
</code></pre>

<p>所有与命名空间的相关的设置都是在上述的两个函数中完成的，Docker 通过命名空间成功完成了与宿主机进程和网络的隔离。</p>

<h3 id="网络">网络</h3>

<p>如果 Docker 的容器通过 Linux 的命名空间完成了与宿主机进程的网络隔离，但是却有没有办法通过宿主机的网络与整个互联网相连，就会产生很多限制，所以 Docker 虽然可以通过命名空间创建一个隔离的网络环境，但是 Docker 中的服务仍然需要与外界相连才能发挥作用。</p>

<p>每一个使用 <code>docker run</code> 启动的容器其实都具有单独的网络命名空间，Docker 为我们提供了四种不同的网络模式，Host、Container、None 和 Bridge 模式。</p>

<p><img src="https://img.nju520.me/2017-11-30-docker-network.png" alt="docker-network" /></p>

<p>在这一部分，我们将介绍 Docker 默认的网络设置模式：网桥模式。在这种模式下，除了分配隔离的网络命名空间之外，Docker 还会为所有的容器设置 IP 地址。当 Docker 服务器在主机上启动之后会创建新的虚拟网桥 docker0，随后在该主机上启动的全部服务在默认情况下都与该网桥相连。</p>

<p><img src="https://img.nju520.me/2017-11-30-docker-network-topology.png" alt="docker-network-topology" /></p>

<p>在默认情况下，每一个容器在创建时都会创建一对虚拟网卡，两个虚拟网卡组成了数据的通道，其中一个会放在创建的容器中，会加入到名为 docker0 网桥中。我们可以使用如下的命令来查看当前网桥的接口：</p>

<pre><code class="language-sh">$ brctl show
bridge name	bridge id		STP enabled	interfaces
docker0		8000.0242a6654980	no		veth3e84d4f
							            veth9953b75
</code></pre>

<p>docker0 会为每一个容器分配一个新的 IP 地址并将 docker0 的 IP 地址设置为默认的网关。网桥 docker0 通过 iptables 中的配置与宿主机器上的网卡相连，所有符合条件的请求都会通过 iptables 转发到 docker0 并由网桥分发给对应的机器。</p>

<pre><code class="language-sh">$ iptables -t nat -L
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
DOCKER     all  --  anywhere             anywhere             ADDRTYPE match dst-type LOCAL

Chain DOCKER (2 references)
target     prot opt source               destination
RETURN     all  --  anywhere             anywhere
</code></pre>

<p>我们在当前的机器上使用 <code>docker run -d -p 6379:6379 redis</code> 命令启动了一个新的 Redis 容器，在这之后我们再查看当前 <code>iptables</code> 的 NAT 配置就会看到在 <code>DOCKER</code> 的链中出现了一条新的规则：</p>

<pre><code class="language-sh">DNAT       tcp  --  anywhere             anywhere             tcp dpt:6379 to:192.168.0.4:6379
</code></pre>

<p>上述规则会将从任意源发送到当前机器 6379 端口的 TCP 包转发到 192.168.0.4:6379 所在的地址上。</p>

<p>这个地址其实也是 Docker 为 Redis 服务分配的 IP 地址，如果我们在当前机器上直接 ping 这个 IP 地址就会发现它是可以访问到的：</p>

<pre><code class="language-sh">$ ping 192.168.0.4
PING 192.168.0.4 (192.168.0.4) 56(84) bytes of data.
64 bytes from 192.168.0.4: icmp_seq=1 ttl=64 time=0.069 ms
64 bytes from 192.168.0.4: icmp_seq=2 ttl=64 time=0.043 ms
^C
--- 192.168.0.4 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 999ms
rtt min/avg/max/mdev = 0.043/0.056/0.069/0.013 ms
</code></pre>

<p>从上述的一系列现象，我们就可以推测出 Docker 是如何将容器的内部的端口暴露出来并对数据包进行转发的了；当有 Docker 的容器需要将服务暴露给宿主机器，就会为容器分配一个 IP 地址，同时向 iptables 中追加一条新的规则。</p>

<p><img src="https://img.nju520.me/2017-11-30-docker-network-forward.png" alt="docker-network-forward" /></p>

<p>当我们使用 <code>redis-cli</code> 在宿主机器的命令行中访问 127.0.0.1:6379 的地址时，经过 iptables 的 NAT PREROUTING 将 ip 地址定向到了 192.168.0.4，重定向过的数据包就可以通过 iptables 中的 FILTER 配置，最终在 NAT POSTROUTING 阶段将 ip 地址伪装成 127.0.0.1，到这里虽然从外面看起来我们请求的是 127.0.0.1:6379，但是实际上请求的已经是 Docker 容器暴露出的端口了。</p>

<pre><code class="language-sh">$ redis-cli -h 127.0.0.1 -p 6379 ping
PONG
</code></pre>

<p>Docker 通过 Linux 的命名空间实现了网络的隔离，又通过 iptables 进行数据包转发，让 Docker 容器能够优雅地为宿主机器或者其他容器提供服务。</p>

<h4 id="libnetwork">libnetwork</h4>

<p>整个网络部分的功能都是通过 Docker 拆分出来的 libnetwork 实现的，它提供了一个连接不同容器的实现，同时也能够为应用给出一个能够提供一致的编程接口和网络层抽象的<strong>容器网络模型</strong>。</p>

<blockquote>
  <p>The goal of libnetwork is to deliver a robust Container Network Model that provides a consistent programming interface and the required network abstractions for applications.</p>
</blockquote>

<p>libnetwork 中最重要的概念，容器网络模型由以下的几个主要组件组成，分别是 Sandbox、Endpoint 和 Network：</p>

<p><img src="https://img.nju520.me/2017-11-30-container-network-model.png" alt="container-network-model" /></p>

<p>在容器网络模型中，每一个容器内部都包含一个 Sandbox，其中存储着当前容器的网络栈配置，包括容器的接口、路由表和 DNS 设置，Linux 使用网络命名空间实现这个 Sandbox，每一个 Sandbox 中都可能会有一个或多个 Endpoint，在 Linux 上就是一个虚拟的网卡 veth，Sandbox 通过 Endpoint 加入到对应的网络中，这里的网络可能就是我们在上面提到的 Linux 网桥或者 VLAN。</p>

<blockquote>
  <p>想要获得更多与 libnetwork 或者容器网络模型相关的信息，可以阅读 <a href="https://github.com/docker/libnetwork/blob/master/docs/design.md">Design · libnetwork</a> 了解更多信息，当然也可以阅读源代码了解不同 OS 对容器网络模型的不同实现。</p>
</blockquote>

<h3 id="挂载点">挂载点</h3>

<p>虽然我们已经通过 Linux 的命名空间解决了进程和网络隔离的问题，在 Docker 进程中我们已经没有办法访问宿主机器上的其他进程并且限制了网络的访问，但是 Docker 容器中的进程仍然能够访问或者修改宿主机器上的其他目录，这是我们不希望看到的。</p>

<p>在新的进程中创建隔离的挂载点命名空间需要在 <code>clone</code> 函数中传入 <code>CLONE_NEWNS</code>，这样子进程就能得到父进程挂载点的拷贝，如果不传入这个参数<strong>子进程对文件系统的读写都会同步回父进程以及整个主机的文件系统</strong>。</p>

<p>如果一个容器需要启动，那么它一定需要提供一个根文件系统（rootfs），容器需要使用这个文件系统来创建一个新的进程，所有二进制的执行都必须在这个根文件系统中。</p>

<p><img src="https://img.nju520.me/2017-11-30-libcontainer-filesystem.png" alt="libcontainer-filesystem" /></p>

<p>想要正常启动一个容器就需要在 rootfs 中挂载以上的几个特定的目录，除了上述的几个目录需要挂载之外我们还需要建立一些符号链接保证系统 IO 不会出现问题。</p>

<p><img src="https://img.nju520.me/2017-11-30-libcontainer-symlinks-and-io.png" alt="libcontainer-symlinks-and-io" /></p>

<p>为了保证当前的容器进程没有办法访问宿主机器上其他目录，我们在这里还需要通过 libcontainer 提供的 <code>pivot_root</code> 或者 <code>chroot</code> 函数改变进程能够访问个文件目录的根节点。</p>

<pre><code class="language-c">// pivor_root
put_old = mkdir(...);
pivot_root(rootfs, put_old);
chdir("/");
unmount(put_old, MS_DETACH);
rmdir(put_old);

// chroot
mount(rootfs, "/", NULL, MS_MOVE, NULL);
chroot(".");
chdir("/");
</code></pre>

<p>到这里我们就将容器需要的目录挂载到了容器中，同时也禁止当前的容器进程访问宿主机器上的其他目录，保证了不同文件系统的隔离。</p>

<blockquote>
  <p>这一部分的内容是作者在 libcontainer 中的 <a href="https://github.com/opencontainers/runc/blob/master/libcontainer/SPEC.md">SPEC.md</a> 文件中找到的，其中包含了 Docker 使用的文件系统的说明，对于 Docker 是否真的使用 <code>chroot</code> 来确保当前的进程无法访问宿主机器的目录，作者其实也<strong>没有确切的答案</strong>，一是 Docker 项目的代码太多庞大，不知道该从何入手，作者尝试通过 Google 查找相关的结果，但是既找到了无人回答的 <a href="https://forums.docker.com/t/does-the-docker-engine-use-chroot/25429">问题</a>，也得到了与 SPEC 中的描述有冲突的 <a href="https://www.quora.com/Do-Docker-containers-use-a-chroot-environment">答案</a> ，如果各位读者有明确的答案可以在博客下面留言，非常感谢。</p>
</blockquote>

<h3 id="chroot">chroot </h3>
<p>在这里不得不简单介绍一下 <code>chroot</code>（change root），在 Linux 系统中，系统默认的目录就都是以 <code>/</code> 也就是根目录开头的，<code>chroot</code> 的使用能够改变当前的系统根目录结构，通过改变当前系统的根目录，我们能够限制用户的权利，在新的根目录下并不能够访问旧系统根目录的结构个文件，也就建立了一个与原系统完全隔离的目录结构。</p>

<blockquote>
  <p>与 chroot 的相关内容部分来自 <a href="https://www.ibm.com/developerworks/cn/linux/l-cn-chroot/index.html">理解 chroot</a> 一文，各位读者可以阅读这篇文章获得更详细的信息。</p>
</blockquote>

<h2 id="cgroups">CGroups</h2>

<p>我们通过 Linux 的命名空间为新创建的进程隔离了文件系统、网络并与宿主机器之间的进程相互隔离，但是命名空间并不能够为我们提供物理资源上的隔离，比如 CPU 或者内存，如果在同一台机器上运行了多个对彼此以及宿主机器一无所知的『容器』，这些容器却共同占用了宿主机器的物理资源。</p>

<p><img src="https://img.nju520.me/2017-11-30-docker-shared-resources.png" alt="docker-shared-resources" /></p>

<p>如果其中的某一个容器正在执行 CPU 密集型的任务，那么就会影响其他容器中任务的性能与执行效率，导致多个容器相互影响并且抢占资源。如何对多个容器的资源使用进行限制就成了解决进程虚拟资源隔离之后的主要问题，而 Control Groups（简称 CGroups）就是能够隔离宿主机器上的物理资源，例如 CPU、内存、磁盘 I/O 和网络带宽。</p>

<p>每一个 CGroup 都是一组被相同的标准和参数限制的进程，不同的 CGroup 之间是有层级关系的，也就是说它们之间可以从父类继承一些用于限制资源使用的标准和参数。</p>

<p><img src="https://img.nju520.me/2017-11-30-cgroups-inheritance.png" alt="cgroups-inheritance" /></p>

<p>Linux 的 CGroup 能够为一组进程分配资源，也就是我们在上面提到的 CPU、内存、网络带宽等资源，通过对资源的分配，CGroup 能够提供以下的几种功能：</p>

<p><img src="https://img.nju520.me/2017-11-30-groups-features.png" alt="groups-features" /></p>

<blockquote>
  <p>在 CGroup 中，所有的任务就是一个系统的一个进程，而 CGroup 就是一组按照某种标准划分的进程，在 CGroup 这种机制中，所有的资源控制都是以 CGroup 作为单位实现的，每一个进程都可以随时加入一个 CGroup 也可以随时退出一个 CGroup。</p>

  <p>– <a href="https://www.ibm.com/developerworks/cn/linux/1506_cgroup/index.html">CGroup 介绍、应用实例及原理描述</a></p>
</blockquote>

<p>Linux 使用文件系统来实现 CGroup，我们可以直接使用下面的命令查看当前的 CGroup 中有哪些子系统：</p>

<pre><code class="language-sh">$ lssubsys -m
cpuset /sys/fs/cgroup/cpuset
cpu /sys/fs/cgroup/cpu
cpuacct /sys/fs/cgroup/cpuacct
memory /sys/fs/cgroup/memory
devices /sys/fs/cgroup/devices
freezer /sys/fs/cgroup/freezer
blkio /sys/fs/cgroup/blkio
perf_event /sys/fs/cgroup/perf_event
hugetlb /sys/fs/cgroup/hugetlb
</code></pre>

<p>大多数 Linux 的发行版都有着非常相似的子系统，而之所以将上面的 cpuset、cpu 等东西称作子系统，是因为它们能够为对应的控制组分配资源并限制资源的使用。</p>

<p>如果我们想要创建一个新的 cgroup 只需要在想要分配或者限制资源的子系统下面创建一个新的文件夹，然后这个文件夹下就会自动出现很多的内容，如果你在 Linux 上安装了 Docker，你就会发现所有子系统的目录下都有一个名为 docker 的文件夹：</p>

<pre><code class="language-shell">$ ls cpu
cgroup.clone_children  
...
cpu.stat  
docker  
notify_on_release 
release_agent 
tasks

$ ls cpu/docker/
9c3057f1291b53fd54a3d12023d2644efe6a7db6ddf330436ae73ac92d401cf1 
cgroup.clone_children  
...
cpu.stat  
notify_on_release 
release_agent 
tasks
</code></pre>

<p><code>9c3057xxx</code> 其实就是我们运行的一个 Docker 容器，启动这个容器时，Docker 会为这个容器创建一个与容器标识符相同的 CGroup，在当前的主机上 CGroup 就会有以下的层级关系：</p>

<p><img src="https://img.nju520.me/2017-11-30-linux-cgroups.png" alt="linux-cgroups" /></p>

<p>每一个 CGroup 下面都有一个 <code>tasks</code> 文件，其中存储着属于当前控制组的所有进程的 pid，作为负责 cpu 的子系统，<code>cpu.cfs_quota_us</code> 文件中的内容能够对 CPU 的使用作出限制，如果当前文件的内容为 50000，那么当前控制组中的全部进程的 CPU 占用率不能超过 50%。</p>

<p>如果系统管理员想要控制 Docker 某个容器的资源使用率就可以在 <code>docker</code> 这个父控制组下面找到对应的子控制组并且改变它们对应文件的内容，当然我们也可以直接在程序运行时就使用参数，让 Docker 进程去改变相应文件中的内容。</p>

<pre><code class="language-shell">$ docker run -it -d --cpu-quota=50000 busybox
53861305258ecdd7f5d2a3240af694aec9adb91cd4c7e210b757f71153cdd274
$ cd 53861305258ecdd7f5d2a3240af694aec9adb91cd4c7e210b757f71153cdd274/
$ ls
cgroup.clone_children  cgroup.event_control  cgroup.procs  cpu.cfs_period_us  cpu.cfs_quota_us  cpu.shares  cpu.stat  notify_on_release  tasks
$ cat cpu.cfs_quota_us
50000
</code></pre>

<p>当我们使用 Docker 关闭掉正在运行的容器时，Docker 的子控制组对应的文件夹也会被 Docker 进程移除，Docker 在使用 CGroup 时其实也只是做了一些创建文件夹改变文件内容的文件操作，不过 CGroup 的使用也确实解决了我们限制子容器资源占用的问题，系统管理员能够为多个容器合理的分配资源并且不会出现多个容器互相抢占资源的问题。</p>

<h2 id="unionfs">UnionFS</h2>

<p>Linux 的命名空间和控制组分别解决了不同资源隔离的问题，前者解决了进程、网络以及文件系统的隔离，后者实现了 CPU、内存等资源的隔离，但是在 Docker 中还有另一个非常重要的问题需要解决 - 也就是镜像。</p>

<p>镜像到底是什么，它又是如何组成和组织的是作者使用 Docker 以来的一段时间内一直比较让作者感到困惑的问题，我们可以使用 <code>docker run</code> 非常轻松地从远程下载 Docker 的镜像并在本地运行。</p>

<p>Docker 镜像其实本质就是一个压缩包，我们可以使用下面的命令将一个 Docker 镜像中的文件导出：</p>

<pre><code class="language-shell">$ docker export $(docker create busybox) | tar -C rootfs -xvf -
$ ls
bin  dev  etc  home proc root sys  tmp  usr  var
</code></pre>

<p>你可以看到这个 busybox 镜像中的目录结构与 Linux 操作系统的根目录中的内容并没有太多的区别，可以说 <strong>Docker 镜像就是一个文件</strong>。</p>

<h3 id="存储驱动">存储驱动</h3>

<p>Docker 使用了一系列不同的存储驱动管理镜像内的文件系统并运行容器，这些存储驱动与 Docker 卷（volume）有些不同，存储引擎管理着能够在多个容器之间共享的存储。</p>

<p>想要理解 Docker 使用的存储驱动，我们首先需要理解 Docker 是如何构建并且存储镜像的，也需要明白 Docker 的镜像是如何被每一个容器所使用的；Docker 中的每一个镜像都是由一系列只读的层组成的，Dockerfile 中的每一个命令都会在已有的只读层上创建一个新的层：</p>

<pre><code class="language-docker">FROM ubuntu:15.04
COPY . /app
RUN make /app
CMD python /app/app.py
</code></pre>

<p>容器中的每一层都只对当前容器进行了非常小的修改，上述的 Dockerfile 文件会构建一个拥有四层 layer 的镜像：</p>

<p><img src="https://img.nju520.me/2017-11-30-docker-container-layer.png" alt="docker-container-laye" /></p>

<p>当镜像被 <code>docker run</code> 命令创建时就会在镜像的最上层添加一个可写的层，也就是容器层，所有对于运行时容器的修改其实都是对这个容器读写层的修改。</p>

<p>容器和镜像的区别就在于，所有的镜像都是只读的，而每一个容器其实等于镜像加上一个可读写的层，也就是同一个镜像可以对应多个容器。</p>

<p><img src="https://img.nju520.me/2017-12-06-docker-images-and-container.png" alt="docker-images-and-container" /></p>

<h3 id="aufs">AUFS</h3>

<p>UnionFS 其实是一种为 Linux 操作系统设计的用于把多个文件系统『联合』到同一个挂载点的文件系统服务。而 AUFS 即 Advanced UnionFS 其实就是 UnionFS 的升级版，它能够提供更优秀的性能和效率。</p>

<p>AUFS 作为联合文件系统，它能够将不同文件夹中的层联合（Union）到了同一个文件夹中，这些文件夹在 AUFS 中称作分支，整个『联合』的过程被称为<em>联合挂载（Union Mount）</em>：</p>

<p><img src="https://img.nju520.me/2017-11-30-docker-aufs.png" alt="docker-aufs" /></p>

<p>每一个镜像层或者容器层都是 <code>/var/lib/docker/</code> 目录下的一个子文件夹；在 Docker 中，所有镜像层和容器层的内容都存储在 <code>/var/lib/docker/aufs/diff/</code> 目录中：</p>

<pre><code class="language-shell">$ ls /var/lib/docker/aufs/diff/00adcccc1a55a36a610a6ebb3e07cc35577f2f5a3b671be3dbc0e74db9ca691c       93604f232a831b22aeb372d5b11af8c8779feb96590a6dc36a80140e38e764d8
00adcccc1a55a36a610a6ebb3e07cc35577f2f5a3b671be3dbc0e74db9ca691c-init  93604f232a831b22aeb372d5b11af8c8779feb96590a6dc36a80140e38e764d8-init
019a8283e2ff6fca8d0a07884c78b41662979f848190f0658813bb6a9a464a90       93b06191602b7934fafc984fbacae02911b579769d0debd89cf2a032e7f35cfa
...
</code></pre>

<p>而 <code>/var/lib/docker/aufs/layers/</code> 中存储着镜像层的元数据，每一个文件都保存着镜像层的元数据，最后的 <code>/var/lib/docker/aufs/mnt/</code> 包含镜像或者容器层的挂载点，最终会被 Docker 通过联合的方式进行组装。</p>

<p><img src="https://img.nju520.me/2017-11-30-docker-filesystems.png" alt="docker-filesystems" /></p>

<p>上面的这张图片非常好的展示了组装的过程，每一个镜像层都是建立在另一个镜像层之上的，同时所有的镜像层都是只读的，只有每个容器最顶层的容器层才可以被用户直接读写，所有的容器都建立在一些底层服务（Kernel）上，包括命名空间、控制组、rootfs 等等，这种容器的组装方式提供了非常大的灵活性，只读的镜像层通过共享也能够减少磁盘的占用。</p>

<h3 id="其他存储驱动">其他存储驱动</h3>

<p>AUFS 只是 Docker 使用的存储驱动的一种，除了 AUFS 之外，Docker 还支持了不同的存储驱动，包括 <code>aufs</code>、<code>devicemapper</code>、<code>overlay2</code>、<code>zfs</code> 和 <code>vfs</code> 等等，在最新的 Docker 中，<code>overlay2</code> 取代了 <code>aufs</code> 成为了推荐的存储驱动，但是在没有 <code>overlay2</code> 驱动的机器上仍然会使用 <code>aufs</code> 作为 Docker 的默认驱动。</p>

<p><img src="https://img.nju520.me/2017-11-30-docker-storage-driver.png" alt="docker-storage-driver" /></p>

<p>不同的存储驱动在存储镜像和容器文件时也有着完全不同的实现，有兴趣的读者可以在 Docker 的官方文档 <a href="https://docs.docker.com/engine/userguide/storagedriver/selectadriver/">Select a storage driver</a> 中找到相应的内容。</p>

<p>想要查看当前系统的 Docker 上使用了哪种存储驱动只需要使用以下的命令就能得到相对应的信息：</p>

<pre><code class="language-shell">$ docker info | grep Storage
Storage Driver: aufs
</code></pre>

<p>作者的这台 Ubuntu 上由于没有 <code>overlay2</code> 存储驱动，所以使用 <code>aufs</code> 作为 Docker 的默认存储驱动。</p>

<h2 id="总结">总结</h2>

<p>Docker 目前已经成为了非常主流的技术，已经在很多成熟公司的生产环境中使用，但是 Docker 的核心技术其实已经有很多年的历史了，Linux 命名空间、控制组和 UnionFS 三大技术支撑了目前 Docker 的实现，也是 Docker 能够出现的最重要原因。</p>

<p>作者在学习 Docker 实现原理的过程中查阅了非常多的资料，从中也学习到了很多与 Linux 操作系统相关的知识，不过由于 Docker 目前的代码库实在是太过庞大，想要从源代码的角度完全理解 Docker 实现的细节已经是非常困难的了，但是如果各位读者真的对其实现细节感兴趣，可以从 <a href="https://github.com/docker/docker-ce">Docker CE</a> 的源代码开始了解 Docker 的原理。</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://www.safaribooksonline.com/library/view/using-docker/9781491915752/ch04.html">Chapter 4. Docker Fundamentals · Using Docker by Adrian Mount</a></li>
  <li><a href="https://washraf.gitbooks.io/the-docker-ecosystem/content/Chapter%201/Section%203/techniques_behind_docker.html">TECHNIQUES BEHIND DOCKER</a></li>
  <li><a href="https://docs.docker.com/engine/docker-overview/#the-underlying-technology">Docker overview</a></li>
  <li><a href="https://lwn.net/Articles/312641/">Unifying filesystems with union mounts</a></li>
  <li><a href="https://coolshell.cn/articles/17061.html">DOCKER 基础技术：AUFS</a></li>
  <li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/">RESOURCE MANAGEMENT GUIDE</a></li>
  <li><a href="http://www.linuxjournal.com/article/7714">Kernel Korner - Unionfs: Bringing Filesystems Together</a></li>
  <li><a href="https://lwn.net/Articles/325369/">Union file systems: Implementations, part I</a></li>
  <li><a href="https://blog.docker.com/2016/05/docker-unikernels-open-source/">IMPROVING DOCKER WITH UNIKERNELS: INTRODUCING HYPERKIT, VPNKIT AND DATAKIT</a></li>
  <li><a href="https://www.toptal.com/linux/separation-anxiety-isolating-your-system-with-linux-namespaces">Separation Anxiety: A Tutorial for Isolating Your System with Linux Namespaces</a></li>
  <li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-chroot/index.html">理解 chroot</a></li>
  <li><a href="http://www.yolinux.com/TUTORIALS/LinuxTutorialInitProcess.html">Linux Init Process / PC Boot Procedure</a></li>
  <li><a href="http://www.infoq.com/cn/articles/docker-network-and-pipework-open-source-explanation-practice#">Docker 网络详解及 pipework 源码解读与实践</a></li>
  <li><a href="https://docs.docker.com/engine/userguide/networking/default_network/container-communication/#communication-between-containers">Understand container communication</a></li>
  <li><a href="https://github.com/docker/labs/blob/master/networking/concepts/05-bridge-networks.md">Docker Bridge Network Driver Architecture</a></li>
  <li><a href="http://www.thegeekstuff.com/2011/01/iptables-fundamentals/">Linux Firewall Tutorial: IPTables Tables, Chains, Rules Fundamentals</a></li>
  <li><a href="http://www.iptables.info/en/structure-of-iptables.html">Traversing of tables and chains</a></li>
  <li><a href="http://dockone.io/article/1255">Docker 网络部分执行流分析（Libnetwork 源码解读）</a></li>
  <li><a href="https://github.com/docker/libnetwork/blob/master/docs/design.md">Libnetwork Design</a></li>
  <li><a href="http://www.infoq.com/cn/articles/analysis-of-docker-file-system-aufs-and-devicemapper">剖析 Docker 文件系统：Aufs与Devicemapper</a></li>
  <li><a href="https://stackoverflow.com/questions/22889241/linux-understanding-the-mount-namespace-clone-clone-newns-flag">Linux - understanding the mount namespace &amp; clone CLONE_NEWNS flag</a></li>
  <li><a href="http://www.infoq.com/cn/articles/docker-kernel-knowledge-namespace-resource-isolation">Docker 背后的内核知识 —— Namespace 资源隔离</a></li>
  <li><a href="https://linuxcontainers.org">Infrastructure for container projects</a></li>
  <li><a href="https://github.com/opencontainers/runc/blob/master/libcontainer/SPEC.md">Spec · libcontainer</a></li>
  <li><a href="https://coolshell.cn/articles/17010.html">DOCKER 基础技术：LINUX NAMESPACE（上）</a></li>
  <li><a href="https://coolshell.cn/articles/17049.html">DOCKER 基础技术：LINUX CGROUP</a></li>
  <li><a href="https://yq.aliyun.com/articles/65034">《自己动手写Docker》书摘之三： Linux UnionFS</a></li>
  <li><a href="http://www.programering.com/a/MDMzAjMwATk.html">Introduction to Docker</a></li>
  <li><a href="https://docs.docker.com/v1.9/engine/userguide/storagedriver/imagesandcontainers/">Understand images, containers, and storage drivers</a></li>
  <li><a href="https://docs.docker.com/engine/userguide/storagedriver/aufs-driver/#configure-docker-with-the-aufs-storage-driver">Use the AUFS storage driver</a></li>
</ul>


  ]]></description>
</item>

<item>
  <title>Ruby Web 服务器的并发模型与性能</title>
  <link>//ruby-webserver</link>
  <author>nju520</author>
  <pubDate>2017-11-17T00:00:00+08:00</pubDate>
  <guid>//ruby-webserver</guid>
  <description><![CDATA[
  <ul>
  <li><a href="https://nju520.me/rack">谈谈 Rack 协议与实现</a></li>
  <li><a href="https://nju520.me/rack-webrick">浅谈 WEBrick 的多线程模型</a></li>
  <li><a href="https://nju520.me/rack-thin">浅谈 Thin 的事件驱动模型</a></li>
  <li><a href="https://nju520.me/rack-unicorn">浅谈 Unicorn 的多进程模型</a></li>
  <li><a href="https://nju520.me/rack-puma">浅谈 Puma 的并发模型与实现</a></li>
  <li><a href="https://nju520.me/ruby-webserver">Ruby Web 服务器的并发模型与性能</a></li>
</ul>

<p>这是整个 Rack 系列文章的最后一篇了，在之前其实也尝试写过很多系列文章，但是到最后都因为各种原因放弃了，最近由于自己对 Ruby 的 webserver 非常感兴趣，所以看了下社区中常见 webserver 的实现原理，包括 WEBrick、Thin、Unicorn 和 Puma，虽然在 Ruby 社区中也有一些其他的 webserver 有着比较优异的性能，但是在这有限的文章中也没有办法全都介绍一遍。</p>

<p><img src="https://img.nju520.me/2017-11-17-webservers.png" alt="webservers" /></p>

<p>在这篇文章中，作者想对 Ruby 社区中不同 webserver 的实现原理和并发模型进行简单的介绍，总结一下前面几篇文章中的内容。</p>

<blockquote>
  <p>文中所有的压力测试都是在内存 16GB、8 CPU、2.6 GHz Intel Core i7 的 macOS 上运行的，如果你想要复现这里的测试可能不会得到完全相同的结果。</p>
</blockquote>

<h2 id="webrick">WEBrick</h2>

<p>WEBrick 是 Ruby 社区中非常古老的 Web 服务器，从 2000 年到现在已经有了将近 20 年的历史了，虽然 WEBrick 有着非常多的问题，但是迄今为止 WEBrick 也是开发环境中最常用的 Ruby 服务器；它使用了最为简单、直接的并发模型，运行一个 WEBrick 服务器只会在后台启动一个进程，默认监听来自 9292 端口的请求。</p>

<p><img src="https://img.nju520.me/2017-11-17-webrick-concurrency-model.png" alt="webrick-concurrency-model" /></p>

<p>当 WEBrick 通过 <code>.select</code> 方法监听到来自客户端的请求之后，会为每一个请求创建一个单独 <code>Thread</code> 并在新的线程中处理 HTTP 请求。</p>

<pre><code class="language-ruby">run Proc.new { |env| ['200', {'Content-Type' =&gt; 'text/plain'}, ['get rack\'d']] }
</code></pre>
<p>如果我们如果创建一个最简单的 Rack 应用，直接返回所有的 HTTP 响应，那么使用下面的命令对 WEBrick 的服务器进行测试会得到如下的结果：</p>

<pre><code class="language-shell">Concurrency Level:      100
Time taken for tests:   22.519 seconds
Complete requests:      10000
Failed requests:        0
Total transferred:      2160000 bytes
HTML transferred:       200000 bytes
Requests per second:    444.07 [#/sec] (mean)
Time per request:       225.189 [ms] (mean)
Time per request:       2.252 [ms] (mean, across all concurrent requests)
Transfer rate:          93.67 [Kbytes/sec] received
</code></pre>

<p>在处理 ApacheBench 发出的 10000 个 HTTP 请求时，WEBrick 对于每个请求平均消耗了 225.189ms，每秒处理了 444.07 个请求；除此之外，在处理请求的过程中 WEBrick 进程的 CPU 占用率很快达到了 100%，通过这个测试我们就可以看出为什么不应该在生产环境中使用 WEBrick 作为 Ruby 的应用服务器，在业务逻辑和代码更加复杂的情况下，WEBrick 的性能想必也不会达到期望。</p>

<h2 id="thin">Thin</h2>

<p>在 2006 和 2007 两年，Ruby 社区中发布了两个至今都非常重要的开源项目，其中一个是 Mongrel，它提供了标准的 HTTP 接口，同时多语言的支持也使得 Mongrel 在当时非常流行，另一个项目就是 Rack 了，它在 Web 应用和 Web 服务器之间建立了一套统一的 <a href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=rack+spec&amp;ie=UTF-8&amp;oe=UTF-8">标准</a>，规定了两者的协作方式，所有的应用只要遵循 Rack 协议就能够随时替换底层的应用服务器。</p>

<p><img src="https://img.nju520.me/2017-11-17-rack-protocol.png" alt="rack-protoco" /></p>

<p>随后，在 2009 年出现的 Thin 就站在了巨人的肩膀上，同时遵循了 Rack 协议并使用了 Mongrel 中的解析器，而它也是 Ruby 社区中第一个使用 Reactor 模型的 Web 服务器。</p>

<p><img src="https://img.nju520.me/2017-11-17-thin-concurrency-model.png" alt="thin-concurrency-model" /></p>

<p>Thin 使用 Reactor 模型处理客户端的 HTTP 请求，每一个请求都会交由 EventMachine，通过内部对事件的分发，最终执行相应的回调，这种事件驱动的 IO 模型与 node.js 非常相似，使用单进程单线程的并发模型却能够快速处理 HTTP 请求；在这里，我们仍然使用 ApacheBench 以及同样的负载对 Thin 的性能进行简单的测试。</p>

<pre><code class="language-shell">Concurrency Level:      100
Time taken for tests:   4.221 seconds
Complete requests:      10000
Failed requests:        0
Total transferred:      880000 bytes
HTML transferred:       100000 bytes
Requests per second:    2368.90 [#/sec] (mean)
Time per request:       42.214 [ms] (mean)
Time per request:       0.422 [ms] (mean, across all concurrent requests)
Transfer rate:          203.58 [Kbytes/sec] received
</code></pre>

<p>对于一个相同的 HTTP 请求，Thin 的吞吐量大约是 WEBrick 的四倍，每秒能够处理 2368.90 个请求，同时处理的速度也大幅降低到了 42.214ms；在压力测试的过程中虽然 CPU 占用率有所上升但是在处理的过程中完全没有超过 90%，可以说 Thin 的性能碾压了 WEBrick，这可能也是开发者都不会在生产环境中使用 WEBrick 的最重要原因。</p>

<p>但是同样作为单进程运行的 Thin，由于没有 master 进程的存在，哪怕当前进程由于各种各样奇怪的原因被操作系统杀掉，我们也不会收到任何的通知，只能手动重启应用服务器。</p>

<h2 id="unicorn">Unicorn</h2>

<p>与 Thin 同年发布的 Unicorn 虽然也是 Mongrel 项目的一个 fork，但是使用了完全不同的并发模型，每Unicorn 内部通过多次 <code>fork</code> 创建多个 worker 进程，所有的 worker 进程也都由一个 master 进程管理和控制：</p>

<p><img src="https://img.nju520.me/2017-11-17-unicorn-master-workers.png" alt="unicorn-master-workers" /></p>

<p>由于 master 进程的存在，当 worker 进程被意外杀掉后会被 master 进程重启，能够保证持续对外界提供服务，多个进程的 worker 也能够很好地压榨多核 CPU 的性能，尽可能地提高请求的处理速度。</p>

<p><img src="https://img.nju520.me/2017-11-17-unicorn-concurrency-model.png" alt="unicorn-concurrency-model" /></p>

<p>一组由 master 管理的 Unicorn worker 会监听绑定的两个 Socket，所有来自客户端的请求都会通过操作系统内部的负载均衡进行调度，将请求分配到不同的 worker 进程上进行处理。</p>

<p>不过由于 Unicorn 虽然使用了多进程的并发模型，但是每个 worker 进程在处理请求时都是用了阻塞 I/O 的方式，所以如果客户端非常慢就会大大影响 Unicorn 的性能，不过这个问题就可以通过反向代理来 nginx 解决。</p>

<p><img src="https://img.nju520.me/2017-11-17-unicorn-multi-processes.png" alt="unicorn-multi-processes" /></p>

<p>在配置 Unicorn 的 worker 数时，为了最大化的利用 CPU 资源，往往会将进程数设置为 CPU 的数量，同样我们使用 ApacheBench 以及相同的负载测试一个使用 8 核 CPU 的 Unicorn 服务的处理效率：</p>

<pre><code class="language-shell">Concurrency Level:      100
Time taken for tests:   2.401 seconds
Complete requests:      10000
Failed requests:        0
Total transferred:      1110000 bytes
HTML transferred:       100000 bytes
Requests per second:    4164.31 [#/sec] (mean)
Time per request:       24.014 [ms] (mean)
Time per request:       0.240 [ms] (mean, across all concurrent requests)
Transfer rate:          451.41 [Kbytes/sec] received
</code></pre>

<p>经过简单的压力测试，当前的一组 Unicorn 服务每秒能够处理 4000 多个请求，每个请求也只消耗了 24ms 的时间，比起使用单进程的 Thin 确实有着比较多的提升，但是并没有数量级的差距。</p>

<p>除此之外，Unicorn 由于其多进程的实现方式会占用大量的内存，在并行的处理大量请求时你可以看到内存的使用量有比较明显的上升。</p>

<h2 id="puma">Puma</h2>

<p>距离 Ruby 社区的第一个 webserver WEBrick 发布的 11 年之后的 2011 年，Puma 正式发布了，它与 Thin 和 Unicorn 一样都从 Mongrel 中继承了 HTTP 协议的解析器，不仅如此它还基于 Rack 协议重新对底层进行了实现。</p>

<p><img src="https://img.nju520.me/2017-11-17-puma-cluster-mode.png" alt="puma-cluster-mode" /></p>

<p>与 Unicorn 不同的是，Puma 是用了多进程加多线程模型，它可以同时在 fork 出来的多个 worker 中创建多个线程来处理请求；不仅如此 Puma 还实现了用于提高并发速度的 Reactor 模块和线程池能够在提升吞吐量的同时，降低内存的消耗。</p>

<p><img src="https://img.nju520.me/2017-11-17-puma-concurrency-model.png" alt="puma-concurrency-mode" /></p>

<p>但是由于 MRI 的存在，往往都需要使用 JRuby 才能最大化 Puma 服务器的性能，但是即便如此，使用 MRI 的 Puma 的吞吐量也能够轻松达到 Unicorn 的两倍。</p>

<pre><code class="language-shell">Concurrency Level:      100
Time taken for tests:   1.057 seconds
Complete requests:      10000
Failed requests:        0
Total transferred:      750000 bytes
HTML transferred:       100000 bytes
Requests per second:    9458.08 [#/sec] (mean)
Time per request:       10.573 [ms] (mean)
Time per request:       0.106 [ms] (mean, across all concurrent requests)
Transfer rate:          692.73 [Kbytes/sec] received
</code></pre>

<p>在这里我们创建了 8 个 Puma 的 worker，每个 worker 中都包含 16~32 个用于处理用户请求的线程，每秒中处理的请求数接近 10000，处理时间也仅为 10.573ms，多进程、多线程以及 Reactor 模式的协作确实能够非常明显的增加 Web 服务器的工作性能和吞吐量。</p>

<p>在 Puma 的 <a href="http://puma.io">官方网站</a> 中，有一张不同 Web 服务器内存消耗的对比图：</p>

<p><img src="https://img.nju520.me/2017-11-17-memory-usage-comparision.png" alt="memory-usage-comparision" /></p>

<p>我们可以看到，与 Unicorn 相比 Puma 的内存使用量几乎可以忽略不计，它明显解决了多个 worker 占用大量内存的问题；不过使用了多线程模型的 Puma 需要开发者在应用中保证不同的线程不会出现竞争条件的问题，Unicorn 的多进程模型就不需要开发者思考这样的事情。</p>

<h2 id="对比">对比</h2>

<p>上述四种不同的 Web 服务器其实有着比较明显的性能差异，在使用同一个最简单的 Web 应用时，不同的服务器表现出了差异巨大的吞吐量：</p>

<p><img src="https://img.nju520.me/2017-11-17-ruby-webservers.jpeg" alt="ruby-webservers" /></p>

<p>Puma 和 Unicorn 两者之间可能还没有明显的数量级差距，1 倍的吞吐量差距也可能很容易被环境因素抹平了，但是 WEBrick 可以说是绝对无法与其他三者匹敌的。</p>

<p>上述的不同服务器其实有着截然不同的 I/O 并发模型，因为 MRI 中 GIL 的存在我们很难利用多核 CPU 的计算资源，所以大多数多线程模型在 MRI 上的性能可能只比单线程略好，达不到完全碾压的效果，但是 JRuby 或者 Rubinius 的使用确实能够利用多核 CPU 的计算资源，从而增加多线程模型的并发效率。</p>

<p><img src="https://img.nju520.me/2017-11-17-jruby.png" alt="jruby" /></p>

<p>传统的 I/O 模型就是在每次接收到客户端的请求时 fork 出一个新的进程来处理当前的请求或者在服务器启动时就启动多个进程，每一个进程在同一时间只能处理一个请求，所以这种并发模型的吞吐量有限，在今天已经几乎看不到使用 <strong>accept &amp; fork</strong> 这种方式处理请求的服务器了。</p>

<p>目前最为流行的方式还是混合多种 I/O 模型，同时使用多进程和多线程压榨 CPU 计算资源，例如 Phusion Passenger 或者 Puma 都支持在单进程和多进程、单线程和多线程之前来回切换，配置的不同会创建不同的并发模型，可以说是 Web 服务器中最好的选择了。</p>

<p>最后要说的 Thin 其实使用了非常不同的 I/O 模型，也就是事件驱动模型，这种模型在 Ruby 社区其实并没有那么热门，主要是因为 Rails 框架以及 Ruby 社区中的大部分项目并没有按照 Reactor 模型的方式进行设计，默认的文件 I/O 也都是阻塞的，而 Ruby 本身也可以利用多进程和多线程的计算资源，没有必要使用事件驱动的方式最大化并发量。</p>

<p><img src="https://img.nju520.me/2017-11-17-nodejs-logo.jpg" alt="nodejs-logo" /></p>

<p>Node.js 就完全不同了。Javascript 作为一个所有操作都会阻塞主线程的语言，更加需要事件驱动模型让主线程只负责接受 HTTP 请求，其余的脏活累活都交给线程池来做了，结果的返回都通过回调的形式通知主线程，这样才能提高吞吐量。</p>

<h2 id="总结">总结</h2>

<p>在这个系列的文章中，我们先后介绍了 Rack 的实现原理以及 Rack 协议，还有四种 webserver 包括 WEBrick、Thin、Unicorn 和 Puma 的实现，除了这四种应用服务器之外，Ruby 社区中还有其他的应用服务器，例如：Rainbows 和 Phusion Passenger，它们都有各自的实现以及优缺点。</p>

<p>从当前的情况来看，还是更推荐开发者使用 Puma 或者 Phusion Passenger 作为应用的服务器，这样能获得最佳的效果。</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://read01.com/zh-hk/zm5B.html#.Wf0oLduB0sk">Ruby Web 服务器：这十五年</a></li>
  <li><a href="https://ruby-china.org/topics/25276">Ruby 服务器对比</a></li>
  <li><a href="https://ruby-china.org/topics/10832">Ruby 的多线程应用服务器介绍</a></li>
  <li><a href="https://stackoverflow.com/questions/4113299/ruby-on-rails-server-options">Ruby on Rails Server options</a></li>
</ul>


  ]]></description>
</item>

<item>
  <title>浅谈 Puma 的并发模型与实现</title>
  <link>//rack-puma</link>
  <author>nju520</author>
  <pubDate>2017-11-10T00:00:00+08:00</pubDate>
  <guid>//rack-puma</guid>
  <description><![CDATA[
  <ul>
  <li><a href="https://nju520.me/rack">谈谈 Rack 协议与实现</a></li>
  <li><a href="https://nju520.me/rack-webrick">浅谈 WEBrick 的多线程模型</a></li>
  <li><a href="https://nju520.me/rack-thin">浅谈 Thin 的事件驱动模型</a></li>
  <li><a href="https://nju520.me/rack-unicorn">浅谈 Unicorn 的多进程模型</a></li>
  <li><a href="https://nju520.me/rack-puma">浅谈 Puma 的并发模型与实现</a></li>
  <li><a href="https://nju520.me/ruby-webserver">Ruby Web 服务器的并发模型与性能</a></li>
</ul>

<p>这篇文章已经是整个 Rack 系列文章的第五篇了，在前面的文章中我们见到了多线程模型、多进程模型以及事件驱动的 I/O 模型，对于几种常见的 webserver 已经很了解了，其实无论是 Ruby 还是其他社区对于 webserver 的实现也就是这么几种方式：多线程、多线程和 Reactor。</p>

<p><img src="https://img.nju520.me/2017-11-10-puma-logo.png" alt="puma-logo" /></p>

<p>在这篇文章中要介绍的 Puma 只是混合了两种 I/O 模型，同时使用多进程和多线程来提高应用的并行能力。</p>

<blockquote>
  <p>文中使用的 Puma 版本是 v3.10.0，如果你使用了不同版本的 Puma，原理上的区别不会太大，只是在一些方法的实现上会有一些细微的不同。</p>
</blockquote>

<h2 id="rack-默认处理器">Rack 默认处理器</h2>

<p>Puma 是目前 Rack 中优先级最高的默认 webserver，如果直接使用 <code>rackup</code> 命令并且当前机器上安装了 <code>puma</code>，那么 Rack 会自动选择 Puma 作为当前处理 HTTP 请求的服务器：</p>

<pre><code class="language-ruby">def self.default
  pick ['puma', 'thin', 'webrick']
end

$ rackup
Puma starting in single mode...
* Version 3.10.0 (ruby 2.3.3-p222), codename: Russell's Teapot
* Min threads: 0, max threads: 16
* Environment: development
* Listening on tcp://localhost:9292
Use Ctrl-C to stop
</code></pre>

<p>通过在 <code>Rack::Handler</code> 下创建一个新的 <code>module Puma</code> 再实现类方法 <code>.run</code>，我们就可以直接将启动的过程转交给 <code>Puma::Launcher</code> 处理：</p>

<pre><code class="language-ruby">module Rack
  module Handler
    module Puma
      def self.run(app, options = {})
        conf   = self.config(app, options)
        events = options.delete(:Silent) ? ::Puma::Events.strings : ::Puma::Events.stdio
        launcher = ::Puma::Launcher.new(conf, :events =&gt; events)

        yield launcher if block_given?
        begin
          launcher.run
        rescue Interrupt
          puts "* Gracefully stopping, waiting for requests to finish"
          launcher.stop
          puts "* Goodbye!"
        end
      end
    end
  end
end
</code></pre>

<h2 id="启动器-launcher">启动器 Launcher</h2>

<p>Puma 中的启动器确实没有做太多的工作，大部分的代码其实都是在做配置，从 <code>ENV</code> 和上下文的环境中读取参数，而整个初始化方法中需要注意的地方也只有不同 <code>@runner</code> 的初始化了：</p>

<pre><code class="language-ruby">From: lib/puma/launcher.rb @ line 44:
Owner: Puma::Launcher

def initialize(conf, launcher_args={})
  @runner        = nil
  @events        = launcher_args[:events] || Events::DEFAULT
  @argv          = launcher_args[:argv] || []
  @config        = conf
  @config.load

  Dir.chdir(@restart_dir)

  if clustered?
    @events.formatter = Events::PidFormatter.new
    @options[:logger] = @events

    @runner = Cluster.new(self, @events)
  else
    @runner = Single.new(self, @events)
  end

  @status = :run
end
</code></pre>

<p>在 <code>#initialize</code> 方法中，<code>@runner</code> 的初始化是根据当前配置中的 worker 数决定的，如果当前的 <code>worker &gt; 0</code>，那么就会选择 <code>Cluster</code> 作为 <code>@runner</code>，否则就会选择 <code>Single</code>，在初始化结束之后会执行 <code>Launcher#run</code> 方法启动当前的 Puma 进程：</p>

<pre><code class="language-ruby">From: lib/puma/launcher.rb @ line 165:
Owner: Puma::Launcher

def run
  previous_env = ENV.to_h

  setup_signals
  @runner.run

  case @status
  when :halt
    log "* Stopping immediately!"
  when :run, :stop
    graceful_stop
  when :restart
    log "* Restarting..."
    ENV.replace(previous_env)
    @runner.before_restart
    restart!
  when :exit
    # nothing
  end
end
</code></pre>

<p>在这个简单的 <code>#run</code> 方法中，Puma 通过 <code>#setup_singals</code> 设置了一些信号的响应过程，在这之后执行 <code>Runner#run</code> 启动 Puma 的服务。</p>

<h2 id="启动服务">启动服务</h2>

<p>根据配置文件中不同的配置项，Puma 在启动时有两种不同的选择，一种是当前的 worker 数为 0，这时会通过 <code>Single</code> 启动单机模式的 Puma 进程，另一种情况是 worker 数大于 0，它使用 <code>Cluster</code> 的 runner 启动一组 Puma 进程。</p>

<p><img src="https://img.nju520.me/2017-11-10-single-cluster.png" alt="single-cluster" /></p>

<p>在这一节中文章将会简单介绍不同的 runner 是如何启动 Puma 进程的。</p>

<h3 id="单机模式">单机模式</h3>

<p>Puma 单机模式的启动通过 <code>Single</code> 类来处理，而定义这个类的文件 single.rb 中其实并没有多少代码，我们从中就可以看到单机模式下 Puma 的启动其实并不复杂：</p>

<pre><code class="language-ruby">From: lib/puma/single.rb @ line 40:
Owner: Puma::Single

def run
  output_header "single"

  if daemon?
    log "* Daemonizing..."
    Process.daemon(true)
    redirect_io
  end

  load_and_bind
  @launcher.write_state
  @server = server = start_server

  begin
    server.run.join
  rescue Interrupt
    # Swallow it
  end
end
</code></pre>

<p>如果我们启动了后台模式，就会通过 Puma 为 Process 模块扩展的方法 <code>.daemon</code> 在后台启动新的 Puma 进程，启动的过程其实和 Unicorn 中的差不多：</p>

<pre><code class="language-ruby">From: lib/puma/daemon_ext.rb @ line 12:
Owner: #&lt;Class:Process&gt;

def self.daemon(nochdir=false, noclose=false)
  exit if fork
  Process.setsid
  exit if fork

  Dir.chdir "/" unless nochdir

  if !noclose
    STDIN.reopen File.open("/dev/null", "r")
    null_out = File.open "/dev/null", "w"
    STDOUT.reopen null_out
    STDERR.reopen null_out
  end

  0
end
</code></pre>

<p>在 Puma 中通过两次 <code>fork</code> 同时将当前进程从终端中分离出来，最终就可以得到一个独立的 Puma 进程，你可以通过下面的图片简单理解这个过程：</p>

<p><img src="https://img.nju520.me/2017-11-10-puma-daemonize.png" alt="puma-daemonize" /></p>

<p>当我们在后台启动了一个 Puma 的 master 进程之后就可以开始启动 Puma 的服务器了，也就是 <code>Puma::Server</code> 的实例：</p>

<pre><code class="language-ruby">From: lib/puma/runner.rb @ line 151:
Owner: Puma::Runner

def start_server
  min_t = @options[:min_threads]
  max_t = @options[:max_threads]

  server = Puma::Server.new app, @launcher.events, @options
  server.min_threads = min_t
  server.max_threads = max_t
  server.inherit_binder @launcher.binder

  if @options[:mode] == :tcp
    server.tcp_mode!
  end

  unless development?
    server.leak_stack_on_error = false
  end

  server
end
</code></pre>

<p>这里有很多不是特别重要的代码，需要注意的是 <code>Server</code> 初始化的过程以及最大、最小线程数的设置，这些信息都是通过命令行或者配置文件传入的，例如 <code>puma -t 8:32</code> 表示当前的最小线程数为 8、最大线程数为 32 个，Puma 会根据当前的流量自动调节同一个进程中的线程个数。</p>

<p>服务在启动时会创建一个线程池 <code>ThreadPool</code> 并传入一个用于处理请求的 block，这个方法的实现其实非常长，这里省略了很多代码；</p>

<pre><code class="language-ruby">From: lib/puma/server.rb @ line 255:
Owner: Puma::Server

def run(background=true)
  queue_requests = @queue_requests

  @thread_pool = ThreadPool.new(@min_threads,
                                @max_threads,
                                IOBuffer) do |client, buffer|
    process_now = false

    begin
      if queue_requests
        process_now = client.eagerly_finish
      else
        client.finish
        process_now = true
      end
    rescue MiniSSL::SSLError, HttpParserError =&gt; e
      # ...
    rescue ConnectionError
      client.close
    else
      if process_now
        process_client client, buffer
      else
        client.set_timeout @first_data_timeout
        @reactor.add client
      end
    end
  end

  if queue_requests
    @reactor = Reactor.new self, @thread_pool
    @reactor.run_in_thread
  end

  @thread = Thread.new { handle_servers }
  @thread
end
</code></pre>

<p>上述代码创建了一个新的 <code>Reactor</code> 对象并在一个新的线程中执行 <code>#handle_servers</code> 接受客户端的请求，文章会在后面介绍请求的处理。</p>

<h3 id="集群模式">集群模式</h3>

<p>如果在启动 puma 进程时使用 <code>-w</code> 参数，例如下面的命令：</p>

<pre><code class="language-shell">$ puma -w 3
[20904] Puma starting in cluster mode...
[20904] * Version 3.10.0 (ruby 2.3.3-p222), codename: Russell's Teapot
[20904] * Min threads: 0, max threads: 16
[20904] * Environment: development
[20904] * Process workers: 3
[20904] * Phased restart available
[20904] * Listening on tcp://0.0.0.0:9292
[20904] Use Ctrl-C to stop
[20904] - Worker 2 (pid: 20907) booted, phase: 0
[20904] - Worker 1 (pid: 20906) booted, phase: 0
[20904] - Worker 0 (pid: 20905) booted, phase: 0

$ ps aux | grep puma
nju520        20909   0.0  0.0  4296440    952 s001  S+   10:23AM   0:00.01 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn puma
nju520        20907   0.0  0.1  4358888  12128 s003  S+   10:23AM   0:00.07 puma: cluster worker 2: 20904 [Desktop]
nju520        20906   0.0  0.1  4358888  12148 s003  S+   10:23AM   0:00.07 puma: cluster worker 1: 20904 [Desktop]
nju520        20905   0.0  0.1  4358888  12196 s003  S+   10:23AM   0:00.07 puma: cluster worker 0: 20904 [Desktop]
nju520        20904   0.0  0.2  4346784  25632 s003  S+   10:23AM   0:00.67 puma 3.10.0 (tcp://0.0.0.0:9292) [Desktop]
</code></pre>

<p>上述命令就会启动一个 Puma 的 master 进程和三个 worker 进程，Puma 集群模式就是通过 <code>Puma::Cluster</code> 类来启动的，而启动集群的方法 <code>#run</code> 仍然是一个非常长的方法，在这里仍然省去了很多的代码：</p>

<pre><code class="language-ruby">From: lib/puma/cluster.rb @ line 386:
Owner: Puma::Cluster

def run
  @status = :run

  output_header "cluster"
  log "* Process workers: #{@options[:workers]}"

  read, @wakeup = Puma::Util.pipe

  Process.daemon(true)
  spawn_workers

  begin
    while @status == :run
      begin
        res = IO.select([read], nil, nil, WORKER_CHECK_INTERVAL)

        if res
          req = read.read_nonblock(1)
          result = read.gets
          pid = result.to_i

          if w = @workers.find { |x| x.pid == pid }
            case req
            when "b"
              w.boot!
            when "t"
              w.dead!
            when "p"
              w.ping!(result.sub(/^\d+/,'').chomp)
            end
          else
            log "! Out-of-sync worker list, no #{pid} worker"
          end
        end

      rescue Interrupt
        @status = :stop
      end
    end

    stop_workers unless @status == :halt
  ensure
    read.close
    @wakeup.close
  end
end
</code></pre>

<p>在使用 <code>#spawn_workers</code> 之后，当前 master 进程就开始通过 Socket 监听所有来自worker 的消息，例如当前的状态以及心跳检查等等。</p>

<p><code>#spawn_workers</code> 方法会通过 fork 创建当前集群中缺少的 worker 数，在新的进程中执行 <code>#worker</code> 方法并将 worker 保存在 master 的 <code>@workers</code> 数组中：</p>

<pre><code class="language-ruby">From: lib/puma/cluster.rb @ line 116:
Owner: Puma::Cluster

def spawn_workers
  diff = @options[:workers] - @workers.size
  return if diff &lt; 1

  master = Process.pid

  diff.times do
    idx = next_worker_index
    pid = fork { worker(idx, master) }

    debug "Spawned worker: #{pid}"
    @workers &lt;&lt; Worker.new(idx, pid, @phase, @options)
  end
end
</code></pre>

<p>在 fork 出的新进程中，<code>#worker</code> 方法与单机模式中一样都创建了新的 <code>Server</code> 实例，调用 <code>#run</code> 和 <code>#join</code> 方法启动服务：</p>

<pre><code class="language-ruby">From: lib/puma/cluster.rb @ line 231:
Owner: Puma::Cluster

def worker(index, master)
  title  = "puma: cluster worker #{index}: #{master}"
  $0 = title

  server = start_server
  server.run.join
end
</code></pre>

<p>与 Unicorn 完全相同，Puma 使用了一个 master 进程来管理所有的 worker 进程：</p>

<p><img src="https://img.nju520.me/2017-11-10-puma-cluster-mode.png" alt="puma-cluster-mode" /></p>

<p>虽然 Puma 集群中的所有节点也都是由 master 管理的，但是所有的事件和信号会由各个接受信号的进程处理的，只有在特定事件发生时会通知主进程。</p>

<h2 id="处理请求">处理请求</h2>

<p>在 Puma 中所有的请求都是通过 <code>Server</code> 和 <code>ThreadPool</code> 协作来响应的，我们在 <code>#handler_servers</code> 方法中通过 <code>IO.select</code> 监听一组套接字上的读写事件：</p>

<pre><code class="language-ruby">From: lib/puma/server.rb @ line 334:
Owner: Puma::Server

def handle_servers
  begin
    sockets = @binder.ios
    pool = @thread_pool

    while @status == :run
      begin
        ios = IO.select sockets
        ios.first.each do |sock|
          begin
            if io = sock.accept_nonblock
              client = Client.new io, @binder.env(sock)
              pool &lt;&lt; client
              pool.wait_until_not_full
            end
          rescue Errno::ECONNABORTED
            io.close rescue nil
          end
        rescue Object =&gt; e
          @events.unknown_error self, e, "Listen loop"
        end
      end
    rescue Exception =&gt; e
      # ...
  end
end
</code></pre>

<p>当有读写事件发生时会非阻塞的接受 Socket，创建新的 <code>Client</code> 对象最后加入到线程池中交给线程池来处理接下来的请求。</p>

<pre><code class="language-ruby">From: lib/puma/thread_pool.rb @ line 140:
Owner: Puma::ThreadPool

def &lt;&lt;(work)
  @mutex.synchronize do
    if @shutdown
      raise "Unable to add work while shutting down"
    end

    @todo &lt;&lt; work

    if @waiting &lt; @todo.size and @spawned &lt; @max
      spawn_thread
    end

    @not_empty.signal
  end
end
</code></pre>

<p><code>ThreadPool</code> 覆写了 <code>#&lt;&lt;</code> 方法，在这个方法中它将 <code>Client</code> 对象加入到 <code>@todo</code> 数组中，通过对比几个参数选择是否创建一个新的线程来处理当前队列中的任务。</p>

<p>重新回到 <code>ThreadPool</code> 的初始化方法 <code>#initialize</code> 中，线程池在初始化时就会创建最低数量的线程保证当前的 worker 进程中有足够的工作线程能够处理客户端的请求：</p>

<pre><code class="language-ruby">From: lib/puma/thread_pool.rb @ line 21:
Owner: Puma::ThreadPool

def initialize(min, max, *extra, &amp;block)
  @mutex = Mutex.new

  @todo = []

  @spawned = 0
  @waiting = 0

  @min = Integer(min)
  @max = Integer(max)
  @block = block
  @extra = extra

  @workers = []

  @mutex.synchronize do
    @min.times { spawn_thread }
  end
end
</code></pre>

<p>每一个线程都是通过 <code>Thread.new</code> 创建的，我们会在这个线程执行的过程中执行传入的 block：</p>

<pre><code class="language-ruby">From: lib/puma/thread_pool.rb @ line 21:
Owner: Puma::ThreadPool

def spawn_thread
  @spawned += 1

  th = Thread.new(@spawned) do |spawned|
    todo  = @todo
    block = @block
    mutex = @mutex

    extra = @extra.map { |i| i.new }

    while true
      work = nil

      continue = true

      mutex.synchronize do
        work = todo.shift
      end

      begin
        block.call(work, *extra)
      rescue Exception =&gt; e
        STDERR.puts "Error reached top of thread-pool: #{e.message} (#{e.class})"
      end
    end

    mutex.synchronize do
      @spawned -= 1
      @workers.delete th
    end
  end

  @workers &lt;&lt; th
  th
end
</code></pre>

<p>在每一个工作完成之后，也会在一个互斥锁内部使用 <code>#delete</code> 方法将当前线程从数组中删除，在这里执行的 block 中将客户端对象 <code>Client</code> 加入了 <code>Reactor</code> 中等待之后的处理。</p>

<pre><code class="language-ruby">@thread_pool = ThreadPool.new(@min_threads,
                              @max_threads,
                              IOBuffer) do |client, buffer|
  begin
    client.finish
  rescue MiniSSL::SSLError =&gt; e
    # ...
  else
    process_client client, buffer
  end
end
</code></pre>

<p>如过当前任务不需要立即处理，就会向 <code>Reactor</code> 加入任务等待一段时间，否则就会立即由 <code>#process_client</code> 方法进行处理，其中调用了 <code>#handle_request</code> 方法尝试处理当前的网络请求：</p>

<pre><code class="language-ruby">From: lib/puma/server.rb @ line 439:
Owner: Puma::Server

def process_client(client, buffer)
  begin
    while true
      case handle_request(client, buffer)
      when false
        return
      when true
        return unless @queue_requests
        buffer.reset
        unless client.reset(@status == :run)
          client.set_timeout @persistent_timeout
          @reactor.add client
          return
        end
      end
    end
  rescue StandardError =&gt; e
    # ...
  ensure
    # ...
  end
end
</code></pre>

<p>用于处理网络请求的方法 <code>#handle_request</code> 足足有 200 多行，代码中处理非常多的实现细节，在这里实在是不想一行一行代码看过去，也就简单梳理一下这段代码的脉络了：</p>

<pre><code class="language-ruby">From: lib/puma/server.rb @ line 574:
Owner: Puma::Server

def handle_request(req, lines)
  env = req.env
  client = req.io

  # ...

  begin
    status, headers, res_body = @app.call(env)

    headers.each do |k, vs|
      # ...
    end

    fast_write client, lines.to_s
    res_body.each do |part|
      fast_write client, part
      client.flush
    end
  ensure
    body.close
  end
end
</code></pre>

<p>我们在这里直接将这段代码压缩至 20 行左右，你可以看到与其他的 webserver 完全相同，这里也调用了 Rack 应用的 <code>#call</code> 方法获得了一个三元组，然后通过 <code>#fast_write</code> 将请求写回客户端的 Socket 结束这个 HTTP 请求。</p>

<h2 id="并发模型">并发模型</h2>

<p>到目前为止，我们已经对 Puma 是如何处理 HTTP 请求的有一个比较清晰的认识了，对于每一个 HTTP 请求都会由操作系统选择不同的进程来处理，这部分的负载均衡完全是由 OS 层来做的，当请求被分配给某一个进程时，当前进程会根据持有的线程数选择是否对请求进行处理，在这时可能会创建新的 <code>Thread</code> 对象来处理这个请求，也可能会把当前请求暂时扔到 <code>Reactor</code> 中进行等待。</p>

<p><img src="https://img.nju520.me/2017-11-10-puma-concurrency-model.png" alt="puma-concurrency-model" /></p>

<p><code>Reactor</code> 主要是为了提高 Puma 服务的性能存在的产物，它能够让当前的 worker 接受所有请求并将它们以队列的形式传入处理器中；如果当前的系统中存在慢客户端，那么也会占用处理请求的资源，不过由于 Puma 是多进程多线程模型的，所以影响没有那么严重，但是我们也经常会通过反向代理来解决慢客户端的问题。</p>

<h2 id="总结">总结</h2>

<p>相比于多进程单线程的 Unicorn，Puma 提供了更灵活的配置功能，每一个进程的线程数都能在一定范围内进行收缩，目前也是绝大多数的 Ruby 项目使用的 webserver，从不同 webserver 的发展我们其实可以看出混合方式的并发模型虽然实现更加复杂，但是确实能够提供更高的性能和容错。</p>

<p>Puma 项目使用了 Rubocop 来规范项目中的代码风格，相比其他的 webserver 来说确实有更好的阅读体验，只是偶尔出现的长方法会让代码在理解时出现一些问题。</p>


  ]]></description>
</item>

<item>
  <title>浅谈 Unicorn 的多进程模型</title>
  <link>//rack-unicorn</link>
  <author>nju520</author>
  <pubDate>2017-11-08T00:00:00+08:00</pubDate>
  <guid>//rack-unicorn</guid>
  <description><![CDATA[
  <ul>
  <li><a href="https://nju520.me/rack">谈谈 Rack 协议与实现</a></li>
  <li><a href="https://nju520.me/rack-webrick">浅谈 WEBrick 的多线程模型</a></li>
  <li><a href="https://nju520.me/rack-thin">浅谈 Thin 的事件驱动模型</a></li>
  <li><a href="https://nju520.me/rack-unicorn">浅谈 Unicorn 的多进程模型</a></li>
  <li><a href="https://nju520.me/rack-puma">浅谈 Puma 的并发模型与实现</a></li>
  <li><a href="https://nju520.me/ruby-webserver">Ruby Web 服务器的并发模型与性能</a></li>
</ul>

<p>作为 Ruby 社区中老牌的 webserver，在今天也有很多开发者在生产环境使用 Unicorn 处理客户端的发出去的 HTTP 请求，与 WEBrick 和 Thin 不同，Unicorn 使用了完全不同的模型，提供了多进程模型批量处理来自客户端的请求。</p>

<p><img src="https://img.nju520.me/2017-11-08-unicorn.jpeg" alt="unicorn" /></p>

<p>Unicorn 为 Rails 应用提供并发的方式是使用 <code>fork</code> 创建多个 worker 线程，监听同一个 Socket 上的输入。</p>

<blockquote>
  <p>本文中使用的是 5.3.1 的 Unicorn，如果你使用了不同版本的 Unicorn，原理上的区别不会太大，只是在一些方法的实现上会有一些细微的不同。</p>
</blockquote>

<h2 id="实现原理">实现原理</h2>

<p>Unicorn 虽然也是一个遵循 Rack 协议的 Ruby webserver，但是因为它本身并没有提供 Rack 处理器，所以没有办法直接通过 <code>rackup -s Unicorn</code> 来启动 Unicorn 的进程。</p>

<pre><code class="language-ruby">$ unicorn -c unicorn.rb
I, [2017-11-06T08:05:03.082116 #33222]  INFO -- : listening on addr=0.0.0.0:8080 fd=10
I, [2017-11-06T08:05:03.082290 #33222]  INFO -- : worker=0 spawning...
I, [2017-11-06T08:05:03.083505 #33222]  INFO -- : worker=1 spawning...
I, [2017-11-06T08:05:03.083989 #33222]  INFO -- : master process ready
I, [2017-11-06T08:05:03.084610 #33223]  INFO -- : worker=0 spawned pid=33223
I, [2017-11-06T08:05:03.085100 #33223]  INFO -- : Refreshing Gem list
I, [2017-11-06T08:05:03.084902 #33224]  INFO -- : worker=1 spawned pid=33224
I, [2017-11-06T08:05:03.085457 #33224]  INFO -- : Refreshing Gem list
I, [2017-11-06T08:05:03.123611 #33224]  INFO -- : worker=1 ready
I, [2017-11-06T08:05:03.123670 #33223]  INFO -- : worker=0 ready
</code></pre>

<p>在使用 Unicorn 时，我们需要直接使用 <code>unicorn</code> 命令来启动一个 Unicorn 服务，在使用时可以通过 <code>-c</code> 传入一个配置文件，文件中的内容其实都是 Ruby 代码，每一个方法调用都是 Unicorn 的一条配置项：</p>

<pre><code class="language-ruby">$ cat unicorn.rb
worker_processes 2
</code></pre>

<h3 id="可执行文件">可执行文件</h3>

<p><code>unicorn</code> 这个命令位于 <code>bin/unicorn</code> 中，在这个可执行文件中，大部分的代码都是对命令行参数的配置和说明，整个文件可以简化为以下的几行代码：</p>

<pre><code class="language-ruby">rackup_opts = # ...
app = Unicorn.builder(ARGV[0] || 'config.ru', op)
Unicorn::Launcher.daemonize!(options) if rackup_opts[:daemonize]
Unicorn::HttpServer.new(app, options).start.join
</code></pre>

<p><code>unicorn</code> 命令会从 Rack 应用的标配 config.ru 文件或者传入的文件中加载代码构建一个新的 Rack 应用；初始化 Rack 应用后会使用 <code>.daemonize!</code> 方法将 unicorn 进程启动在后台运行；最后会创建并启动一个新的 <code>HttpServer</code> 的实例。</p>

<h3 id="构建应用">构建应用</h3>

<p>读取 config.ru 文件并解析的过程其实就是直接使用了 Rack 的 <code>Builder</code> 模块，通过 <code>eval</code> 运行一段代码得到一个 Rack 应用：</p>

<pre><code class="language-ruby">From: lib/unicorn.rb @ line 39:
Owner: #&lt;Class:Unicorn&gt;

def self.builder(ru, op)
  raw = File.read(ru)
  inner_app = eval("Rack::Builder.new {(\n#{raw}\n)}.to_app", TOPLEVEL_BINDING, ru)

  middleware = {
    ContentLength: nil,
    Chunked: nil,
    CommonLogger: [ $stderr ],
    ShowExceptions: nil,
    Lint: nil,
    TempfileReaper: nil,
  }

  Rack::Builder.new do
    middleware.each do |m, args|
      use(Rack.const_get(m), *args) if Rack.const_defined?(m)
    end
    run inner_app
  end.to_app
end
</code></pre>

<p>在该方法中会执行两次 <code>Rack::Builder.new</code> 方法，第一次会运行 config.ru 中的代码，第二次会添加一些默认的中间件，最终会返回一个接受 <code>#call</code> 方法返回三元组的 Rack 应用。</p>

<h3 id="守护进程">守护进程</h3>

<p>在默认情况下，Unicorn 的进程都是以前台进程的形式运行的，但是在生产环境我们往往需要在后台运行 Unicorn 进程，这也就是 <code>Unicorn::Launcher</code> 所做的工作。</p>

<pre><code class="language-ruby">From: lib/unicorn.rb @ line 23:
Owner: #&lt;Class:Unicorn::Launcher&gt;

def self.daemonize!(options)
  cfg = Unicorn::Configurator
  $stdin.reopen("/dev/null")

  unless ENV['UNICORN_FD']
    rd, wr = IO.pipe
    grandparent = $$
    if fork
      wr.close
    else
      rd.close
      Process.setsid
      exit if fork
    end

    if grandparent == $$
      master_pid = (rd.readpartial(16) rescue nil).to_i
      unless master_pid &gt; 1
        warn "master failed to start, check stderr log for details"
        exit!(1)
      end
      exit 0
    else
      options[:ready_pipe] = wr
    end
  end
  cfg::DEFAULTS[:stderr_path] ||= "/dev/null"
  cfg::DEFAULTS[:stdout_path] ||= "/dev/null"
  cfg::RACKUP[:daemonized] = true
end
</code></pre>

<p>想要真正理解上述代码的工作，我们需要理解广义上的 daemonize 过程，在 Unix-like 的系统中，一个 <a href="https://en.wikipedia.org/wiki/Daemon_(computing)">daemon</a>（守护进程）是运行在后台不直接被用户操作的进程；一个进程想要变成守护进程通常需要做以下的事情：</p>

<ol>
  <li>执行 <code>fork</code> 和 <code>exit</code> 来创建一个后台任务；</li>
  <li>从 tty 的控制中分离、创建一个新的 session 并成为新的 session 和进程组的管理者；</li>
  <li>将根目录 <code>/</code> 设置为当前进程的工作目录；</li>
  <li>将 umask 更新成 <code>0</code> 以提供自己的权限管理掩码；</li>
  <li>使用日志文件、控制台或者 <code>/dev/null</code> 设备作为标准输入、输出和错误；</li>
</ol>

<p>在 <code>.daemonize!</code> 方法中我们总共使用 fork 创建了两个进程，整个过程涉及三个进程的协作，其中 grandparent 是启动 Unicorn 的进程一般指终端，parent 是用来启动 Unicorn 服务的进程，master 就是 Unicorn 服务中的主进程，三个进程有以下的关系：</p>

<p><img src="https://img.nju520.me/2017-11-08-unicorn-daemonize.png" alt="unicorn-daemonize" /></p>

<p>上述的三个进程中，grandparent 表示用于启动 Unicorn 进程的终端，parent 只是一个用于设置进程状态和掩码的中间进程，它在启动 Unicorn 的 master 进程后就会立刻退出。</p>

<p>在这里，我们会分三个部分分别介绍 grandparent、parent 和 master 究竟做了哪些事情；首先，对于 grandparent 进程来说，我们实际上运行了以下的代码：</p>

<pre><code class="language-ruby">def self.daemonize!(options)
  $stdin.reopen("/dev/null")
  rd, wr = IO.pipe
  wr.close

  # fork

  master_pid = (rd.readpartial(16) rescue nil).to_i
  unless master_pid &gt; 1
    warn "master failed to start, check stderr log for details"
    exit!(1)
  end
end
</code></pre>

<p>通过 <code>IO.pipe</code> 方法创建了一对 Socket 节点，其中一个用于读，另一个用于写，在这里由于当前进程 grantparent 不需要写，所以直接将写的一端 <code>#close</code>，保留读的一端等待 Unicorn master 进程发送它的 <code>pid</code>，如果 master 没有成功启动就会报错，这也是 grandparent 进程的主要作用。</p>

<p>对于 parent 进程来说做的事情其实就更简单了，在 <code>fork</code> 之后会直接将读的一端执行 <code>#close</code>，这样无论是当前进程 parent 还是 parent fork 出来的进程都无法通过 <code>rd</code> 读取数据：</p>

<pre><code class="language-ruby">def self.daemonize!(options)
  $stdin.reopen("/dev/null")
  rd, wr = IO.pipe

  # fork

  rd.close
  Process.setsid
  exit if fork
end
</code></pre>

<p>在 parent 进程中，我们通过 <code>Process.setsid</code> 将当前的进程设置为新的 session 和进程组的管理者，从 tty 中分离；最后直接执行 <code>fork</code> 创建一个新的进程 master 并退出 parent 进程，parent 进程的作用其实就是为了启动新 Unicorn master 进程。</p>

<pre><code class="language-ruby">def self.daemonize!(options)
  cfg = Unicorn::Configurator
  $stdin.reopen("/dev/null")

  rd, wr = IO.pipe
  rd.close

  Process.setsid

  # fork

  options[:ready_pipe] = wr
  cfg::DEFAULTS[:stderr_path] ||= "/dev/null"
  cfg::DEFAULTS[:stdout_path] ||= "/dev/null"
  cfg::RACKUP[:daemonized] = true
end
</code></pre>

<p>新的进程 Unicorn master 就是一个不关联在任何 tty 的一个后台进程，不过到这里为止也仅仅创建另一个进程，Unicorn 还无法对外提供服务，我们将可读的 Socket <code>wr</code> 写入 <code>options</code> 中，在 webserver 成功启动后将通过 <code>IO.pipe</code> 创建的一对 Socket 将信息回传给 grandparent 进程通知服务启动的结果。</p>

<h3 id="初始化服务">初始化服务</h3>

<p>HTTP 服务在初始化时其实也没有做太多的事情，只是对 Rack 应用进行存储并初始化了一些实例变量：</p>

<pre><code class="language-ruby">From: lib/unicorn/http_server.rb @ line 69:
Owner: Unicorn::HttpServer

def initialize(app, options = {})
  @app = app
  @request = Unicorn::HttpRequest.new
  @reexec_pid = 0
  @ready_pipe = options.delete(:ready_pipe)
  @init_listeners = options[:listeners] ? options[:listeners].dup : []
  self.config = Unicorn::Configurator.new(options)
  self.listener_opts = {}

  @self_pipe = []
  @workers = {}
  @sig_queue = []
  @pid = nil

  config.commit!(self, :skip =&gt; [:listeners, :pid])
  @orig_app = app
  @queue_sigs = [:WINCH, :QUIT, :INT, :TERM, :USR1, :USR2, :HUP, :TTIN, :TTOU]
end
</code></pre>

<p>在 <code>.daemonize!</code> 方法中存储的 <code>ready_pipe</code> 在这时被当前的 <code>HttpServer</code> 对象持有，之后会通过这个管道上传数据。</p>

<h3 id="启动服务">启动服务</h3>

<p><code>HttpServer</code> 服务的启动一看就是这个 <code>#start</code> 实例方法控制的，在这个方法中总过做了两件比较重要的事情：</p>

<pre><code class="language-ruby">From: lib/unicorn/http_server.rb @ line 120:
Owner: Unicorn::HttpServer

def start
  @queue_sigs.each { |sig| trap(sig) { @sig_queue &lt;&lt; sig; awaken_master } }
  trap(:CHLD) { awaken_master }

  self.pid = config[:pid]

  spawn_missing_workers
  self
end
</code></pre>

<p>第一件事情是将构造器中初始化的 <code>queue_sigs</code> 实例变量中的全部信号，通过 <code>trap</code> 为信号提供用于响应事件的代码。</p>

<p>第二件事情就是通过 <code>#spawn_missing_workers</code> 方法 <code>fork</code> 当前 master 进程创建一系列的 worker 进程：</p>

<pre><code class="language-ruby">From: lib/unicorn/http_server.rb @ line 531:
Owner: Unicorn::HttpServer

def spawn_missing_workers
  worker_nr = -1
  until (worker_nr += 1) == @worker_processes
    worker = Unicorn::Worker.new(worker_nr)
    before_fork.call(self, worker)

    pid = fork

    unless pid
      after_fork_internal
      worker_loop(worker)
      exit
    end

    @workers[pid] = worker
    worker.atfork_parent
  end
rescue =&gt; e
  @logger.error(e) rescue nil
  exit!
end
</code></pre>

<p>在这种调用了 <code>fork</code> 的方法中，我们还是将其一分为二来看，在这里就是 master 和 worker 进程，对于 master 进程来说：</p>

<pre><code class="language-ruby">From: lib/unicorn/http_server.rb @ line 531:
Owner: Unicorn::HttpServer

def spawn_missing_workers
  worker_nr = -1
  until (worker_nr += 1) == @worker_processes
    worker = Unicorn::Worker.new(worker_nr)
    before_fork.call(self, worker)

    pid = fork
    
    # ...

    @workers[pid] = worker
  end
rescue =&gt; e
  @logger.error(e) rescue nil
  exit!
end
</code></pre>

<p>通过一个 until 循环，master 进程能够创建 <code>worker_processes</code> 个 worker 进程，在每个循环中，上述方法都会创建一个 <code>Unicorn::Worker</code> 对象并在 <code>fork</code> 之后，将子进程的 <code>pid</code> 和 <code>worker</code> 以键值对的形式存到 <code>workers</code> 这个实例变量中。</p>

<p><code>before_fork</code> 中存储的 block 是我们非常熟悉的，其实就是向服务器的日志中追加内容：</p>

<pre><code class="language-ruby">DEFAULTS = {
  # ...
  :after_fork =&gt; lambda { |server, worker|
    server.logger.info("worker=#{worker.nr} spawned pid=#{$$}")
  },
  :before_fork =&gt; lambda { |server, worker|
    server.logger.info("worker=#{worker.nr} spawning...")
  },
  :before_exec =&gt; lambda { |server|
    server.logger.info("forked child re-executing...")
  },
  :after_worker_exit =&gt; lambda { |server, worker, status|
    m = "reaped #{status.inspect} worker=#{worker.nr rescue 'unknown'}"
    if status.success?
      server.logger.info(m)
    else
      server.logger.error(m)
    end
  },
  :after_worker_ready =&gt; lambda { |server, worker|
    server.logger.info("worker=#{worker.nr} ready")
  },
  # ...
}
</code></pre>

<p>所有日志相关的输出大都在 <code>Unicorn::Configurator</code> 类中作为常量定义起来，并在初始化时作为缺省值赋值到 <code>HttpServer</code> 相应的实例变量上。而对于真正处理 HTTP 请求的 worker 进程来说，就会进入更加复杂的逻辑了：</p>

<pre><code class="language-ruby">def spawn_missing_workers
  worker_nr = -1
  until (worker_nr += 1) == @worker_processes
    worker = Unicorn::Worker.new(worker_nr)
    before_fork.call(self, worker)

    # fork

    after_fork_internal
    worker_loop(worker)
    exit
  end
rescue =&gt; e
  @logger.error(e) rescue nil
  exit!
end
</code></pre>

<p>在这里调用了两个实例方法，其中一个是 <code>#after_fork_internal</code>，另一个是 <code>#worker_loop</code> 方法，前者用于处理一些 <code>fork</code> 之后收尾的逻辑，比如关闭仅在 master 进程中使用的 <code>self_pipe</code>：</p>

<pre><code class="language-ruby">def after_fork_internal
  @self_pipe.each(&amp;:close).clear
  @ready_pipe.close if @ready_pipe
  Unicorn::Configurator::RACKUP.clear
  @ready_pipe = @init_listeners = @before_exec = @before_fork = nil
end
</code></pre>

<p>而后者就是 worker 持续监听 Socket 输入并处理请求的循环了。</p>

<h3 id="循环">循环</h3>

<p>当我们开始运行 worker 中的循环时，就开始监听 Socket 上的事件，整个过程还是比较直观的：</p>

<pre><code class="language-ruby">From: lib/unicorn/http_server.rb @ line 681:
Owner: Unicorn::HttpServer

def worker_loop(worker)
  ppid = @master_pid
  readers = init_worker_process(worker)
  ready = readers.dup
  @after_worker_ready.call(self, worker)

  begin
    tmp = ready.dup
    while sock = tmp.shift
      if client = sock.kgio_tryaccept
        process_client(client)
      end
    end

    unless nr == 0
      tmp = ready.dup
      redo
    end

    ppid == Process.ppid or return

    ret = IO.select(readers, nil, nil, @timeout) and ready = ret[0]
  rescue =&gt; e
    # ...
  end while readers[0]
end
</code></pre>

<p>如果当前 Socket 上有等待处理的 HTTP 请求，就会执行 <code>#process_client</code> 方法队请求进行处理，在这里调用了 Rack 应用的 <code>#call</code> 方法得到了三元组：</p>

<pre><code class="language-ruby">From: lib/unicorn/http_server.rb @ line 605:
Owner: Unicorn::HttpServer

def process_client(client)
  status, headers, body = @app.call(env = @request.read(client))

  begin
    return if @request.hijacked?

    @request.headers? or headers = nil
    http_response_write(client, status, headers, body,
                        @request.response_start_sent)
  ensure
    body.respond_to?(:close) and body.close
  end

  unless client.closed?
    client.shutdown
    client.close
  end
rescue =&gt; e
  handle_error(client, e)
end
</code></pre>

<p>请求的解析是通过 <code>Request#read</code> 处理的，而向 Socket 写 HTTP 响应是通过 <code>#http_response_write</code> 方法来完成的，在这里有关 HTTP 请求的解析和响应的处理都属于一些不重要的实现细节，在这里也就不展开介绍了；当我们已经响应了用户的请求就可以将当前 Socket 直接关掉，断掉这个 TCP 连接了。</p>

<h2 id="调度">调度</h2>

<p>我们在上面已经通过多次 <code>fork</code> 启动了用于管理 Unicorn worker 进程的 master 以及多个 worker 进程，由于 Unicorn webserver 涉及了多个进程，所以需要进程之间进行调度。</p>

<p>在 Unix 中，进程的调度往往都是通过信号来进行的，<code>HttpServer#join</code> 就在 Unicorn 的 master 进程上监听外界发送的各种信号，不过在监听信号之前，要通过 <code>ready_pipe</code> 通知 grandparent 进程当前 master 进程已经启动完毕：</p>

<pre><code class="language-ruby">From: lib/unicorn/http_server.rb @ line 267:
Owner: Unicorn::HttpServer

def join
  respawn = true
  last_check = time_now

  proc_name 'master'
  logger.info "master process ready" # test_exec.rb relies on this message
  if @ready_pipe
    begin
      @ready_pipe.syswrite($$.to_s)
    rescue =&gt; e
      logger.warn("grandparent died too soon?: #{e.message} (#{e.class})")
    end
    @ready_pipe = @ready_pipe.close rescue nil
  end

  # ...
end
</code></pre>

<p>当 grandparent 进程，也就是执行 Unicorn 命令的进程接收到命令退出之后，就可以继续做其他的操作了，而 master 进程会进入一个 while 循环持续监听外界发送的信号：</p>

<pre><code class="language-ruby">def join
  # ...

  begin
    reap_all_workers
    case @sig_queue.shift
    # ...
    when :WINCH
      respawn = false
      soft_kill_each_worker(:QUIT)
      self.worker_processes = 0
    when :TTIN
      respawn = true
      self.worker_processes += 1
    when :TTOU
      self.worker_processes -= 1 if self.worker_processes &gt; 0
    when # ...
    end
  rescue =&gt; e
    Unicorn.log_error(@logger, "master loop error", e)
  end while true

  # ...
end
</code></pre>

<p>这一部分的几个信号都会改变当前 Unicorn worker 的进程数，无论是 <code>TTIN</code>、<code>TTOU</code> 还是 <code>WINCH</code> 信号最终都修改了 <code>worker_processes</code> 变量，其中 <code>#soft_kill_each_worker</code> 方法向所有的 Unicorn worker 进程发送了 <code>QUIT</code> 信号。</p>

<p>除了一些用于改变当前 worker 数量的信号，Unicorn 的 master 进程还监听了一些用于终止 master 进程或者更新配置文件的信号。</p>

<pre><code class="language-ruby">def join
  # ...

  begin
    reap_all_workers
    case @sig_queue.shift
    # ...
    when :QUIT
      break
    when :TERM, :INT
      stop(false)
      break
    when :HUP
      respawn = true
      if config.config_file
        load_config!
      else # exec binary and exit if there's no config file
        reexec
      end
    when # ...
    end
  rescue =&gt; e
    Unicorn.log_error(@logger, "master loop error", e)
  end while true

  # ...
end
</code></pre>

<p>无论是 <code>QUIT</code> 信号还是 <code>TERM</code>、<code>INT</code> 最终都执行了 <code>#stop</code> 方法，选择使用不同的信号干掉当前 master 管理的 worker 进程：</p>

<pre><code class="language-ruby">From: lib/unicorn/http_server.rb @ line 339:
Owner: Unicorn::HttpServer

def stop(graceful = true)
  self.listeners = []
  limit = time_now + timeout
  until @workers.empty? || time_now &gt; limit
    if graceful
      soft_kill_each_worker(:QUIT)
    else
      kill_each_worker(:TERM)
    end
    sleep(0.1)
    reap_all_workers
  end
  kill_each_worker(:KILL)
end
</code></pre>

<p>上述方法其实非常容易理解，它会根据传入的参数选择强制终止或者正常停止所有的 worker 进程，这样整个 Unicorn 服务才真正停止并不再为外界提供服务了。</p>

<p>当我们向 master 发送 <code>TTIN</code> 或者 <code>TTOU</code> 信号时只是改变了实例变量 <code>worker_process</code> 的值，还并没有 <code>fork</code> 出新的进程，这些操作都是在 <code>nil</code> 条件中完成的：</p>

<pre><code class="language-ruby">def join
  # ...

  begin
    reap_all_workers
    case @sig_queue.shift
    when nil
      if (last_check + @timeout) &gt;= (last_check = time_now)
        sleep_time = murder_lazy_workers
      else
        sleep_time = @timeout/2.0 + 1
      end
      maintain_worker_count if respawn
      master_sleep(sleep_time)
    when # ...
    end
  rescue =&gt; e
    Unicorn.log_error(@logger, "master loop error", e)
  end while true

  # ...
end
</code></pre>

<p>当 <code>@sig_queue.shift</code> 返回 <code>nil</code> 时也就代表当前没有需要处理的信号，如果需要创建新的进程或者停掉进程就会通过 <code>#maintain_worker_count</code> 方法，之后 master 进程会陷入睡眠直到被再次唤醒。</p>

<pre><code class="language-ruby">From: lib/unicorn/http_server.rb @ line 561:
Owner: Unicorn::HttpServer

def maintain_worker_count
  (off = @workers.size - worker_processes) == 0 and return
  off &lt; 0 and return spawn_missing_workers
  @workers.each_value { |w| w.nr &gt;= worker_processes and w.soft_kill(:QUIT) }
end
</code></pre>

<p>通过创建缺失的进程并关闭多余的进程，我们能够实时的保证整个 Unicorn 服务中的进程数与期望的配置完全相同。</p>

<p>在 Unicorn 的服务中，不仅 master 进程能够接收到来自用户或者其他进程的各种信号，worker 进程也能通过以下的方式将接受到的信号交给 master 处理： </p>
<pre><code class="language-ruby">From: lib/unicorn/http_server.rb @ line 120:
Owner: Unicorn::HttpServer

def start
  # ...
  @queue_sigs.each { |sig| trap(sig) { @sig_queue &lt;&lt; sig; awaken_master } }
  trap(:CHLD) { awaken_master }
end

From: lib/unicorn/http_server.rb @ line 391:
Owner: Unicorn::HttpServer

def awaken_master
  return if $$ != @master_pid
  @self_pipe[1].kgio_trywrite('.')
end
</code></pre>

<p>所以即使向 worker 进程发送 <code>TTIN</code> 或者 <code>TTOU</code> 等信号也能够改变整个 Unicorn 服务中 worker 进程的个数。</p>

<h2 id="多进程模型">多进程模型</h2>

<p>总的来说，Unicorn 作为 Web 服务使用了多进程的模型，通过一个 master 进程来管理多个 worker 进程，其中 master 进程不负责处理客户端的 HTTP 请求，多个 worker 进程监听同一组 Socket：</p>

<p><img src="https://img.nju520.me/2017-11-08-unicorn-io-model.png" alt="unicorn-io-mode" /></p>

<p>一组 worker 进程在监听 Socket 时，如果发现当前的 Socket 有等待处理的请求时就会在当前的进程中直接通过 <code>#process_client</code> 方法处理，整个过程会阻塞当前的进程，而多进程阻塞 I/O 的方式没有办法接受慢客户端造成的性能损失，只能通过反向代理 nginx 才可以解决这个问题。</p>

<p><img src="https://img.nju520.me/2017-11-08-unicorn-multi-processes.png" alt="unicorn-multi-processes" /></p>

<p>在 Unicorn 中，worker 之间的负载均衡是由操作系统解决的，所有的 worker 是通过 <code>.select</code> 方法等待共享 Socket 上的请求，一旦出现可用的 worker，就可以立即进行处理，避开了其他负载均衡算法没有考虑到请求处理时间的问题。</p>

<h2 id="总结">总结</h2>

<p>Unicorn 的源代码其实是作者读过的可读性最差的 Ruby 代码了，很多 Ruby 代码的风格写得跟 C 差不多，看起来也比较头疼，可能是需要处理很多边界条件以及信号，涉及较多底层的进程问题；虽然代码风格上看起来确实让人头疼，不过实现还是值得一看的，重要的代码大都包含在 unicorn.rb 和 http_server.rb 两个文件中，阅读时也不需要改变太多的上下文。</p>

<p>相比于 WEBrick 的单进程多线程的 I/O 模型，Unicorn 的多进程模型有很多优势，一是能够充分利用多核 CPU 的性能，其次能够通过 master 来管理并监控 Unicorn 中包含的一组 worker 并提供了零宕机部署的功能，除此之外，多进程的 I/O 模型还不在乎当前的应用是否是线程安全的，所以不会出现线程竞争等问题，不过 Unicorn 由于 <code>fork</code> 了大量的 worker 进程，如果长时间的在 Unicorn 上运行内存泄露的应用会非常耗费内存资源，可以考虑使用 <a href="https://github.com/kzk/unicorn-worker-killer">unicorn-worker-killer</a> 来自动重启。</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://www.digitalocean.com/community/tutorials/how-to-optimize-unicorn-workers-in-a-ruby-on-rails-app">How To Optimize Unicorn Workers in a Ruby on Rails App</a></li>
  <li><a href="https://read01.com/zh-hk/zm5B.html#.Wf0oLduB0sk">Ruby Web 服务器：这十五年</a></li>
  <li><a href="https://github.com/kzk/unicorn-worker-killer">unicorn-worker-killer</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Daemon_(computing)">Daemon (computing)</a></li>
  <li><a href="http://jiangpeng.info/blogs/2014/03/10/nginx-unicorn.html">Nginx 与 Unicorn</a></li>
  <li><a href="https://github.com/blog/517-unicorn">Unicorn!</a></li>
</ul>

  ]]></description>
</item>

<item>
  <title>浅谈 Thin 的事件驱动模型</title>
  <link>//rack-thin</link>
  <author>nju520</author>
  <pubDate>2017-11-04T00:00:00+08:00</pubDate>
  <guid>//rack-thin</guid>
  <description><![CDATA[
  <ul>
  <li><a href="https://nju520.me/rack">谈谈 Rack 协议与实现</a></li>
  <li><a href="https://nju520.me/rack-webrick">浅谈 WEBrick 的多线程模型</a></li>
  <li><a href="https://nju520.me/rack-thin">浅谈 Thin 的事件驱动模型</a></li>
  <li><a href="https://nju520.me/rack-unicorn">浅谈 Unicorn 的多进程模型</a></li>
  <li><a href="https://nju520.me/rack-puma">浅谈 Puma 的并发模型与实现</a></li>
  <li><a href="https://nju520.me/ruby-webserver">Ruby Web 服务器的并发模型与性能</a></li>
</ul>

<p>在上一篇文章中我们已经介绍了 WEBrick 的实现，它的 handler 是写在 Rack 工程中的，而在这篇文章介绍的 webserver <a href="https://github.com/macournoyer/thin">thin</a> 的 Rack 处理器也是写在 Rack 中的；与 WEBrick 相同，Thin 的实现也非常简单，官方对它的介绍是：</p>

<blockquote>
  <p>A very fast &amp; simple Ruby web server.</p>
</blockquote>

<p>它将 <a href="https://zedshaw.com/archive/ragel-state-charts/">Mongrel</a>、<a href="https://github.com/eventmachine/eventmachine">EventMachine</a> 和 <a href="http://rack.github.io">Rack</a> 三者进行组合，在其中起到胶水的作用，所以在理解 Thin 的实现的过程中我们也需要分析 EventMachine 到底是如何工作的。</p>

<h2 id="thin-的实现">Thin 的实现</h2>

<p>在这一节中我们将从源代码来分析介绍 Thin 的实现原理，因为部分代码仍然是在 Rack 工程中实现的，所以我们要从 Rack 工程的代码开始理解 Thin 的实现。</p>

<h3 id="从-rack-开始">从 Rack 开始</h3>

<p>Thin 的处理器 <code>Rack::Handler::Thin</code> 与其他遵循 Rack 协议的 webserver 一样都实现了 <code>.run</code> 方法，接受 Rack 应用和 <code>options</code> 作为输入：</p>

<pre><code class="language-ruby">module Rack
  module Handler
    class Thin
      def self.run(app, options={})
        environment  = ENV['RACK_ENV'] || 'development'
        default_host = environment == 'development' ? 'localhost' : '0.0.0.0'

        host = options.delete(:Host) || default_host
        port = options.delete(:Port) || 8080
        args = [host, port, app, options]
        args.pop if ::Thin::VERSION::MAJOR &lt; 1 &amp;&amp; ::Thin::VERSION::MINOR &lt; 8
        server = ::Thin::Server.new(*args)
        yield server if block_given?
        server.start
      end
    end
  end
end
</code></pre>

<p>上述方法仍然会从 <code>options</code> 中取出 ip 地址和端口号，然后初始化一个 <code>Thin::Server</code> 的实例后，执行 <code>#start</code> 方法在 8080 端口上监听来自用户的请求。</p>

<h3 id="初始化服务">初始化服务</h3>

<p>Thin 服务的初始化由以下的代码来处理，首先会处理在 <code>Rack::Handler::Thin.run</code> 中传入的几个参数 <code>host</code>、<code>port</code>、<code>app</code> 和 <code>options</code>，将 Rack 应用存储在临时变量中：</p>

<pre><code class="language-ruby">From: lib/thin/server.rb @ line 100:
Owner: Thin::Server

def initialize(*args, &amp;block)
  host, port, options = DEFAULT_HOST, DEFAULT_PORT, {}

  args.each do |arg|
    case arg
    when 0.class, /^\d+$/ then port    = arg.to_i
    when String           then host    = arg
    when Hash             then options = arg
    else
      @app = arg if arg.respond_to?(:call)
    end
  end

  @backend = select_backend(host, port, options)
  @backend.server = self
  @backend.maximum_connections            = DEFAULT_MAXIMUM_CONNECTIONS
  @backend.maximum_persistent_connections = DEFAULT_MAXIMUM_PERSISTENT_CONNECTIONS
  @backend.timeout                        = options[:timeout] || DEFAULT_TIMEOUT

  @app = Rack::Builder.new(&amp;block).to_app if block
end
</code></pre>

<p>在初始化服务的过程中，总共只做了三件事情，处理参数、选择并配置 <code>backend</code>，创建新的应用：</p>

<p><img src="https://img.nju520.me/2017-11-04-thin-initialize-server.png" alt="thin-initialize-serve" /></p>

<p>处理参数的过程自然不用多说，只是这里判断的方式并不是按照顺序处理的，而是按照参数的类型；在初始化器的最后，如果向初始化器传入了 block，那么就会使用 <code>Rack::Builder</code> 和 block 中的代码初始化一个新的 Rack 应用。</p>

<h3 id="选择后端">选择后端</h3>

<p>在选择后端时 Thin 使用了 <code>#select_backend</code> 方法，这里使用 <code>case</code> 语句替代多个 <code>if</code>、<code>else</code>，也是一个我们可以使用的小技巧：</p>

<pre><code class="language-ruby">From: lib/thin/server.rb @ line 261:
Owner: Thin::Server

def select_backend(host, port, options)
  case
  when options.has_key?(:backend)
    raise ArgumentError, ":backend must be a class" unless options[:backend].is_a?(Class)
    options[:backend].new(host, port, options)
  when options.has_key?(:swiftiply)
    Backends::SwiftiplyClient.new(host, port, options)
  when host.include?('/')
    Backends::UnixServer.new(host)
  else
    Backends::TcpServer.new(host, port)
  end
end
</code></pre>

<p>在大多数时候，我们只会选择 <code>UnixServer</code> 和 <code>TcpServer</code> 两种后端中的一个，而后者又是两者中使用更为频繁的后端：</p>

<pre><code class="language-ruby">From: lib/thin/backends/tcp_server.rb @ line 8:
Owner: Thin::Backends::TcpServer

def initialize(host, port)
  @host = host
  @port = port
  super()
end

From: lib/thin/backends/base.rb @ line 47:
Owner: Thin::Backends::Base

def initialize
  @connections                    = {}
  @timeout                        = Server::DEFAULT_TIMEOUT
  @persistent_connection_count    = 0
  @maximum_connections            = Server::DEFAULT_MAXIMUM_CONNECTIONS
  @maximum_persistent_connections = Server::DEFAULT_MAXIMUM_PERSISTENT_CONNECTIONS
  @no_epoll                       = false
  @ssl                            = nil
  @threaded                       = nil
  @started_reactor                = false
end
</code></pre>

<p>初始化的过程中只是对属性设置默认值，比如 <code>host</code>、<code>port</code> 以及超时时间等等，并没有太多值得注意的代码。</p>

<h3 id="启动服务">启动服务</h3>

<p>在启动服务时会直接调用 <code>TcpServer#start</code> 方法并在其中传入一个用于处理信号的 block：</p>

<pre><code class="language-ruby">From: lib/thin/server.rb @ line 152:
Owner: Thin::Server

def start
  raise ArgumentError, 'app required' unless @app
  
  log_info  "Thin web server (v#{VERSION::STRING} codename #{VERSION::CODENAME})"
  log_debug "Debugging ON"
  trace     "Tracing ON"
  
  log_info "Maximum connections set to #{@backend.maximum_connections}"
  log_info "Listening on #{@backend}, CTRL+C to stop"

  @backend.start { setup_signals if @setup_signals }
end
</code></pre>

<p>虽然这里的 <code>backend</code> 其实已经被选择成了 <code>TcpServer</code>，但是该子类并没有覆写 <code>#start</code> 方法，这里执行的方法其实是从父类继承的：</p>

<pre><code class="language-ruby">From: lib/thin/backends/base.rb @ line 60:
Owner: Thin::Backends::Base

def start
  @stopping = false
  starter   = proc do
    connect
    yield if block_given?
    @running = true
  end
  
  # Allow for early run up of eventmachine.
  if EventMachine.reactor_running?
    starter.call
  else
    @started_reactor = true
    EventMachine.run(&amp;starter)
  end
end
</code></pre>

<p>上述方法在构建一个 <code>starter</code> block 之后，将该 block 传入 <code>EventMachine.run</code> 方法，随后执行的 <code>#connect</code> 会启动一个 <code>EventMachine</code> 的服务器用于处理用户的网络请求：</p>

<pre><code class="language-ruby">From: lib/thin/backends/tcp_server.rb @ line 15:
Owner: Thin::Backends::TcpServer

def connect
  @signature = EventMachine.start_server(@host, @port, Connection, &amp;method(:initialize_connection))
  binary_name = EventMachine.get_sockname( @signature )
  port_name = Socket.unpack_sockaddr_in( binary_name )
  @port = port_name[0]
  @host = port_name[1]
  @signature
end
</code></pre>

<p>在 EventMachine 的文档中，<code>.start_server</code> 方法被描述成一个在指定的地址和端口上初始化 TCP 服务的方法，正如这里所展示的，它经常在 <code>.run</code> 方法的 block 中执行；该方法的参数 <code>Connection</code> 作为处理 TCP 请求的类，会实现不同的方法接受各种各样的回调，传入的 <code>initialize_connection</code> block 会在有请求需要处理时对 <code>Connection</code> 对象进行初始化：</p>

<blockquote>
  <p><code>Connection</code> 对象继承自 <code>EventMachine::Connection</code>，是 EventMachine 与外界的接口，在 EventMachine 中的大部分事件都会调用 <code>Connection</code> 的一个实例方法来传递数据和参数。</p>
</blockquote>

<pre><code class="language-ruby">From: lib/thin/backends/base.rb @ line 145:
Owner: Thin::Backends::Base

def initialize_connection(connection)
  connection.backend                 = self
  connection.app                     = @server.app
  connection.comm_inactivity_timeout = @timeout
  connection.threaded                = @threaded
  connection.start_tls(@ssl_options) if @ssl

  if @persistent_connection_count &lt; @maximum_persistent_connections
    connection.can_persist!
    @persistent_connection_count += 1
  end
  @connections[connection.__id__] = connection
end
</code></pre>

<h3 id="处理请求的连接">处理请求的连接</h3>

<p><code>Connection</code> 类中有很多的方法 <code>#post_init</code>、<code>#receive_data</code> 方法等等都是由 EventMachine 在接收到请求时调用的，当 Thin 的服务接收到来自客户端的数据时就会调用 <code>#receive_data</code> 方法：</p>

<pre><code class="language-ruby">From: lib/thin/connection.rb @ line 36:
Owner: Thin::Connection

def receive_data(data)
  @idle = false
  trace data
  process if @request.parse(data)
rescue InvalidRequest =&gt; e
  log_error("Invalid request", e)
  post_process Response::BAD_REQUEST
end
</code></pre>

<p>在这里我们看到了与 WEBrick 在处理来自客户端的原始数据时使用的方法 <code>#parse</code>，它会解析客户端请求的原始数据并执行 <code>#process</code> 来处理 HTTP 请求：</p>

<pre><code class="language-ruby">From: lib/thin/connection.rb @ line 47:
Owner: Thin::Connection

def process
  if threaded?
    @request.threaded = true
    EventMachine.defer { post_process(pre_process) }
  else
    @request.threaded = false
    post_process(pre_process)
  end
end
</code></pre>

<p>如果当前的连接允许并行处理多个用户的请求，那么就会在 <code>EventMachine.defer</code> 的 block 中执行两个方法 <code>#pre_process</code> 和 <code>#post_process</code>：</p>

<pre><code class="language-ruby">From: lib/thin/connection.rb @ line 63:
Owner: Thin::Connection

def pre_process
  @request.remote_address = remote_address
  @request.async_callback = method(:post_process)

  response = AsyncResponse
  catch(:async) do
    response = @app.call(@request.env)
  end
  response
rescue Exception =&gt; e
  unexpected_error(e)
  can_persist? &amp;&amp; @request.persistent? ? Response::PERSISTENT_ERROR : Response::ERROR
end
</code></pre>

<p>在 <code>#pre_process</code> 中没有做太多的事情，只是调用了 Rack 应用的 <code>#call</code> 方法，得到一个三元组 <code>response</code>，在这之后将这个数组传入 <code>#post_process</code> 方法：</p>

<pre><code class="language-ruby">From: lib/thin/connection.rb @ line 95:
Owner: Thin::Connection

def post_process(result)
  return unless result
  result = result.to_a
  return if result.first == AsyncResponse.first

  @response.status, @response.headers, @response.body = *result
  @response.each do |chunk|
    send_data chunk
  end
rescue Exception =&gt; e
  unexpected_error(e)
  close_connection
ensure
  if @response.body.respond_to?(:callback) &amp;&amp; @response.body.respond_to?(:errback)
    @response.body.callback { terminate_request }
    @response.body.errback  { terminate_request }
  else
    terminate_request unless result &amp;&amp; result.first == AsyncResponse.first
  end
end
</code></pre>

<p><code>#post_response</code> 方法将传入的数组赋值给 <code>response</code> 的 <code>status</code>、<code>headers</code> 和 <code>body</code> 这三部分，在这之后通过 <code>#send_data</code> 方法将 HTTP 响应以块的形式写回 Socket；写回结束后可能会调用对应的 <code>callback</code> 并关闭持有的 <code>request</code> 和 <code>response</code> 两个实例变量。</p>

<blockquote>
  <p>上述方法中调用的 <code>#send_data</code> 继承自 <code>EventMachine::Connection</code> 类。</p>
</blockquote>

<h3 id="小结">小结</h3>

<p>到此为止，我们对于 Thin 是如何处理来自用户的 HTTP 请求的就比较清楚了，我们可以看到 Thin 本身并没有做一些类似解析 HTTP 数据包以及发送数据的问题，它使用了来自 Rack 和 EventMachine 两个开源框架中很多已有的代码逻辑，确实只做了一些胶水的事情。</p>

<p>对于 Rack 是如何工作的我们在前面的文章 <a href="https://nju520.me/rack">谈谈 Rack 协议与实现</a> 中已经介绍过了；虽然我们看到了很多与 EventMachine 相关的代码，但是到这里我们仍然对 EventMachine 不是太了解。</p>

<h2 id="eventmachine-和-reactor-模式">EventMachine 和 Reactor 模式</h2>

<p>为了更好地理解 Thin 的工作原理，在这里我们会介绍一个 EventMachine 和 Reactor 模式。</p>

<p>EventMachine 其实是一个使用 Ruby 实现的事件驱动的并行框架，它使用 Reactor 模式提供了事件驱动的 IO 模型，如果你对 Node.js 有所了解的话，那么你一定对事件驱动这个词并不陌生，EventMachine 的出现主要是为了解决两个核心问题：</p>

<ul>
  <li>为生产环境提供更高的可伸缩性、更好的性能和稳定性；</li>
  <li>为上层提供了一些能够减少高性能的网络编程复杂性的 API；</li>
</ul>

<p>其实 EventMachine 的主要作用就是将所有同步的 IO 都变成异步的，调度都通过事件来进行，这样用于监听用户请求的进程不会被其他代码阻塞，能够同时为更多的客户端提供服务；在这一节中，我们需要了解一下在 Thin 中使用的 EventMachine 中几个常用方法的实现。</p>

<h3 id="启动事件循环">启动事件循环</h3>

<p>EventMachine 其实就是一个事件循环（Event Loop），当我们想使用 EventMachine 来处理某些任务时就一定需要调用 <code>.run</code> 方法启动这个事件循环来接受外界触发的各种事件：</p>

<pre><code class="language-ruby">From: lib/eventmachine.rb @ line 149:
Owner: #&lt;Class:EventMachine&gt;

def self.run blk=nil, tail=nil, &amp;block
  # ...
  begin
    @reactor_pid = Process.pid
    @reactor_running = true
    initialize_event_machine
    (b = blk || block) and add_timer(0, b)
    if @next_tick_queue &amp;&amp; !@next_tick_queue.empty?
      add_timer(0) { signal_loopbreak }
    end
    @reactor_thread = Thread.current

    run_machine
  ensure
    until @tails.empty?
      @tails.pop.call
    end

    release_machine
    cleanup_machine
    @reactor_running = false
    @reactor_thread = nil
  end
end
</code></pre>

<p>在这里我们会使用 <code>.initialize_event_machine</code> 初始化当前的事件循环，其实也就是一个全局的 <code>Reactor</code> 的单例，最终会执行 <code>Reactor#initialize_for_run</code> 方法：</p>

<pre><code class="language-ruby">From: lib/em/pure_ruby.rb @ line 522:
Owner: EventMachine::Reactor

def initialize_for_run
  @running = false
  @stop_scheduled = false
  @selectables ||= {}; @selectables.clear
  @timers = SortedSet.new # []
  set_timer_quantum(0.1)
  @current_loop_time = Time.now
  @next_heartbeat = @current_loop_time + HeartbeatInterval
end
</code></pre>

<p>在启动事件循环的过程中，它还会将传入的 block 与一个 <code>interval</code> 为 0 的键组成键值对存到 <code>@timers</code> 字典中，所有加入的键值对都会在大约 <code>interval</code> 的时间过后执行一次 block。</p>

<p>随后执行的 <code>#run_machine</code> 在最后也会执行 <code>Reactor</code> 的 <code>#run</code> 方法，该方法中包含一个 loop 语句，也就是我们一直说的事件循环：</p>

<pre><code class="language-ruby">From: lib/em/pure_ruby.rb @ line 540:
Owner: EventMachine::Reactor

def run
  raise Error.new( "already running" ) if @running
  @running = true

  begin
    open_loopbreaker

    loop {
      @current_loop_time = Time.now

      break if @stop_scheduled
      run_timers
      break if @stop_scheduled
      crank_selectables
      break if @stop_scheduled
      run_heartbeats
    }
  ensure
    close_loopbreaker
    @selectables.each {|k, io| io.close}
    @selectables.clear

    @running = false
  end
end
</code></pre>

<p>在启动事件循环之间会在 <code>#open_loopbreaker</code> 中创建一个 <code>LoopbreakReader</code> 的实例绑定在 <code>127.0.0.1</code> 和随机的端口号组成的地址上，然后开始运行事件循环。</p>

<p><img src="https://img.nju520.me/2017-11-04-reactor-eventloop.png" alt="reactor-eventloop" /></p>

<p>在事件循环中，Reactor 总共需要执行三部分的任务，分别是执行定时器、处理 Socket 上的事件以及运行心跳方法。</p>

<p>无论是运行定时器还是执行心跳方法其实都非常简单，只要与当前时间进行比较，如果到了触发的时间就调用正确的方法或者回调，最后的 <code>#crank_selectables</code> 方法就是用于处理 Socket 上读写事件的方法了：</p>

<pre><code class="language-ruby">From: lib/em/pure_ruby.rb @ line 540:
Owner: EventMachine::Reactor

def crank_selectables
  readers = @selectables.values.select { |io| io.select_for_reading? }
  writers = @selectables.values.select { |io| io.select_for_writing? }

  s = select(readers, writers, nil, @timer_quantum)

  s and s[1] and s[1].each { |w| w.eventable_write }
  s and s[0] and s[0].each { |r| r.eventable_read }

  @selectables.delete_if {|k,io|
    if io.close_scheduled?
      io.close
      begin
        EventMachine::event_callback io.uuid, ConnectionUnbound, nil
      rescue ConnectionNotBound; end
      true
    end
  }
end
</code></pre>

<p>上述方法会在 Socket 变成可读或者可写时执行 <code>#eventable_write</code> 或 <code>#eventable_read</code> 执行事件的回调，我们暂时放下这两个方法，先来了解一下 EventMachine 是如何启动服务的。</p>

<h3 id="启动服务-1">启动服务</h3>

<p>在启动服务的过程中，最重要的目的就是创建一个 Socket 并绑定在指定的 ip 和端口上，在实现这个目的的过程中，我们使用了以下的几个方法，首先是 <code>EventMachine.start_server</code>：</p>

<pre><code class="language-ruby">From: lib/eventmachine.rb @ line 516:
Owner: #&lt;Class:EventMachine&gt;

def self.start_server server, port=nil, handler=nil, *args, &amp;block
  port = Integer(port)
  klass = klass_from_handler(Connection, handler, *args)

  s = if port
        start_tcp_server server, port
      else
        start_unix_server server
      end
  @acceptors[s] = [klass, args, block]
  s
end
</code></pre>

<p>该方法其实使我们在使用 EventMachine 时常见的接口，只要我们想要启动一个新的 TCP 或者 UNIX 服务器，就可以上述方法，在这里会根据端口号是否存在，选择执行 <code>.start_tcp_server</code> 或者 <code>.start_unix_server</code> 创建一个新的 Socket 并存储在 <code>@acceptors</code> 中：</p>

<pre><code class="language-ruby">From: lib/em/pure_ruby.rb @ line 184:
Owner: #&lt;Class:EventMachine&gt;

def self.start_tcp_server host, port
  (s = EvmaTCPServer.start_server host, port) or raise "no acceptor"
  s.uuid
end
</code></pre>

<p><code>EventMachine.start_tcp_server</code> 在这里也只做了个『转发』方法的作用的，直接调用 <code>EvmaTCPServer.start_server</code> 创建一个新的 Socket 对象并绑定到传入的 <code>&lt;host, port&gt;</code> 上：</p>

<pre><code class="language-ruby">From: lib/em/pure_ruby.rb @ line 1108:
Owner: #&lt;Class:EventMachine::EvmaTCPServer&gt;

def self.start_server host, port
  sd = Socket.new( Socket::AF_LOCAL, Socket::SOCK_STREAM, 0 )
  sd.setsockopt( Socket::SOL_SOCKET, Socket::SO_REUSEADDR, true )
  sd.bind( Socket.pack_sockaddr_in( port, host ))
  sd.listen( 50 ) # 5 is what you see in all the books. Ain't enough.
  EvmaTCPServer.new sd
end
</code></pre>

<p>方法的最后会创建一个新的 <code>EvmaTCPServer</code> 实例的过程中，我们需要通过 <code>#fcntl</code> 将 Socket 变成非阻塞式的：</p>

<pre><code class="language-ruby">From: lib/em/pure_ruby.rb @ line 687:
Owner: EventMachine::Selectable

def initialize io
  @io = io
  @uuid = UuidGenerator.generate
  @is_server = false
  @last_activity = Reactor.instance.current_loop_time

  m = @io.fcntl(Fcntl::F_GETFL, 0)
  @io.fcntl(Fcntl::F_SETFL, Fcntl::O_NONBLOCK | m)

  @close_scheduled = false
  @close_requested = false

  se = self; @io.instance_eval { @my_selectable = se }
  Reactor.instance.add_selectable @io
end
</code></pre>

<p>不只是 <code>EvmaTCPServer</code>，所有的 <code>Selectable</code> 子类在初始化的最后都会将新的 Socket 以 <code>uuid</code> 为键存储到 <code>Reactor</code> 单例对象的 <code>@selectables</code> 字典中：</p>

<pre><code class="language-ruby">From: lib/em/pure_ruby.rb @ line 532:
Owner: EventMachine::Reactor

def add_selectable io
  @selectables[io.uuid] = io
end
</code></pre>

<p>在整个事件循环的大循环中，这里存入的所有 Socket 都会被 <code>#select</code> 方法监听，在响应的事件发生时交给合适的回调处理，作者在 <a href="https://nju520.me/redis-eventloop">Redis 中的事件循环</a> 一文中也介绍过非常相似的处理过程。</p>

<p><img src="https://img.nju520.me/2017-11-04-eventmachine-select.png" alt="eventmachine-select" /></p>

<p>所有的 Socket 都会存储在一个 <code>@selectables</code> 的哈希中并由 <code>#select</code> 方法监听所有的读写事件，一旦相应的事件触发就会通过 <code>eventable_read</code> 或者 <code>eventable_write</code> 方法来响应该事件。</p>

<h3 id="处理读写事件">处理读写事件</h3>

<p>所有的读写事件都是通过 <code>Selectable</code> 和它的子类来处理的，在 EventMachine 中，总共有以下的几种子类：</p>

<p><img src="https://img.nju520.me/2017-11-04-selectable-and-subclasses.png" alt="selectable-and-subclasses" /></p>

<p>所有处理服务端读写事件的都是 <code>Selectable</code> 的子类，也就是 <code>EvmaTCPServer</code> 和 <code>EvmaUNIXServer</code>，而所有处理客户端读写事件的都是 <code>StreamObject</code> 的子类 <code>EvmaTCPServer</code> 和 <code>EvmaUNIXClient</code>。</p>

<p>当我们初始化的绑定在 <code>&lt;host, port&gt;</code> 上的 Socket 对象监听到了来自用户的 TCP 请求时，当前的 Socket 就会变得可读，事件循环中的 <code>#select</code> 方法就会调用 <code>EvmaTCPClient#eventable_read</code> 通知由一个请求需要处理：</p>

<pre><code class="language-ruby">From: lib/em/pure_ruby.rb @ line 1130:
Owner: EventMachine::EvmaTCPServer

def eventable_read
  begin
    10.times {
      descriptor, peername = io.accept_nonblock
      sd = EvmaTCPClient.new descriptor
      sd.is_server = true
      EventMachine::event_callback uuid, ConnectionAccepted, sd.uuid
    }
  rescue Errno::EWOULDBLOCK, Errno::EAGAIN
  end
end
</code></pre>

<p>在这里会尝试多次 <code>#accept_non_block</code> 当前的 Socket 并会创建一个 TCP 的客户端对象 <code>EvmaTCPClient</code>，同时通过 <code>.event_callback</code> 方法发送 <code>ConnectionAccepted</code> 消息。</p>

<p><code>EventMachine::event_callback</code> 就像是一个用于处理所有事件的中心方法，所有的回调都要通过这个中继器进行调度，在实现上就是一个庞大的 <code>if</code>、<code>else</code> 语句，里面处理了 EventMachine 中可能出现的 10 种状态和操作：</p>

<p><img src="https://img.nju520.me/2017-11-04-event-callback.png" alt="event-callback" /></p>

<p>大多数事件在触发时，都会从 <code>@conns</code> 中取出相应的 <code>Connection</code> 对象，最后执行合适的方法来处理，而这里触发的 <code>ConnectionAccepted</code> 事件是通过以下的代码来处理的：</p>

<pre><code class="language-ruby">From: lib/eventmachine.rb @ line 1462:
Owner: #&lt;Class:EventMachine&gt;

def self.event_callback conn_binding, opcode, data
  if opcode == # ...
    # ...
  elsif opcode == ConnectionAccepted
    accep, args, blk = @acceptors[conn_binding]
    raise NoHandlerForAcceptedConnection unless accep
    c = accep.new data, *args
    @conns[data] = c
    blk and blk.call(c)
    c
  else
    # ...
  end
end
</code></pre>

<p>上述的 <code>accep</code> 变量就是我们在 Thin 调用 <code>.start_server</code> 时传入的 <code>Connection</code> 类，在这里我们初始化了一个新的实例，同时以 Socket 的 <code>uuid</code> 作为键存到 <code>@conns</code> 中。</p>

<p>在这之后 <code>#select</code> 方法就会监听更多 Socket 上的事件了，当这个 “accept” 后创建的 Socket 接收到数据时，就会触发下面的 <code>#eventable_read</code> 方法：</p>

<pre><code class="language-ruby">From: lib/em/pure_ruby.rb @ line 1130:
Owner: EventMachine::StreamObject

def eventable_read
  @last_activity = Reactor.instance.current_loop_time
  begin
    if io.respond_to?(:read_nonblock)
      10.times {
        data = io.read_nonblock(4096)
        EventMachine::event_callback uuid, ConnectionData, data
      }
    else
      data = io.sysread(4096)
      EventMachine::event_callback uuid, ConnectionData, data
    end
  rescue Errno::EAGAIN, Errno::EWOULDBLOCK, SSLConnectionWaitReadable
  rescue Errno::ECONNRESET, Errno::ECONNREFUSED, EOFError, Errno::EPIPE, OpenSSL::SSL::SSLError
    @close_scheduled = true
    EventMachine::event_callback uuid, ConnectionUnbound, nil
  end
end
</code></pre>

<p>方法会从 Socket 中读取数据并通过 <code>.event_callback</code> 发送 <code>ConnectionData</code> 事件：</p>

<pre><code class="language-ruby">From: lib/eventmachine.rb @ line 1462:
Owner: #&lt;Class:EventMachine&gt;

def self.event_callback conn_binding, opcode, data
  if opcode == # ...
    # ...
  elsif opcode == ConnectionData
    c = @conns[conn_binding] or raise ConnectionNotBound, "received data #{data} for unknown signature: #{conn_binding}"
    c.receive_data data
  else
    # ...
  end
end
</code></pre>

<p>从上述方法对 <code>ConnectionData</code> 事件的处理就可以看到通过传入 Socket 的 <code>uuid</code> 和数据，就可以找到上面初始化的 <code>Connection</code> 对象，<code>#receive_data</code> 方法就能够将数据传递到上层，让用户在自定义的 <code>Connection</code> 中实现自己的处理逻辑，这也就是 Thin 需要覆写 <code>#receive_data</code> 方法来接受数据的原因了。</p>

<p>当 Thin 以及 Rack 应用已经接收到了来自用户的请求、完成处理并返回之后经过一系列复杂的调用栈就会执行 <code>Connection#send_data</code> 方法：</p>

<pre><code class="language-ruby">From: lib/em/connection.rb @ line 324:
Owner: EventMachine::Connection

def send_data data
  data = data.to_s
  size = data.bytesize if data.respond_to?(:bytesize)
  size ||= data.size
  EventMachine::send_data @signature, data, size
end

From: lib/em/pure_ruby.rb @ line 172:
Owner: #&lt;Class:EventMachine&gt;

def self.send_data target, data, datalength
  selectable = Reactor.instance.get_selectable( target ) or raise "unknown send_data target"
  selectable.send_data data
end

From: lib/em/pure_ruby.rb @ line 851:
Owner: EventMachine::StreamObject

def send_data data
  unless @close_scheduled or @close_requested or !data or data.length &lt;= 0
    @outbound_q &lt;&lt; data.to_s
  end
end
</code></pre>

<p>经过一系列同名方法的调用，在调用栈末尾的 <code>StreamObject#send_data</code> 中，将所有需要写入的数据全部加入 <code>@outbound_q</code> 中，这其实就是一个待写入数据的队列。</p>

<p>当 Socket 变得可写之后，就会由 <code>#select</code> 方法触发 <code>#eventable_write</code> 将 <code>@outbound_q</code> 队列中的数据通过 <code>#write_nonblock</code> 或者 <code>syswrite</code> 写入 Socket，也就是将请求返回给客户端。</p>

<pre><code class="language-ruby">From: lib/em/pure_ruby.rb @ line 823:
Owner: EventMachine::StreamObject

def eventable_write
  @last_activity = Reactor.instance.current_loop_time
  while data = @outbound_q.shift do
    begin
      data = data.to_s
      w = if io.respond_to?(:write_nonblock)
            io.write_nonblock data
          else
            io.syswrite data
          end

      if w &lt; data.length
        @outbound_q.unshift data[w..-1]
        break
      end
    rescue Errno::EAGAIN, SSLConnectionWaitReadable, SSLConnectionWaitWritable
      @outbound_q.unshift data
      break
    rescue EOFError, Errno::ECONNRESET, Errno::ECONNREFUSED, Errno::EPIPE, OpenSSL::SSL::SSLError
      @close_scheduled = true
      @outbound_q.clear
    end
  end
end
</code></pre>

<h3 id="关闭-socket">关闭 Socket</h3>

<p>当数据写入时发生了 <code>EOFError</code> 或者其他错误时就会将 <code>close_scheduled</code> 标记为 <code>true</code>，在随后的事件循环中会关闭 Socket 并发送 <code>ConnectionUnbound</code> 事件：</p>

<pre><code class="language-ruby">From: lib/em/pure_ruby.rb @ line 540:
Owner: EventMachine::Reactor

def crank_selectables
  # ...

  @selectables.delete_if {|k,io|
    if io.close_scheduled?
      io.close
      begin
        EventMachine::event_callback io.uuid, ConnectionUnbound, nil
      rescue ConnectionNotBound; end
      true
    end
  }
end
</code></pre>

<p><code>.event_callback</code> 在处理 <code>ConnectionUnbound</code> 事件时会在 <code>@conns</code> 中将结束的 <code>Connection</code> 剔除：</p>

<pre><code class="language-ruby">def self.event_callback conn_binding, opcode, data
  if opcode == ConnectionUnbound
    if c = @conns.delete( conn_binding )
      c.unbind
      io = c.instance_variable_get(:@io)
      begin
        io.close
      rescue Errno::EBADF, IOError
      end
    elsif c = @acceptors.delete( conn_binding )
    else
      raise ConnectionNotBound, "received ConnectionUnbound for an unknown signature: #{conn_binding}"
    end
  elsif opcode = 1
    #...
  end
end
</code></pre>

<p>在这之后会调用 <code>Connection</code> 的 <code>#unbind</code> 方法，再次执行 <code>#close</code> 确保 Socket 连接已经断掉了。</p>

<h3 id="小结-1">小结</h3>

<p>EventMachine 在处理用户的请求时，会通过一个事件循环和一个中心化的事件处理中心 <code>.event_callback</code> 来响应所有的事件，你可以看到在使用 EventMachine 时所有的响应都是异步的，尤其是对 Socket 的读写，所有外部的输入在 EventMachine 看来都是一个事件，它们会被 EventMachine 选择合适的处理器进行转发。</p>

<h2 id="io-模型">I/O 模型</h2>

<p>Thin 本身其实没有实现任何的 I/O 模型，它通过对 EventMachine 进行封装，使用了其事件驱动的特点，为上层提供了处理并发 I/O 的 Reactor 模型，在不同的阶段有着不同的工作流程，在启动 Thin 的服务时，Thin 会直接通过 <code>.start_server</code> 创建一个 Socket 监听一个 <code>&lt;host, port&gt;</code> 组成的元组：</p>

<p><img src="https://img.nju520.me/2017-11-04-thin-start-server.png" alt="thin-start-server" /></p>

<p>当服务启动之后，就可以接受来自客户端的 HTTP 请求了，处理 HTTP 请求总共需要三个模块的合作，分别是 EventMachine、Thin 以及 Rack 应用：</p>

<p><img src="https://img.nju520.me/2017-11-04-thin-handle-request.png" alt="thin-handle-request" /></p>

<p>在上图中省略了 Rack 的处理部分，不过对于其他部分的展示还是比较详细的，EventMachine 负责对 TCP Socket 进行监听，在发生事件时通过 <code>.event_callback</code> 进行处理，将消息转发给位于 Thin 中的 <code>Connection</code>，该类以及模块负责处理 HTTP 协议相关的内容，将整个请求包装成一个 <code>env</code> 对象，调用 <code>#call</code> 方法。</p>

<p>在这时就开始了返回响应的逻辑了，<code>#call</code> 方法会返回一个三元组，经过 Thin 中的 <code>#send_data</code> 最终将数据写入 <code>outbound_q</code> 队列中等待处理：</p>

<p><img src="https://img.nju520.me/2017-11-04-thin-send-response.png" alt="thin-send-response" /></p>

<p>EventMachine 会通过一个事件循环，使用 <code>#select</code> 监听当前 Socket 的可读写状态，并在合适的时候触发 <code>#eventable_write</code> 从 <code>outbound_q</code> 队列中读取数据写入 Socket，在写入结束后 Socket 就会被关闭，整个请求的响应也就结束了。</p>

<p><img src="https://img.nju520.me/2017-11-04-thin-io-model.png" alt="thin-io-model" /></p>

<p>Thin 使用了 EventMachine 作为底层处理 TCP 协议的框架，提供了事件驱动的 I/O 模型，也就是我们理解的 Reactor 模型，对于每一个 HTTP 请求都会创建一个对应的 <code>Connection</code> 对象，所有的事件都由 EventMachine 来派发，最大程度做到了 I/O 的读写都是异步的，不会阻塞当前的线程，这也是 Thin 以及 Node.js 能够并发处理大量请求的原因。</p>

<h2 id="总结">总结</h2>

<p>Thin 作为一个 Ruby 社区中简单的 webserver，其实本身没有做太多的事情，只是使用了 EventMachine 提供的事件驱动的 I/O 模型，为上层提供了更加易用的 API，相比于其他同步处理请求的 webserver，Reactor 模式的优点就是 Thin 的优点，主程序只负责监听事件和分发事件，一旦涉及到 I/O 的工作都尽量使用回调的方式处理，当回调完成后再发送通知，这种方式能够减少进程的等待时间，时刻都在处理用户的请求和事件。</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://zedshaw.com/archive/ragel-state-charts/">Ragel State Charts</a></li>
  <li><a href="http://www.colm.net/open-source/ragel/">Ragel State Machine Compiler</a></li>
  <li><a href="https://www.igvita.com/2008/05/27/ruby-eventmachine-the-speed-demon/">Ruby EventMachine - The Speed Demon</a></li>
</ul>


  ]]></description>
</item>

<item>
  <title>浅谈 WEBrick 的多线程模型</title>
  <link>//rack-webrick</link>
  <author>nju520</author>
  <pubDate>2017-11-01T00:00:00+08:00</pubDate>
  <guid>//rack-webrick</guid>
  <description><![CDATA[
  <ul>
  <li><a href="https://nju520.me/rack">谈谈 Rack 协议与实现</a></li>
  <li><a href="https://nju520.me/rack-webrick">浅谈 WEBrick 的多线程模型</a></li>
  <li><a href="https://nju520.me/rack-thin">浅谈 Thin 的事件驱动模型</a></li>
  <li><a href="https://nju520.me/rack-unicorn">浅谈 Unicorn 的多进程模型</a></li>
  <li><a href="https://nju520.me/rack-puma">浅谈 Puma 的并发模型与实现</a></li>
  <li><a href="https://nju520.me/ruby-webserver">Ruby Web 服务器的并发模型与性能</a></li>
</ul>

<p>这篇文章会介绍在开发环境中最常用的应用容器 WEBrick 的实现原理，除了通过源代码分析之外，我们也会介绍它的 IO 模型以及一些特点。</p>

<p>在 GitHub 上，WEBrick 从 2003 年的六月份就开始开发了，有着十几年历史的 WEBrick 的实现非常简单，总共只有 4000 多行的代码：</p>

<pre><code class="language-ruby">$ loc_counter .
40 files processed
Total     6918 lines
Empty     990 lines
Comments  1927 lines
Code      4001 lines
</code></pre>

<h2 id="webrick-的实现">WEBrick 的实现</h2>

<p>由于 WEBrick 是 Rack 中内置的处理器，所以与 Unicorn 和 Puma 这种第三方开发的 webserver 不同，WEBrick 的处理器是在 Rack 中实现的，而 WEBrick 的运行也都是从这个处理器的开始的。</p>

<pre><code class="language-ruby">module Rack
  module Handler
    class WEBrick &lt; ::WEBrick::HTTPServlet::AbstractServlet
      def self.run(app, options={})
        environment  = ENV['RACK_ENV'] || 'development'
        default_host = environment == 'development' ? 'localhost' : nil

        options[:BindAddress] = options.delete(:Host) || default_host
        options[:Port] ||= 8080
        @server = ::WEBrick::HTTPServer.new(options)
        @server.mount "/", Rack::Handler::WEBrick, app
        yield @server  if block_given?
        @server.start
      end
    end
  end
end
</code></pre>

<p>我们在上一篇文章 <a href="https://nju520.me/rack">谈谈 Rack 协议与实现</a> 中介绍 Rack 的实现原理时，最终调用了上述方法，从这里开始大部分的实现都与 WEBrick 有关了。</p>

<p>在这里，你可以看到方法会先处理传入的参数比如：地址、端口号等等，在这之后会使用 WEBrick 提供的 <code>HTTPServer</code> 来处理 HTTP 请求，调用 <code>mount</code> 在根路由上挂载应用和处理器 <code>Rack::Handler::WEBrick</code> 接受请求，最后执行 <code>#start</code> 方法启动服务器。</p>

<h3 id="初始化服务器">初始化服务器</h3>

<p><code>HTTPServer</code> 的初始化分为两个阶段，一部分是 <code>HTTPServer</code> 的初始化，另一部分调用父类的 <code>initialize</code> 方法，在自己构造器中，会配置当前服务器能够处理的 HTTP 版本并初始化新的 <code>MountTable</code> 实例：</p>

<pre><code class="language-ruby">From: lib/webrick/httpserver.rb @ line 46:
Owner: #&lt;Class:WEBrick::HTTPServer&gt;

def initialize(config={}, default=Config::HTTP)
  super(config, default)
  @http_version = HTTPVersion::convert(@config[:HTTPVersion])

  @mount_tab = MountTable.new
  if @config[:DocumentRoot]
    mount("/", HTTPServlet::FileHandler, @config[:DocumentRoot],
          @config[:DocumentRootOptions])
  end

  unless @config[:AccessLog]
    @config[:AccessLog] = [
      [ $stderr, AccessLog::COMMON_LOG_FORMAT ],
      [ $stderr, AccessLog::REFERER_LOG_FORMAT ]
    ]
  end

  @virtual_hosts = Array.new
end
</code></pre>

<p>在父类 <code>GenericServer</code> 中初始化了用于监听端口号的 Socket 连接：</p>

<pre><code class="language-ruby">From: lib/webrick/server.rb @ line 185:
Owner: #&lt;Class:WEBrick::GenericServer&gt;

def initialize(config={}, default=Config::General)
  @config = default.dup.update(config)
  @status = :Stop

  @listeners = []
  listen(@config[:BindAddress], @config[:Port])
  if @config[:Port] == 0
    @config[:Port] = @listeners[0].addr[1]
  end
end
</code></pre>

<p>每一个服务器都会在初始化的时候创建一系列的 <code>listener</code> 用于监听地址和端口号组成的元组，其内部调用了 <code>Utils</code> 模块中定义的方法：</p>

<pre><code class="language-ruby">From: lib/webrick/server.rb @ line 127:
Owner: #&lt;Class:WEBrick::GenericServer&gt;

def listen(address, port)
  @listeners += Utils::create_listeners(address, port)
end

From: lib/webrick/utils.rb @ line 61:
Owner: #&lt;Class:WEBrick::Utils&gt;

def create_listeners(address, port)
  sockets = Socket.tcp_server_sockets(address, port)
  sockets = sockets.map {|s|
    s.autoclose = false
    ts = TCPServer.for_fd(s.fileno)
    s.close
    ts
  }
  return sockets
end
module_function :create_listeners
</code></pre>

<p>在 <code>.create_listeners</code> 方法中调用了 <code>.tcp_server_sockets</code> 方法由于初始化一组 <code>Socket</code> 对象，最后得到一个数组的 <code>TCPServer</code> 实例。</p>

<h3 id="挂载应用">挂载应用</h3>

<p>在使用 <code>WEBrick</code> 启动服务的时候，第二步就是将处理器和 Rack 应用挂载到根路由下：</p>

<pre><code class="language-ruby">@server.mount "/", Rack::Handler::WEBrick, app
</code></pre>

<p><code>#mount</code> 方法其实是一个比较简单的方法，因为我们在构造器中已经初始化了 <code>MountTable</code> 对象，所以这一步只是将传入的多个参数放到这个表中：</p>

<pre><code class="language-ruby">From: lib/webrick/httpserver.rb @ line 155:
Owner: WEBrick::HTTPServer

def mount(dir, servlet, *options)
  @mount_tab[dir] = [ servlet, options ]
end
</code></pre>

<p><code>MountTable</code> 是一个包含从路由到 Rack 处理器一个 App 的映射表：</p>

<p><img src="https://img.nju520.me/2017-11-01-mounttable-and-applications.png" alt="mounttable-and-applications" /></p>

<p>当执行了 <code>MountTable</code> 的 <code>#compile</code> 方法时，上述的对象就会将表中的所有键按照加入的顺序逆序拼接成一个如下的正则表达式用来匹配传入的路由：</p>

<pre><code class="language-ruby">^(/|/admin|/user)(?=/|$)
</code></pre>

<p>上述正则表达式在使用时如果匹配到了指定的路由就会返回 <code>$&amp;</code> 和 <code>$'</code> 两个部分，前者表示整个匹配的文本，后者表示匹配文本后面的字符串。</p>

<h3 id="启动服务器">启动服务器</h3>

<p>在 <code>Rack::Handler::WEBrick</code> 中的 <code>.run</code> 方法先初始化了服务器，将处理器和应用挂载到了根路由上，在最后执行 <code>#start</code> 方法启动服务器：</p>

<pre><code class="language-ruby">From: lib/webrick/server.rb @ line 152:
Owner: WEBrick::GenericServer

def start(&amp;block)
  raise ServerError, "already started." if @status != :Stop

  @status = :Running
  begin
    while @status == :Running
      begin
        if svrs = IO.select([*@listeners], nil, nil, 2.0)
          svrs[0].each{ |svr|
            sock = accept_client(svr)
            start_thread(sock, &amp;block)
          }
        end
      rescue Errno::EBADF, Errno::ENOTSOCK, IOError, StandardError =&gt; ex
      rescue Exception =&gt; ex
        raise
      end
    end
  ensure
    cleanup_listener
    @status = :Stop
  end
end
</code></pre>

<p>由于原方法的实现比较复杂不容易阅读，在这里对方法进行了简化，省略了向 logger 中输出内容、处理服务的关闭以及执行回调等功能。</p>

<p>我们可以理解为上述方法通过 <code>.select</code> 方法对一组 Socket 进行监听，当有消息需要处理时就依次执行 <code>#accept_client</code> 和 <code>#start_thread</code> 两个方法处理来自客户端的请求：</p>

<pre><code class="language-ruby">From: lib/webrick/server.rb @ line 254:
Owner: WEBrick::GenericServer

def accept_client(svr)
  sock = nil
  begin
    sock = svr.accept
    sock.sync = true
    Utils::set_non_blocking(sock)
  rescue Errno::ECONNRESET, Errno::ECONNABORTED,
         Errno::EPROTO, Errno::EINVAL
  rescue StandardError =&gt; ex
    msg = "#{ex.class}: #{ex.message}\n\t#{ex.backtrace[0]}"
    @logger.error msg
  end
  return sock
end
</code></pre>

<p>WEBrick 在 <code>#accept_client</code> 方法中执行了 <code>#accept</code> 方法来得到一个 TCP 客户端 Socket，同时会通过 <code>set_non_blocking</code> 将该 Socket 变成非阻塞的，最后在方法末尾返回创建的 Socket。</p>

<p>在 <code>#start_thread</code> 方法中会<strong>开启一个新的线程</strong>，并在新的线程中执行 <code>#run</code> 方法来处理请求：</p>

<pre><code class="language-ruby">From: lib/webrick/server.rb @ line 278:
Owner: WEBrick::GenericServer

def start_thread(sock, &amp;block)
  Thread.start {
    begin
      Thread.current[:WEBrickSocket] = sock
      run(sock)
    rescue Errno::ENOTCONN, ServerError, Exception
    ensure
      Thread.current[:WEBrickSocket] = nil
      sock.close
    end
  }
end
</code></pre>

<h3 id="处理请求">处理请求</h3>

<p>所有的请求都不会由 <code>GenericServer</code> 这个通用的服务器来处理，它只处理通用的逻辑，对于 HTTP 请求的处理都是在 <code>HTTPServer#run</code> 中完成的：</p>

<pre><code class="language-ruby">From: lib/webrick/httpserver.rb @ line 69:
Owner: WEBrick::HTTPServer

def run(sock)
  while true
    res = HTTPResponse.new(@config)
    req = HTTPRequest.new(@config)
    server = self
    begin
      timeout = @config[:RequestTimeout]
      while timeout &gt; 0
        break if sock.to_io.wait_readable(0.5)
        break if @status != :Running
        timeout -= 0.5
      end
      raise HTTPStatus::EOFError if timeout &lt;= 0 || @status != :Running
      raise HTTPStatus::EOFError if sock.eof?
      req.parse(sock)
      res.request_method = req.request_method
      res.request_uri = req.request_uri
      res.request_http_version = req.http_version
      self.service(req, res)
    rescue HTTPStatus::EOFError, HTTPStatus::RequestTimeout, HTTPStatus::Error =&gt; ex
      res.set_error(ex)
    rescue HTTPStatus::Status =&gt; ex
      res.status = ex.code
    rescue StandardError =&gt; ex
      res.set_error(ex, true)
    ensure
      res.send_response(sock) if req.request_line
    end
    break if @http_version &lt; "1.1"
  end
end
</code></pre>

<p>对 HTTP 协议了解的读者应该能从上面的代码中看到很多与 HTTP 协议相关的东西，比如 HTTP 的版本号、方法、URL 等等，上述方法总共做了三件事情，等待监听的 Socket 变得可读，执行 <code>#parse</code> 方法解析 Socket 上的数据，通过 <code>#service</code> 方法完成处理请求的响应，首先是对 Socket 上的数据进行解析：</p>

<pre><code class="language-ruby">From: lib/webrick/httprequest.rb @ line 192:
Owner: WEBrick::HTTPRequest

def parse(socket=nil)
  @socket = socket
  begin
    @peeraddr = socket.respond_to?(:peeraddr) ? socket.peeraddr : []
    @addr = socket.respond_to?(:addr) ? socket.addr : []
  rescue Errno::ENOTCONN
    raise HTTPStatus::EOFError
  end

  read_request_line(socket)
  if @http_version.major &gt; 0
    # ...
  end
  return if @request_method == "CONNECT"
  return if @unparsed_uri == "*"

  begin
    setup_forwarded_info
    @request_uri = parse_uri(@unparsed_uri)
    @path = HTTPUtils::unescape(@request_uri.path)
    @path = HTTPUtils::normalize_path(@path)
    @host = @request_uri.host
    @port = @request_uri.port
    @query_string = @request_uri.query
    @script_name = ""
    @path_info = @path.dup
  rescue
    raise HTTPStatus::BadRequest, "bad URI `#{@unparsed_uri}'."
  end

  if /close/io =~ self["connection"]
    # deal with keep alive
  end
end
</code></pre>

<p>由于 HTTP 协议本身就比较复杂，请求中包含的信息也非常多，所以在这里用于<strong>解析</strong> HTTP 请求的代码也很多，想要了解 WEBrick 是如何解析 HTTP 请求的可以看 httprequest.rb 文件中的代码，在处理了 HTTP 请求之后，就开始执行 <code>#service</code> 响应该 HTTP 请求了：</p>

<pre><code class="language-ruby">From: lib/webrick/httpserver.rb @ line 125:
Owner: WEBrick::HTTPServer

def service(req, res)
  servlet, options, script_name, path_info = search_servlet(req.path)
  raise HTTPStatus::NotFound, "`#{req.path}' not found." unless servlet
  req.script_name = script_name
  req.path_info = path_info
  si = servlet.get_instance(self, *options)
  si.service(req, res)
end
</code></pre>

<p>在这里我们会从上面提到的 <code>MountTable</code> 中找出在之前注册的处理器 handler 和 Rack 应用：</p>

<pre><code class="language-ruby">From: lib/webrick/httpserver.rb @ line 182:
Owner: WEBrick::HTTPServer

def search_servlet(path)
  script_name, path_info = @mount_tab.scan(path)
  servlet, options = @mount_tab[script_name]
  if servlet
    [ servlet, options, script_name, path_info ]
  end
end
</code></pre>

<p>得到了处理器 handler 之后，通过 <code>.get_instance</code> 方法创建一个新的实例，这个方法在大多数情况下等同于初始化方法 <code>.new</code>，随后调用了该处理器 <code>Rack::WEBrick::Handler</code> 的 <code>#service</code> 方法，该方法是在 rack 工程中定义的：</p>

<pre><code class="language-ruby">From: rack/lib/handler/webrick.rb @ line 57:
Owner: Rack::Handler::WEBrick

def service(req, res)
  res.rack = true
  env = req.meta_vars
  env.delete_if { |k, v| v.nil? }

  env.update(
    # ...
    RACK_URL_SCHEME   =&gt; ["yes", "on", "1"].include?(env[HTTPS]) ? "https" : "http",
    # ...
  )
  
  status, headers, body = @app.call(env)
  begin
    res.status = status.to_i
    headers.each { |k, vs|
      # ...
    }

    body.each { |part|
      res.body &lt;&lt; part
    }
  ensure
    body.close  if body.respond_to? :close
  end
end
</code></pre>

<p>由于上述方法也涉及了非常多 HTTP 协议的实现细节所以很多过程都被省略了，在上述方法中，我们先构建了应用的输入 <code>env</code> 哈希变量，然后通过执行 <code>#call</code> 方法将控制权交给 Rack 应用，最后获得一个由 <code>status</code>、<code>headers</code> 和 <code>body</code> 组成的三元组；在接下来的代码中，分别对这三者进行处理，为这次请求『填充』一个完成的 HTTP 请求。</p>

<p>到这里，最后由 <code>WEBrick::HTTPServer#run</code> 方法中的 <code>ensure</code> block 来结束整个 HTTP 请求的处理：</p>

<pre><code class="language-ruby">From: lib/webrick/httpserver.rb @ line 69:
Owner: WEBrick::HTTPServer

def run(sock)
  while true
    res = HTTPResponse.new(@config)
    req = HTTPRequest.new(@config)
    server = self
    begin
      # ...
    ensure
      res.send_response(sock) if req.request_line
    end
    break if @http_version &lt; "1.1"
  end
end
</code></pre>

<p>在 <code>#send_reponse</code> 方法中，分别执行了 <code>#send_header</code> 和 <code>#send_body</code> 方法向当前的 Socket 中发送 HTTP 响应中的数据：</p>

<pre><code class="language-ruby">From: lib/webrick/httpresponse @ line 205:
Owner: WEBrick::HTTPResponse

def send_response(socket)
  begin
    setup_header()
    send_header(socket)
    send_body(socket)
  rescue Errno::EPIPE, Errno::ECONNRESET, Errno::ENOTCONN =&gt; ex
    @logger.debug(ex)
    @keep_alive = false
  rescue Exception =&gt; ex
    @logger.error(ex)
    @keep_alive = false
  end
end
</code></pre>

<p>所有向 Socket 中写入数据的工作最终都会由 <code>#_write_data</code> 这个方法来处理，将数据全部写入 Socket 中：</p>

<pre><code class="language-ruby">From: lib/webrick/httpresponse @ line 464:
Owner: WEBrick::HTTPResponse

def _write_data(socket, data)
  socket &lt;&lt; data
end
</code></pre>

<p>从解析 HTTP 请求、调用 Rack 应用、创建 Response 到最后向 Socket 中写回数据，WEBrick 处理 HTTP 请求的部分就结束了。</p>

<h2 id="io-模型">I/O 模型</h2>

<p>通过对 WEBrick 源代码的阅读，我们其实已经能够了解整个 webserver 的工作原理，当我们启动一个 WEBrick 服务时只会启动一个进程，该进程会在指定的 ip 和端口上使用 <code>.select</code> 监听来自用户的所有 HTTP 请求：</p>

<p><img src="https://img.nju520.me/2017-11-01-webrick-io-model.png" alt="webrick-io-mode" /></p>

<p>当 <code>.select</code> 接收到来自用户的请求时，会为每一个请求创建一个新的 <code>Thread</code> 并在新的线程中对 HTTP 请求进行处理。</p>

<p>由于 WEBrick 在运行时只会启动一个进程，并没有其他的守护进程，所以它不够健壮，不能在发生问题时重启持续对外界提供服务，再加上 WEBrick 确实历史比较久远，代码的风格也不是特别的优雅，还有普遍知道的内存泄漏以及 HTTP 解析的问题，所以在生产环境中很少被使用。</p>

<p>虽然 WEBrick 有一些性能问题，但是作为 Ruby 自带的默认 webserver，在开发阶段使用 WEBrick 提供服务还是没有什么问题的。</p>

<h2 id="总结">总结</h2>

<p>WEBrick 是 Ruby 社区中老牌的 webserver，虽然至今也仍然被广泛了解和使用，但是在生产环境中开发者往往会使用更加稳定的 Unicorn 和 Puma 代替它，我们选择在这个系列的文章中介绍它很大原因就是 WEBrick 的源代码与实现足够简单，我们很快就能了解一个 webserver 到底具备那些功能，在接下来的文章中我们就可以分析更加复杂的 webserver、了解更复杂的 IO 模型与实现了。</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://stackoverflow.com/questions/4113299/ruby-on-rails-server-options">Ruby on Rails Server options</a></li>
</ul>


  ]]></description>
</item>

<item>
  <title>谈谈 Rack 的协议与实现</title>
  <link>//rack</link>
  <author>nju520</author>
  <pubDate>2017-10-29T00:00:00+08:00</pubDate>
  <guid>//rack</guid>
  <description><![CDATA[
  <ul>
  <li><a href="https://nju520.me/rack">谈谈 Rack 协议与实现</a></li>
  <li><a href="https://nju520.me/rack-webrick">浅谈 WEBrick 的多线程模型</a></li>
  <li><a href="https://nju520.me/rack-thin">浅谈 Thin 的事件驱动模型</a></li>
  <li><a href="https://nju520.me/rack-unicorn">浅谈 Unicorn 的多进程模型</a></li>
  <li><a href="https://nju520.me/rack-puma">浅谈 Puma 的并发模型与实现</a></li>
  <li><a href="https://nju520.me/ruby-webserver">Ruby Web 服务器的并发模型与性能</a></li>
</ul>

<p>作为 Rails 开发者，基本上每天都与 Rails 的各种 API 以及数据库打交道，Rails 的世界虽然非常简洁，不过其内部的实现还是很复杂的，很多刚刚接触 Rails 的开发者可能都不知道 Rails 其实就是一个 <a href="https://github.com/rack/rack">Rack</a> 应用，在这一系列的文章中，我们会分别介绍 Rack 以及一些常见的遵循 Rack 协议的 webserver 的实现原理。</p>

<p><img src="https://img.nju520.me/2017-10-29-rack-logo.png" alt="rack-logo" /></p>

<p>不只是 Rails，几乎所有的 Ruby 的 Web 框架都是一个 Rack 的应用，除了 Web 框架之外，Rack 也支持相当多的 Web 服务器，可以说 Ruby 世界几乎一切与 Web 相关的服务都与 Rack 有关。</p>

<p><img src="https://img.nju520.me/2017-10-29-rack-and-web-servers-frameworks.png" alt="rack-and-web-servers-frameworks" /></p>

<p>所以如果想要了解 Rails 或者其他 Web 服务底层的实现，那么一定需要了解 Rack 是如何成为应用容器（webserver）和应用框架之间的桥梁的，本文中介绍的是 2.0.3 版本的 rack。</p>

<h2 id="rack-协议">Rack 协议</h2>

<p>在 Rack 的协议中，将 Rack 应用描述成一个可以响应 <code>call</code> 方法的 Ruby 对象，它仅接受来自外界的一个参数，也就是环境，然后返回一个只包含三个值的数组，按照顺序分别是状态码、HTTP Headers 以及响应请求的正文。</p>

<blockquote>
  <p>A Rack application is a Ruby object (not a class) that responds to call. It takes exactly one argument, the environment and returns an Array of exactly three values: The status, the headers, and the body.</p>
</blockquote>

<p><img src="https://img.nju520.me/2017-10-29-rack-protocol.png" alt="rack-protoco" /></p>

<p>Rack 在 webserver 和应用框架之间提供了一套最小的 API 接口，如果 webserver 都遵循 Rack 提供的这套规则，那么所有的框架都能通过协议任意地改变底层使用 webserver；所有的 webserver 只需要在 <code>Rack::Handler</code> 的模块中创建一个实现了 <code>.run</code> 方法的类就可以了：</p>

<pre><code class="language-ruby">module Rack
  module Handler
    class WEBrick &lt; ::WEBrick::HTTPServlet::AbstractServlet
      def self.run(app, options={})
        # ..
      end
    end
  end
end
</code></pre>

<p>这个类方法接受两个参数，分别是一个 Rack 应用对象和一个包含各种参数的 <code>options</code> 字典，其中可能包括自定义的 ip 地址和端口号以及各种配置，根据 Rack 协议，所有应用对象在接受到一个 <code>#call</code> 方法并且传入 <code>env</code> 时，都会返回一个三元组：</p>

<p><img src="https://img.nju520.me/2017-10-29-rack-app.png" alt="rack-app" /></p>

<p>最后的 <code>body</code> 响应体其实是一个由多个响应内容组成的数组，Rack 使用的 webserver 会将 <code>body</code> 中几个部分的连接到一起最后拼接成一个 HTTP 响应后返回。</p>

<h2 id="rack-的使用">Rack 的使用</h2>

<p>我们在大致了解 Rack 协议之后，其实可以从一段非常简单的代码入手来了解 Rack 是如何启动 webserver 来处理来自用户的请求的，我们可以在任意目录下创建如下所示的 config.ru 文件：</p>

<pre><code class="language-ruby"># config.ru

run Proc.new { |env| ['200', {'Content-Type' =&gt; 'text/html'}, ['get rack\'d']] }
</code></pre>

<blockquote>
  <p>因为 <code>Proc</code> 对象也能够响应 <code>#call</code> 方法，所以上述的 Proc 对象也可以看做是一个 Rack 应用。</p>
</blockquote>

<p>接下来，我们在同一目录使用 <code>rackup</code> 命令在命令行中启动一个 webserver 进程：</p>

<pre><code class="language-bash">$ rackup config.ru
[2017-10-26 22:59:26] INFO  WEBrick 1.3.1
[2017-10-26 22:59:26] INFO  ruby 2.3.3 (2016-11-21) [x86_64-darwin16]
[2017-10-26 22:59:26] INFO  WEBrick::HTTPServer#start: pid=83546 port=9292
</code></pre>

<p>从命令的输出我们可以看到，使用 rackup 运行了一个 WEBrick 的进程，监听了 9292 端口，如果我们使用 curl 来访问对应的请求，就可以得到在 config.ru 文件中出现的 <code>'get rack\'d'</code> 文本：</p>

<blockquote>
  <p>在这篇文章中，作者都会使用开源的工具 <a href="https://github.com/jakubroztocil/httpie">httpie</a> 代替 curl 在命令行中发出 HTTP 请求，相比 curl 而言 httpie 能够提供与 HTTP 响应有关的更多信息。</p>
</blockquote>

<pre><code class="language-ruby">$ http http://localhost:9292
HTTP/1.1 200 OK
Connection: Keep-Alive
Content-Type: text/html
Date: Thu, 26 Oct 2017 15:07:47 GMT
Server: WEBrick/1.3.1 (Ruby/2.3.3/2016-11-21)
Transfer-Encoding: chunked

get rack'd
</code></pre>

<p>从上述请求返回的 HTTP 响应头中的信息，我们可以看到 WEBrick 确实按照 config.ru 文件中的代码对当前的 HTTP 请求进行了处理。</p>

<h3 id="中间件">中间件</h3>

<p>Rack 协议和中间件是 Rack 能达到今天地位不可或缺的两个功能或者说特性，Rack 协议规定了 webserver 和 Rack 应用之间应该如何通信，而 Rack 中间件能够在上层改变 HTTP 的响应或者请求，在不改变应用的基础上为 Rack 应用增加新的功能。</p>

<p>Rack 的中间件是一个实现了两个方法 <code>.initialize</code> 和 <code>#call</code> 的类，初始化方法会接受两个参数，分别是 <code>app</code> 和 <code>options</code> 字典，而 <code>#call</code> 方法接受一个参数也就是 HTTP 请求的环境参数 <code>env</code>，在这里我们创建了一个新的 Rack 中间件 <code>StatusLogger</code>：</p>

<pre><code class="language-ruby">class StatusLogger
  def initialize(app, options={})
    @app = app
  end

  def call(env)
    status, headers, body = @app.call(env)
    puts status
    [status, headers, body]
  end
end
</code></pre>

<p>在所有的 <code>#call</code> 方法中都<strong>应该</strong>调用 <code>app.call</code> 让应用对 HTTP 请求进行处理并在方法结束时将所有的参数按照顺序返回。</p>

<pre><code class="language-ruby">use StatusLogger
run Proc.new { |env| ['200', {'Content-Type' =&gt; 'text/html'}, ['get rack\'d']] }
</code></pre>

<p>如果需要使用某一个 Rack 中间件只需要在当前文件中使用 <code>use</code> 方法，在每次接收到来自用户的 HTTP 请求时都会打印出当前响应的状态码。</p>

<pre><code class="language-ruby">$ rackup
[2017-10-27 19:46:40] INFO  WEBrick 1.3.1
[2017-10-27 19:46:40] INFO  ruby 2.3.3 (2016-11-21) [x86_64-darwin16]
[2017-10-27 19:46:40] INFO  WEBrick::HTTPServer#start: pid=5274 port=9292
200
127.0.0.1 - - [27/Oct/2017:19:46:53 +0800] "GET / HTTP/1.1" 200 - 0.0004
</code></pre>

<p>除了直接通过 <code>use</code> 方法直接传入 <code>StatusLogger</code> 中间件之外，我们也可以在 <code>use</code> 中传入配置参数，所有的配置都会通过 <code>options</code> 最终初始化一个中间件的实例，比如，我们有以下的中间件 <code>BodyTransformer</code>：</p>

<pre><code class="language-ruby">class BodyTransformer
  def initialize(app, options={})
    @app = app
    @count = options[:count]
  end

  def call(env)
    status, headers, body = @app.call(env)
    body = body.map { |str| str[0...@count].upcase + str[@count..-1] }
    [status, headers, body]
  end
end
</code></pre>

<p>上述中间件会在每次调用时都将 Rack 应用返回的 <code>body</code> 中前 <code>count</code> 个字符变成大写的，我们可以在 config.ru 中添加一个新的中间件：</p>

<pre><code class="language-ruby">use StatusLogger
use BodyTransformer, count: 3
run Proc.new { |env| ['200', {'Content-Type' =&gt; 'text/html'}, ['get rack\'d']] }
</code></pre>

<p>当我们再次使用 http 命令请求相同的 URL 时，就会获得不同的结果，同时由于我们保留了 <code>StatusLogger</code>，所以在 console 中也会打印出当前响应的状态码：</p>

<pre><code class="language-ruby"># session 1
$ rackup
[2017-10-27 21:04:05] INFO  WEBrick 1.3.1
[2017-10-27 21:04:05] INFO  ruby 2.3.3 (2016-11-21) [x86_64-darwin16]
[2017-10-27 21:04:05] INFO  WEBrick::HTTPServer#start: pid=7524 port=9292
200
127.0.0.1 - - [27/Oct/2017:21:04:19 +0800] "GET / HTTP/1.1" 200 - 0.0005

# session 2
$ http http://localhost:9292
HTTP/1.1 200 OK
Connection: Keep-Alive
Content-Type: text/html
Date: Fri, 27 Oct 2017 13:04:19 GMT
Server: WEBrick/1.3.1 (Ruby/2.3.3/2016-11-21)
Transfer-Encoding: chunked

GET rack'd
</code></pre>

<p>Rack 的中间件的使用其实非常简单，我们只需要定义符合要求的类，然后在合适的方法中返回合适的结果就可以了，在接下来的部分我们将介绍 Rack 以及中间件的实现原理。</p>

<h2 id="rack-的实现原理">Rack 的实现原理</h2>

<p>到这里，我们已经对 Rack 的使用有一些基本的了解了，包括如何使用 <code>rackup</code> 命令启动一个 webserver，也包括 Rack 的中间件如何使用，接下来我们就准备开始对 Rack 是如何实现上述功能进行分析了。</p>

<h3 id="rackup-命令">rackup 命令</h3>

<p>那么 <code>rackup</code> 到底是如何工作的呢，首先我们通过 <code>which</code> 命令来查找当前 <code>rackup</code> 的执行路径并打印出该文件的全部内容：</p>

<pre><code class="language-ruby">$ which rackup
/Users/nju520/.rvm/gems/ruby-2.3.3/bin/rackup

$ cat /Users/nju520/.rvm/gems/ruby-2.3.3/bin/rackup
#!/usr/bin/env ruby_executable_hooks
#
# This file was generated by RubyGems.
#
# The application 'rack' is installed as part of a gem, and
# this file is here to facilitate running it.
#

require 'rubygems'

version = "&gt;= 0.a"

if ARGV.first
  str = ARGV.first
  str = str.dup.force_encoding("BINARY") if str.respond_to? :force_encoding
  if str =~ /\A_(.*)_\z/ and Gem::Version.correct?($1) then
    version = $1
    ARGV.shift
  end
end

load Gem.activate_bin_path('rack', 'rackup', version)
</code></pre>

<p>从上述文件中的注释中可以看到当前文件是由 RubyGems 自动生成的，在文件的最后由一个 <code>load</code> 方法加载了某一个文件中的代码，我们可以在 pry 中尝试运行一下这个命令。</p>

<p>首先，通过 <code>gem list</code> 命令得到当前机器中所有 rack 的版本，然后进入 pry 执行 <code>.activate_bin_path</code> 命令：</p>

<pre><code class="language-ruby">$ gem list "^rack$"

*** LOCAL GEMS ***

rack (2.0.3, 2.0.1, 1.6.8, 1.2.3)

$ pry
[1] pry(main)&gt; Gem.activate_bin_path('rack', 'rackup', '2.0.3')
=&gt; "/Users/nju520/.rvm/gems/ruby-2.3.3/gems/rack-2.0.3/bin/rackup"

$ cat /Users/nju520/.rvm/gems/ruby-2.3.3/gems/rack-2.0.3/bin/rackup
#!/usr/bin/env ruby

require "rack"
Rack::Server.start
</code></pre>

<blockquote>
  <p><code>rackup</code> 命令定义在 rack 工程的 bin/rackup 文件中，在通过 rubygems 安装后会生成另一个加载该文件的可执行文建。</p>
</blockquote>

<p>在最后打印了该文件的内容，到这里我们就应该知道 <code>.activate_bin_path</code> 方法会查找对应 gem 当前生效的版本，并返回文件的路径；在这个可执行文件中，上述代码只是简单的 <code>require</code> 了一下 rack 方法，之后运行 <code>.start</code> 启动了一个 <code>Rack::Server</code>。</p>

<h3 id="server-的启动">Server 的启动</h3>

<p>从这里开始，我们就已经从 rackup 命令的执行进入了 rack 的源代码，可以直接使用 pry 找到 <code>.start</code> 方法所在的文件，从方法中可以看到当前类方法初始化了一个新的实例后，在新的对象上执行了 <code>#start</code> 方法：</p>

<pre><code class="language-ruby">$ pry
[1] pry(main)&gt; require 'rack'
=&gt; true
[2] pry(main)&gt; $ Rack::Server.start

From: lib/rack/server.rb @ line 147:
Owner: #&lt;Class:Rack::Server&gt;

def self.start(options = nil)
  new(options).start
end
</code></pre>

<h3 id="初始化和配置">初始化和配置</h3>

<p>在 <code>Rack::Server</code> 启动的过程中初始化了一个新的对象，初始化的过程中其实也包含了整个服务器的配置过程：</p>

<pre><code class="language-ruby">From: lib/rack/server.rb @ line 185:
Owner: #&lt;Class:Rack::Server&gt;

def initialize(options = nil)
  @ignore_options = []

  if options
    @use_default_options = false
    @options = options
    @app = options[:app] if options[:app]
  else
    argv = defined?(SPEC_ARGV) ? SPEC_ARGV : ARGV
    @use_default_options = true
    @options = parse_options(argv)
  end
end
</code></pre>

<p>在这个 <code>Server</code> 对象的初始化器中，虽然可以通过 <code>options</code> 从外界传入参数，但是当前类中仍然存在这个 <code>#options</code> 和 <code>#default_options</code> 两个实例方法：</p>

<pre><code class="language-ruby">From: lib/rack/server.rb @ line 199:
Owner: Rack::Server

def options
  merged_options = @use_default_options ? default_options.merge(@options) : @options
  merged_options.reject { |k, v| @ignore_options.include?(k) }
end

From: lib/rack/server.rb @ line 204:
Owner: Rack::Server

def default_options
  environment  = ENV['RACK_ENV'] || 'development'
  default_host = environment == 'development' ? 'localhost' : '0.0.0.0'
  {
    :environment =&gt; environment,
    :pid         =&gt; nil,
    :Port        =&gt; 9292,
    :Host        =&gt; default_host,
    :AccessLog   =&gt; [],
    :config      =&gt; "config.ru"
  }
end
</code></pre>

<p>上述两个方法中处理了一些对象本身定义的一些参数，比如默认的端口号 9292 以及默认的 config 文件，config 文件也就是 <code>rackup</code> 命令接受的一个文件参数，文件中的内容就是用来配置一个 Rack 服务器的代码，在默认情况下为 config.ru，也就是如果文件名是 config.ru，我们不需要向 <code>rackup</code> 命令传任何参数，它会自动找当前目录的该文件：</p>

<pre><code class="language-ruby">$ rackup
[2017-10-27 09:00:34] INFO  WEBrick 1.3.1
[2017-10-27 09:00:34] INFO  ruby 2.3.3 (2016-11-21) [x86_64-darwin16]
[2017-10-27 09:00:34] INFO  WEBrick::HTTPServer#start: pid=96302 port=9292
</code></pre>

<p>访问相同的 URL 能得到完全一致的结果，在这里就不再次展示了，有兴趣的读者可以亲自尝试一下。</p>

<h3 id="包装应用">『包装』应用</h3>

<p>当我们执行了 <code>.initialize</code> 方法初始化了一个新的实例之后，接下来就会进入 <code>#start</code> 实例方法尝试启动一个 webserver 处理 config.ru 中定义的应用了：</p>

<pre><code class="language-ruby">From: lib/rack/server.rb @ line 258:
Owner: Rack::Server

def start &amp;blk
  # ...

  wrapped_app
  # ..

  server.run wrapped_app, options, &amp;blk
end
</code></pre>

<p>我们已经从上述方法中删除了很多对于本文来说不重要的代码实现，所以上述方法中最重要的部分就是 <code>#wrapped_app</code> 方法，以及另一个 <code>#server</code> 方法，首先来看 <code>#wrapped_app</code> 方法的实现。</p>

<pre><code class="language-ruby">From: lib/rack/server.rb @ line 353:
Owner: Rack::Server

def wrapped_app
  @wrapped_app ||= build_app app
end
</code></pre>

<p>上述方法有两部分组成，分别是 <code>#app</code> 和 <code>#build_app</code> 两个实例方法，其中 <code>#app</code> 方法的调用栈比较复杂：</p>

<p><img src="https://img.nju520.me/2017-10-29-server-app-call-stack.png" alt="server-app-call-stack" /></p>

<p>整个方法在最终会执行 <code>Builder.new_from_string</code> 通过 Ruby 中元编程中经常使用的 <code>eval</code> 方法，将输入文件中的全部内容与两端字符串拼接起来，并直接执行这段代码：</p>

<pre><code class="language-ruby">From: lib/rack/builder.rb @ line 48:
Owner: Rack::Builder

def self.new_from_string(builder_script, file="(rackup)")
  eval "Rack::Builder.new {\n" + builder_script + "\n}.to_app",
    TOPLEVEL_BINDING, file, 0
end
</code></pre>

<p>在 <code>eval</code> 方法中执行代码的作用其实就是如下所示的：</p>

<pre><code class="language-ruby">Rack::Builder.new {
  use StatusLogger
  use BodyTransformer, count: 3
  run Proc.new { |env| ['200', {'Content-Type' =&gt; 'text/html'}, ['get rack\'d']] }
}.to_app
</code></pre>

<p>我们先暂时不管这段代码是如何执行的，我们只需要知道上述代码存储了所有的中间件以及 Proc 对象，最后通过 <code>#to_app</code> 方法返回一个 Rack 应用。</p>

<p>在这之后会使用 <code>#build_app</code> 方法将所有的中间件都包括在 Rack 应用周围，因为所有的中间件也都是一个响应 <code>#call</code> 方法，返回三元组的对象，其实也就是一个遵循协议的 App，唯一的区别就是中间件中会调用初始化时传入的 Rack App：</p>

<pre><code class="language-ruby">From: lib/rack/server.rb @ line 343:
Owner: Rack::Server

def build_app(app)
  middleware[options[:environment]].reverse_each do |middleware|
    middleware = middleware.call(self) if middleware.respond_to?(:call)
    next unless middleware
    klass, *args = middleware
    app = klass.new(app, *args)
  end
  app
end
</code></pre>

<p>经过上述方法，我们在一个 Rack 应用周围一层一层包装上了所有的中间件，最后调用的中间件在整个调用栈中的最外层，当包装后的应用接受来自外界的请求时，会按照如下的方式进行调用：</p>

<p><img src="https://img.nju520.me/2017-10-29-wrapped-app.png" alt="wrapped-app" /></p>

<p>所有的请求都会先经过中间件，每一个中间件都会在 <code>#call</code> 方法内部调用另一个中间件或者应用，在接收到应用的返回之后会分别对响应进行处理最后由最先定义的中间件返回。</p>

<h3 id="中间件的实现">中间件的实现</h3>

<p>在 Rack 中，中间件是由两部分的代码共同处理的，分别是 <code>Rack::Builder</code> 和 <code>Rack::Server</code> 两个类，前者包含所有的能够在 config.ru 文件中使用的 DSL 方法，当我们使用 <code>eval</code> 执行 config.ru 文件中的代码时，会先初始化一个 <code>Builder</code> 的实例，然后执行 <code>instance_eval</code> 运行代码块中的所有内容：</p>

<pre><code class="language-ruby">From: lib/rack/builder.rb @ line 53:
Owner: Rack::Builder

def initialize(default_app = nil, &amp;block)
  @use, @map, @run, @warmup = [], nil, default_app, nil
  instance_eval(&amp;block) if block_given?
end
</code></pre>

<p>在这时，config.ru 文件中的代码就会在当前实例的环境下执行，文件中的 <code>#use</code> 和 <code>#run</code> 方法在调用时就会执行 <code>Builder</code> 的实例方法，我们可以先看一下 <code>#use</code> 方法是如何实现的：</p>

<pre><code class="language-ruby">From: lib/rack/builder.rb @ line 81:
Owner: Rack::Builder

def use(middleware, *args, &amp;block)
  @use &lt;&lt; proc { |app| middleware.new(app, *args, &amp;block) }
end
</code></pre>

<p>上述方法会将传入的参数组合成一个接受 <code>app</code> 作为入参的 <code>Proc</code> 对象，然后加入到 <code>@use</code> 数组中存储起来，在这里并没有发生任何其他的事情，另一个 <code>#run</code> 方法的实现其实就更简单了：</p>

<pre><code class="language-ruby">From: lib/rack/builder.rb @ line 103:
Owner: Rack::Builder

def run(app)
  @run = app
end
</code></pre>

<p>它只是将传入的 <code>app</code> 对象存储到持有的 <code>@run</code> 实例变量中，如果我们想要获取当前的 <code>Builder</code> 生成的应用，只需要通过 <code>#to_app</code> 方法：</p>

<pre><code class="language-ruby">From: lib/rack/builder.rb @ line 144:
Owner: Rack::Builder

def to_app
  fail "missing run or map statement" unless @run
  @use.reverse.inject(@run) { |a,e| e[a] }
end
</code></pre>

<p>上述方法将所有传入 <code>#use</code> 和 <code>#run</code> 命令的应用和中间件进行了组合，通过 <code>#inject</code> 方法达到了如下所示的效果：</p>

<pre><code class="language-ruby"># config.ru
use MiddleWare1
use MiddleWare2
run RackApp

# equals to
MiddleWare1.new(MiddleWare2.new(RackApp)))
</code></pre>

<p><code>Builder</code> 类其实简单来看就做了这件事情，将一种非常难以阅读的代码，变成比较清晰可读的 DSL，最终返回了一个中间件（也可以说是应用）对象，虽然在 <code>Builder</code> 中也包含其他的 DSL 语法元素，但是在这里都没有介绍。</p>

<p>上一小节提到的 <code>#build_app</code> 方法其实也只是根据当前的环境选择合适的中间件继续包裹到这个链式的调用中：</p>

<pre><code class="language-ruby">From: lib/rack/server.rb @ line 343:
Owner: Rack::Server

def build_app(app)
  middleware[options[:environment]].reverse_each do |middleware|
    middleware = middleware.call(self) if middleware.respond_to?(:call)
    next unless middleware
    klass, *args = middleware
    app = klass.new(app, *args)
  end
  app
end
</code></pre>

<p>在这里的 <code>#middleware</code> 方法可以被子类覆写，如果不覆写该方法会根据环境的不同选择不同的中间件数组包裹当前的应用：</p>

<pre><code class="language-ruby">From: lib/rack/server.rb @ line 229:
Owner: #&lt;Class:Rack::Server&gt;

def default_middleware_by_environment
  m = Hash.new {|h,k| h[k] = []}
  m["deployment"] = [
    [Rack::ContentLength],
    [Rack::Chunked],
    logging_middleware,
    [Rack::TempfileReaper]
  ]
  m["development"] = [
    [Rack::ContentLength],
    [Rack::Chunked],
    logging_middleware,
    [Rack::ShowExceptions],
    [Rack::Lint],
    [Rack::TempfileReaper]
  ]
  m
end
</code></pre>

<p><code>.default_middleware_by_environment</code> 中就包含了不同环境下应该使用的中间件，<code>#build_app</code> 会视情况选择中间件加载。</p>

<h3 id="webserver-的选择">webserver 的选择</h3>

<p>在 <code>Server#start</code> 方法中，我们已经通过 <code>#wrapped_app</code> 方法将应用和中间件打包到了一起，然后分别执行 <code>#server</code> 和 <code>Server#run</code> 方法选择并运行 webserver，先来看 webserver 是如何选择的：</p>

<pre><code class="language-ruby">From: lib/rack/server.rb @ line 300:
Owner: Rack::Server

def server
  @_server ||= Rack::Handler.get(options[:server])
  unless @_server
    @_server = Rack::Handler.default
  end
  @_server
end
</code></pre>

<p>如果我们在运行 <code>rackup</code> 命令时传入了 <code>server</code> 选项，例如 <code>rackup -s WEBrick</code>，就会直接使用传入的 webserver，否则就会使用默认的 Rack 处理器：</p>

<pre><code class="language-ruby">From: lib/rack/handler.rb @ line 46:
Owner: #&lt;Class:Rack::Handler&gt;

def self.default
  # Guess.
  if ENV.include?("PHP_FCGI_CHILDREN")
    Rack::Handler::FastCGI
  elsif ENV.include?(REQUEST_METHOD)
    Rack::Handler::CGI
  elsif ENV.include?("RACK_HANDLER")
    self.get(ENV["RACK_HANDLER"])
  else
    pick ['puma', 'thin', 'webrick']
  end
end
</code></pre>

<p>在这个方法中，调用 <code>.pick</code> 其实最终也会落到 <code>.get</code> 方法上，在 <code>.pick</code> 中我们通过遍历传入的数组<strong>尝试</strong>对其进行加载：</p>

<pre><code class="language-ruby">From: lib/rack/handler.rb @ line 34:
Owner: #&lt;Class:Rack::Handler&gt;

def self.pick(server_names)
  server_names = Array(server_names)
  server_names.each do |server_name|
    begin
      return get(server_name.to_s)
    rescue LoadError, NameError
    end
  end

  raise LoadError, "Couldn't find handler for: #{server_names.join(', ')}."
end
</code></pre>

<p><code>.get</code> 方法是用于加载 webserver 对应处理器的方法，方法中会通过一定的命名规范从对应的文件目录下加载相应的常量：</p>

<pre><code class="language-ruby">From: lib/rack/handler.rb @ line 11:
Owner: #&lt;Class:Rack::Handler&gt;

def self.get(server)
  return unless server
  server = server.to_s

  unless @handlers.include? server
    load_error = try_require('rack/handler', server)
  end

  if klass = @handlers[server]
    klass.split("::").inject(Object) { |o, x| o.const_get(x) }
  else
    const_get(server, false)
  end

rescue NameError =&gt; name_error
  raise load_error || name_error
end
</code></pre>

<p>一部分常量是预先定义在 handler.rb 文件中的，另一部分是由各个 webserver 的开发者自己定义或者遵循一定的命名规范加载的：</p>

<pre><code class="language-ruby">register 'cgi', 'Rack::Handler::CGI'
register 'fastcgi', 'Rack::Handler::FastCGI'
register 'webrick', 'Rack::Handler::WEBrick'
register 'lsws', 'Rack::Handler::LSWS'
register 'scgi', 'Rack::Handler::SCGI'
register 'thin', 'Rack::Handler::Thin'
</code></pre>

<p>在默认的情况下，如果不在启动服务时指定服务器就会按照 puma、thin 和 webrick 的顺序依次尝试加载响应的处理器。</p>

<h3 id="webserver-的启动">webserver 的启动</h3>

<p>当 Rack 已经使用中间件对应用进行包装并且选择了对应的 webserver 之后，我们就可以将处理好的应用作为参数传入 <code>WEBrick.run</code> 方法了：</p>

<pre><code class="language-ruby">module Rack
  module Handler
    class WEBrick &lt; ::WEBrick::HTTPServlet::AbstractServlet
      def self.run(app, options={})
        environment  = ENV['RACK_ENV'] || 'development'
        default_host = environment == 'development' ? 'localhost' : nil

        options[:BindAddress] = options.delete(:Host) || default_host
        options[:Port] ||= 8080
        @server = ::WEBrick::HTTPServer.new(options)
        @server.mount "/", Rack::Handler::WEBrick, app
        yield @server  if block_given?
        @server.start
      end
    end
  end
end
</code></pre>

<p>所有遵循 Rack 协议的 webserver 都会实现上述 <code>.run</code> 方法接受 <code>app</code>、<code>options</code> 和一个 block 作为参数运行一个进程来处理所有的来自用户的 HTTP 请求，在这里就是每个 webserver 自己需要解决的了，它其实并不属于 Rack 负责的部门，但是 Rack 实现了一些常见 webserver 的 handler，比如 CGI、Thin 和 WEBrick 等等，这些 handler 的实现原理都不会包含在这篇文章中。</p>

<h2 id="rails-和-rack">Rails 和 Rack</h2>

<p>在了解了 Rack 的实现之后，其实我们可以发现 Rails 应用就是一堆 Rake 中间件和一个 Rack 应用的集合，在任意的工程中我们执行 <code>rake middleware</code> 的命令都可以得到以下的输出：</p>

<pre><code class="language-ruby">$ rake middleware
use Rack::Sendfile
use ActionDispatch::Static
use ActionDispatch::Executor
use ActiveSupport::Cache::Strategy::LocalCache::Middleware
use Rack::Runtime
use ActionDispatch::RequestId
use ActionDispatch::RemoteIp
use Rails::Rack::Logger
use ActionDispatch::ShowExceptions
use ActionDispatch::DebugExceptions
use ActionDispatch::Reloader
use ActionDispatch::Callbacks
use ActiveRecord::Migration::CheckPending
use Rack::Head
use Rack::ConditionalGet
use Rack::ETag
run ApplicationName::Application.routes
</code></pre>

<p>在这里包含了很多使用 <code>use</code> 加载的 Rack 中间件，当然在最后也包含一个 Rack 应用，也就是 <code>ApplicationName::Application.routes</code>，这个对象其实是一个 <code>RouteSet</code> 实例，也就是说在 Rails 中所有的请求在经过中间件之后都会先有一个路由表来处理，路由会根据一定的规则将请求交给其他控制器处理：</p>

<p><img src="https://img.nju520.me/2017-10-29-rails-application.png" alt="rails-application" /></p>

<p>除此之外，<code>rake middleware</code> 命令的输出也告诉我们 Rack 其实为我们提供了很多非常方便的中间件比如 <code>Rack::Sendfile</code> 等可以减少我们在开发一个 webserver 时需要处理的事情。</p>

<h2 id="总结">总结</h2>

<p>Rack 协议可以说占领了整个 Ruby 服务端的市场，无论是常见的服务器还是框架都遵循 Rack 协议进行了设计，而正因为 Rack 以及 Rack 协议的存在我们在使用 Rails 或者 Sinatra 开发 Web 应用时才可以对底层使用的 webserver 进行无缝的替换，在接下来的文章中会逐一介绍不同的 webserver 是如何对 HTTP 请求进行处理以及它们拥有怎样的 I/O 模型。</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://github.com/rack/rack">Rack · A modular Ruby webserver interface</a></li>
  <li><a href="http://rack.github.io">Rack: a Ruby Webserver Interface</a></li>
  <li><a href="http://rubydoc.info/github/rack/rack/master/file/SPEC">Rack interface specification</a></li>
  <li><a href="http://guides.rubyonrails.org/rails_on_rack.html">Rails on Rack</a></li>
  <li><a href="http://railscasts.com/episodes/151-rack-middleware">Rack Middleware</a></li>
  <li><a href="http://chneukirchen.org/blog/archive/2007/02/introducing-rack.html">Introducing Rack</a></li>
  <li><a href="https://stackoverflow.com/questions/4113299/ruby-on-rails-server-options">Ruby on Rails Server options</a></li>
</ul>

  ]]></description>
</item>

<item>
  <title>分布式键值存储 Dynamo 的实现原理</title>
  <link>//dynamo</link>
  <author>nju520</author>
  <pubDate>2017-10-24T00:00:00+08:00</pubDate>
  <guid>//dynamo</guid>
  <description><![CDATA[
  <p>在最近的一周时间里，一直都在研究和阅读 Amazon 的一篇论文 <a href="http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">Dynamo: Amazon’s Highly Available Key-value Store</a>，论文中描述了 Amazon 的高可用分布式键值存储服务 Dynamo 的实现原理。</p>

<p><img src="https://img.nju520.me/2017-10-24-dynamodb.png" alt="dynamodb" /></p>

<p>之前在阅读 Google 的 <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf">Bigtable: A Distributed Storage System for Structured Data</a> 时写了一篇 <a href="https://nju520.me/bigtable-leveldb">浅析 Bigtable 和 LevelDB 的实现</a> 文章分析了 Bigtable 的单机版 LevelDB 的实现原理；在研究 Dynamo 时，作者发现 Dynamo 虽然和 Bigtable 同为 NoSQL，但是它们的实现却有着很大的不同，最主要的原因来自不同的应用场景和不同的目的。</p>

<h2 id="bigtable-和-dynamo">Bigtable 和 Dynamo</h2>

<p>Bigtable 和 Dynamo 两者分别是 Google 和 Amazon 两大巨头给出的存储海量数据的解决方法，作为 NoSQL 两者都具有分布式、容错以及可扩展的几大特性。</p>

<p><img src="https://img.nju520.me/2017-10-24-nosql-main-characteristics.png" alt="nosql-main-characteristics" /></p>

<p>虽然两者都是 NoSQL，并且有着相似的特性，但是它们在侧重的方向上有非常明显的不同，从两个数据库论文的标题中，我们就能看到 Amazon 的 Dynamo 追求的是高可用性并且提供的是类似 MongoDB 的 Key-value 文档存储，而 Bigtable 中描述的数据库却可以用于结构化的数据存储。</p>

<p>由于 Bigtable 和 Dynamo 都属于同一个类别 - NoSQL，所以它们经常会被放在一起进行对比，这篇文章不仅会介绍 Dynamo 的设计理念以及架构等问题，还会就其中的部分问题与 Bigtable 中相对应的概念进行对比，这样能够让我们更加清楚地了解不同的数据库对不同问题，因设计理念的差异做出的权衡。</p>

<h2 id="架构">架构</h2>

<p>在数据库领域中尤其是分布式数据库，最重要的就是服务的架构，多数的分布式系统在设计时都会假设服务运行在廉价的节点上，并没有出众的性能和也不能提供稳定的服务，所以水平扩展和容错的能力是分布式数据库的标配；但是不同的分布式数据库选用了不同的架构来组织大量的节点。</p>

<p>很多的分布式服务例如 GFS 和 Bigtable 都使用了带有主节点的架构来维护整个系统中的元数据，包括节点的位置等信息，而 Dynamo 的实现不同于这些中心化的分布式服务，在 Dynamo 中所有的节点都有着完全相同的职责，会对外界提供同样的服务，所以在整个系统中并不会出现单点故障的问题。</p>

<p><img src="https://img.nju520.me/2017-10-24-dynamo-architecture.png" alt="dynamo-architecture" /></p>

<p>去中心化的架构使得系统的水平扩展非常容易，节点可以在任何时候直接加入到整个 Dynamo 的集群中，并且只会造成集群中少量数据的迁移。</p>

<p>Bigtable 使用了中心化的架构，通过主节点来维护整个系统中全部的元数据信息，但是 Bigtable 本身其实并不会处理来自客户端的读写请求，所有请求都会由客户端直接和从节点通信，不过由于有了中心化的主节点，所以主节点一旦发生故障宕机就会造成服务的不可用，虽然 Bigtable 以及类似的服务通过其他方式解决这个问题，但是这个问题仍然是中心化的设计所造成的。</p>

<p><img src="https://img.nju520.me/2017-10-24-centralized-architecture.png" alt="centralized-architecture" /></p>

<p>中心化或者去中心化并不是一个绝对好或者绝对坏的选择，选择中心化的解决方案能够降低系统实现的复杂度，而去中心化的方式能够避免单点故障，让系统能够更好更快地增加新的节点，提供优秀的水平扩展能力。</p>

<h2 id="分片和复制">分片和复制</h2>

<p>Dynamo 在设计之初就定下了<strong>增量扩展</strong>（Incremental Scalability）的核心需求，这也就需要一种能够在一组节点中动态分片的机制，Dynamo 的分片策略依赖于<em>一致性哈希</em>，通过这种策略 Dynamo 能够将负载合理的分配到不同的存储节点上。</p>

<p>所有的键在存储之前都会通过哈希函数得到一个唯一的值，哈希函数的输出被看做是一个固定长度的环，也就是其输出的最大值和最小值是『连接』到一起的：</p>

<p><img src="https://img.nju520.me/2017-10-24-partition-in-dynamo.png" alt="partition-in-dynamo" /></p>

<p>每一个节点都会被 Dynamo 在这个环中分配一个随机的位置，而这个节点会处理从哈希的输出在当前节点前的所有键；假设我们有一个键值对 <code>(hacker, developer)</code>，<code>Hash(hacker)</code> 的结果位于上图中的绿色区域，从环中的位置开始按照<strong>顺时针</strong>的顺序寻找，找到的以第一个节点 B 就会成为协调者（coordinator）负责处理当前的键值对，上图中的每一个节点都会负责与其颜色相同的部分。</p>

<p>由于 Dynamo 系统中的每一个节点在刚刚加入当前的集群时，会被分配一个随机的位置，所以由于算法的随机性可能会导致不同节点处理的范围有所不同，最终每一个节点的负载也并不相同；为了解决这个问题，Dynamo 使用了一致性哈希算法的变种，将同一个物理节点分配到环中的多个位置（标记），成为多个虚拟节点，但是在这种策略下，如果当前的 Dynamo 节点一天处理上百万的请求，那么新增节点为了不影响已有节点的性能，会在后台进行启动，整个过程大约会<strong>消耗一整天</strong>的时间，这其实是很难接受的，除此之外这种策略还会造成系统进行日常归档极其缓慢。</p>

<p><img src="https://img.nju520.me/2017-10-24-equal-size-partition-in-dynamo.png" alt="equal-size-partition-in-dynamo" /></p>

<p>为了解决负载的不均衡的问题，除了上面使用虚拟节点的策略之外，Dynamo 论文中还提供了另外两种策略，其中性能相对较好的是将数据的哈希分成 Q 个大小相等的区域，S 个节点每一个处理 Q/S 个分区，当某一个节点因为故障或者其他原因需要退出集群时，会将它处理的数据分片随机分配给其它的节点，当有节点加入系统时，会从其它的节点中『接管』对应的数据分片。上图只是对这种策略下的分片情况简单展示，在真实环境中分片数 Q 的值远远大于节点数 S。</p>

<p>Dynamo 为了达到高可用性和持久性，防止由于节点宕机故障或者数据丢失，将同一份数据在协调者和随后的 <code>N-1</code> 个节点上备份了多次，N 是一个可以配置的值，在一般情况下都为 3。</p>

<p><img src="https://img.nju520.me/2017-10-24-replication-in-dynamo.png" alt="replication-in-dynamo" /></p>

<p>也就是说，上图中黄色区域的值会存储在三个节点 A、B 和 C 中，绿色的区域会被 B、C、D 三个节点处理，从另一个角度来看，A 节点会处理范围在 <code>(C, A]</code> 之间的值，而 B 节点会处理从 <code>(D, B]</code> 区域内的值。</p>

<p><img src="https://img.nju520.me/2017-10-24-replication-range-in-dynamo.png" alt="replication-range-in-dynamo" /></p>

<p>负责存储某一个特定键值对的节点列表叫做偏好列表（preference list），因为虚拟节点在环中会随机存在，为了保证出现节点故障时不会影响可用性和持久性，偏好列表中的全部节点必须都为<strong>不同的物理节点</strong>。</p>

<p>Bigtable 中对分片和复制的实现其实就与 Dynamo 中完全不同，这不仅是因为 Bigtable 的节点有主从之分，还因为 Bigtable 的设计理念与 Dynamo 完全不同。在 Bigtable 中，数据是按照键的顺序存储的，数据存储的单位都是 tablet，每一张表都由多个 tablet 组成，而每一个的 tablet 都有一个 tablet 服务器来处理，而 tablet 的位置都存储在 METADATA 表中。</p>

<p><img src="https://img.nju520.me/2017-10-24-partition-in-bigtable.png" alt="partition-in-bigtable" /></p>

<p>在 Bigtable 中，所有的 tablet 都在 GFS 中以 SSTable 的格式存储起来，这些 SSTable 都被分成了固定大小的块在 chunkserver 上存储，而每一个块也都会在存储在多个 chunkserver 中。</p>

<h2 id="读写请求的执行">读写请求的执行</h2>

<p>Dynamo 集群中的任意节点都能够接受来自客户端的对于任意键的读写请求，所有的请求都通过 RPC 调用执行，客户端在选择节点时有两种不同的策略：一种是通过一个负载均衡器根据负载选择不同的节点，另一种是通过一个清楚当前集群分片的库直接请求相应的节点。</p>

<p><img src="https://img.nju520.me/2017-10-24-node-selecting-strategies.png" alt="node-selecting-strategies" /></p>

<p>从上面我们就已经知道了处理读写请求的节点就叫做协调者（coordinator），前 N 个『健康』的节点会参与读写请求的处理；Dynamo 使用了 Quorum 一致性协议来保证系统中的一致性，协议中有两个可以配置的值：R 和 W，其中 R 是成功参与一个读请求的最小节点数，而 W 是成功参与写请求的最小节点数。</p>

<p><img src="https://img.nju520.me/2017-10-24-dynamo-read-write-operation.png" alt="dynamo-read-write-operation" /></p>

<p>当 R = 2 时，所有的读请求必须等待两个节点成功返回对应键的结果，才认为当前的请求结束了，也就是说读请求的时间取决于返回最慢的节点，对于写请求来说也是完全相同的；当协调者接收到了来自客户端的写请求 <code>put()</code> 时，它会创建一个新的向量时钟（vector clock），然后将新版本的信息存储在本地，之后向偏好列表（preference list）中的前 <code>N-1</code> 个节点发送消息，直到其中的 <code>W-1</code> 个返回这次请求才成功结束，读请求 <code>get()</code> 与上述请求的唯一区别就是，如果协调者发现节点中的数据出现了冲突，就会对冲突尝试进行解决并将结果重新写回对应的节点。</p>

<h2 id="冲突和向量时钟">冲突和向量时钟</h2>

<p>Dynamo 与目前的绝大多数分布式系统一样都提供了<strong>最终一致性</strong>，最终一致性能够允许我们异步的更新集群中的节点，<code>put()</code> 请求可能会在所有的节点后更新前就返回对应的结果了，在这时随后的 <code>get()</code> 就可能获取到过期的数据。</p>

<p><img src="https://img.nju520.me/2017-10-24-inconsistent-in-dynamo.png" alt="inconsistent-in-dynamo" /></p>

<p>如果在系统中出现了节点故障宕机，那么数据的更新可能在一段时间内都不会到达失效的节点，这也是在使用 Dynamo 或者使用相似原理的系统时会遇到的问题，Amazon 中的很多应用虽然都能够忍受这种数据层面可能发生的不一致性，但是有些对业务数据一致性非常高的应用在选择 Dynamo 时就需要好好考虑了。</p>

<p>因为 Dynamo 在工作的过程中不同的节点可能会发生数据不一致的问题，这种问题肯定是需要解决的，Dynamo 能够确保<strong>一旦数据之间发生了冲突不会丢失</strong>，但是可能会有<strong>已被删除的数据重新出现</strong>的问题。</p>

<p>在多数情况下，Dynamo 中的最新版本的数据都会取代之前的版本，系统在这时可以通过语法调解（syntactic reconcile）数据库中的正确版本。但是版本也可能会出现分支，在这时，Dynamo 就会返回所有它无法处理的数据版本，由客户端在多个版本的数据中选择或者创建（collapse）合适的版本返回给 Dynamo，其实这个过程比较像出现冲突的 <code>git merge</code> 操作，git 没有办法判断当前的哪个版本是合适的，所以只能由开发者对分支之间的冲突进行处理。</p>

<p><img src="https://img.nju520.me/2017-10-24-version-evolution-in-dynamo.png" alt="version-evolution-in-dynamo" /></p>

<p>上图中的每一个对象的版本 Dx 中存储着一个或多个向量时钟 <code>[Sn, N]</code>，每次 Dynamo 对数据进行写入时都会更新向量时钟的版本，节点 Sx 第一次写入时向量时钟为 <code>[Sx, 1]</code>，第二次为 <code>[Sx, 2]</code>，在这时假设节点 Sy 和 Sz 都不知道 Sx 已经对节点进行写入了，它们接收到了来自其他客户端的请求，在本地也对同样键做出了写入并分别生成了不同的时钟 <code>[Sy, 1]</code> 和 <code>[Sz, 1]</code>，当客户端再次使用 <code>get()</code> 请求时就会发现数据出现了冲突，由于 Dynamo 无法根据向量时钟自动解决，所以它需要手动合并三个不同的数据版本。</p>

<p>论文中对 24 小时内的请求进行了统计，其中 99.94% 的请求仅会返回一个版本，0.00057% 的请求会返回两个版本，0.00047 的请求会返回三个版本，0.000009% 的请求会返回四个版本，虽然论文中说：</p>

<blockquote>
  <p>This shows that divergent versions are created rarely.</p>
</blockquote>

<p>但是作者仍然认为在海量的数据面前 99.94% 并不是一个特别高的百分比，处理分歧的数据版本仍然会带来额外的工作量和负担。虽然在这种情况下，数据库本身确实没有足够的信息来解决数据的不一致问题，也确实只能由客户端去解决冲突，但是这种将问题抛给上层去解决的方式并不友好，论文中也提到了 Amazon 中使用 Dynamo 的应用程序也都是能够适应并解决这些数据不一致的问题的，不过对于作者来说，仅仅这一个问题就成为不选择 Dynamo 的理由了。</p>

<h2 id="节点的增删">节点的增删</h2>

<p>因为在分布式系统中节点的失效是非常常见的事情，而节点也很少会因为某些原因永久失效，往往大部分节点会临时宕机然后快速重新加入系统；由于这些原因，Dynamo 选择使用了显式的机制向系统中添加和移除节点。</p>

<p><img src="https://img.nju520.me/2017-10-24-ring-membership.png" alt="ring-membership" /></p>

<p>添加节点时可以使用命令行工具或者浏览器连接 Dynamo 中的任意节点后触发一个成员变动的事件，这个事件会从当前的环中移除或者向环中添加一个新的节点，当节点的信息发生改变时，该节点会通过 Gossip 协议通知它所能通知的最多的节点。</p>

<p><img src="https://img.nju520.me/2017-10-24-gossip-protocol.png" alt="gossip-protoco" /></p>

<p>在 Gossip 协议中，每次通讯的两个节点会对当前系统中的节点信息达成一致；通过节点之间互相传递成员信息，最终整个 Dyanmo 的集群中所有的节点都会就成员信息达成一致，如上图所示，”gossip” 首先会被 C 节点接收，然后它会传递给它能接触到的最多的节点 A、D、F、G 四个节点，然后 “gossip” 会进行二次传播传递给系统中的灰色节点，到此为止系统中的所有节点都得到了最新的 “gossip” 消息。</p>

<p>当我们向 Dynamo 中加入了新的节点时，会发生节点之间的分片转移，假设我们连接上了 Dynamo 数据库，然后添加了一个 X 节点，该节点被分配到了如下图所示的 A 和 B 节点之间。</p>

<p><img src="https://img.nju520.me/2017-10-24-adding-storage-node.png" alt="adding-storage-node" /></p>

<p>新引入的节点 X 会从三个节点 C、D、E 中接受它们管理的分片的一部分，也就是上图中彩色的 <code>(E, A]</code>、<code>(A, B]</code> 和 <code>(B, X]</code> 三个部分，在 X 节点加入集群之前分别属于与其颜色相同的节点管理。</p>

<p>Dynamo 由于其去中心化的架构，节点增删的事件都需要通过 Gossip 协议进行传递，然而拥有主从节点之分的 Bigtable 就不需要上述的方式对集群中的节点进行增删了，它可以直接通过用于管理其他从节点的服务直接注册新的节点或者撤下已有的节点。</p>

<h2 id="副本同步">副本同步</h2>

<p>在 Dynamo 运行的过程中，由于一些情况会造成不同节点中的数据不一致的问题，Dynamo 使用了反信息熵（anti-entropy）的策略保证所有的副本存储的信息都是同步的。</p>

<p>为了快速确认多个副本之间的数据的一致性并避免大量的数据传输，Dynamo 使用了 <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle tree</a> 对不同节点中的数据进行快速验证。</p>

<p><img src="https://img.nju520.me/2017-10-24-merkle-hash-tree.png" alt="merkle-hash-tree" /></p>

<p>在 Merkle 树中，所有父节点中的内容都是叶子节点的哈希，通过这种方式构建的树形结构能够保证整棵树不会被篡改，任何的改动都能被立刻发现。</p>

<p>Dynamo 中的每一个节点都为其持有的键的范围维护了一颗 Merkle 树，在验证两份节点中的数据是否相同时，只需要发送根节点中的哈希值，如果相同那么说明两棵树的内容全部相同，否则就会依次对比不同层级节点中的内容，直到找出不同的副本，这种做法虽然能够减少数据的传输并能够快速找到副本之间的不同，但是当有新的节点加入或者旧的节点退出时会导致大量的 Merkle 树重新计算。</p>

<h2 id="总结">总结</h2>

<p>在 Dynamo 的论文公开之后，有一篇文章将 Dynamo 的设计称作 <a href="http://jsensarma.com/blog/?p=55">“A flawed architecture”</a>，这篇文章的作者在文中对 Dynamo 的实现进行了分析，主要对其最终一致性和 Quorom 机制进行了批评，它在 <a href="https://news.ycombinator.com/item?id=915212">HackerNews</a> 上也引起了广泛的讨论，帖子中的很多内容都值得一看，能够帮助我们了解 Dynamo 的设计原理，而 Amazon 的 CTO 对于这篇文章也发了一条 Twitter：</p>

<p><img src="https://img.nju520.me/2017-10-24-amazon-cto-twitter-about-dynamo.png" alt="amazon-cto-twitter-about-dynamo" /></p>

<p>不管如何，Dynamo 作为支撑亚马逊业务的底层服务，其实现原理和思想对于整个社区都是非常有价值的，然而它使用的去中心化的策略也带了很多问题，虽然作者可能会因为这个原因在选择数据库时不会 Dynamo，不过相信它也是有合适的应用场景的。</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">Dynamo: Amazon’s Highly Available Key-value Store</a></li>
  <li><a href="http://jsensarma.com/blog/?p=55">Dynamo: A flawed architecture – Part I</a></li>
  <li><a href="http://jsensarma.com/blog/?p=64">Dynamo – Part I: a followup and re-rebuttals</a></li>
  <li><a href="https://www.slideshare.net/GrishaWeintraub/presentation-46722530">Dynamo and BigTable - Review and Comparison</a></li>
  <li><a href="http://vschart.com/compare/dynamo-db/vs/bigtable">DynamoDB vs. BigTable · vsChart</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle tree</a></li>
  <li><a href="https://link.springer.com/content/pdf/10.1007/3-540-48184-2_32.pdf">A Digital Signature Based on a Conventional Encryption Function</a></li>
  <li><a href="http://www.raychase.net/2396">Dynamo 的实现技术和去中心化</a></li>
  <li><a href="https://nju520.me/bigtable-leveldb">浅析 Bigtable 和 LevelDB 的实现</a></li>
</ul>

  ]]></description>
</item>

<item>
  <title>全面理解 ActiveRecord</title>
  <link>//activerecord</link>
  <author>nju520</author>
  <pubDate>2017-10-21T00:00:00+08:00</pubDate>
  <guid>//activerecord</guid>
  <description><![CDATA[
  <p>最近事情并不是特别多，看了一些数据库相关的书籍，最后想到自己并不了解每天都在用的 ActiveRecord，对于它是如何创建模型、建立关系、执行 SQL 查询以及完成数据库迁移的，作者一直都有着自己的猜测，但是真正到源代码中去寻找答案一直都是没有做过的。</p>

<p><img src="https://img.nju520.me/2017-10-21-activerecord-architecture.png" alt="activerecord-architecture" /></p>

<p>我们可以将 ActiveRecord 理解为一个不同 SQL 数据库的 Wrapper，同时为上层提供一种简洁、优雅的 API 或者说 DSL，能够极大得减轻开发者的负担并提升工作效率。</p>

<p>文章分四个部分介绍了 ActiveRecord 中的重要内容，模型的创建过程、Scope 和查询的实现、模型关系的实现以及最后的 Migrations 任务的实现和执行过程，各个模块之间没有太多的关联，由于文章内容比较多，如果读者只对某一部分的内容感兴趣，可以只挑选一部分进行阅读。</p>

<h2 id="模型的创建过程">模型的创建过程</h2>

<p>在这篇文章中，我们会先分析阅读 ActiveRecord 是如何创建模型并将数据插入到数据库中的，由于 ActiveRecord 的源码变更非常迅速，这里使用的 ActiveRecord 版本是 v5.1.4，如果希望重现文中对方法的追踪过程可以 checkout 到 v5.1.4 的标签上并使用如下所示的命令安装指定版本的 ActiveRecord：</p>

<pre><code class="language-shell">$ gem install activerecord -v '5.1.4'
</code></pre>

<h3 id="引入-activerecord">引入 ActiveRecord</h3>

<p>在正式开始使用 <a href="https://github.com/pry/pry">pry</a> 对方法进行追踪之前，我们需要现在 pry 中 <code>require</code> 对应的 gem，并且创建一个用于追踪的模型类：</p>

<pre><code class="language-ruby">pry(main)&gt; require 'active_record'
=&gt; true
pry(main)&gt; class Post &lt; ActiveRecord::Base; end
=&gt; nil
</code></pre>

<p>这个步骤非常的简单，这里也不多说什么了，只是创建了一个继承自 <code>ActiveRecord::Base</code> 的类 <code>Post</code>，虽然我们并没有在数据库中创建对应的表结构，不过目前来说已经够用了。</p>

<h3 id="从-postcreate-开始">从 Post.create 开始</h3>

<p>使用过 ActiveRecord 的人都知道，当我们使用 <code>Post.create</code> 方法的时候就会在数据库中创建一条数据记录，所以在这里我们就将该方法作为入口一探究竟：</p>

<pre><code class="language-ruby">pry(main)&gt; $ Post.create

From: lib/active_record/persistence.rb @ line 29:
Owner: ActiveRecord::Persistence::ClassMethods

def create(attributes = nil, &amp;block)
  if attributes.is_a?(Array)
    attributes.collect { |attr| create(attr, &amp;block) }
  else
    object = new(attributes, &amp;block)
    object.save
    object
  end
end
</code></pre>

<blockquote>
  <p><code>$</code> 是 pry 为我们提供的用于查看方法源代码的工具，这篇文章中会省略 <code>$</code> 方法的一部分输出，还可能会对方法做一些简化减少理解方法实现时的干扰。</p>
</blockquote>

<p>通过 pry 的输出，我们可以在 ActiveRecord 的 <code>lib/active_record/persistence.rb</code> 文件中找到 <code>ActiveRecord::Base.create</code> 方法的实现，如果传入的参数是一个 <code>Hash</code>，该方法会先后执行 <code>ActiveRecord::Base.new</code> 和 <code>ActiveRecord::Base#save!</code> 创建一个新的对象并保存。</p>

<h4 id="使用-pry-追踪-save">使用 pry 追踪 #save!</h4>

<p><code>ActiveRecord::Base.new</code> 在大多数情况下都会调用父类的 <code>#initialize</code> 方法初始化实例，所以没有什么好说的，而 <code>ActiveRecord::Base#save!</code> 方法就做了很多事情：</p>

<pre><code class="language-ruby">pry(main)&gt; $ ActiveRecord::Base#save!

From: lib/active_record/suppressor.rb @ line 45:
Owner: ActiveRecord::Suppressor

def save!(*) # :nodoc:
  SuppressorRegistry.suppressed[self.class.name] ? true : super
end
</code></pre>

<p>首先是使用 <code>SuppressorRegistry</code> 来判断是否需要对当前的存取请求进行抑制，然后执行 <code>super</code> 方法，由于从上述代码中没有办法知道这里的 <code>super</code> 到底是什么，所以我们就需要通过 <code>.ancestors</code> 方法看看 <code>ActiveRecord::Base</code> 到底有哪些父类了：</p>

<pre><code class="language-ruby">pry(main)&gt; ActiveRecord::Base.ancestors
=&gt; [ActiveRecord::Base,
 ActiveRecord::Suppressor,
 ...
 ActiveRecord::Persistence,
 ActiveRecord::Core,
 ActiveSupport::ToJsonWithActiveSupportEncoder,
 Object,
 ...
 Kernel,
 BasicObject]

pry(main)&gt; ActiveRecord::Base.ancestors.count
=&gt; 65
</code></pre>

<p>使用 <code>.ancestors</code> 方法，你就可以看到整个方法调用链上包含 64 个父类，在这时简单的使用 pry 就已经不能帮助我们理解方法的调用过程了，因为 pry 没法查看当前的方法在父类中是否存在，我们需要从工程中分析哪些类的 <code>#save!</code> 方法在整个过程中被执行了并根据上述列表排出它们执行的顺序；经过分析，我们得到如下的结果：</p>

<p><img src="https://img.nju520.me/2017-10-21-activerecord-base-save.png" alt="activerecord-base-save" /></p>

<p>从 <code>ActiveRecord::Suppressor</code> 到 <code>ActiveRecord::Persistence</code> 一共有五个 module 实现了 <code>#save!</code> 方法，上面我们已经知道了 <code>ActiveRecord::Suppressor#save!</code> 模块提供了对保存的抑制功能，接下来将依次看后四个方法都在保存模型的过程中做了什么。</p>

<h4 id="事务的执行">事务的执行</h4>

<p>从名字就可以看出 <code>ActiveRecord::Transactions</code> 主要是为数据库事务提供支持，并在数据库事务的不同阶段执行不同的回调，这个 module 中的 <code>#save!</code> 方法仅在 <code>#with_transaction_returning_status</code> 的 block 中执行了 <code>super</code>：</p>

<pre><code class="language-ruby">module ActiveRecord
  module Transactions
    def save!(*) #:nodoc:
      with_transaction_returning_status { super }
    end
  end
end
</code></pre>

<p><code>#with_transaction_returning_status</code> 方法会运行外部传入的 block 通过 <code>super</code> 执行父类的 <code>#save!</code> 方法：</p>

<pre><code class="language-ruby">def with_transaction_returning_status
  status = nil
  self.class.transaction do
    add_to_transaction
    begin
      status = yield
    rescue ActiveRecord::Rollback
      clear_transaction_record_state
      status = nil
    end

    raise ActiveRecord::Rollback unless status
  end
  status
ensure
  if @transaction_state &amp;&amp; @transaction_state.committed?
    clear_transaction_record_state
  end
end
</code></pre>

<p>通过上述方法，我们将所有的 SQL 请求都包装在了一个 <code>.transaction</code> 中，开启一个新的数据库事务并在其中执行请求，在这里统一处理一些跟事务回滚以及异常相关的逻辑，同时 <code>ActiveRecord::Transactions</code> 又能为当前的模型添加一些回调的支持：</p>

<pre><code class="language-ruby">module ActiveRecord
  module Transactions
    included do
      define_callbacks :commit, :rollback,
                       :before_commit,
                       :before_commit_without_transaction_enrollment,
                       :commit_without_transaction_enrollment,
                       :rollback_without_transaction_enrollment,
                       scope: [:kind, :name]
    end
  end
end
</code></pre>

<p>开发者就能够在模型中根据需要注册回调用来监听各种数据库事务相关的事件，绝大多数的事务最终都会在 <code>ActiveRecord::ConnectionAdapters::Transaction#within_new_transaction</code> 方法中执行：</p>

<pre><code class="language-ruby">def within_new_transaction(options = {})
  @connection.lock.synchronize do
    begin
      transaction = begin_transaction options
      yield
    rescue Exception =&gt; error
      if transaction
        rollback_transaction
        after_failure_actions(transaction, error)
      end
      raise
    ensure
      unless error
        if Thread.current.status == "aborting"
          rollback_transaction if transaction
        else
          begin
            commit_transaction
          rescue Exception
            rollback_transaction(transaction) unless transaction.state.completed?
            raise
          end
        end
      end
    end
  end
end
</code></pre>

<p>上述方法虽然看起来非常复杂，但是方法的逻辑还是还是非常清晰的，如果事务没有抛出任何的异常，就可以将上述代码简化成以下的几行代码：</p>

<pre><code class="language-ruby">def within_new_transaction(options = {})
  @connection.lock.synchronize do
      begin_transaction options
      yield
      commit_transaction
    end
  end
end
</code></pre>

<p>我们可以看到，经过一系列的方法调用最后会在数据库中执行 <code>BEGIN</code>、SQL 语句和 <code>COMMIT</code> 来完成数据的持久化。</p>

<h4 id="追踪属性的重置">追踪属性的重置</h4>

<p>当 <code>ActiveRecord::Transactions#save!</code> 通过 <code>super</code> 将方法抛给上层之后，就由 <code>ActiveRecord::AttributesMethod::Dirty</code> 来处理了：</p>

<pre><code class="language-ruby">def save!(*)
  super.tap do
    changes_applied
  end
end
</code></pre>

<p>如果 <code>#save!</code> 最终执行成功，在这个阶段会将所有模型改变的标记全部清除，对包括 <code>@changed_attributes</code>、<code>@mutation_tracker</code> 在内的实例变量全部重置，为追踪下一次模型的修改做准备。</p>

<h4 id="字段的验证">字段的验证</h4>

<p>沿着整个继承链往下走，下一个被执行的模块就是 <code>ActiveRecord::Validations</code> 了，正如这么模块名字所暗示的，我们在这里会对模型中的字段进行验证：</p>

<pre><code class="language-ruby">def save!(options = {})
  perform_validations(options) ? super : raise_validation_error
end
</code></pre>

<p>上述代码使用 <code>#perform_validations</code> 方法验证模型中的全部字段，以此来保证所有的字段都符合我们的预期：</p>

<pre><code class="language-ruby">def perform_validations(options = {})
  options[:validate] == false || valid?(options[:context])
end
</code></pre>

<p>在这个方法中我们可以看到如果在调用 <code>save!</code> 方法时，传入了 <code>validate: false</code> 所有的验证就都会被跳过，我们通过 <code>#valid?</code> 来判断当前的模型是否合法，而这个方法的执行过程其实也包含两个过程：</p>

<pre><code class="language-ruby">module ActiveRecord
  module Validations
    def valid?(context = nil)
      context ||= default_validation_context
      output = super(context)
      errors.empty? &amp;&amp; output
    end
  end
end

module ActiveModel
  module Validations
    def valid?(context = nil)
      current_context, self.validation_context = validation_context, context
      errors.clear
      run_validations!
    ensure
      self.validation_context = current_context
    end
  end
end
</code></pre>

<p>由于 <code>ActiveModel::Validations</code> 是 <code>ActiveRecord::Validations</code> 的『父类』，所以在 <code>ActiveRecord::Validations</code> 执行 <code>#valid?</code> 方法时，最终会执行父类 <code>#run_validations</code> 运行全部的验证回调。</p>

<pre><code class="language-ruby">module ActiveModel
  module Validations
    def run_validations!
      _run_validate_callbacks
      errors.empty?
    end
  end
end
</code></pre>

<p>通过上述方法的实现，我们可以发现验证是否成功其实并不是通过我们在 <code>validate</code> 中传入一个返回 <code>true/false</code> 的方法决定的，而是要向当前模型的 <code>errors</code> 中添加更多的错误：</p>

<pre><code class="language-ruby">class Invoice &lt; ApplicationRecord
  validate :active_customer
 
  def active_customer
    errors.add(:customer_id, "is not active") unless customer.active?
  end
end
</code></pre>

<p>在这个过程中执行的另一个方法 <code>#_run_validate_callbacks</code> 其实是通过 <code>ActiveSupport::Callbacks</code> 提供的 <code>#define_callbacks</code> 方法动态生成的，所以我们没有办法在工程中搜索到：</p>

<pre><code class="language-ruby">def define_callbacks(*names)
  options = names.extract_options!

  names.each do |name|
    name = name.to_sym
    set_callbacks name, CallbackChain.new(name, options)
    module_eval &lt;&lt;-RUBY, __FILE__, __LINE__ + 1
      def _run_#{name}_callbacks(&amp;block)
        run_callbacks #{name.inspect}, &amp;block
      end

      def self._#{name}_callbacks
        get_callbacks(#{name.inspect})
      end

      def self._#{name}_callbacks=(value)
        set_callbacks(#{name.inspect}, value)
      end

      def _#{name}_callbacks
        __callbacks[#{name.inspect}]
      end
    RUBY
  end
end
</code></pre>

<p>在这篇文章中，我们只需要知道该 <code>#save!</code> 在合适的时机运行了正确的回调就可以了，在后面的文章（可能）中会详细介绍整个 callbacks 的具体执行流程。</p>

<h4 id="数据的持久化">数据的持久化</h4>

<p><code>#save!</code> 的调用栈最顶端就是 <code>ActiveRecord::Persistence#save!</code> 方法：</p>

<pre><code class="language-ruby">def save!(*args, &amp;block)
  create_or_update(*args, &amp;block) || raise(RecordNotSaved.new("Failed to save the record", self))
end

def create_or_update(*args, &amp;block)
  _raise_readonly_record_error if readonly?
  result = new_record? ? _create_record(&amp;block) : _update_record(*args, &amp;block)
  result != false
end
</code></pre>

<p>在这个方法中，我们执行了 <code>#create_or_update</code> 以及 <code>#_create_record</code> 两个方法来创建模型：</p>

<pre><code class="language-ruby">def _create_record(attribute_names = self.attribute_names)
  attributes_values = arel_attributes_with_values_for_create(attribute_names)
  new_id = self.class.unscoped.insert attributes_values
  self.id ||= new_id if self.class.primary_key
  @new_record = false
  yield(self) if block_given?
  id
end
</code></pre>

<p>在这个私有方法中开始执行数据的插入操作了，首先是通过 <code>ActiveRecord::AttributeMethods#arel_attributes_with_values_for_create</code> 方法获取一个用于插入数据的字典，其中包括了数据库中的表字段和对应的待插入值。</p>

<p><img src="https://img.nju520.me/2017-10-21-database-statement-insert.png" alt="database-statement-insert" /></p>

<p>而下面的 <code>.insert</code> 方法就会将这个字典转换成 SQL 语句，经过上图所示的调用栈最终到不同的数据库中执行语句并返回最新的主键。</p>

<h3 id="小结">小结</h3>

<p>从整个模型的创建过程中，我们可以看到 ActiveRecord 对于不同功能的组织非常优雅，每一个方法都非常简短并且易于阅读，通过对应的方法名和模块名我们就能够明确的知道这个东西是干什么的，对于同一个方法的不同执行逻辑也分散了不同的模块中，最终使用 module 加上 include 的方式组织起来，如果要对某个方法添加一些新的逻辑也可以通过增加更多的 module 达到目的。</p>

<p>通过对源代码的阅读，我们可以看到对于 ActiveRecord 来说，<code>#create</code> 和 <code>#save!</code> 方法的执行路径其实是差不多的，只是在细节上有一些不同之处。</p>

<p><img src="https://img.nju520.me/2017-10-21-actual-callstack-for-activerecord-base-save.png" alt="actual-callstack-for-activerecord-base-save" /></p>

<p>虽然模型或者说数据行的创建过程最终会从子类一路执行到父类的 <code>#save!</code> 方法，但是逻辑的<strong>处理顺序</strong>并不是按照从子类到父类执行的，我们可以通过上图了解不同模块的真正执行过程。</p>

<h2 id="scope-和查询的实现">Scope 和查询的实现</h2>

<p>除了模型的插入、创建和迁移模块，ActiveRecord 中还有另一个非常重要的模块，也就是 Scope 和查询；为什么同时介绍这两个看起来毫不相干的内容呢？这是因为 Scope 和查询是完全分不开的一个整体，在 ActiveRecord 的实现中，两者有着非常紧密的联系。</p>

<h3 id="activerecordrelation">ActiveRecord::Relation</h3>

<p>对 ActiveRecord 稍有了解的人都知道，在使用 ActiveRecord 进行查询时，所有的查询方法其实都会返回一个 <code>#{Model}::ActiveRecord_Relation</code> 类的对象，比如 <code>User.all</code>：</p>

<pre><code class="language-ruby">pry(main)&gt; User.all.class
=&gt; User::ActiveRecord_Relation
</code></pre>

<p>在这里使用 pry 来可以帮助我们快速理解整个过程到底都发生了什么事情：</p>

<pre><code class="language-ruby">pry(main)&gt; $ User.all

From: lib/active_record/scoping/named.rb @ line 24:
Owner: ActiveRecord::Scoping::Named::ClassMethods

def all
  if current_scope
    current_scope.clone
  else
    default_scoped
  end
end
</code></pre>

<p><code>#all</code> 方法中的注释中也写着它会返回一个 <code>ActiveRecord::Relation</code> 对象，它其实可以理解为 ActiveRecord 查询体系中的单位元，它的调用并不改变当前查询；而如果我们使用 pry 去看其他的方法例如 <code>User.where</code> 的时候：</p>

<pre><code class="language-ruby">pry(main)&gt; $ User.where

From: lib/active_record/querying.rb @ line 10:
Owner: ActiveRecord::Querying

delegate :select, :group, :order, :except, :reorder, :limit, :offset, :joins, :left_joins, :left_outer_joins, :or,
         :where, :rewhere, :preload, :eager_load, :includes, :from, :lock, :readonly, :extending,
         :having, :create_with, :distinct, :references, :none, :unscope, :merge, to: :all
</code></pre>

<p>从这里我们可以看出，真正实现为 <code>User</code> 类方法的只有 <code>.all</code>，其他的方法都会代理给 <code>all</code> 方法，在 <code>.all</code> 方法返回的对象上执行：</p>

<p><img src="https://img.nju520.me/2017-10-21-active-record-relation-delegation.png" alt="active-record-relation-delegation" /></p>

<p>所有直接在类上调用的方法都会先执行 <code>#all</code>，也就是说下面的几种写法是完全相同的：</p>

<pre><code class="language-ruby">User    .where(name: 'hacker')
User.all.where(name: 'hacker')
User.all.where(name: 'hacker').all
</code></pre>

<p>当我们了解了 <code>.where == .all + #where</code> 就可以再一次使用 pry 来查找真正被 ActiveRecord 实现的 <code>#where</code> 方法：</p>

<pre><code class="language-ruby">pry(main)&gt; $ User.all.where

From: lib/active_record/relation/query_methods.rb @ line 599:
Owner: ActiveRecord::QueryMethods

def where(opts = :chain, *rest)
  if :chain == opts
    WhereChain.new(spawn)
  elsif opts.blank?
    self
  else
    spawn.where!(opts, *rest)
  end
end
</code></pre>

<p>在分析查询的过程中，我们会选择几个常见的方法作为入口，尽可能得覆盖较多的查询相关的代码，增加我们对 ActiveRecord 的理解和认识。</p>

<h3 id="从-userall-开始">从 User.all 开始</h3>

<p>再来看一下上面看到的 <code>ActiveRecord::Relation.all</code> 方法，无论是 <code>#current_scope</code> 还是 <code>#default_scoped</code> 其实返回的都是当前的 <code>ActiveRecord</code> 对象：</p>

<pre><code class="language-ruby">def all
  if current_scope
    current_scope.clone
  else
    default_scoped
  end
end
</code></pre>

<h4 id="current_scope-和-default_scope">current_scope 和 default_scope</h4>

<p>如果当前没有 <code>#current_scope</code> 那么，就会调用 <code>#default_scoped</code> 返回响应的结果，否则就会 clone 当前对象并返回，可以简单举一个例子证明这里的猜测：</p>

<pre><code class="language-ruby">pry(main)&gt; User.current_scope
=&gt; nil
pry(main)&gt; User.all.current_scope
  User Load (0.1ms)  SELECT "users".* FROM "users"
=&gt; []
pry(main)&gt; User.all.current_scope.class
=&gt; User::ActiveRecord_Relation
</code></pre>

<p><code>.current_scope</code> 是存储在位于线程变量的 <code>ScopeRegistry</code> 中，它其实就是当前的查询语句的上下文，存储着这一次链式调用造成的全部副作用：</p>

<pre><code class="language-ruby">def current_scope(skip_inherited_scope = false)
  ScopeRegistry.value_for(:current_scope, self, skip_inherited_scope)
end
</code></pre>

<p>而 <code>.default_scoped</code> 就是在当前查询链刚开始时执行的第一个方法，因为在执行第一个查询方法之前 <code>.current_scope</code> 一定为空：</p>

<pre><code class="language-ruby">def default_scoped(scope = relation)
  build_default_scope(scope) || scope
end

def build_default_scope(base_rel = nil)
  return if abstract_class?

  if default_scopes.any?
    base_rel ||= relation
    evaluate_default_scope do
      default_scopes.inject(base_rel) do |default_scope, scope|
        scope = scope.respond_to?(:to_proc) ? scope : scope.method(:call)
        default_scope.merge(base_rel.instance_exec(&amp;scope))
      end
    end
  end
end
</code></pre>

<p>当我们在 Rails 的模型层中使用 <code>.default_scope</code> 定义一些默认的上下文时，所有的 block 都换被转换成 <code>Proc</code> 对象最终添加到 <code>default_scopes</code> 数组中：</p>

<pre><code class="language-ruby">def default_scope(scope = nil) # :doc:
  scope = Proc.new if block_given?
  # ...
  self.default_scopes += [scope]
end
</code></pre>

<p>上面提到的 <code>.build_default_scope</code> 方法其实只是在 <code>default_scopes</code> 数组不为空时，将当前的 <code>Relation</code> 对象和数组中的全部 scope 一一 <code>#merge</code> 并返回一个新的 <code>Relation</code> 对象。</p>

<h4 id="activerecordrelation-对象">ActiveRecord::Relation 对象</h4>

<p><code>.default_scoped</code> 方法的参数 <code>scope</code> 其实就有一个默认值 <code>#relation</code>，这个默认值其实就是一个 <code>Relation</code> 类的实例：</p>

<pre><code class="language-ruby">def relation
  relation = Relation.create(self, arel_table, predicate_builder)

  if finder_needs_type_condition? &amp;&amp; !ignore_default_scope?
    relation.where(type_condition).create_with(inheritance_column.to_s =&gt; sti_name)
  else
    relation
  end
end
</code></pre>

<p><code>Relation.create</code> 对象的创建过程其实比较复杂，我们只需要知道经过 ActiveRecord 一系列的疯狂操作，最终会将几个参数传入 <code>.new</code> 方法初始化一个 <code>ActiveRecord::Relation</code> 实例：</p>

<pre><code class="language-ruby">class Relation
  def initialize(klass, table, predicate_builder, values = {})
    @klass  = klass
    @table  = table
    @values = values
    @offsets = {}
    @loaded = false
    @predicate_builder = predicate_builder
  end
end
</code></pre>

<p>当执行的是 <code>#all</code>、<code>.all</code> 或者绝大多数查询方法时，都会直接将这个初始化的对象返回来接受随后的链式调用。</p>

<h3 id="where-方法">where 方法</h3>

<p>相比于 <code>#all</code>、<code>#where</code> 查询的实现就复杂多了，不像 <code>#all</code> 会返回一个默认的 <code>Relation</code> 对象，<code>#where</code> 由 <code>WhereClause</code> 以及 <code>WhereClauseFactory</code> 等类共同处理；在 <code>#where</code> 的最正常的执行路径中，它会执行 <code>#where!</code> 方法：</p>

<pre><code class="language-ruby">def where(opts = :chain, *rest)
  if :chain == opts
    WhereChain.new(spawn)
  elsif opts.blank?
    self
  else
    spawn.where!(opts, *rest)
  end
end

def where!(opts, *rest)
  opts = sanitize_forbidden_attributes(opts)
  references!(PredicateBuilder.references(opts)) if Hash === opts
  self.where_clause += where_clause_factory.build(opts, rest)
  self
end
</code></pre>

<blockquote>
  <p><code>#spawn</code> 其实就是对当前的 <code>Relation</code> 对象进行 <code>#clone</code>。</p>
</blockquote>

<p>查询方法 <code>#where!</code> 中的四行代码只有一行代码是我们需要关注的，该方法调用 <code>WhereClauseFactory#build</code> 生成一条 where 查询并存储到当前对象的 <code>where_clause</code> 中，在这个过程中并不会生成 SQL，而是会生成一个 <code>WhereClause</code> 对象，其中存储着 SQL 节点树：</p>

<pre><code class="language-ruby">pry(main)&gt; User.where(name: 'hacker').where_clause
=&gt; #&lt;ActiveRecord::Relation::WhereClause:0x007fe5a10bf2c8
 @binds=
  [#&lt;ActiveRecord::Relation::QueryAttribute:0x007fe5a10bf4f8
    @name="name",
    @original_attribute=nil,
    @type=#&lt;ActiveModel::Type::String:0x007fe59d33f2e0 @limit=nil, @precision=nil, @scale=nil&gt;,
    @value_before_type_cast="hacker"&gt;],
 @predicates=
  [#&lt;Arel::Nodes::Equality:0x007fe5a10bf368
    @left=
     #&lt;struct Arel::Attributes::Attribute
      relation=
       #&lt;Arel::Table:0x007fe59cc87830
        @name="users",
        @table_alias=nil,
        @type_caster=
         #&lt;ActiveRecord::TypeCaster::Map:0x007fe59cc87bf0
          @types=
           User(id: integer, avatar: string, nickname: string, wechat: string, name: string, gender: integer, school: string, grade: string, major: string, completed: boolean, created_at: datetime, updated_at: datetime, mobile: string, admin: boolean)&gt;&gt;,
      name="name"&gt;,
    @right=#&lt;Arel::Nodes::BindParam:0x007fe5a10bf520&gt;&gt;]&gt;
</code></pre>

<blockquote>
  <p><a href="https://github.com/rails/arel">Arel</a> 是一个 Ruby 的 SQL 抽象语法树的管理器，ActiveRecord 查询的过程都是惰性的，在真正进入数据库查询之前，查询条件都是以语法树的形式存储的。</p>
</blockquote>

<p>在这里不像展开介绍 SQL 语法树的生成过程，因为过程比较复杂，详细分析也没有太大的意义。</p>

<h3 id="order-方法">order 方法</h3>

<p>除了 <code>#where</code> 方法之外，在这里还想简单介绍一下另外一个常用的方法 <code>#order</code>：</p>

<pre><code class="language-ruby">def order(*args)
  check_if_method_has_arguments!(:order, args)
  spawn.order!(*args)
end

def order!(*args)
  preprocess_order_args(args)
  self.order_values += args
  self
end
</code></pre>

<p>该方法的调用栈与 <code>#where</code> 非常相似，在调用栈中都会执行另一个带有 <code>!</code> 的方法，也都会向自己持有的某个『属性』追加一些参数，参数的处理也有点复杂，在这里简单看一看就好：</p>

<pre><code class="language-ruby">def preprocess_order_args(order_args)
  order_args.map! do |arg|
    klass.send(:sanitize_sql_for_order, arg)
  end
  order_args.flatten!
  validate_order_args(order_args)

  references = order_args.grep(String)
  references.map! { |arg| arg =~ /^([a-zA-Z]\w*)\.(\w+)/ &amp;&amp; $1 }.compact!
  references!(references) if references.any?

  # if a symbol is given we prepend the quoted table name
  order_args.map! do |arg|
    case arg
    when Symbol
      arel_attribute(arg).asc
    when Hash
      arg.map { |field, dir|
        case field
        when Arel::Nodes::SqlLiteral
          field.send(dir.downcase)
        else
          arel_attribute(field).send(dir.downcase)
        end
      }
    else
      arg
    end
  end.flatten!
end
</code></pre>

<p>同样的，<code>#order</code> 方法的使用也会向 <code>order_values</code> 数组中添加对应的语法元素：</p>

<pre><code class="language-ruby">pry(main)&gt; User.order(name: :desc).order_values
=&gt; [#&lt;Arel::Nodes::Descending:0x007fe59ce4f190
  @expr=
   #&lt;struct Arel::Attributes::Attribute
    relation=
     #&lt;Arel::Table:0x007fe59cc87830
      @name="users",
      @table_alias=nil,
      @type_caster=
       #&lt;ActiveRecord::TypeCaster::Map:0x007fe59cc87bf0
        @types=
         User(id: integer, avatar: string, nickname: string, wechat: string, name: string, gender: integer, school: string, grade: string, major: string, completed: boolean, created_at: datetime, updated_at: datetime, mobile: string, admin: boolean)&gt;&gt;,
    name=:name&gt;&gt;]
</code></pre>

<p>在这个方法的返回值中，我们也能看到与 Arel 相关的各种节点，可以大致理解上述语法树的作用。</p>

<h3 id="语法树的存储">语法树的存储</h3>

<p>无论是 <code>#where</code> 还是 <code>#order</code> 方法，它们其实都会向当前的 <code>Relation</code> 对象中追加相应的语法树节点，而除了上述的两个方法之外 <code>#from</code>、<code>#distinct</code>、<code>#lock</code>、<code>#limit</code> 等等，几乎所有的查询方法都会改变 <code>Relation</code> 中的某个值，然而所有的值其实都是通过 <code>@values</code> 这个实例变量存储的：</p>

<p><img src="https://img.nju520.me/2017-10-21-activerecord-relation-value-methods.png" alt="activerecord-relation-value-methods" /></p>

<p><code>@values</code> 中存储的值分为三类，<code>SINGLE_VALUE</code>、<code>MULTI_VALUE</code> 和 <code>CLAUSE</code>，这三类属性会按照下面的规则存储在 <code>@values</code> 中：</p>

<pre><code class="language-ruby">Relation::VALUE_METHODS.each do |name|
  method_name = \
    case name
    when *Relation::MULTI_VALUE_METHODS then "#{name}_values"
    when *Relation::SINGLE_VALUE_METHODS then "#{name}_value"
    when *Relation::CLAUSE_METHODS then "#{name}_clause"
    end
  class_eval &lt;&lt;-CODE, __FILE__, __LINE__ + 1
    def #{method_name}                   # def includes_values
      get_value(#{name.inspect})         #   get_value(:includes)
    end                                  # end

    def #{method_name}=(value)           # def includes_values=(value)
      set_value(#{name.inspect}, value)  #   set_value(:includes, value)
    end                                  # end
  CODE
end
</code></pre>

<p>各种不同的值在最后都会按照一定的命名规则，存储在这个 <code>@values</code> 字典中：</p>

<pre><code class="language-ruby">def get_value(name)
  @values[name] || default_value_for(name)
end

def set_value(name, value)
  assert_mutability!
  @values[name] = value
end
</code></pre>

<p>如果我们直接在一个查询链中访问 <code>#values</code> 方法可以获得其中存储的所有查询条件：</p>

<pre><code class="language-ruby">pry(main)&gt; User.where(name: 'hacker').order(name: :desc).values
=&gt; {:references=&gt;[],
 :where=&gt;
  #&lt;ActiveRecord::Relation::WhereClause:0x007fe59d14d860&gt;,
 :order=&gt;
  [#&lt;Arel::Nodes::Descending:0x007fe59d14cd98&gt;]}
</code></pre>

<p>很多 ActiveRecord 的使用者其实在使用的过程中都感觉在各种链式方法调用时没有改变任何事情，所有的方法都可以任意组合进行链式调用，其实每一个方法的调用都会对 <code>@values</code> 中存储的信息进行了修改，只是 ActiveRecord 很好地将它隐藏了幕后，让我们没有感知到它的存在。</p>

<h3 id="scope-方法">scope 方法</h3>

<p>相比于 <code>.default_scope</code> 这个类方法只是改变了当前模型中的 <code>default_scopes</code> 数组，另一个方法 <code>.scope</code> 会为当前类定义一个新的类方法：</p>

<pre><code class="language-ruby">From: lib/active_record/scoping/named.rb @ line 155:
Owner: ActiveRecord::Scoping::Named::ClassMethods

def scope(name, body, &amp;block)
  extension = Module.new(&amp;block) if block

  if body.respond_to?(:to_proc)
    singleton_class.send(:define_method, name) do |*args|
      scope = all.scoping { instance_exec(*args, &amp;body) }
      scope = scope.extending(extension) if extension
      scope || all
    end
  else
    singleton_class.send(:define_method, name) do |*args|
      scope = all.scoping { body.call(*args) }
      scope = scope.extending(extension) if extension
      scope || all
    end
  end
end
</code></pre>

<p>上述方法会直接在当前类的单类上通过 <code>define_methods</code> 为当前类定义类方法，定义的方法会在上面提到的 <code>.all</code> 的返回结果上执行 <code>#scoping</code>，存储当前执行的上下文，执行传入的 block，再恢复 <code>current_scope</code>：</p>

<pre><code class="language-ruby">def scoping
  previous, klass.current_scope = klass.current_scope(true), self
  yield
ensure
  klass.current_scope = previous
end
</code></pre>

<p>在这里其实有一个可能很多人从来没用过的特性，就是在 <code>.scope</code> 方法中传入一个 block：</p>

<pre><code class="language-ruby">class User
  scope :male, -&gt; { where gender: :male } do
    def twenty
      where age: 20
    end
  end
end

pry(main)&gt; User.male.twenty
#=&gt; &lt;#User:0x007f98f3d61c38&gt;
pry(main)&gt; User.twenty
#=&gt; NoMethodError: undefined method `twenty' for #&lt;Class:0x007f98f5c7b2b8&gt;
pry(main)&gt; User.female.twenty
#=&gt; NoMethodError: undefined method `twenty' for #&lt;User::ActiveRecord_Relation:0x007f98f5d950e0&gt;
</code></pre>

<p>这个传入的 block 只会在当前 <code>Relation</code> 对象的单类上添加方法，如果我们想定义一些不想在其他作用域使用的方法就可以使用这种方式：</p>

<pre><code class="language-ruby">def extending(*modules, &amp;block)
  if modules.any? || block
    spawn.extending!(*modules, &amp;block)
  else
    self
  end
end

def extending!(*modules, &amp;block)
  modules &lt;&lt; Module.new(&amp;block) if block
  modules.flatten!
  self.extending_values += modules
  extend(*extending_values) if extending_values.any?
  self
end
</code></pre>

<p>而 <code>extending</code> 方法的实现确实与我们预期的一样，创建了新的 <code>Module</code> 对象之后，直接使用 <code>#extend</code> 将其中的方法挂载当前对象的单类上。</p>

<h3 id="小结-1">小结</h3>

<p>到这里为止，我们对 ActiveRecord 中查询的分析就已经比较全面了，从最终要的 <code>Relation</code> 对象，到常见的 <code>#all</code>、<code>#where</code> 和 <code>#order</code> 方法，到 ActiveRecord 对语法树的存储，如何与 Arel 进行协作，在最后我们也介绍了 <code>.scope</code> 方法的工作原理，对于其它方法或者功能的实现其实也都大同小异，在这里就不展开细谈了。</p>

<h2 id="模型的关系">模型的关系</h2>

<p>作为一个关系型数据库的 ORM，ActiveRecord 一定要提供对模型之间关系的支持，它为模型之间的关系建立提供了四个类方法 <code>has_many</code>、<code>has_one</code>、<code>belongs_to</code> 和 <code>has_and_belongs_to_many</code>，在文章的这一部分，我们会从上面几个方法中选择一部分介绍 ActiveRecord 是如何建立模型之间的关系的。</p>

<p><img src="https://img.nju520.me/2017-10-21-activerecord-associations.png" alt="activerecord-associations" /></p>

<h3 id="association-和继承链">Association 和继承链</h3>

<p>首先来看 <code>.has_many</code> 方法是如何实现的，我们可以通过 pry 直接找到该方法的源代码：</p>

<pre><code class="language-ruby">pry(main)&gt; $ User.has_many

From: lib/active_record/associations.rb @ line 1401:
Owner: ActiveRecord::Associations::ClassMethods

def has_many(name, scope = nil, options = {}, &amp;extension)
  reflection = Builder::HasMany.build(self, name, scope, options, &amp;extension)
  Reflection.add_reflection self, name, reflection
end
</code></pre>

<p>整个 <code>.has_many</code> 方法的实现也只有两行代码，总共涉及两个类 <code>Builder::HasMany</code> 和 <code>Reflection</code>，其中前者用于创建新的 <code>HasMany</code> 关系，后者负责将关系添加到当前类中。</p>

<p><code>HasMany</code> 类的实现其实非常简单，但是它从父类和整个继承链中继承了很多方法：</p>

<p><img src="https://img.nju520.me/2017-10-21-activerecord-hasmany-ancestors.png" alt="activerecord-hasmany-ancestors" /></p>

<p>我们暂时先忘记 <code>.has_many</code> 方法的实现，先来看一下这里涉及的两个非常重要的类都是如何工作的，首先是 <code>Association</code> 以及它的子类；在 ActiveRecord 的实现中，我们其实能够找到四种关系的 Builder，它们有着非常清晰简单的继承关系：</p>

<p><img src="https://img.nju520.me/2017-10-21-activerecord-ancestor-builders.png" alt="activerecord-ancestor-builders" /></p>

<p>在这里定义的 <code>.build</code> 方法其实实现也很清晰，它通过调用当前抽象类 <code>Association</code> 或者子类的响应方法完成一些建立关系必要的工作：</p>

<pre><code class="language-ruby">def self.build(model, name, scope, options, &amp;block)
  extension = define_extensions model, name, &amp;block
  reflection = create_reflection model, name, scope, options, extension
  define_accessors model, reflection
  define_callbacks model, reflection
  define_validations model, reflection
  reflection
end
</code></pre>

<p>其中包括创建用于操作、查询和管理当前关系扩展 Module 的 <code>.define_extensions</code> 方法，同时也会使用 <code>.create_reflection</code> 创建一个用于检查 ActiveRecord 类的关系的 <code>Reflection</code> 对象，我们会在下一节中展开介绍，在创建了 <code>Reflection</code> 后，我们会根据传入的模型和 <code>Reflection</code> 对象为当前的类，例如 <code>User</code> 定义属性存取方法、回调以及验证:</p>

<pre><code class="language-ruby">def self.define_accessors(model, reflection)
  mixin = model.generated_association_methods
  name = reflection.name
  define_readers(mixin, name)
  define_writers(mixin, name)
end

def self.define_readers(mixin, name)
  mixin.class_eval &lt;&lt;-CODE, __FILE__, __LINE__ + 1
    def #{name}(*args)
      association(:#{name}).reader(*args)
    end
  CODE
end

def self.define_writers(mixin, name)
  mixin.class_eval &lt;&lt;-CODE, __FILE__, __LINE__ + 1
    def #{name}=(value)
      association(:#{name}).writer(value)
    end
  CODE
end
</code></pre>

<p>存取方法还是通过 Ruby 的元编程能力定义的，在这里通过 <code>.class_eval</code> 方法非常轻松地就能在当前的模型中定义方法，关于回调和验证的定义在这里就不在展开介绍了。</p>

<h3 id="reflection-和继承链">Reflection 和继承链</h3>

<p><code>Reflection</code> 启用了检查 ActiveRecord 类和对象的关系和聚合的功能，它能够在 Builder 中使用为 ActiveRecord 中的类创建对应属性和方法。</p>

<p>与 <code>Association</code> 一样，ActiveRecord 中的不同关系也有不同的 <code>Reflection</code>，根据不同的关系和不同的配置，ActiveRecord 中建立了一套 Reflection 的继承体系与数据库中的不同关系一一对应：</p>

<p><img src="https://img.nju520.me/2017-10-21-activerecord-reflections.png" alt="activerecord-reflections" /></p>

<p>当我们在上面使用 <code>.has_many</code> 方法时，会通过 <code>.create_reflection</code> 创建一个 <code>HasManyReflection</code> 对象：</p>

<pre><code class="language-ruby">def self.create_reflection(model, name, scope, options, extension = nil)
  if scope.is_a?(Hash)
    options = scope
    scope   = nil
  end

  validate_options(options)
  scope = build_scope(scope, extension)
  ActiveRecord::Reflection.create(macro, name, scope, options, model)
end
</code></pre>

<p><code>Reflection#create</code> 方法是一个工厂方法，它会根据传入的 <code>macro</code> 和 <code>options</code> 中的值选择合适的类实例化：</p>

<pre><code class="language-ruby">def self.create(macro, name, scope, options, ar)
  klass = \
    case macro
    when :composed_of
      AggregateReflection
    when :has_many
      HasManyReflection
    when :has_one
      HasOneReflection
    when :belongs_to
      BelongsToReflection
    else
      raise "Unsupported Macro: #{macro}"
    end

  reflection = klass.new(name, scope, options, ar)
  options[:through] ? ThroughReflection.new(reflection) : reflection
end
</code></pre>

<p>这个创建的 <code>Reflection</code> 在很多时候都有非常重要的作用，在创建存储方法、回调和验证时，都需要将这个对象作为参数传入提供一定的支持，起到了数据源和提供 Helper 方法的作用。</p>

<p>在整个定义方法、属性以及回调的工作完成之后，会将当前的对象以 <code>name</code> 作为键存储到自己持有的一个 <code>_reflections</code> 字典中：</p>

<pre><code class="language-ruby"># class_attribute :_reflections, instance_writer: false

def self.add_reflection(ar, name, reflection)
  ar.clear_reflections_cache
  ar._reflections = ar._reflections.merge(name.to_s =&gt; reflection)
end
</code></pre>

<p>这个字典中存储着所有在当前类中使用 <code>has_many</code>、<code>has_one</code>、<code>belongs_to</code> 等方法定义的关系对应的映射。</p>

<h3 id="一对多关系">一对多关系</h3>

<p>一对多关系的这一节会分别介绍两个极其重要的方法 <code>.has_many</code> 和 <code>.belongs_to</code> 的实现；在这里，会先通过 <code>.has_many</code> 关系了解它是如何通过覆写父类方法定制自己的特性的，之后会通过 <code>.belongs_to</code> 研究 getter/setter 方法的调用栈。</p>

<p><img src="https://img.nju520.me/2017-10-21-one-to-many-association.png" alt="one-to-many-association" /></p>

<p>一对多关系在数据库的模型之间非常常见，而这两个方法在 ActiveRecord 也经常成对出现。</p>

<h4 id="has_many">has_many</h4>

<p>当我们对构建关系模块的两大支柱都已经有所了解之后，再来看这几个常用的方法就没有太多的难度了，首先来看一下一对多关系中的『多』是怎么实现的：</p>

<pre><code class="language-ruby">def has_many(name, scope = nil, options = {}, &amp;extension)
  reflection = Builder::HasMany.build(self, name, scope, options, &amp;extension)
  Reflection.add_reflection self, name, reflection
end
</code></pre>

<p>由于已经对 <code>Reflection.add_reflection</code> 方法的实现有所了解，所以这里直接看 <code>.has_many</code> 调用的 <code>Builder::HasMany.build</code> 方法的实现就可以知道这个类方法究竟做了什么，：</p>

<pre><code class="language-ruby">def self.build(model, name, scope, options, &amp;block)
  extension = define_extensions model, name, &amp;block
  reflection = create_reflection model, name, scope, options, extension
  define_accessors model, reflection
  define_callbacks model, reflection
  define_validations model, reflection
  reflection
end
</code></pre>

<p>在这里执行的 <code>.build</code> 方法与抽象类中的方法实现完全相同，子类并没有覆盖父类实现的方法，我们来找一下 <code>.define_accessors</code>、<code>.define_callbacks</code> 和 <code>.define_validations</code> 三个方法在 has_many 关系中都做了什么。</p>

<p><code>HasMany</code> 作为 has_many 关系的 Builder 类，其本身并没有实现太多的方法，只是对一些关系选项有一些自己独有的声明：</p>

<pre><code class="language-ruby">module ActiveRecord::Associations::Builder
  class HasMany &lt; CollectionAssociation
    def self.macro
      :has_many
    end

    def self.valid_options(options)
      super + [:primary_key, :dependent, :as, :through, :source, :source_type, :inverse_of, :counter_cache, :join_table, :foreign_type, :index_errors]
    end

    def self.valid_dependent_options
      [:destroy, :delete_all, :nullify, :restrict_with_error, :restrict_with_exception]
    end
  end
end
</code></pre>

<p>由于本身 has_many 关系中的读写方法都是对集合的操作，所以首先覆写了 <code>.define_writers</code> 和 <code>.define_readers</code> 两个方法生成了另外一组操作 id 的 getter/setter 方法：</p>

<pre><code class="language-ruby">def self.define_readers(mixin, name)
  super

  mixin.class_eval &lt;&lt;-CODE, __FILE__, __LINE__ + 1
    def #{name.to_s.singularize}_ids
      association(:#{name}).ids_reader
    end
  CODE
end

def self.define_writers(mixin, name)
  super

  mixin.class_eval &lt;&lt;-CODE, __FILE__, __LINE__ + 1
    def #{name.to_s.singularize}_ids=(ids)
      association(:#{name}).ids_writer(ids)
    end
  CODE
end
</code></pre>

<p>has_many 关系在 <code>CollectionAssociation</code> 和 <code>HasManyAssociation</code> 中实现的几个方法 <code>#reader</code>、<code>#writer</code>、<code>#ids_reader</code> 和 <code>#ids_writer</code> 其实还是比较复杂的，在这里就跳过不谈了。</p>

<p>而 <code>.define_callbacks</code> 和 <code>.define_extensions</code> 其实都大同小异，在作者看来没有什么值得讲的，has_many 中最重要的部分还是读写方法的实现过程，不过由于篇幅所限这里就不多说了。</p>

<h4 id="belongs_to">belongs_to</h4>

<p>在一对多关系中，经常与 has_many 对应的关系 belongs_to 其实实现和调用栈也几乎完全相同：</p>

<pre><code class="language-ruby">def belongs_to(name, scope = nil, options = {})
  reflection = Builder::BelongsTo.build(self, name, scope, options)
  Reflection.add_reflection self, name, reflection
end
</code></pre>

<p>但是与 has_many 比较大的不同是 <code>Builder::BelongsTo</code> 通过继承的父类定义了很多用于创建新关系的方法：</p>

<pre><code class="language-ruby">def self.define_accessors(model, reflection)
  super
  mixin = model.generated_association_methods
  name = reflection.name
  define_constructors(mixin, name) if reflection.constructable?
  mixin.class_eval &lt;&lt;-CODE, __FILE__, __LINE__ + 1
    def reload_#{name}
      association(:#{name}).force_reload_reader
    end
  CODE
end

def self.define_constructors(mixin, name)
  mixin.class_eval &lt;&lt;-CODE, __FILE__, __LINE__ + 1
    def build_#{name}(*args, &amp;block)
      association(:#{name}).build(*args, &amp;block)
    end
    def create_#{name}(*args, &amp;block)
      association(:#{name}).create(*args, &amp;block)
    end
    def create_#{name}!(*args, &amp;block)
      association(:#{name}).create!(*args, &amp;block)
    end
  CODE
end
</code></pre>

<p>其他的部分虽然实现上也与 has_many 有着非常大的不同，但是原理基本上完全一致，不过在这里我们可以来看一下 belongs_to 关系创建的两个方法 <code>association</code> 和 <code>association=</code> 究竟是如何对数据库进行操作的。</p>

<pre><code class="language-ruby">class Topic &lt; ActiveRecord::Base
  has_many :subtopics
end

class Subtopic &lt; ActiveRecord::Base
  belongs_to :topic
end
</code></pre>

<p>假设我们有着如上所示的两个模型，它们之间是一对多关系，我们以这对模型为例先来看一下 <code>association</code> 这个读方法的调用栈。</p>

<p><img src="https://img.nju520.me/2017-10-21-callstack-for-belongs-to-association-getter.png" alt="callstack-for-belongs-to-association-gette" /></p>

<p>通过我们对源代码和调用栈的阅读，我们可以发现其实如下的所有方法调用在大多数情况下是完全等价的，假设我们已经持有了一个 <code>Subtopic</code> 对象：</p>

<pre><code class="language-ruby">subtopic = Subtopic.first #=&gt; #&lt;Subtopic:0x007ff513f67768&gt;

subtopic.topic
subtopic.association(:topic).reader
subtopic.association(:topic).target
subtopic.association(:topic).load_target
subtopic.association(:topic).send(:find_target)
</code></pre>

<p>上述的五种方式都可以获得当前 <code>Subtopic</code> 对象的 belongs_to 关系对应的 <code>Topic</code> 数据行，而最后一个方法 <code>#find_target</code> 其实也就是真正创建、绑定到最后执行查询 SQL 的方法：</p>

<pre><code class="language-ruby">pry(main)&gt; $ subtopic.association(:topic).find_target

From: lib/active_record/associations/singular_association.rb @ line 38:
Owner: ActiveRecord::Associations::SingularAssociation

def find_target
  return scope.take if skip_statement_cache?

  conn = klass.connection
  sc = reflection.association_scope_cache(conn, owner) do
    StatementCache.create(conn) { |params|
      as = AssociationScope.create { params.bind }
      target_scope.merge(as.scope(self, conn)).limit(1)
    }
  end

  binds = AssociationScope.get_bind_values(owner, reflection.chain)
  sc.execute(binds, klass, conn) do |record|
    set_inverse_instance record
  end.first
rescue ::RangeError
  nil
end
</code></pre>

<p>我们已经对 <code>association</code> 方法的实现有了非常清楚的认知了，下面再来过一下 <code>association=</code> 方法的实现，首先还是来看一下 setter 方法的调用栈：</p>

<p><img src="https://img.nju520.me/2017-10-21-callstack-for-belongs-to-association-setter.png" alt="callstack-for-belongs-to-association-sette" /></p>

<p>相比于 getter 的调用栈，setter 方法的调用栈都复杂了很多，在研究 setter 方法实现的过程中我们一定要记住这个方法并不会改变数据库中对应的数据行，只会改变当前对应的某个属性，经过对调用栈和源代码的分析，我们可以有以下的结论：假设现在有一个 <code>Subtopic</code> 对象和一个新的 <code>Topic</code> 实例，那么下面的一系列操作其实是完全相同的：</p>

<pre><code class="language-ruby">subtopic = Subtopic.first #=&gt; #&lt;Subtopic:0x007ff513f67768&gt;
new_topic = Topic.first   #=&gt; #&lt;Topic:0x007ff514b24cb8&gt;

subtopic.topic = new_topic
subtopic.topic_id = new_topic.id
subtopic.association(:topic).writer(new_topic)
subtopic.association(:topic).replace(new_topic)
subtopic.association(:topic).replace_keys(new_topic)
subtopic.association(:topic).owner[:topic_id] = new_topic.id
subtopic[:topic_id] = new_topic.id
subtopic.write_attribute(:topic_id, new_topic.id)
</code></pre>

<p>虽然这些方法最后返回的结果可能有所不同，但是它们最终都会将 <code>subtopic</code> 对象的 <code>topic_id</code> 属性更新成 <code>topic.id</code>，上面的方法中有简单的，也有复杂的，不过都能达到相同的目的；我相信如果读者亲手创建上述的关系并使用 pry 查看源代码一定会对 getter 和 setter 的执行过程有着非常清楚的认识。</p>

<h3 id="多对多关系-habtm">多对多关系 habtm</h3>

<p>无论是 has_many 还是 belongs_to 其实都是一个 ORM 原生需要支持的关系，但是 habtm(has_and_belongs_to_many) 却是 ActiveRecord 为我们提供的一个非常方便的语法糖，哪怕是并没有 <code>.has_and_belongs_to_many</code> 这个方法，我们也能通过 <code>.has_many</code> 实现多对多关系，得到与前者完全等价的效果，只是实现的过程稍微麻烦一些。</p>

<p>在这一小节中，我们想要了解 habtm 这个语法糖是如何工作的，它是如何将现有的关系组成更复杂的 habtm 的多对多关系的；想要了解它的工作原理，我们自然要分析它的源代码：</p>

<pre><code class="language-ruby">def has_and_belongs_to_many(name, scope = nil, **options, &amp;extension)
  builder = Builder::HasAndBelongsToMany.new name, self, options
  join_model = ActiveSupport::Deprecation.silence { builder.through_model }
  const_set join_model.name, join_model
  private_constant join_model.name

  habtm_reflection = ActiveRecord::Reflection::HasAndBelongsToManyReflection.new(name, scope, options, self)
  middle_reflection = builder.middle_reflection join_model
  Builder::HasMany.define_callbacks self, middle_reflection
  Reflection.add_reflection self, middle_reflection.name, middle_reflection
  middle_reflection.parent_reflection = habtm_reflection

  # ...

  hm_options = {}
  hm_options[:through] = middle_reflection.name
  hm_options[:source] = join_model.right_reflection.name

  # ...

  ActiveSupport::Deprecation.silence { has_many name, scope, hm_options, &amp;extension }
  _reflections[name.to_s].parent_reflection = habtm_reflection
end
</code></pre>

<blockquote>
  <p>在这里，我们对该方法的源代码重新进行组织和排序，方法的作用与 v5.1.4 中的完全相同。</p>
</blockquote>

<p>上述方法在最开始先创建了一个 <code>HasAndBelongsToMany</code> 的 Builder 实例，然后在 block 中执行了这个 Builder 的 <code>#through_model</code> 方法：</p>

<pre><code class="language-ruby">def through_model
  habtm = JoinTableResolver.build lhs_model, association_name, options

  join_model = Class.new(ActiveRecord::Base) {
    class &lt;&lt; self;
      attr_accessor :left_model
      attr_accessor :name
      attr_accessor :table_name_resolver
      attr_accessor :left_reflection
      attr_accessor :right_reflection
    end

    # ...
  }

  join_model.name                = "HABTM_#{association_name.to_s.camelize}"
  join_model.table_name_resolver = habtm
  join_model.left_model          = lhs_model
  join_model.add_left_association :left_side, anonymous_class: lhs_model
  join_model.add_right_association association_name, belongs_to_options(options)
  join_model
end
</code></pre>

<p><code>#through_model</code> 方法会返回一个新的继承自 <code>ActiveRecord::Base</code> 的类，我们通过一下的例子来说明一下这里究竟做了什么，假设在我们的工程中定义了如下的两个类：</p>

<pre><code class="language-ruby">class Post &lt; ActiveRecord::Base
  has_and_belongs_to_many :tags
end

class Tag &lt; ActiveRecord::Base
  has_and_belongs_to_many :posts
end
</code></pre>

<p>它们每个类都通过 <code>.has_and_belongs_to_many</code> 创建了一个 <code>join_model</code> 类，这两个类都是在当前类的命名空间下的：</p>

<pre><code class="language-ruby">class Post::HABTM_Posts &lt; ActiveRecord::Base; end
class Tags::HABTM_Posts &lt; ActiveRecord::Base; end
</code></pre>

<p>除了在当前类的命名空间下定义两个新的类之外，<code>#through_model</code> 方法还通过 <code>#add_left_association</code> 和 <code>#add_right_association</code> 为创建的私有类添加了两个 <code>.belongs_to</code> 方法的调用：</p>

<pre><code class="language-ruby">join_model = Class.new(ActiveRecord::Base) {
  # ...

  def self.add_left_association(name, options)
    belongs_to name, required: false, **options
    self.left_reflection = _reflect_on_association(name)
  end

  def self.add_right_association(name, options)
    rhs_name = name.to_s.singularize.to_sym
    belongs_to rhs_name, required: false, **options
    self.right_reflection = _reflect_on_association(rhs_name)
  end
}
</code></pre>

<p>所以在这里，每一个 HABTM 类中都通过 <code>.belongs_to</code> 增加了两个对数据库表中对应列的映射：</p>

<pre><code class="language-ruby">class Post::HABTM_Posts &lt; ActiveRecord::Base
  belongs_to :post_id, required: false
  belongs_to :tag_id, required: false
end

class Tags::HABTM_Posts &lt; ActiveRecord::Base
  belongs_to :tag_id, required: false
  belongs_to :post_id, required: false
end
</code></pre>

<p>看到这里，你可能会认为既然有两个模型，那么应该会有两张表分别对应这两个模型，但是实际情况却不是这样。</p>

<p><img src="https://img.nju520.me/2017-10-21-habtm-association-table-name.png" alt="habtm-association-table-name" /></p>

<p>ActiveRecord 通过覆写这两个类的 <code>.table_name</code> 方法，使用一个 <code>JoinTableResolver</code> 来解决不同的模型拥有相同的数据库表的问题：</p>

<pre><code class="language-ruby">class Migration
  module JoinTable
    def join_table_name(table_1, table_2)
      ModelSchema.derive_join_table_name(table_1, table_2).to_sym
    end
  end
end

module ModelSchema
  def self.derive_join_table_name(first_table, second_table) 
    [first_table.to_s, second_table.to_s].sort.join("\0").gsub(/^(.*_)(.+)\0\1(.+)/, '\1\2_\3').tr("\0", "_")
  end
end
</code></pre>

<p>在默认的 <code>join_table</code> 规则中，两张表会按照字母顺序排序，最后通过 <code>_</code> 连接到一起，但是如果两张表有着完全相同的前缀，比如 music_artists 和 music_records 两张表，它们连接的结果就是 music_artists_records，公共的前缀会被删除，这种情况经常发生在包含命名空间的模型中，例如：<code>Music::Artist</code>。</p>

<p>当我们已经通过多对多关系的 Builder 创建了一个中间模型之后，就会建立两个 <code>Reflection</code> 对象：</p>

<pre><code class="language-ruby">habtm_reflection = ActiveRecord::Reflection::HasAndBelongsToManyReflection.new(name, scope, options, self)
middle_reflection = builder.middle_reflection join_model
Builder::HasMany.define_callbacks self, middle_reflection
Reflection.add_reflection self, middle_reflection.name, middle_reflection
middle_reflection.parent_reflection = habtm_reflection
</code></pre>

<p>其中一个对象是 <code>HasAndBelongsToManyReflection</code> 实例，表示当前的多对多关系，另一个对象是 <code>#middle_reflection</code> 方法返回的 <code>HasMany</code>，表示当前的类与 <code>join_model</code> 之间有一个一对多关系，这个关系是隐式的，不过我们可以通过下面的代码来『理解』它：</p>

<pre><code class="language-ruby">class Post &lt; ActiveRecord::Base
  # has_and_belongs_to_many :posts
  # =
  has_many :posts_tag
  # + 
  # ...
end
</code></pre>

<p>上述的代码构成了整个多对多关系的一部分，而另一部分由下面的代码来处理，当模型持有了一个跟中间模型相关的一对多关系之后，就会创建另一个以中间模型为桥梁 has_many 关系：</p>

<pre><code class="language-ruby">hm_options = {}
hm_options[:through] = middle_reflection.name
hm_options[:source] = join_model.right_reflection.name

ActiveSupport::Deprecation.silence { has_many name, scope, hm_options, &amp;extension }
</code></pre>

<p>这里还是使用 <code>Post</code> 和 <code>Tag</code> 这两个模型之间的关系举例子，通过上述代码，我们会在两个类中分别建立如下的关系：</p>

<pre><code class="language-ruby">class Post &lt; ActiveRecord::Base
  # has_many :posts_tag
  has_many :tags, through: :posts_tag, source: :tag
end

class Tag &lt; ActiveRecord::Base
  # has_many :tags_post
  has_many :post, through: :tags_post, source: :post
end
</code></pre>

<p>通过两个隐式的 has_many 关系，两个显示的 has_many 就能够通过 <code>through</code> 和 <code>source</code> 间接找到自己对应的多个数据行，而从开发者的角度来看，整个工程中只使用了一行代码 <code>has_and_belongs_to_many :models</code>，其他的工作完全都是隐式的。</p>

<p><img src="https://img.nju520.me/2017-10-21-many-to-many-associations.png" alt="many-to-many-associations" /></p>

<p>由于关系型数据库其实并没有物理上的多对多关系，只有在逻辑上才能实现多对多，所以对于每一个模型来说，它实现的都是一对多关系；只有从整体来看，通过 <code>PostsTags</code> 第三张表的引入，我们实现的才是从 <code>Post</code> 到 <code>Tag</code> 之间的多对多关系。</p>

<h3 id="小结-2">小结</h3>

<p>ActiveRecord 对关系的支持其实非常全面，从最常见的一对一、一对多关系，再到多对多关系，都有着非常优雅、简洁的实现，虽然这一小节中没能全面的介绍所有关系的实现，但是对整个模块中重要类和整体架构的介绍已经非常具体了；不得不感叹 ActiveRecord 对多对多关系方法 <code>has_and_belongs_to_many</code> 的实现非常整洁，我们在分析其实现时也非常顺畅。</p>

<h2 id="migrations-任务和执行过程">Migrations 任务和执行过程</h2>

<p>Migrations（迁移）是 ActiveRecord 提供的一种用于更改数据库 Schema 的方式，它提供了可以直接操作数据库的 DSL，这样我们就不需要自己去手写所有的 SQL 来更新数据库中的表结构了。</p>

<p><img src="https://img.nju520.me/2017-10-21-activerecord-migrations.png" alt="activerecord-migrations" /></p>

<p>每一个 Migration 都具有一个唯一的时间戳，每次进行迁移时都会在现有的数据库中执行当前 Migration 文件的 DSL 更新数据库 Schema 得到新的数据库版本。而想要理解 Migrations 是如何工作的，就需要知道 <code>#create_table</code>、<code>#add_column</code> 等 DSL 是怎么实现的。</p>

<h3 id="migration51">Migration[5.1]</h3>

<p>我在使用 ActiveRecord 提供的数据库迁移的时候一直都特别好奇 <code>Migration[5.1]</code> 后面跟着的这个 <code>[5.1]</code> 是个什么工作原理，看了源代码之后我才知道：</p>

<pre><code class="language-ruby">class Migration
  def self.[](version)
    Compatibility.find(version)
  end
end
</code></pre>

<p><code>.[]</code> 是 <code>ActiveRecord::Migration</code> 的类方法，它通过执行 <code>Compatibility.find</code> 来判断当前的代码中使用的数据库迁移版本是否与 gem 中的版本兼容：</p>

<pre><code class="language-ruby">class Current &lt; Migration
end
</code></pre>

<p><code>compatibility.rb</code> 在兼容性方面做了很多事情，保证 ActiveRecord 中的迁移都是可以向前兼容的，在这里也就不准备介绍太多了。</p>

<h3 id="从-rake-dbmigrate-开始">从 rake db:migrate 开始</h3>

<p>作者在阅读迁移部分的源代码时最开始以 <code>Migration</code> 类作为入口，结果发现这并不是一个好的选择，最终也没能找到定义 DSL 的位置，所以重新选择了 <code>rake db:migrate</code> 作为入口分析迁移的实现；通过对工程目录的分析，很快就能发现 ActiveRecord 中所有的 rake 命令都位于 <code>lib/railties/database.rake</code> 文件中，在文件中也能找到 <code>db:migrate</code> 对应的 rake 任务：</p>

<pre><code class="language-ruby">db_namespace = namespace :db do
  desc "Migrate the database (options: VERSION=x, VERBOSE=false, SCOPE=blog)."
  task migrate: [:environment, :load_config] do
    ActiveRecord::Tasks::DatabaseTasks.migrate
    db_namespace["_dump"].invoke
  end
end
</code></pre>

<p>上述代码中的 <code>DatabaseTasks</code> 类就包含在 <code>lib/active_record/tasks</code> 目录中的 <code>database_tasks.rb</code> 文件里：</p>

<pre><code class="language-ruby">lib/active_record/tasks/
├── database_tasks.rb
├── mysql_database_tasks.rb
├── postgresql_database_tasks.rb
└── sqlite_database_tasks.rb
</code></pre>

<p><code>#migrate</code> 方法就是 <code>DatabaseTasks</code> 的一个实例方法，同时 ActiveRecord 通过 <code>extend self</code> 将 <code>#migrate</code> 方法添加到了当前类的单类上，成为了当前类的类方法：</p>

<pre><code class="language-ruby">module Tasks
  module DatabaseTasks
    extend self
    
    def migrate
      raise "Empty VERSION provided" if ENV["VERSION"] &amp;&amp; ENV["VERSION"].empty?

      version = ENV["VERSION"] ? ENV["VERSION"].to_i : nil
      scope = ENV["SCOPE"]
      Migrator.migrate(migrations_paths, version) do |migration|
        scope.blank? || scope == migration.scope
      end
      ActiveRecord::Base.clear_cache!
    end
  end
end
</code></pre>

<h4 id="迁移器migrator">『迁移器』Migrator</h4>

<p>迁移任务中主要使用了 <code>Migrator.migrate</code> 方法，通过传入迁移文件的路径和期望的迁移版本对数据库进行迁移：</p>

<pre><code class="language-ruby">class Migrator#:nodoc:
  class &lt;&lt; self
    def migrate(migrations_paths, target_version = nil, &amp;block)
      case
      when target_version.nil?
        up(migrations_paths, target_version, &amp;block)
      when current_version == 0 &amp;&amp; target_version == 0
        []
      when current_version &gt; target_version
        down(migrations_paths, target_version, &amp;block)
      else
        up(migrations_paths, target_version, &amp;block)
      end
    end
  end
end
</code></pre>

<p>在默认情况下，显然我们是不会传入目标的数据库版本的，也就是 <code>target_version.nil? == true</code>，这时会执行 <code>.up</code> 方法，对数据库向『上』迁移：</p>

<pre><code class="language-ruby">def up(migrations_paths, target_version = nil)
  migrations = migrations(migrations_paths)
  migrations.select! { |m| yield m } if block_given?

  new(:up, migrations, target_version).migrate
end
</code></pre>

<h4 id="方法调用栈">方法调用栈</h4>

<p>通过 <code>.new</code> 方法 ActiveRecord 初始化了一个新的 <code>Migrator</code> 实例，然后执行了 <code>Migrator#migrate</code>，在整个迁移执行的过程中，我们有以下的方法调用栈：</p>

<p><img src="https://img.nju520.me/2017-10-21-rake-db-migrate.png" alt="rake-db-migrate" /></p>

<p>在整个迁移过程的调用栈中，我们会关注以下的四个部分，首先是 <code>Migrator#migrate_without_lock</code> 方法：</p>

<pre><code class="language-ruby">def migrate_without_lock
  if invalid_target?
    raise UnknownMigrationVersionError.new(@target_version)
  end

  result = runnable.each do |migration|
    execute_migration_in_transaction(migration, @direction)
  end

  record_environment
  result
end
</code></pre>

<p>这个方法其实并没有那么重要，但是这里调用了 <code>Migrator#runnable</code> 方法，这个无参的方法返回了所有需要运行的 <code>Migration</code> 文件，<code>Migrator#runnable</code> 是如何选择需要迁移的文件是作者比较想要了解的，也是作者认为比较重要的地方：</p>

<pre><code class="language-ruby">def runnable
  runnable = migrations[start..finish]
  if up?
    runnable.reject { |m| ran?(m) }
  else
    runnable.pop if target
    runnable.find_all { |m| ran?(m) }
  end
end

def ran?(migration)
  migrated.include?(migration.version.to_i)
end
</code></pre>

<p>通过对这个方法的阅读的分析，我们可以看到，如果迁移模式是 <code>:up</code>，那么就会选择所有未迁移的文件，也就是说在这时<strong>迁移文件的选择与创建的顺序是无关的</strong>。</p>

<h4 id="迁移的执行">迁移的执行</h4>

<p>当我们通过 <code>#runnable</code> 获得了整个待运行的迁移文件数组之后，就可以遍历所有的文件一次执行 <code>Migrator#execute_migrate_in_transaction</code> 方法了，在调用栈的最后会执行 <code>Migration#exec_migration</code>：</p>

<pre><code class="language-ruby">def exec_migration(conn, direction)
  @connection = conn
  if respond_to?(:change)
    if direction == :down
      revert { change }
    else
      change
    end
  else
    send(direction)
  end
ensure
  @connection = nil
end
</code></pre>

<p>到这里就能与我们平时在 <code>Migration</code> 中实现的 <code>#change</code>、<code>#up</code> 和 <code>#down</code> 连到一起，逻辑也走通了；上述代码的逻辑还是很清晰的，如果当前的 <code>Migratoin</code> 实现了 <code>#change</code> 方法就会根据 <code>direction</code> 选择执行 <code>#change</code> 还是 <code>#revert + #change</code>，否则就会按照迁移的方向执行对应的方法。</p>

<h3 id="migrations-的-dsl">Migrations 的 DSL</h3>

<p>在数据迁移的模块执行的 Migration 文件中包含的都是 ActiveRecord 提供的 DSL 语法，这部分语法包含两部分，一部分是 Schema 相关的 DSL <code>schema_statements.rb</code>，其中包括表格的创建和删除以及一些用于辅助 Schema 创建的 <code>#column_exists?</code> 等方法，另一部分是表定义相关的 DSL <code>schema_definitions.rb</code>，其中包括处理表结构的 <code>TableDefinition</code> 类和抽象代表一张数据库中表的 <code>Table</code> 类。</p>

<h4 id="抽象适配器">抽象适配器</h4>

<p>在整个 <code>connection_adapters</code> 的子模块中，绝大多数模块在三大 SQL 数据库，MySQL、PostgreSQL 和 sqlite3 中都有着各自的实现：</p>

<pre><code class="language-ruby">lib/active_record/connection_adapters
├── abstract
│   ├── connection_pool.rb
│   ├── database_limits.rb
│   ├── database_statements.rb
│   ├── query_cache.rb
│   ├── quoting.rb
│   ├── savepoints.rb
│   ├── schema_creation.rb
│   ├── schema_definitions.rb
│   ├── schema_dumper.rb
│   ├── schema_statements.rb
│   └── transaction.rb
├── mysql
│   ├── column.rb
│   ├── database_statements.rb
│   ├── explain_pretty_printer.rb
│   ├── quoting.rb
│   ├── schema_creation.rb
│   ├── schema_definitions.rb
│   ├── schema_dumper.rb
│   ├── schema_statements.rb
│   └── type_metadata.rb
├── postgresql
│   └── ...
├── sqlite3
│   └── ...
├── abstract_adapter.rb
├── ...
└── sqlite3_adapter.rb
</code></pre>

<p>不过这三个数据库的所有子模块都继承自 <code>AbstractAdapter</code> 下面对应的子模块，以获得一些三者共用的能力，包括数据库、Schema 的声明与管理等功能。</p>

<p><img src="https://img.nju520.me/2017-10-21-abstract-adapter-and-much-more.png" alt="abstract-adapter-and-much-more" /></p>

<p>通过 <code>AbstractAdapter</code> 抽离出的公用功能，我们可以通过新的适配器随时适配其他的 SQL 数据库。</p>

<h4 id="schema-dsl">Schema DSL</h4>

<p>数据库的 Schema DSL 部分就包含我们经常使用的 <code>#create_table</code>、<code>#rename_table</code> 以及 <code>#add_column</code> 这些需要表名才能执行的方法，在这里以最常见的 <code>#create_table</code> 为例，简单分析一下这部分代码的实现：</p>

<pre><code class="language-ruby">def create_table(table_name, comment: nil, **options)
  td = create_table_definition table_name, options[:temporary], options[:options], options[:as], comment: comment

  yield td if block_given?

  execute schema_creation.accept td
end
</code></pre>

<p>首先，在创建表时先通过 <code>#create_table_definition</code> 方法创建一个新的 <code>TableDefinition</code> 实例，然后将这个实例作为参数传入 block：</p>

<pre><code class="language-ruby">create_table :users do |t|
end
</code></pre>

<p>在 block 对这个 <code>TableDefinition</code> 对象一顿操作后，会通过 <code>SchemaCreation#accept</code> 方法获得一个用于在数据库中，能够创建表的 SQL 语句：</p>

<pre><code class="language-ruby">def accept(o)
  m = @cache[o.class] ||= "visit_#{o.class.name.split('::').last}"
  send m, o
end

def visit_TableDefinition(o)
  create_sql = "CREATE#{' TEMPORARY' if o.temporary} TABLE #{quote_table_name(o.name)} "

  statements = o.columns.map { |c| accept c }
  statements &lt;&lt; accept(o.primary_keys) if o.primary_keys

  create_sql &lt;&lt; "(#{statements.join(', ')})" if statements.present?
  add_table_options!(create_sql, table_options(o))
  create_sql &lt;&lt; " AS #{@conn.to_sql(o.as)}" if o.as
  create_sql
end
</code></pre>

<p><code>SchemaCreation</code> 类就是一个接受各种各样的 <code>TableDefinition</code>、<code>PrimaryKeyDefinition</code> 对象返回 SQL 的一个工具，可以将 <code>SchemaCreation</code> 理解为一个表结构的解释器；最后的 <code>#execute</code> 会在数据库中执行 SQL 改变数据库中的表结构。</p>

<p>在 <code>SchemaStatements</code> 中定义的其它方法的实现也都是大同小异，比如 <code>#drop_table</code> 其实都是删除数据库中的某张表：</p>

<pre><code class="language-ruby">def drop_table(table_name, options = {})
  execute "DROP TABLE#{' IF EXISTS' if options[:if_exists]} #{quote_table_name(table_name)}"
end
</code></pre>

<h4 id="表定义-dsl">表定义 DSL</h4>

<p><code>SchemaStatements</code> 中定义的方法，参数大都包含 <code>table_name</code>，而另一个类 <code>TableDefinitions</code> 就包含了直接对表操作的 DSL：</p>

<pre><code class="language-ruby">create_table :foo do |t|
  puts t.class  # =&gt; "ActiveRecord::ConnectionAdapters::TableDefinition"
end
</code></pre>

<p>当我们在 <code>#create_table</code> 中使用例如 <code>#string</code>、<code>#integer</code> 等方法时，所有的方法都会通过元编程的魔法最终执行 <code>TableDefinition#column</code> 改变表的定义：</p>

<pre><code class="language-ruby">module ColumnMethods
  [
    :bigint,
    # ...
    :integer,
    :string,
    :text,
    :time,
    :timestamp,
    :virtual,
  ].each do |column_type|
    module_eval &lt;&lt;-CODE, __FILE__, __LINE__ + 1
      def #{column_type}(*args, **options)
        args.each { |name| column(name, :#{column_type}, options) }
      end
    CODE
  end
  alias_method :numeric, :decimal
end
</code></pre>

<p><code>#column</code> 方法非常神奇，它从各处收集有关当前表的定义，最终为表中的每一个字段创建一个 <code>ColumnDefinition</code> 实例，并存储到自己持有的 <code>@columns_hash</code> 中：</p>

<pre><code class="language-ruby">def column(name, type, options = {})
  name = name.to_s
  type = type.to_sym if type
  options = options.dup

  index_options = options.delete(:index)
  index(name, index_options.is_a?(Hash) ? index_options : {}) if index_options
  @columns_hash[name] = new_column_definition(name, type, options)
  self
end

def new_column_definition(name, type, **options)
  type = aliased_types(type.to_s, type)
  options[:primary_key] ||= type == :primary_key
  options[:null] = false if options[:primary_key]
  create_column_definition(name, type, options)
end

def create_column_definition(name, type, options)
  ColumnDefinition.new(name, type, options)
end
</code></pre>

<p>除了 <code>ColumnDefinition</code> 之外，在 ActiveRecord 中还存在 <code>PrimaryKeyDefinition</code>、<code>IndexDefinition</code> 等等类和结构体用于表示数据库中的某一种元素。</p>

<p>表结构在最后会被 <code>SchemaCreation</code> 类的 <code>#accept</code> 方法展开，最后在数据库中执行。</p>

<h3 id="小结-3">小结</h3>

<p>到这里整个 Migrations 部分的实现就已经阅读分析完了，整个『模块』包含两个部分，一部分是 rake 任务执行 DSL 代码的过程，另一部分是 DSL 的实现，两部分的结合最终构成了整个 Migrations 模块的全部内容。</p>

<p>ActiveRecord 对于 Migration 迁移机制的设计确实很好的解决数据库中的表结构不断变更的问题，同时因为所有的 Migration 文件都在版本控制中管理，我们也能够随时还原数据库中的表结构。</p>

<h2 id="总结">总结</h2>

<p>文章对 ActiveRecord 中涉及的很多问题都进行了分析和介绍，包括模型的创建、查询以及关系，还包括数据库表迁移的实现，本来想将文中的几个部分分开进行介绍，但是写着写着就懒得分开了，如果对文章的内容有疑问，请在博客下面的评论系统中留言。</p>

<blockquote>

</blockquote>


  ]]></description>
</item>


  </channel>
</rss>
