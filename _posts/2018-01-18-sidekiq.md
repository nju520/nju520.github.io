---
layout: post
toc: true
permalink: /sidekiq
title: Sidekiq 异步任务调度与执行
tags: Ruby Sidekiq workers Redis
desc: sidekiq 是 Ruby 中一款非常优秀的后台任务处理软件, 其本身提供的API十分简洁, 源代码也易于阅读, 没有太多花哨的代码. Sidekiq 将 Redis 的各种数据结构用得都起到好处, 我们可以通过 Sidekiq 加深对 Redis 的印象以及学习如何恰当高效地结合 Redis 实现业务逻辑.本篇文章从 Sidekiq 的启动开始,详细解读 Sidekiq 的异步任务调度和执行.
---

  sidekiq 是 Ruby 中一款非常优秀的后台任务处理软件, 其本身提供的API十分简洁, 源代码也易于阅读, 没有太多花哨的代码. Sidekiq 将 Redis 的各种数据结构用得都起到好处, 我们可以通过 Sidekiq 加深对 Redis 的印象以及学习如何恰当高效地结合 Redis 实现业务逻辑.本篇文章从 Sidekiq 的启动开始,详细解读 Sidekiq 的异步任务调度和执行.  除此之外, 我还会介绍中间件机制以及在此基础上实现的任务重试机制.



> 本篇文章涉及的 Sidekiq 版本是 5.0.5



## 初识 Sidekiq

在我们具体解读`Sidekiq`的源码之前, 我们先来熟悉一下`Sidekiq`异步任务的创建和执行, 保证我们对其结构有一个总体的认识.

`Sidekiq`的使用非常简洁, 我们只需要在`app/workers`文件夹中添加一个`worker`,来处理异步请求:

~~~ruby
class HardWorker
  include Sidekiq::Worker

  def perform(name, count)
  # do something you want
  end
end
~~~



我们可以在需要执行操作的地方提交异步任务了:

~~~ruby
#. 常规提交
HardWorker.perform_async('hehe', 10)

# 延迟提交 10分钟
HardWorker.perform_in(10.minutes, 'sleep', 10)

# 指定将来的某个时刻提交
# 我们指定此任务明天的这个此刻执行
HardWorker.perform_at(Time.now + 1.day, 'run', 200)
~~~

当我们执行上述三个提交方法时, `Sidekiq Worker`会将一个异步任务以`JSON`的形式将相关的参数信息加入到 `Redis`中并等待消费者对任务的拉取和处理.



`Sidekiq`的消费者由三个部分:

* Sidekiq::Scheduled::Poller: 定时任务拉取器.
  * 负责在一定时间范围内不定时检查定时任务(scheduled)以及重试任务(retry), 将计划时间已经超过当前时间的任务追加到各自对应的任务队列中

* Sidekiq::Manager: worker 管理器. 负责按照配置的`concurrency`参数创建匹配数量的`worker`, 同时负责`worker`的管理. 这里的`worker`实际上就是一个`Processor`的实例

* Sidekiq::Processor:  负责执行指定的任务

它们三者会相互协作共同完成对`Redis`中任务消费的全过程.



![Sidekiq Module]()



## 异步任务入队


当我们对需要异步执行的任务执行`Worker.perform_async`的方法时, `Sidekiq`其实并不会真正取创建一个`HardWroker`等具体`Worker`对象, 它实际上会调用`Worker.client_push`方法将当前的`class`和`args`参数传进去, 也就是我们需要异步执行的类和`perform`方法所需要的参数, 以及`Sidekiq`添加的额外参数:

~~~json
{
  "class": "Platform::ActiveUserWorker",
  "args": ["2018-03-09"],
  "retry": true,
  "queue": "default",
  "jid": "f2c20ffd382925563ffbc6b0",
  "created_at": 1520524801.3932867,
  "enqueued_at": 1520524801.3934016
}
~~~



使用`pry`工具来查看一下源码:

~~~ruby
[4] pry(main)> $ Sidekiq::Worker::ClassMethods#perform_async

From: /sidekiq-5.0.5/lib/sidekiq/worker.rb @ line 86:
Owner: Sidekiq::Worker::ClassMethods
Visibility: public
Number of lines: 3

def perform_async(*args)
  client_push('class'.freeze => self, 'args'.freeze => args)
end

~~~

除了`perform_async`之外, `Worker`还提供了两种用于在一段时间之后或者未来的某个时刻执行相应任务的方法 `Worker.perform_at` 和 `Worker.perform_in`:

~~~ruby
From: /sidekiq-5.0.5/lib/sidekiq/worker.rb @ line 92:
Owner: Sidekiq::Worker::ClassMethods
Visibility: public
Number of lines: 12

def perform_in(interval, *args)
  int = interval.to_f
  now = Time.now.to_f
  ts = (int < 1_000_000_000 ? now + int : int)
  # 比普通的 perform_async 多了一个 at 参数
  item = { 'class'.freeze => self, 'args'.freeze => args, 'at'.freeze => ts }
  item.delete('at'.freeze) if ts <= now

  client_push(item)
end

#. 在底层实现中, perform_at 与 perform_in 是同一个方法的两种形式的调用
alias_method :perform_at, :perform_in
~~~



为了使用同一个接口支持两种不同的安排方式(时间点和多久之后), 方法内部对传入的`internal`进行了判定:

* `interval.to_f < 1_000_000_000`: 此时方法就认为传入的参数是一段时间.
  * `Time.at 1_000_000_000` == 2001-09-09 09:46:40 +0800
* interval.to_f >= 1_000_000_000: 此时方法断定传入的参数是未来的某个时间点, eg:  `Time.now + 1.day`
  * 如果传入的时间点是过去的时间点, 那么才 `item`中会删除`at`

虽然`Worker.perform_at`和`Worker.perform_in`是完全相同的方法, 但是我们在使用时还是尽量遵循方法的语义选择两者中更符合使用逻辑的方法.



以上三种创建异步任务的方式, 最终都执行了`Worker.client_push`方法. 该方法接受一个哈希参数, 参数大致形式如下:

~~~ruby
{
  class: "Platform::ActiveUserWorker",
  args: ["2018-03-09"],
  at: '60.0'
 }
~~~

在方法的实现中, 首先获取上下文中的`Redis`线程池, 并将传入的`item`对象压入`Redis`队列中

~~~ruby
[3] pry(main)> $ Sidekiq::Worker::ClassMethods#client_push

From: /sidekiq-5.0.5/lib/sidekiq/worker.rb @ line 136:
Owner: Sidekiq::Worker::ClassMethods
Visibility: public
Number of lines: 9

def client_push(item) # :nodoc:
  # Redis 连接池
  pool = Thread.current[:sidekiq_via_pool] || get_sidekiq_options['pool'.freeze] || Sidekiq.redis_pool
  # stringify
  item.keys.each do |key|
    item[key.to_s] = item.delete(key)
  end

  Sidekiq::Client.new(pool).push(item)
end
~~~



`client_push`方法最后调用了`Sidekiq::Client.new` 实例化一个`Sidekiq::Client`, 并将`item`  压入到`Redis`队列.

~~~ruby
[4] pry(main)> $ Sidekiq::Client#push

From: /sidekiq-5.0.5/lib/sidekiq/client.rb @ line 69:
Owner: Sidekiq::Client
Visibility: public
Number of lines: 9

def push(item)
  normed = normalize_item(item)
  payload = process_single(item['class'.freeze], normed)

  if payload
    # 此时传入的 payload 只有一个
    raw_push([payload])
    payload['jid'.freeze]
  end
end

def normalize_item(item)
  # 省略错误处理
  # 如果传入的 item 没有携带某些参数时, 就采用系统默认的参数
  normalized_hash(item['class'])
    .each{ |key, value| item[key] = value if item[key].nil? }

  item['class'] = item['class'].to_s
  item['queue'] = item['queue'].to_s
  item['jid'] ||= SecureRandom.hex(12)
  item['created_at'] ||= Time.now.to_f
  item
end

# 获取默认参数
def normalized_hash(item_class)
  if item_class.is_a?(Class)
    # 省略错误处理(需要普通的 SomeWorker include Sidekiq::Worker)
    item_class.get_sidekiq_options
  else
    Sidekiq.default_worker_options
  end
end

# Sidekiq 提供了两个默认参数
DEFAULT_WORKER_OPTIONS = {
  'retry' => true,
  'queue' => 'default'
}


# 每个中间件对传入的哈希进行处理之后,返回 item
# 具体实现请见 ·又见中间件·
def process_single(worker_class, item)
  queue = item['queue']

  middleware.invoke(worker_class, item, queue, @redis_pool) do
    item
  end
end
~~~

从代码的注释我们可以知道,  `Sidekiq::Client#push`方法接受的哈希参数包括以下内容:

* queue: 具名队列, 默认为 `default`
* class: 被调用的`worker`
* args: 传给`Worker.perform`的参数, 必须是 `JSON-serializable`, 而且必须是一个数组
* at: 计划执行的时间点, 必须是 `Numeric`
* retry: 如果任务失败是否重试标志, 默认为 `true`



从`Worker.perform_async`到`Client#push`方法, 都对即将加入到`Redis`队列的哈希进行处理, 从添加`at`字段到字符串化、再到`Client#normalize_item`方法中添加默认参数`retry`、`queue`, `jid`、`created_at`. 经过 `process_single`的处理, 传入 `raw_push`的哈希值大致如下:

~~~json
{
 "jobstr":
     {
      "class": "Platform::ActiveUserWorker",
      "args": ["2018-03-09"],
      "retry": true,
      "queue": "default",
      "jid": "f2c20ffd382925563ffbc6b0",
      "created_at": 1520524801.3932867,
      "enqueued_at": 1520524801.3934016
     }
}
~~~



所有添加异步任务的方法最终都调用了私有方法`Client#raw_push` , 此方法继续调用`atomc_push`向`Redis`添加数据.

~~~ruby
def raw_push(payloads)
  # #
  @redis_pool.with do |conn|
    conn.multi do
      atomic_push(conn, payloads)
    end
  end
  true
end
~~~

添加数据时会分两种情况:

* 当异步任务再未来的某一个时间点进行安排时, 此任务就会加入到一个有序集合 `schedule`
  * 有序集合的 `score`自然是异步任务执行的时刻
    ​
* 当任务为立即执行任务时:
  * 设置当前异步任务入队的时间`enqueued_at`
  * Sidekiq将`payload`所属的**队列**加入到一个大队列 `queues`的集合中
  * 将负载 `payload`直接压入 `"#queue:#{q}"`队列中等待消费者的拉取.



~~~ruby
From: sidekiq-5.0.5/lib/sidekiq/client.rb @ line 191:
Owner: Sidekiq::Client
Visibility: private
Number of lines: 17

def atomic_push(conn, payloads)
  # 根据传入的负载是否有 at key
  if payloads.first['at'.freeze]
    conn.zadd('schedule'.freeze, payloads.map do |hash|
      at = hash.delete('at'.freeze).to_s
      # 传入的 payload 需要转成 JSON 格式
      # [score, payload]
      [at, Sidekiq.dump_json(hash)]
    end)
  else
    q = payloads.first['queue'.freeze]
    now = Time.now.to_f
    to_push = payloads.map do |entry|
      entry['enqueued_at'.freeze] = now
      Sidekiq.dump_json(entry)
    end
    conn.sadd('queues'.freeze, q)
    conn.lpush("queue:#{q}", to_push)
  end
end
~~~



### Redis的存储

无论是立即执行还是未来计划的异步任务都会进入`Redis`的队列中, 但是它们之间的存储还是有所区别.

* `Worker.perform_at/in`会将任务以`[at, payload]`的形式加入到`schedules`有序集合中
* `Worker.perform_async`将负载直接加入到指定的队列 `"queue:#{q}"`中, 并向整个`Sidekiq`的队伍集合`queues`中添加该队列

所有的`payload`都包含一个异步任务需要执行的全部信息:

* 执行的队列: queue

* 异步队列的类 `class`

* 参数 `args`: 将传入 `Worker.perform`方法
  * `sidekiq_options`中的默认参数: `retry` 、 `queue`

* `jid`: 任务唯一标识符, 通过`SecureRandom.hex(12)`生成

* enqueued_at: 入队时间

* `created_at`: 创建时间


  ​

  ![payload]()

  ​

接下来我们就从`Sidekiq`启动画面着手, 还是我们的`Sidekiq`源码解读之旅吧!


## 启动

每当我们启动一个`Sidekiq`服务时, 令人印象深刻地就是在命令行中出现了一个功夫小子:

~~~

         m,
         `$b
    .ss,  $$:         .,d$
    `$$P,d$P'    .,md$P"'
     ,$$$$$bmmd$$$P^'
   .d$$$$$$$$$$P'
   $$^' `"^$$$'       ____  _     _      _    _
   $:     ,$$:       / ___|(_) __| | ___| | _(_) __ _
   `b     :$$        \___ \| |/ _` |/ _ \ |/ / |/ _` |
          $$:         ___) | | (_| |  __/   <| | (_| |
          $$         |____/|_|\__,_|\___|_|\_\_|\__, |
        .d$$                                       |_|


~~~



我们可以通过如下指令找到运行`sidekiq`的bin文件:

~~~ruby
$ where sidekiq
/Users/bobo/.rvm/gems/ruby-2.4.2/bin/sidekiq
/usr/local/bin/sidekiq
~~~

我们就从 `bin/sidekiq.rb` 文件开始我们的源码之旅:

~~~ruby
require_relative '../lib/sidekiq/cli'

begin
  cli = Sidekiq::CLI.instance # <==== just skip
  cli.parse
  cli.run # <======== here we go
rescue => e
  raise e if $DEBUG
  STDERR.puts e.message
  STDERR.puts e.backtrace.join("\n")
  exit 1
end
~~~

启动文件首先是创建一个`CLI`对象, 执行`CLI#parse`方法对参数进行解析, 其中包括队列的配置, worker数量的配置, 在此不展开. 紧接着调用`CLI#run`方法. 让我们继续往下分析, 打开一个`CLI#run`方法:

~~~ruby
def run
  # 打印控制台 banner 信息, 打印日志及运行环境
  # 信号处理

  self_read, self_write = IO.pipe
  require 'sidekiq/launcher'
  @launcher = Sidekiq::Launcher.new(options)
  begin
    launcher.run # <======= here we go
    while readable_io = IO.select([self_read])
      signal = readable_io.first[0].gets.strip
      handle_single(signal)
    end
  rescue Interrupt
    # 进程接收到的信号处理以及退出逻辑
    launcher.stop
   exit(0)
  end
end
~~~



### 从 Launcher 到 Manager

`CLI#run`方法首先是实例化一个`Sidekiq::Launcher`对象, 紧随其后调用了`Launcher#run`方法, `Launcher#run`方法又做了哪些事情呢?

~~~ruby
# lib/launcher.rb
def run
  @thread = safe_thread("heartbeat", &method(:start_heartbeat))
  @poller.start
  @manager.start
end
~~~

`Launcher#run`方法首先通过`safe_thread`创建了一个新线程, 线程主要负责执行`start_heartbeat`方法, 其实就是心跳代码, 负责定时检查`sidekiq`的健康状态, 暂且不表.



~~~ruby
# lib/launcher.rb
def safe_thread(name, &block)
  Thread.new do
    Thread.current['sidekiq_label'] = name
    watchdog(name, &block)
  end
end

def watchdog(last_words)
  yield
rescue Exception => ex
  handle_exception(ex, { context: last_words })
  raise ex
end
~~~



`Launcher#run`第二行和第三行代码分别启动了`@poller`以及`@manager`. 这两个实例是从创建的?

让我们回顾一下前面的`lib/cli.rb`中的`CLI#run`方法, 它会负责创建`Sidekiq::Launcher`的实例, 让我们来看一下`Sidekiq::Launcher#initialize`定义:

~~~ruby
# lib/launcher.rb
def initialize(options)
  @manager = Sidekiq::Manager.new(options)
  @poller = Sidekiq::Scheduled::Poller.new
  @done = false
  @options = options
end
~~~

我们可以看到, `@manager`是在创建`Sidekiq::Launcher`实例的过程中同步创建的`Sidekiq::Manager`实例.

同理, `@poller`是同步创建的`Sidekiq::Scheduled::Poller`实例.



我们首先来看一下`@poller.start`的逻辑:

~~~ruby
# lib/scheduled.rb
def start
  @thread ||= safe_thread("scheduler") do
    initial_wait

    while !@done
      enqueue
      wait
    end
    Sidekiq.logger.info("Scheduler exiting...")
  end
end
~~~

我们可以看到 `Sidekiq::Scheduled::Poller#start`方法创建了一个新线程, 在线程中执行了两部分代码:

* 初始化等待值
* 在一个循环中不断的`enqueue`以及`wait`

PS: `Sidekiq::Scheduled::Poller#start`方法在线程创建完毕之后就会立刻返回, 至于新启动的新线程中的逻辑, 请前往下面的章节`Sidekiq::Scheduled::Poller`作更深一步分析.

我们继续查看一下`@manager`的启动到底做了什么:

~~~ruby
# lib/manager.rb
def start
  @workers.each do |x|
    x.start
  end
end
~~~

这里的 `@workers`是什么? 我们来看一下`Sidekiq::Manager#initialize`方法:

~~~ruby
# lib/manager.rb
def initialize(options={})
   @options = options
   @count = options[:concurrency] || 25

   @done = false
   @workers = Set.new
   @count.times do
     # 创建 Processor 实例时传入的参数就是 Manager 实例
     @workers << Processor.new(self)
   end
   # Mutex
   @plock = Mutex.new
 end
~~~

原来如此, 在创建了`Sidekiq::Manager`实例之后, 又同步创建了多个`Sidekiq::Processor`的实例, 实例的个数取决于`options[:concurrency] || 25`, 也就是配置的`concurrency`的值, 缺省值为`25`. 至此, 我们知晓 sidekiq中的`worker`数量就在此设置, `Sidekiq::Manager`按照配置的数量创建指定数量的 `worker`.

继续来看我们的`Sidekiq::Manager#start`方法. 简而言之, `Sidekiq::Manager`在 `start`的时候就只做了一件事: 调用其管理的所有的`worker`的`start`方法, 就是`Sidekiq::Processor#start`.



~~~ruby
# lib/processor.rb
def start
  @thread ||= safe_thread("processor", &method(:run))
end
~~~

又是熟悉的味道, 在这里又调用了`safe_thread`来创建一个新线程, 这就意味着每个`worker`都是基于自己的一个新线程的, 在这个新线程中执行的是私有方法 `Sidekiq::Processor#run`:

~~~ruby
# lib/processor.rb
def run
  begin
    while !@done
      process_one
    end
    @mgr.processor_stopped(self)
  rescue Sidekiq::Shutdown
    @mgr.processor_stopped(self)
  rescue Exception => ex
    @mgr.processor_died(self, ex)
  end
end
~~~



在一个`while`循环中, 只调用了一个`Sidekiq::Processor#process_one`实例方法. 顾名思义, 这里是说每个`worker`(Processor 实例)在没被结束之前, 都重复处理一个新的任务.

`Sidekiq::Processor#process_one`又做了什么工作? 怎么决定应该先处理那个任务? 这就会在后面章节`Sidekiq::Processor才是做工的!`深入挖掘.





###  流程时序

我们来总结一下`Sidekiq`启动之后的处理流程



![Sidekiq start]()



1. 首先创建`Sidekiq::CLI`实例, 并执行其`run`方法
2. `Sidekiq::CLI`的实例在执行`#run`过程中, 创建了`Sidekiq::Launcher`实例, 并调用其`#run`方法
3. `Sidekiq::Launcher`的实例在创建后, 同步创建了`Sidekiq::Scheduled::Poller`的实例以及`Sidekiq::Manager`的实例. 在其执行`Sidekiq::Launcher::start`过程中, 分别调用了这两个实例的`start`方法
4. `Sidekiq::Scheduled::Poller`的实例在执行`start`过程中, 创建了一个内部循环执行的线程, 不断执行`enqueue` -> `wait`
5. `Sidekiq::Manager`的实例在创建后, 同步创建若干个指定的`worker`, 也就是`Sidekiq::Processor`的实例, 并在执行`start`方法的过程中对每个`worker`执行`start`
6. `Sidekiq::Processor`实例`worker`在执行`start`方法的过程中创建了一个新的线程, 在其中循环执行`process_one`

以上就是`Sidekiq`的主要启动过程, 后续分别针对:

* Sidekiq::Scheduled::Poller
* Sidekiq::Manager

深入研究.







## 定时任务拉取器

我们从`Sidekiq::Scheduled::Poller#start`方法继续我们的源码之旅:

~~~ruby
# lib/scheduled.rb
def start
  @thread ||= safe_thread("scheduler") do
    initial_wait

    while !@done
      enqueue
      wait
    end
    Sidekiq.logger.info("Scheduler exiting...")
  end
end
~~~

我们可以看到, `start`方法的核心就在`while`循环中, 在循环之前调用了`initial_wait`方法:

~~~ruby
INITIAL_WAIT = 10

def initial_wait
  # Have all processes sleep between 5-15 seconds.  
  # 10 seconds to give time for the heartbeat to register
  # (if the poll interval is going to be calculated by the number of workers)
  # 5 random seconds to ensure they don't all hit Redis at the same time.
  total = 0
  total += INITIAL_WAIT unless Sidekiq.options[:poll_interval_average]
  total += (5 * rand)

  @sleeper.pop(total)
  rescue Timeout::Error
end
~~~

结合注释我们可以看出, `initial_wait`为了避免所有进程在后续逻辑中同时触发`Redis IO`而做的设计.

这里是为了防止类似雪崩之类的系统故障出现. 让当前进程随机等待一定范围的时间, 从而就可以跟其他进程错开了.

即随其后, 我们来研究一下`while`循环体中的方法:

~~~ruby
while !@done
  enqueue
  wait
end
~~~

继续查看`enqueue`的实现:

~~~ruby
def enqueue
  begin
    @enq.enqueue_jobs
  rescue => ex
    # Most likely a problem with redis networking.
    # Punt and try again at the next interval
    logger.error ex.message
    handle_exception(ex)
  end
end

~~~

`enqueue`只是调用了实例变量`@enq`的`enqueue_jobs`方法而已. `@enq`是在初始化`Sidekiq::Scheduled::Poller`实例对象中创建的:

~~~ruby
def initialize
  @enq = (Sidekiq.options[:scheduled_enq] || Sidekiq::Scheduled::Enq).new
  @sleeper = ConnectionPool::TimedStack.new
  @done = false
  @thread = nil
end
~~~

缺省的情况下, `@enq`就是`Sidekiq::Scheduled::Enq`的实例, 让我们来看一下`@enq`的实例方法`enqueue_jobs`:

~~~ruby
# lib/scheduled.rb
SETS = %w(retry schedule)

def enqueue_jobs(now=Time.now.to_f.to_s, sorted_sets=SETS)
  Sidekiq.redis do |conn|
    sorted_sets.each do |sorted_set|
      while job = conn.zrangebyscore(sorted_set, '-inf', now, :limit => [0, 1]).first do
        if conn.zrem(sorted_set, job)
          Sidekiq::Client.push(Sidekiq.load_json(job))
          Sidekiq::Logging.logger.debug { "enqueued #{sorted_set}: #{job}" }
        end
      end
    end
  end
end
~~~

我把原代码中的注释移除, 让我们来一步步研究`enqueue_jobs`是如何将定时任务和重试任务推入指定的队列中去的.

首先传入`enqueue_jobs`的`now`默认为当前时间,`sorted_sets`默认为`["retry", "schedule"]`.

* retry: 重试任务队列

* schedule: 定时任务队列


  在`Sidekiq`中, 重试任务和定时任务实质上都是`scheduled jobs`. 这两个队列使用了`Redis`中有序集合类型, 进入队列的任务以其执行时间作为数据的`score`, 写入`Redis`之后按照其`score`排序, 也就是按照任务的计划执行时间排序.


`Sidekiq`分别针对`retry`队列和`schedule`队列做了一个循环, 循环体内每次通过`Redis`的`ZRANGEBYSCORE`命令取出一个计划时间小于等于当前时间的任务:
~~~ruby
job = conn.zrangebyscore(sorted_set, '-inf'.freeze, now, :limit => [0, 1]).first
~~~

拿到一个`job`之后, 将其从原队列中移除, 并调用`Sidekiq::Client.push`  方法将此任务加到指定队列中.

此时`job`可以看作是马上执行的任务, 可以直接被推入指定的队列

 `job`中的内容就是我们之前分析过的哈希 `payload`:

~~~json
{
  "class": "Platform::ActiveUserWorker",
  "args": ["2018-03-09"],
  "retry": true,
  "queue": "default",
  "jid": "f2c20ffd382925563ffbc6b0",
  "created_at": 1520524801.3932867,
  "enqueued_at": 1520524801.3934016
}
~~~

至此, 我们就知晓了`enqueue_jobs`就是分别从`retry有序集合`和`schedule`有序集合中取出已经到达计划时间的任务, 并将其一一加入到原来的队列.

PS: **定时任务以及重试任务的计划时间只是计划加进执行中队列的时间, 并非执行时间, 执行的时间取决于队列的长度以及队列的执行速度了**.



接着我们的`enqueue_jobs`, 后面调用`wait`方法:

~~~ruby
# lib/scheduled.rb
def wait
  @sleeper.pop(random_poll_interval)
rescue Timeout::Error
  # expected
rescue => ex
  # if poll_interval_average hasn't been calculated yet, we can
  # raise an error trying to reach Redis.
  logger.error ex.message
  handle_exception(ex)
  sleep 5
end
~~~

`wait`方法只是做了一个休眠, 休眠的实现依赖`@sleeper`的`pop`方法的实现.

`@sleeper`是在`Sidekiq::Scheduled::Poller#initialize`的实现的, 它是`ConnectionPool::TimeStack`的实例, 其`pop`方法会阻塞当前代码的执行, 直到有值返回或者到达指定的超时时间, 这里`Sidekiq`就利用了其阻塞的特性, 作为`wait`方法休眠器的实现.

休眠时间`random_poll_interval`不固定. 一般来说, 如果没有自行配置, 每次拉取的时间间隔大约在7.5秒--22.5秒



### 小结

从本小节的源码分析来看, 我们可以知晓`Sidekiq`对定时任务和重试任务都一视同仁,处理流程如下:

1. 所有定时任务(包括重试任务)以其计划时间为`score`,加入到`retry`和`schedule`有序集合中
2. sidekiq的定时任务拉取器从`retry`以及`schedule`有序集合中取出已到达计划时间的任务, 并将其加入该任务计划的队列中, 后续的执行则和普通队列中的任务一致.
3. 拉取器会每隔随机事件进行休眠, 然后继续从步骤2开始, 周而复始



=> 定时任务`perform_in`以及`perform_at`计划时间都不是确切的时间!只是允许计划任务加入到普通队列的时间, 具体执行时间还得由队列的长度以及队列的处理速度决定.





## Sidekiq::Processor 才是做工的!

本小节我们来深入研究一下`Sidekiq`中做苦力的那个`worker`.

`worker`核心实现在于`process_one`

~~~ruby
# lib/processor.rb
def process_one
  @job = fetch  #<===== here we go
  process(@job) if @job # <=== next step
  @job = nil
end
~~~



通过调用`fetch`方法抓取一个任务, 当任务成功获取后, 就将其最为参数传入`process`方法中去, 由`process`实际执行任务; 如果没有获取到任务, 则直接重新尝试获取新的任务

~~~ruby
# lib/processor.rb
def fetch
  j = get_one
  if j && @done
    j.requeue
    nil
  else
    j
  end
end
~~~

`fetch`方法中的`j`仿佛又回到了大学期间写`C`语言的那段时光.  

`fetch`方法通过`get_one`方法从队列中获取任务.

当获取任务之后, 判断当前`worker`是否已经停止(@done == true), 如果是就将任务重新压入队列中;否则就返回抓取到的一个任务.



~~~ruby
# lib/processor.rb
def get_one
  begin
    work = @strategy.retrieve_work
    # 省略 logger
    work
  rescue Sidekiq::Shutdown
  rescue => ex
    handle_fetch_exception(ex)
  end
end
~~~

核心代码就是`work = @strategy.retrive_work`.

`@strategy`必然来自`Sidekiq::Processor#initialize` 方法:

~~~ruby
# lib/processor.rb
def initialize(mgr)
  # ...
  @strategy = (mgr.options[:fetch] || Sidekiq::BasicFetch).new(mgr.options)
end
~~~

默认情况下使用`Sidekiq::BasicFetch`类生成一个`@strategy`实例.

让我们查看一下这个策略类的`retrive_work`方法:

~~~ruby
# lib/fetch.rb
def retrieve_work
  # 返回值有两个(key, value) queue_name, job => work
  work = Sidekiq.redis { |conn| conn.brpop(*queues_cmd) } # <===== here we go
  UnitOfWork.new(*work) if work
end
~~~

`Sidekiq::BasicFetch`抓取任务的逻辑是直接通过 `Redis BRPOP` 命令从所有队列中阻塞地取出第一个任务:

> BRPOP is a blocking list pop primitive. It is the blocking version of RPOP because it blocks the connection when there are no elements to pop from any of the given lists. An element is popped from the tail of the first list that is non-empty, with the given keys being checked in the order that they are given.
>
> `BRPOP key1 [key2 key3 ....] timeout`

我们来查看一下`queues_cmd`此方法究竟做了什么?

~~~ruby
# Creating the Redis#brpop command takes into account any
# configured queue weights. By default Redis#brpop returns
# data from the first queue that has pending elements. We
# recreate the queue command each time we invoke Redis#brpop
# to honor weights and avoid queue starvation.
def queues_cmd
  if @strictly_ordered_queues
    @queues
  else
    queues = @queues.shuffle.uniq # here we go
    queues << TIMEOUT
    queues
  end
end
~~~

上述代码中的两个实例变量设置于`Sidekiq::BasicFetch#initialize`:

~~~ruby
def initialize(options)
  @strictly_ordered_queues = !!options[:strict]
  # 读取 `sidekiq` 配置文件中的 `:queues`选项
  @queues = options[:queues].map { |q| "queue:#{q}" }
  if @strictly_ordered_queues
    @queues = @queues.uniq
    @queues << TIMEOUT
  end
end
~~~

默认情况下我们没有设置`options[:strict]`, 因此 `queue_cmd`进入`else`分支.

~~~ruby
queues = @queues.shuffle.uniq
~~~

这里的`@queues`来自于`options[:queues]`中的配置.

让我们来分析一下这个配置到底来自哪里:



![options]()

最终我们在`Sidekiq::CLI`中调用`parse`设置`options`参数的.

~~~ruby
def parse_queue(opts, q, weight=nil)
  [weight.to_i, 1].max.times do
   (opts[:queues] ||= []) << q
  end
  opts[:strict] = false if weight.to_i > 0
end
~~~

`Sidekiq`在解析`:queues`的相关配置时, 会按照每个队列及其权重, 生成了一个重复次数等于队列权重的队列的新数组. 看一下我们项目的配置文件`sidekiq.yml`:

~~~yaml
:queues:
  - [default, 2]
  - [review, 5]
  - [finance, 3]

~~~

根据队列的权重, 生成的数组中就会有同等数量的队列:

~~~ruby
%w(default default review review review review review finance finance finance)
~~~

这里的权重主要用于后面确定每个不同队列被处理到的优先权的比重.

让我们继续讨论:

~~~ruby
queues = @queues.shuffle.uniq
queues << TIMEOUT
~~~

每次`worker`在请求信的任务时, `Sidekiq`都会按照原来的`@queues`执行`shuffle`方法. `shuffle`方法将数组元素随机排序, 亦即“洗牌”. 结合前面的权重, 每个队列洗牌后排在第一位的概率与其权重挂钩.

最后的`uniq`方法确保队列名称没有重复,避免`Redis`在执行`BRPOP`命令时重复检查同一队列.

这里使用`BRPOP`命令还有一个好处,就是当前面优先级的队列里面没有任务时, 可以依次将机会给后面的队列.

第二行`queues << TIMEOUT`则是在`BRPOP`命令末尾追加超时设置, 也就是`Redis`命令最多阻塞2秒, 超时则直接放弃.



了解了如何获取任务之后, 任务通过`Sidekiq::BasicFetch::UnitOfwork`结构化实例后返回给调用方:

~~~ruby
UnitOfWork = Struct.new(:queue, :job) do
  def acknowledge
    # nothing to do
  end

  def queue_name
    queue.sub(/.*queue:/, '')
  end

  def requeue
    Sidekiq.redis do |conn|
      conn.rpush("queue:#{queue_name}", job)
    end
  end
end
~~~

让我们重新回到`Sidekiq::Processor#process_one`

~~~ruby
# lib/processor.rb
def process_one
  @job = fetch
  process(@job) if @job  # here we go
  @job = nil
end
~~~

`fetch`方法返回一个结构体化的实例对象, 然后交给`process`全权处理:

~~~ruby
# lib/processor.rb
# 移除了一些异常处理代码
def process(work)
  jobstr = work.job
  queue = work.queue_name

  ack = false
  begin
    job_hash = Sidekiq.load_json(jobstr)
    ack = true
    # dispatch 返回经过中间件处理过的一个 SomeWorker实例
    dispatch(job_hash, queue) do |worker|
      # 此处的解释见 `又见中间件`
      Sidekiq.server_middleware.invoke(worker, job_hash, queue) do
        execute_job(worker, cloned(job_hash['args']))
      end
    end
  ensure
    work.acknowledge if ack
  end
end


~~~



我们传入的参数`work`中就包含之前被压入队列的任务信息,包括队列名称, 任务对应的类, 任务调用所需要的参数,等等.

~~~json
{
  "class": "Platform::ActiveUserWorker",
  "args": ["2018-03-09"],
  "retry": true,
  "queue": "default",
  "jid": "f2c20ffd382925563ffbc6b0",
  "created_at": 1520524801.3932867,
  "enqueued_at": 1520524801.3934016
}
~~~
根据这些信息我们重新实例化任务对象, 并且将实例化的任务对象`worker`以及任务参数都传递给`execute_job`调用.

让我们一睹`execute_job`的实现:

~~~ruby
def execute_job(worker, cloned_args)
  worker.perform(*cloned_args)
end
~~~

原来如此嘛, 我们使用`Sidekiq`创建的某个`Worker`, 最终在此处调用.

至此, 任务的调度过程就到此为止, 剩下的就是周而复始的重复了.



### 小结

经过上面的分析, 我们可以明白`Sidekiq`中`worker`的工作原理:

1. 按照配置文件中设置的队列名称及其权重, 每次重新排列等待处理队列顺序, 高权重的队列有更高的优先级
2. 将重新排列的队列按顺序传递给`Redis BRPOP`命令, 同时设置2秒超时
3. `Sidekiq`将从队列中获取到实例化的任务, 并且根据携带的参数调用了具体任务的`perform`方法








## 又遇中间件



我们前面在探究`Sidekiq::Processor#process`方法时有个关键的`中间件`代码片段:

~~~ruby
Sidekiq.server_middleware.invoke(worker, job_hash, queue) do
  execute_job(worker, cloned(job_hash['args']))
end
~~~

让我们来看一下`server_middleware`方法:

~~~ruby
def self.server_middleware
  @server_chain ||= default_server_middleware
  yield @server_chain if block_given?
  @server_chain
end
~~~



默认情况下 `@server_chain`为`default_server_middleware`:

~~~ruby
def self.default_server_middleware
  Middleware::Chain.new
end
~~~



这里并没有发现内置的中间件, 这是因为`sidekiq 5.0.0`版本以上的移除了原来存在的`RetryJobs`以及`Logging`:

> - **BREAKING CHANGE** Job dispatch was refactored for safer integration with
>   Rails 5.  The **Logging** and **RetryJobs** server middleware were removed and
>   functionality integrated directly into Sidekiq::Processor.  These aren't
>   commonly used public APIs so this shouldn't impact most users.
> ```
> Sidekiq::Middleware::Server::RetryJobs -> Sidekiq::JobRetry
> Sidekiq::Middleware::Server::Logging -> Sidekiq::JobLogger
> ```

从`Sidekiq`更新日志可以看出, 原来的两个内置中间件现在已经直接移到了`Sidekiq::Processor类中`.

让我们来看一下`Sidekiq::Processor#dispatch`方法的实现:

~~~ruby
def dispatch(job_hash, queue)
  # since middleware can mutate the job hash
  # we clone here so we report the original
  # job structure to the Web UI
  pristine = cloned(job_hash)

  Sidekiq::Logging.with_job_hash_context(job_hash) do
    @retrier.global(pristine, queue) do
      @logging.call(job_hash, queue) do
        stats(pristine, queue) do
          # Rails 5 requires a Reloader to wrap code execution.  In order to
          # constantize the worker and instantiate an instance, we have to call
          # the Reloader.  It handles code loading, db connection management, etc.
          # Effectively this block denotes a "unit of work" to Rails.
          @reloader.call do
            klass  = constantize(job_hash['class'])
            worker = klass.new
            worker.jid = job_hash['jid']
            @retrier.local(worker, pristine, queue) do
              yield worker
            end
          end
        end
      end
    end
  end
end
~~~

原来的Sidekiq::Processor::`Logger`中间件以及`Sidekiq::Processor::Retry`放在了这里处理, 我们直接看一下`local`方法:

~~~ruby
def local(worker, msg, queue)
  yield
rescue Skip => ex
  raise ex
rescue Sidekiq::Shutdown => ey
  # ignore, will be pushed back onto queue during hard_shutdown
  raise ey
rescue Exception => e
  # ignore, will be pushed back onto queue during hard_shutdown
  raise Sidekiq::Shutdown if exception_caused_by_shutdown?(e)

  if msg['retry'] == nil
    msg['retry'] = worker.class.get_sidekiq_options['retry']
  end

  raise e unless msg['retry']
  attempt_retry(worker, msg, queue, e)
  # We've handled this error associated with this job, don't
  # need to handle it at the global level
  raise Skip
end
~~~

关注点还是在代码的最后`attempt_retry`. 此处表示当执行中的任务出现异常时, 除去停机的因素以及禁用了重试机制后, 尝试进行下次重试运行.

~~~ruby
# lib/processor.rb
# 移除一些无关紧要的配置
def attempt_retry(worker, msg, queue, exception)
  max_retry_attempts = retry_attempts_from(msg['retry'], @max_retries)

  count = if msg['retry_count']
    msg['retried_at'] = Time.now.to_f
    msg['retry_count'] += 1
  else
    msg['failed_at'] = Time.now.to_f
    msg['retry_count'] = 0
  end

  if count < max_retry_attempts
    delay = delay_for(worker, count, exception)
    logger.debug { "Failure! Retry #{count} in #{delay} seconds" }
    retry_at = Time.now.to_f + delay
    payload = Sidekiq.dump_json(msg)
    Sidekiq.redis do |conn|
      conn.zadd('retry', retry_at.to_s, payload)
    end
  else
    # Goodbye dear message, you (re)tried your best I'm sure.
    retries_exhausted(worker, msg, exception)
  end
end
~~~

`Sidekiq`在捕获异常之后, 首先检查此任务是否已经重试过. 如果之前已经重试, 就在原来计数的基础上`+1`, 同时更新重试时间; 如果之前没有重试过, 就初始化重试次数为0, 设定初次失败的时间.

 随后`Sidekiq`检查重试的累积次数是否已经超过了最大限制次数, 如果已经超过, 则放弃重试, 毕竟努力了这么多次还失败, 还是`go to dead`吧; 如果没有超过最大限制次数, 说明还有机会成功, 此任务就会被压入`retry`队列中.

关于下次重试的时间`delay_for`本篇文章就不再涉及, 有兴趣的同学可以深入研究一下.



### 小结

* `Sidekiq`在执行任务时, 通过与`Rack`类似的中间件机制即使捕获失败的任务, 针对允许再次重试的任务, 按照一定的策略计算重试时间



## 总结

关于`Sidekiq`源码的解读暂时告一段落. 整个源码很少有弄不懂的地方, 代码的风格也很`Ruby`, 没有过多的奇异技巧.

`Sidekiq`与`Redis`的队列和有序集合等数据结构的结合恰到好处, 我们可以通过`Sidekiq`来加深对`Redis`的认识, 还可以从中学习如何高效地结合`Redis`实现业务逻辑.

解读的过程中有一些和我们架构不甚相关的逻辑处理和异常处理都被忽略, 这也是阅读一份源码需要注意的地方,.我们要从大局出发, 将整个框架的组织结构和大的模块理清楚, 然后针对关键的方法深入挖掘.  



## 再会

本篇文章主要从`架构`入手, 着重分析了`Sidekiq`异步任务的调度和实现, 关于多线程以及`Unix`信号等相关的知识我打算再下一篇文章中详细解读, 敬请期待~
